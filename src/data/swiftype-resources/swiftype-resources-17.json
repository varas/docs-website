{
  "/docs/style-guide/processes-procedures/embed-videos": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-25T17:04:43Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.0595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-25T18:17:02Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.93454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.71408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/include-a-doc-in-multiple-menus": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.79505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A <em>multiple</em>-step procedure may be an ordered list. And for something buried"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-06-25T18:15:27Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.98812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshooting <em>docs</em> guide",
        "sections": "Troubleshooting <em>docs</em> guide",
        "tags": "<em>Article</em> templates",
        "body": " the user is trying to solve. <em>Include</em> steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this <em>doc</em> via Google. If the problem text is very short, you can <em>include</em> the cause text here. Solution Generally"
      },
      "id": "6043f591196a675446960f74"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/five-questions-help-write-docs/",
      "sections": [
        "Five questions to help write docs",
        "There's really only 1Q",
        "5Qs and sub-questions",
        "1. Did you use or observe the thing you are writing about?",
        "2. Is this the best place to put this information?",
        "3. Can readers tell in ten seconds if they are in the right place?",
        "4. Is the information in the best possible format?",
        "5. Is the language approachable, expert, and visionary?"
      ],
      "published_at": "2021-06-26T04:08:04Z",
      "title": "Five questions to help write docs",
      "updated_at": "2021-06-14T18:19:44Z",
      "type": "docs",
      "external_id": "14fd5c4efd0e8aa26e04d97ae61da33eef9489ee",
      "document_type": "page",
      "popularity": 1,
      "body": "Our five questions form the core of how our Tech Docs team thinks about writing excellent technical documentation. Informally, we call these our 5Qs. Anyone can contribute to our Docs site. We want you to feel confident and proud that your contributions provide valuable content and quality. We also want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this doc. There's really only 1Q The 5Qs exist to help answer one question. Whenever you write a doc, ask yourself: What problem are we trying to solve? It's critical you know what you're trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you're building the right thing. 5Qs and sub-questions Each of the five questions includes sub-questions to help guide your thinking. 1. Did you use or observe the thing you are writing about? Think about who your audience is and the level of complexity they need. End users' point of view Ask yourself: Audience Do you know who is reading your document (dev/ops teams, support personnel, non-technical staff, etc.)? Can you articulate what this thing is (feature, procedure) and why it matters to our customers? For conceptual info, did you interview multiple stakeholders? Testing Put yourself in the user's shoes. For example: Did you use the thing on your own? Did you watch a subject matter expert use the thing? If you can't do it on your own or observe, did you send the draft to at least three SMEs? Before publishing Did you compare the final version of your text against the thing you're writing about? 2. Is this the best place to put this information? Think about where this information belongs. Where does this information belong? Ask yourself: What problem are you trying to solve? Is text always the best answer? Does this doc need to exist at all? For example: Are we duplicating content from somewhere else in the Docs site? Are we duplicating content already in the UI? Could customers have a better experience if we modified the UI design or copy instead of creating a doc? Would another web property be a better home for this information? For example: The Explorers Hub? NRU course? NRU video embedded into the doc? The public New Relic blog? The public New Relic website? 3. Can readers tell in ten seconds if they are in the right place? Think about what the content is and what you can do to make the information easy to skim to find information. Can users skim to find information? Ask yourself: Title and headings Does the title accurately represent what's in the doc? Do the headings accurately represent what's in the doc? Do the title and headings use words the way your readers do? Do the title and headings avoid New Relic jargon? Structure Does the overall structure of the doc help readers find what they're looking for? Is the doc trying to address too many topics? When you glance at the doc, do you see short paragraphs, short sentences, and other visual aids? Or do you see a dense wall of text? Introduction Does the intro give a concise synopsis of what's in the doc? Does the intro give readers an alternate path if they're in the wrong place? 4. Is the information in the best possible format? Think about how to present the information visually. Presentation of information Ask yourself: Visual formats Did you use visual formats appropriately? Would a screenshot make any of the information easier to understand? Does your image caption clearly explain what matters so that the user does not necessarily even need to read the surrounding text? Would a diagram make any of the information easier to understand? Is there a video we could embed to make things clearer? Can step-by-step UI procedures be replaced with a \"show me\" video? Procedures Are your procedures well-structured? Do step-by-step UI procedures even need to be documented? Did you limit the procedural text to action steps and omit detailed explanatory text or edge cases? If detailed explanations need to enhance a procedure, have you organized the info in a way that expert users can skip the details? Text flow Read your draft more than once. Is the documentation direct and to the point? Did you use bullets, tables, or clamshells to improve flow? 5. Is the language approachable, expert, and visionary? Think about why the information matters and why readers will trust and use it. For tips to make it easier for users to read, understand, and use documentation, go to plainlanguage.gov. Also, if you are a New Relic employee, we encourage you to review the corporate brand guidelines. For more information, contact Marketing. Effective language Ask yourself: Readers' point of view Did you tell users why as well as how? Can you articulate not only what this thing is (feature, procedure) and also why it matters to our customers? Did you include useful examples or use cases? Did you include information about relationships this feature has to other New Relic platform tools? Style guide resources Did you follow our style guide? Did you use our edit checklist? Did you use pronouns, contractions, and a conversational tone throughout? Did you review the usage dictionary and other resources in the style guide to make sure that terms are used correctly? Readability Is the text easy to read? Is the language clear? Do you have to reread any sentences or paragraphs to understand them? If so, can you simplify the wording and sentence structure? Does the doc score 40 or better on the Flesch-Kinkaid reading ease scale? If not, try taking another pass at the prose. But don't chase the Flesch-Kincaid score in itself: we're not out to frustrate ourselves, but to write docs that are a pleasure to read. Where to go from here Did you offer readers a clear \"next step\" in each section? If it is necessary to tell a user not to do something, did you also tell them what to do instead? Is the topic complete? Is the doc actionable?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.385345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Five questions to help write <em>docs</em>",
        "sections": "3. Can readers tell <em>in</em> ten seconds if they <em>are</em> <em>in</em> the right place?",
        "body": " want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this <em>doc</em>. There&#x27;s really only 1Q The 5Qs exist to help answer one question. Whenever you write a <em>doc</em>, ask yourself: What problem are we trying"
      },
      "id": "60421ef3196a676926a83d81"
    }
  ],
  "/docs/style-guide/processes-procedures/rename-or-redirect-document": [
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-25T17:04:43Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.0595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use content types <em>and</em> text formats",
        "sections": "Use content types <em>and</em> text formats",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and <em>style</em> of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-25T18:17:02Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.93452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.71408,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/processes-procedures/update-left-navigation-pane": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/layout-item/",
      "sections": [
        "LayoutItem",
        "Usage",
        "Props"
      ],
      "published_at": "2021-06-25T14:02:17Z",
      "title": "LayoutItem",
      "updated_at": "2021-06-25T02:04:24Z",
      "type": "developer",
      "external_id": "c9659b5b5157ef8b10e5a5a29b0d1d80bac09810",
      "document_type": "page",
      "popularity": 1,
      "body": "Child element of the <Layout> component. By default uses the main type, to span the full width of the Layout area. Split left and split right provide a fixed left/right area. Layout only supports one type of each. Usage import { LayoutItem } from 'nr1' Copy Props childrenrequirednode Content to display inside the child item. classNamestring Appends class names to the component. sizeTypeenum DEFAULT LayoutItem . SIZE_TYPE . MEDIUM Determines the width of the layout item. We recommend you use the small size for navigation purposes (ex. sidebars) and the medium size for showing contextualized information (ex. activity stream). Size type only works on SPLIT_LEFT and SPLIT_RIGHT items. <One of LayoutItem.SIZE_TYPE.MEDIUM , LayoutItem.SIZE_TYPE.SMALL , > styleobject Inline style for custom styling. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests. typeenum DEFAULT LayoutItem . TYPE . MAIN Type can be: Main — Used to place the main content on each view. It spans the full width of the layout area. Split left — Render as a fixed area on the left of the layout. Split right — Render as a fixed area on the right of the layout. <One of LayoutItem.TYPE.MAIN , LayoutItem.TYPE.SPLIT_LEFT , LayoutItem.TYPE.SPLIT_RIGHT , >",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.78683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Child element of the &lt;Layout&gt; component. By default uses the main type, to span the full width of the Layout area. Split <em>left</em> and split right provide a fixed <em>left</em>&#x2F;right area. Layout only supports one type of each. Usage import { LayoutItem } from &#x27;nr1&#x27; Copy Props childrenrequirednode Content"
      },
      "id": "6091f8cee7b9d20dce5068b5"
    },
    {
      "sections": [
        "OneLogin SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up OneLogin's New Relic app",
        "Step 3. Configure SCIM/SSO application",
        "Fill in the configuration form",
        "Fill in the rules form",
        "A rule that only uses actions",
        "Fill in the provisioning form",
        "Tip",
        "Fill in the Parameters form",
        "Save your changes",
        "Step 4. Assign users",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "OneLogin SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d298162c055490c99117f564c3ea9c2ea5dfd8d1",
      "image": "https://docs.newrelic.com/static/8f585557ea58f70d94a746e6439bf1ad/c1b63/onelogin_rules_conditions_actions.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/onelogin-scimsso-application-configuration/",
      "published_at": "2021-06-25T16:34:34Z",
      "updated_at": "2021-06-20T07:03:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides OneLogin-specific details on how to configure the New Relic OneLogin SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up OneLogin's New Relic app Next, you'll be setting up OneLogin's New Relic SAML/SCIM app. To set this up: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click on Administration. From the OneLogin Administration page, choose the Applications menu. From the OneLogin Applications page, click on Add App. In the search field on the OneLogin Find Applications page, enter \"New Relic by organization\" (not \"New Relic by account\") and then click on the application when it shows in the search results. From the Add New Relic by Organization page, click on Save. Step 3. Configure SCIM/SSO application Configuration for the New Relic SCIM/SSO application is split across several forms. This section describes the different forms that need to be configured. From the New Relic by organization application page, fill in the following forms: Fill in the configuration form In the left pane, select Configuration and complete the following: Get the authentication domain ID (top of New Relic's authentication domain UI and SCIM bearer token (in authentication domain UI as \"SAML 2.0 endpoint) and input them into the appropriate fields in the OneLogin app. Leave the API Connection disabled until all the configuration described in the following sections is completed. After completing all the configuration, enable the connection. Fill in the rules form Configure the user groups to send to New Relic using rules. OneLogin provides this documentation which describes how to use rules to provision groups for users. Decide what type of groups to send along with your users to New Relic. If your organization is using Active Directory or LDAP, you might choose to use security groups to define your users capabilities at New Relic. Another reasonable group choice is OneLogin role. On the New Relic side, your user's groups define their capabilities. The groups that are sent with users will be mapped to New Relic capability groups. Note that at the moment, there is no way to delete a group from the OneLogin side. This is a known limitation from OneLogin. Removing or changing rules does not delete groups already sent to New Relic. If you wish to no longer use a group, removing all the users from the group will prevent it from being used at New Relic. A rule that only uses actions Here's an example rule configuration does not use any conditions. The conditions are left empty to avoid applying any filtering logic to the users. All users will be sent in this example. If you want to send only a subset of users, you need to specify conditions to select the subset. The actions describe where to retrieve the value for the group name and how to parse the value. In this example, we retrieve the group name from the OneLogin role field. The OneLogin role field only has a single value, but sometimes the source for the group name contains other fields besides group name. In other words, some sources give you a list of fields and values and only one of those fields has the value you want to use. In this case, you can insert a regular expression in with value that matches field to find and extract the value for the group name. This example uses the entire value of the For each field for the group name. Fill in the provisioning form In the left pane, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user Update user Tip If you do not uncheck these options, SCIM provisioning requests will not be sent until an administrator approves them. Set When users are deleted in OneLogin, or the user's app access is removed, perform the below action to Delete. Set When user accounts are suspended in OneLogin, perform the following action to Suspend. Fill in the Parameters form In the left pane, select Parameters and complete the following: Click Groups field. Check Include in User Provisioning. Click Save. Save your changes After you complete the above forms, click Save. Then, return to the Configuration form and enable the API connection. Step 4. Assign users After New Relic SCIM/SSO application configuration is finished and New Relic side configuration is finished, you can begin to assign users to the application. Assign the New Relic SCIM/SSO application to a user: Go to the OneLogin web site and sign in with an account that has administrator permissions. From the OneLogin home page, click Administration. From the OneLogin Administration page, choose the Users menu Users item. From the OneLogin Users page, click the user you want to assign the application to. From the user's page, click Applications. From the user's application page, click the plus sign and select the \"New Relic by Organization\" application. Important: Updating users' time zones is important, as charts and other user assets display times. Default is UMT. From the Edit New Relic by Organization login for user page, enter the user's time zone in IANA Time Zone database format (also known as the Olson time zone database format) and click Save. If you're using Roles to define your New Relic capability groups, from the user's application page, click the proper role(s) for the user and then click Save User. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you should be able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Step 6. Assign access grants Once your users are in New Relic, you need to grant them access to specific New Relic accounts, specific groups, and specific roles. Without doing this, your users have no access to New Relic accounts. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.83905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " name. Fill in the provisioning form In the <em>left</em> <em>pane</em>, select Provisioning and complete the following: Check Enable provisioning. Under Require admin approval before this action is performed, uncheck these options: Create user Delete user <em>Update</em> user Tip If you do not uncheck these options, SCIM"
      },
      "id": "6043f34228ccbccafb2c606a"
    },
    {
      "sections": [
        "Azure AD SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Azure's New Relic app",
        "Step 3. Configure connection",
        "Step 4. Configure provisioning rules",
        "Tip",
        "Step 5. Downgrade some users to basic",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO"
      ],
      "title": "Azure AD SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "d6e7f7e95daa833451159a3db4e2c4257270b5e9",
      "image": "https://docs.newrelic.com/static/0a9a32fd5041e6e2ea37cc5f032b6910/8c557/Azure_AD_Provisioning_Attribute_Mapping_2_0.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/azure-ad-scimsso-application-configuration/",
      "published_at": "2021-06-26T02:06:22Z",
      "updated_at": "2021-06-20T07:01:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Azure AD-specific details on how to configure the New Relic Azure AD SCIM/SSO application. Requirements Before using this guide, read the requirements and procedure overview. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Azure's New Relic app Next, you'll set up Azure's New Relic SAML/SCIM app. Azure AD provides an application gallery, which includes various integrations for Azure AD, including the ones that New Relic offers. To set this up: Go to the Azure Active Directory admin center, and sign in if necessary. aad.portal.azure.com/ Click on All services in the left hand menu. In the main pane, click on Enterprise applications. Click on +New Application. Find our SCIM/SSO application by entering New Relic in the name search box, and click on the application New Relic by organization (not New Relic by account). Click on Add. Step 3. Configure connection Configure the New Relic SCIM/SSO application to automatically provision your users to New Relic. From the New Relic SCIM/SSO application page, click on the Provisioning link in the sidebar. In the main pane, click on Get started. In the Provisioning Mode pick-list, choose Automatic. In New Relic's authentication domain UI, set up a new domain with SCIM enabled. In Azure AD's New Relic SCIM/SSO app, in the Admin credentials section, fill out the Tenant URL and Secret token fields with the values provided in New Relic's authentication domain UI. To verify you can connect to New Relic, click Test Connection. When you see a message indicating verification success, click Save. The New Relic SCIM/SSO application can now connect with New Relic. Continue with the following section to configure the provisioning rules. Step 4. Configure provisioning rules Initially, nothing is configured to be sent to New Relic. You must configure Azure AD to send changes for user creation, updates, and deactivation. Go to the Provisioning page and complete the following: Expand the Mappings section. Click Provision Azure Active Directory Users. Verify the Target Object Actions Create Update and Delete checkboxes are all checked. Verify the Attribute Mappings look correct for your environment. Each of the New Relic attributes shown in the list must receive a value. Tip Ensure that the Azure Active Directory attributes shown in the list on the left are good sources for the information to send to New Relic. In particular, not all environments set the mail attribute. If your environment does not set the mail attribute, userPrincipalName could be a good alternative. Leave the switch for Enabled set to Off until you're done with the user and group configuration in the next section. Once all configuration is ready, return to this page and set the switch to On. Click Save. Here's an example of a filled-in attribute mapping page with the default values. Your values may be configured differently depending on your situation. After saving the provisioning rules, the New Relic SCIM/SSO application is ready to provision any changes made to users assigned to the application. Continue with the following section to assign users and groups to the New Relic SCIM/SSO application. Step 5. Downgrade some users to basic When your users are provisioned in New Relic, you should be able to see them in the User management UI. Users provisioned via your identity provider start out as full users. If your organization is on New Relic One pricing, these users are billable. To convert users to free basic users, use the User management UI. Step 6. Assign access grants Once your users are in New Relic, you need to grant them access to specific New Relic accounts, specific groups, and specific roles. Without doing this, your users have no access to New Relic accounts. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO for your users, see the SAML instructions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.70108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Directory admin center, and sign in if necessary. aad.portal.azure.com&#x2F; Click on All services in the <em>left</em> hand menu. In the main <em>pane</em>, click on Enterprise applications. Click on +New Application. Find our SCIM&#x2F;SSO application by entering New Relic in the name search box, and click on the application New"
      },
      "id": "6043f5c964441fcfb0378ef3"
    }
  ],
  "/docs/style-guide/processes-procedures/use-content-types-text-formats": [
    {
      "sections": [
        "Embed images",
        "Important",
        "Add an image",
        "Embed an image",
        "Update an image",
        "Write image captions",
        "Add an inline image",
        "Add a fixed width, block level image",
        "Icons",
        "Tip",
        "Insert icons as tag attributes",
        "Insert inline icons",
        "Install new Feather icons"
      ],
      "title": "Embed images",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "3efaef1bbb576b1e91d8e1362f5b86c14953e7dc",
      "image": "https://docs.newrelic.com/static/260eb3b62364143206af57cd5a84e77d/c1b63/NR1-dashboards-image.png",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/embed-images/",
      "published_at": "2021-06-25T18:17:02Z",
      "updated_at": "2021-04-12T12:43:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "A well-chosen screenshot or image can greatly improve the readability and clarity of a doc. Too many images or an image that's tough to parse can really slow things down. Read on for more information about how to get an image added to one of our docs. Important If you're not part of the Docs team and you want to add an image to the docs site, create a GitHub issue. If you're a New Relic employee, contact @hero in the #documentation Slack channel. Here are some things to keep in mind when you're creating an image: Make sure your image provides useful information at a glance. Include a caption with helpful context for the image. For screenshot captions, include the path in bold. For video captions, include the approximate running time. Add an image Our doc site images are stored in individual images directories at the root level of each taxonomy category. These images directories contain all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs/style-guide/processes-procdures you would use the docs/style-guide/processes-procdures/images directory. If the images directory does not exist, create one in VScode or Finder. Place your image in the images directory. Give the image a descriptive file name: fso-ui-overview.png is much better than 123-go-dawgs.png. Follow the steps below to embed the image in a doc. Embed an image Use markdown to embed an image in a doc. The basic structure: ![alt text](PATH_TO_IMAGE \"Image title text\")` Copy Here's a filled in example: ![An image showing an overview of the synthetics UI](./images/synthetics-ui-overview.png \"Synthetics UI overview\")` Copy Update an image To update an image: Delete the original image file in the corresponding images directory. Place the new image file in the same images directory. Ensure the image file has the same name as the original file. Write image captions Descriptive captions help the reader know why the image matters. If it's a screenshot, it's helpful to include the path in bold in addition to a description. For example: one.newrelic.com > Dashboards: Quickly create information-dense custom views into the data that matters most to you with dashboards in New Relic One. For more help with captions and other supporting text around images, see Guidelines for explaining images. Add an inline image If you'd like to use an inline image, you'll use something like this: From the Overview page, select your app's gear `![alt text](PATH_TO_IMAGE \"Image title text\")` icon. Copy If the image is being used as an icon, always describe it first. When you embed the icon image, follow the image with the word \"icon\" in the text. For example, \"select your app's gear icon.\" Add a fixed width, block level image Fixed width, block level images are similar in format to full column width images, except the original image width is smaller than the column width (800px) of a page. It's important that you edit the HTML like you would an inline image. This way the image will be rendered at 100% of the column width and also be responsive to smaller screen sizes. Use these images when a screenshot is a small part of the page with a width of less than 800px, but when it still needs a caption like a full width image. Here's an example of the HTML for a fixed width, block level image: <div style=\"width: 100%; max-width: Npx;\"> <img alt=\"ALT TEXT\" height=\"X\" src=\"IMG_URL\" title=\"FILENAME\" width=\"N\"> </div> <div class=\"dnd-legend-wrapper\" style=\"width: 100%; max-width: Npx;\"> <div class=\"meta\"><p>CAPTION TEXT</p></div> </div> Copy Icons You can choose from a variety of icons to include in your docs: Feather icons (prefixed with 'fe-) Tip Feather icons replace our previous Font Awesome icons. New Relic icons (prefixed with nr-) Logos for third-party products (prefixed with logo-) Here are the two places you can look to see if we have the icon you need. If the icons are in either of these locations, you can use them in your documents. At the moment, these locations have separate, non-overlapping buckets of icons (this may change): Gatsby theme: This is a subset of Feather, New Relic, and product logo icons that are available across the developer and docs sites. Docs site Feather icons: These are the Feather icons available in the docs project but are not included in the Gatsby theme. Insert icons as tag attributes If your icon appears as an attribute inside another tag, prefix it with icon as in this example: <LandingPageTileGrid> <LandingPageTile title=\"AWS Lambda\" href=\"/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring\" icon=\"logo-aws\" > </LandingPageTile> Copy Insert inline icons If your icon appears inside running text, use the <Icon> component. Here are some examples: Feather: <Icon name=\"fe-database\" /> New Relic:<Icon name=\"nr-tdp\" /> Logos: <Icon name=\"logo-apple\" /> Install new Feather icons If you don't see the icon you want in either the Gatsby theme or in the docs site Feather icons, you can add a new icon to the Gatsby theme. Here's an example of adding a \"database\" icon: Tip Instead of following the instructions below, you can also ask developers to add the icon you want. Go to feathericons.com. Download the \"database\" feather icon by clicking on the icon itself. Once downloaded, open the SVG file in your text editor. Grab the \"guts\" of the SVG, which is everything in between the <svg> tags. For example, if the SVG looks like this: <svg><path m=\"1\"></path></svg>, then you'll grab only the <path m=\"1\"></path> portion. Open the list of feather icons at src/@newrelic/gatsby-theme-newrelic/icons/feather.js. Add an entry for database and assign the code from step #4 to it. This particular icon has multiple paths, so you'll want that <> wrapper around it like you'll see with other icons. Save that feather.js file. The fe- prefix gets automatically added. Once that icon is added, you can use it with the Icon component, for example, <Icon name=\"fe-database\" />.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.93452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " all the images used in the docs for that category. To add an image from scratch: Find the images directory for your doc. For example, if your docs lives in docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures you would use the docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-procdures&#x2F;images directory. If the images directory does"
      },
      "id": "604220ec196a67105da83dc2"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.71407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Procedures</em>",
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original <em>tech</em> <em>writer</em> or Docs site contributor"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-06-26T13:06:18Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 236.08557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> <em>style</em> <em>guide</em>",
        "body": " a document: &#x2F;docs&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document.mdx Copy The URL is: https:&#x2F;&#x2F;docs.newrelic.com&#x2F;<em>style</em>-<em>guide</em>&#x2F;<em>processes</em>-<em>procedures</em>&#x2F;rename-or-redirect-document Copy If you rename a document&#x27;s filename or change its path by moving it to a new directory, make sure to add"
      },
      "id": "604220ec196a670d0ba83dd4"
    }
  ],
  "/docs/style-guide/quick-reference/bold-or-code-not-italics": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.27014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.1865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.8005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/callouts": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.27014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.1865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.8005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/capitalization": [
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.8005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-26T03:59:04Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.14922,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/code-examples": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.27002,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.8005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/collapsers": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.2699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-26T03:59:04Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.1492,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/lists": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.2699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.80048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/tables": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.26978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.1864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.80048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/quick-reference/titles": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.17761,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "UI elements and UI page <em>paths</em>",
        "body": " of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document <em>titles</em>. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-06-26T13:06:18Z",
      "updated_at": "2021-03-16T14:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based on its filename and filepath in the GitHub repository. For example, this is the filename and path for Rename or redirect a document: /docs/style-guide/processes-procedures/rename-or-redirect-document.mdx Copy The URL is: https://docs.newrelic.com/style-guide/processes-procedures/rename-or-redirect-document Copy If you rename a document's filename or change its path by moving it to a new directory, make sure to add a redirect to its old filepath. To change the document's location in the left navigation, update the navigation configuration file. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update the title in the left navigation, edit the yml file for the section that you're in. For example, the Style guide docs use /src/nav/style-guide.yml. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.02364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or <em>redirect</em> a document",
        "sections": "Rename or <em>redirect</em> a document",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete <em>redirects</em>. Procedures are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing <em>titles</em> or updating <em>redirects</em> can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/levels-headings/",
      "sections": [
        "Levels of headings",
        "Use parallel construction",
        "Keep it short, avoid -ing words",
        "Do not use h1 headings",
        "Use level two headings to identify chunks of information",
        "Important",
        "Avoid using level three headings"
      ],
      "published_at": "2021-06-25T15:38:32Z",
      "title": "Levels of headings",
      "updated_at": "2021-05-21T14:31:50Z",
      "type": "docs",
      "external_id": "981282f676b2697e24f69ad23bce7e3412bb1d22",
      "document_type": "page",
      "popularity": 1,
      "body": "Taking some time to consider your headings and document titles will be time well spent. Titles and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document titles, use sentence case. Use parallel construction Use parallel construction when naming headers. For example, use all nouns (\"Organization,\" \"Tone\"), all verbs (\"Create,\" \"Delete\"), etc. Keep it short, avoid -ing words For all headers, keep the title as short as possible. In particular, avoid headers that are more than a line long. As with all our writing, you should feel free to address the reader directly: Install the agent, for example, rather than Agent installation. You should also avoid -ing words, which add to character count without contributing clarity. Do not use h1 headings After you publish your doc, the Docs site will automatically use what you added to the Title field as the doc's level one heading (h1). To ensure that your doc is properly indexed for search, do not manually create additional h1 headings. If your doc's title is long and you would like a shorter title to appear in the sidebar menu, create a GitHub issue and we'll help you with that change. Use level two headings to identify chunks of information Organize chunks of information into sections with level two headings (##). For example: ## Create a new user [#create-new-user] Copy Important If you don't specify an ID manually, the site will use your header text as that header's ID (also known as anchor link). Create a manual ID to preserve links to that header if you change the header text. If you have too many level sections, consider splitting the document into multiple pages. Avoid using level three headings Avoid using ### headings unless it makes sense for the content or if the content is lengthy. Collapsers, tables, and other structural elements are often a better choice. Be particularly careful about level three headings that make a level two section longer than a single screen height. Here are two examples of good scenarios for using level three headings: Example #1: Events-to-metrics API doc Example #2: Infrastructure integration doc",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.77803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Keep it <em>short</em>, avoid -ing words",
        "body": "Taking some time to consider your headings and document <em>titles</em> will be time well spent. <em>Titles</em> and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document <em>titles</em>, use sentence case. Use parallel construction Use parallel"
      },
      "id": "604221d3196a677e3aa83db4"
    }
  ],
  "/docs/style-guide/quick-reference/ui-paths": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.26962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.80048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    },
    {
      "sections": [
        "Usage dictionary",
        "account ID",
        "agent",
        "am and pm",
        "Amazon Web Services (AWS) product names",
        "app name vs. app alias",
        "beta",
        "bits and bytes",
        "Tip",
        "blacklist and whitelist",
        "capitalization",
        "click",
        "collector vs. connect to New Relic",
        "contractions",
        "dashboard",
        "doc, document, documentation",
        "dropdown",
        "e.g. and i.e.",
        "em dash (—)",
        "etc.",
        "hostname",
        "icons",
        "index",
        "infrastructure",
        "introduction",
        "macOS",
        "master account",
        "menu",
        "mouse over",
        ".NET",
        "New Relic One",
        "Node.js",
        "NR ONLY",
        "Oxford comma",
        "open source",
        "page",
        "parent account",
        "permissions",
        "pricing",
        "real user monitoring (RUM)",
        "record vs. report vs. collect",
        "RPM",
        "serial comma",
        "time zone",
        "UI",
        "UI paths",
        "update vs. upgrade",
        "users",
        "username, not user name",
        "version number references",
        "we",
        "you"
      ],
      "title": "Usage dictionary",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "eb1b15a359f1676c50bb9f0a1270f4659c435f63",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/usage-dictionary/",
      "published_at": "2021-06-26T03:59:04Z",
      "updated_at": "2021-05-06T04:01:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use this dictionary to guide your writing on docs.newrelic.com. We use this to help ensure consistency across our Docs site. Other than the terms listed here, we generally follow the Microsoft Style Guide, but we'll use Chicago Manual of Style in a pinch. We also follow American English conventions, rather than British English ones. For a glossary of terminology specific to New Relic, see the public glossary on the Docs site. account ID A unique number that identifies a particular New Relic account. Don't use account number. agent Don't capitalize. Install the Ruby agent, not Install the Ruby Agent. Don't refer to a Synthetics private minion as an agent. am and pm Use the 12-hour clock followed by the (lowercased) time period am or pm. Don’t put a space after the last number in a timestamp (12:00am, not 12:00 am). Don't include a leading 0 when the hour is less than 10. 9:30am, 12:30pm, 8:30pm Copy Amazon Web Services (AWS) product names Refer to the specific product, not just AWS broadly. As a courtesy to your readers, on first mention always refer to Amazon products by their full names; for example Amazon Web Services (AWS). You can use the acronym after that, if there is one. Example: Amazon Elastic Compute Cloud. After that, use the short name according to the AWS Documentation site. Example: Amazon EC2. app name vs. app alias The \"machine name\" that the collector uses to uniquely identify an app is its app name. The server-side configuration setting that changes the visible \"name\" of an app without changing its unique identifier is its app alias. beta When using as a watermark or in the doc's title, use all caps: <div id=\"watermark\">BETA</div> Copy Don't include a callout within the document unless the beta requires additional explanation. In the body text, use lowercase. For example: <Callout variant=\"important\"> This feature currently is in private beta. To join the beta, contact your New Relic account rep. </Callout> Copy If the developer team prefers to use a term other than beta or private beta, clarify what is driving that use of the term (Legal requirement?), and add any relevant info here in the usage dictionary. bits and bytes Use standard prefixes and capitalization for International System of Units (SI), International Organization for Standardization (ISO), or Joint Electron Device Engineering Council (JEDEC memory) values when referring to multiples of bits (b) and bytes (B). 1 byte = 8 bits. Decimal value SI prefix Binary value ISO prefix JEDEC prefix 1000 k: kilo 1024 Ki: kibi K: kilo 1000^2 M: mega 1024^2 Mi: mebi M: mega 1000^3 G: giga 1024^3 Gi: gibi G: giga 1000^4 T: tera 1024^4 Ti: tebi - -- 1000^5 P: peta 1024^5 Pi: pebi - -- Tip For help with converting byte values (such as bytes to kilobytes), try this byte converter. blacklist and whitelist Don't use. Instead, use deny list and allow list; for example, \"Add a hostname to your deny list.\" capitalization This is more complex than can be covered in this usage dictionary. For detailed information, see: Heading capitalization Capitalization of features and UI elements click In general, use click rather than the vaguer select. For example, you might click something in the UI, but then select something from a list. Be particularly careful to use click to describe actions that only make sense with a mouse; for example, with a right-click or a click and drag. Also use click when the user must click on a non-selectable object (to save your changes, click anywhere outside the dialog box). See also mouse over. collector vs. connect to New Relic When referring to an agent talking to the New Relic servers, describe this as the New Relic collector. Although internally the collector refers only to specific parts of our architecture, we use it more broadly in our documentation to mean \"any endpoint a customer must connect to report data, for any product.\" Avoid \"connect to New Relic,\" and do not use \"connect to the New Relic UI.\" contractions When it makes sense for clarity, conciseness, and tone and voice, use contractions. Use them where they make the writing sound more like natural speech, and where they improve clarity and accessibility without sacrificing expertise and authority. There are no hard and fast rules for which contractions are or aren't acceptable, but simple and common is preferable to complicated and rare. For example, it's for it is is fine, but less common constructions like mustn't or wouldn't've are best avoided. Also: When using a negative contraction (don't, can't, won't) try to provide some additional info about what what to do and what can be done. (See the style guide intro for more on this.) There are places in our docs—for example, in notes and warnings—where spelling out do not, cannot, or will not is preferable to contractions to emphasize the action or blockage to be avoided. dashboard Don't use. Instead, use page. doc, document, documentation Avoid referring to the document itself (the docs site page) as much as possible. If there's not a good alternative, you can use doc, document, or documentation (whatever sounds most natural; try reading it aloud). For example, This document explains how to... or For related docs, see... dropdown Use dropdown instead of drop-down or drop down. Although it isn't common usage, you can use dropdown independently as a noun, without needing to say dropdown menu or dropdown list. For example, select a date from the <b>date</b> dropdown. e.g. and i.e. Don't use Latin abbreviations. Instead of e.g., use for example or such as. Instead of i.e. or its English equivalent in other words, rewrite so your description is clear. em dash (—) Em dashes are rarely needed in tech docs, sadly. You can usually accomplish what you need to by breaking the thought into multiple sentences or using parentheses. In some rare cases, though, an em dash can add drama and spice. If you think you've found such a case, make sure you use them right. An em dash should always use the real em dash character (not a hyphen), and no space before and after. For example: You can sign up for New Relic fast and free—we won't even ask for a credit card number. Copy You can insert an em dash with the COMMAND+OPTION+- shortcut or use the HTML entity. etc. Unlike the Latin abbreviations e.g. or i.e.), you're welcome to use etc. Please ensure that you have several meaningful examples, though, before using. For example, cities including Portland, Seattle, Dublin, etc. but not cities including Portland, etc.. hostname This is one word. Don't hyphenate. icons When using an inline icon from the UI, always describe it first, then embed the icon image, and then end with the word icon. For example, select the delete icon. Don't put icons in bold. When writing about icons, describe the icon for its purpose or action, not what the icon looks like. For example: Yes: Select the edit icon. No: Select the pencil icon. For technical information on embedding images, see Inserting inline images and Embedding Font Awesome icons. index A list of entities, such as the APM applications index, the Synthetics Monitors index, or the Alerts Incidents index. See also page. infrastructure Don't use, unless referring to the New Relic Infrastructure product. Instead, use an appropriate substitute such as architecture, environment, system, host, etc. introduction Always use Introduction to for overview docs for a particular product. For example, Introduction to New Relic Infrastructure or Introduction to the PHP agent or Introduction to transaction traces. Don't use welcome to, basics, intro, overview, etc. Also avoid the Thing: Tagline format, as in X-Ray sessions: Traces and thread profiles for key transactions, unless having a title with keywords will help with SEO. macOS The proper name for Apple's desktop operating system is macOS. Don't use the older product names Mac OS X or OS X. master account The primary account in a New Relic account with sub-accounts. Refer to a master's subordinate accounts as sub-accounts, not children or slaves. menu The list of pages and indexes on the top and left sides of the New Relic user interface. mouse over For mouse movements that involve placing the mouse pointer over an area, but not clicking it. For example, the APM Overview page includes functions that are only visible when the mouse pointer is over a particular chart. Do not use point to or hover over. See also click. .NET Always refer to the agent and language as .NET, never as .Net or .net or dotnet. New Relic One New Relic One isn't a product. It's a way to view New Relic data more easily, all in one place, and from multiple related accounts. This has several implications for how we should refer to it: Avoid phrasing that makes New Relic One sound like a separate product or a separate platform. There is a single New Relic platform through which our users interact with our products. Avoid mentioning New Relic One where it can be avoided. For example, instead of saying \"Use New Relic One workloads to...\", you could instead say, \"In New Relic, you can use workloads to...\" and then in the doc explain where to find the feature. Another example: instead of referring to \"The programmable New Relic One platform,\" we might say, \"The New Relic platform is programmable: To start building, go to one.newrelic.com and...\" Do not use NR1 or nr1 as an abbreviation of New Relic One. The only reason to use nr1 is when referring to the nr1 package or library (for example: a reference to the command nr1 nerdpack:serve). In general, we want to avoid overloading our docs with \"New Relic\". For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always refer to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this style guide). Don't use NR-ONLY or NRONLY or New Relic Only. Oxford comma See serial comma. open source Use lower case for open source. Some legal contracts may require upper case. page A specific place in the New Relic UI, located at a particular URL. Compare and contrast index, menu, and UI. Don't use dashboard, menu, tab, screen, or similar terms. parent account Don't use. See master account. permissions See User-related language. For pricing tier/edition language, see Pricing language. pricing See Pricing language. real user monitoring (RUM) Don't use this outside of Browser docs. Often abbreviated as RUM, this is a generic industry term for Browser monitoring. New Relic refers to this as page load timing (in Browser docs) or New Relic Browser (in non-Browser docs). Within Browser docs, use this term only for SEO or clarification, never to refer to the actual feature. record vs. report vs. collect Use report when discussing data sent to New Relic, such as, \"your host reports data to New Relic.\" Avoid using report as a noun. Instead use \"the reported metrics\" or \"the collected data.\" If \"report\" sounds too clunky, you can also use collect as long as whatever New Relic is collecting doesn't sound security sensitive. RPM Don't refer to the New Relic UI as RPM. Always refer to the specific product, such as the APM UI or the Browser UI. However, you may use rpm when required in the visible URL string in UI paths. serial comma Also referred to as an Oxford comma. Always use serial commas with inline lists. For example, Portland, Seattle, and Dublin rather than Portland, Seattle and Dublin. time zone Include a space (time zone). Don't hyphenate or run together as timezone. UI The graphical component of a New Relic product, encompassing all its pages, menus, and indexes. See also UI paths. UI paths If you need to tell a user how to path through the UI, see our style guide page on UI paths. update vs. upgrade Use update when users need to change the version of whatever they're using. No money or payment is needed for an update. Use upgrade whenever money or payment may be involved, such as upgrading to the Pro version of a product. The new pricing model makes it unlikely that you'll need to use this. users For styles and formats related to user roles and groups and more, see User-related style. username, not user name One word (username), not two. This is the most common usage and is recommended by Microsoft and Google style guides. version number references When referring to multiple version numbers, always use or higher. Don't use and higher, or the words greater or later. Also don't use punctuation, as in version 1.2+. For example: Foo requires Ruby agent version 1.2.3 or higher. Copy In addition: Tell users to use the latest version and not an up-to-date or current version. To abbreviate the word version, use a lowercase v with no space before the number; for example, v2 or v1.2.3. Use update not upgrade when talking about agent versions, as in \"To update to the latest version...\" For security reasons, do not use version numbers with licensing docs. The Tech Docs team doesn't have a set standard when referring to previous versions. Recommendation: Consider using version x.x or lower when identifying a specific version. Consider using In earlier agent versions when referring to versions more vaguely. we Say “we” and “our” when it works with the flow of your writing. Avoid overloading paragraphs with “New Relic” mentions, or reword so the focus is on the user, not New Relic. For example, avoid writing something like this: New Relic recommends setting a startup timeout. Copy Instead, write something like this: Recommendation: To help with troubleshooting, include a startup timeout in your configuration. Copy OR We recommend setting a startup timeout. Copy you We use “you” and “your” liberally in our docs. Addressing the reader directly makes for simpler, cleaner sentences. It also tends to expose lazy uses of passive construction and it helps users to understand procedures. However, avoid using generic “you” or “your” when permissions are involved, because we can't assume what permissions the user has. For example, we can't just say “you can add and remove users from your account settings” when that is actually an Owner or Admin level capability. When permissions are relevant, use a permissions callout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.14919,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "version number <em>references</em>",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " with &quot;New Relic&quot;. For more details, see the New Relic One messaging guidelines, the docs glossary entry, or the New Relic One docs. Node.js Always <em>refer</em> to the programming language as Node.js, not Node. NR ONLY Use NR ONLY for watermarking docs for internal consumption only (such as this <em>style</em> <em>guide</em>"
      },
      "id": "60421ec1196a676986a83d87"
    }
  ],
  "/docs/style-guide/quick-reference/usage-dictionary": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.26962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": ", such as a variable or function, then capitalize it exactly as it&#x27;s used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft <em>Style</em> <em>Guide</em> for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "UI paths",
        "Guidelines for writing good UI paths",
        "Use your best judgment"
      ],
      "title": "UI paths",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "3197ec6c676c5b5931c10e19ea62524fd7301abd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/ui-paths/",
      "published_at": "2021-06-26T03:57:54Z",
      "updated_at": "2021-06-02T16:01:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Explaining where to find UI pages and elements can be tricky. When done well, path descriptions can make navigating our UI easier for readers. Read on for tips on writing and formatting a UI path. Guidelines for writing good UI paths Our goal for UI paths is to make them easy to use and understand, preferably written in a conversational way. We're not concerned with absolute consistency. The examples here are guidelines and not firm rules. Guideline Description Use a concise, conversational format More often than not, we should keep UI paths short and conversational. For example: From the top navigation, select APM, select your application, and then click Distributed tracing. Consider path length The length of the path should influence your approach. A simple three-step navigation can be fully conversational. A multiple-step procedure may be an ordered list. And for something buried eight steps deep, consider using the x > y > z convention. Here's an example of a simple navigation: From one.newrelic.com, click the Query builder icon to start querying your data. Here's one for a multi-step procedure: To see details for a specific span: From the top navigation, click APM and then choose your application. Click Distributed tracing and select a trace from the trace index. Select a span to see its details. Here's one for a lengthier path, though this can usually be avoided by following our other guidelines: Go to one.newrelic.com > APM > (select an app) > Transactions > (select a transaction) > (select a transaction trace) > Trace details: Avoid redundancy If there’s an existing doc or doc section that explains how to get to a specific UI element, section, or page, link to it. Here's an example that links to an existing doc: From the account dropdown, select Account settings, and then select Plan management. Here's one that links to an earlier section: To find details about the entity associated with a span: From a span’s details pane [ link to doc section above], select Attributes. Look for entity-related attributes, like entityId and entity.name. Orient the reader If something's hard to locate, you can use terms like top of the screen or left navigation. For example: From the top navigation, click APM and then choose your application. Use natural verbs Use natural, actionable verbs. Think about the user and the logic of the action and then read your steps out loud before deciding. Examples: click, select, choose. Use screenshots Screenshots can help ground the reader. For instance, if the UI contains a dashboard with multiple options, a screenshot can orient the reader with a common set of procedures. Exclude log-in instructions We should assume our readers are logged in. In other words, don’t include log in to New Relic instructions. Use your best judgment If you’re ever feeling stuck when writing a UI path, use your best judgment. The best way to format or word a UI path may depend on the path’s length and context. For example, whether or not to include a URL is up to you. If including Go to one.newrelic.com in a path description is cumbersome or unnatural, exclude it. If it helps orient the reader, feel free to include it. This same thinking applies towards most of our guidelines.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.1864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Guidelines</em> for writing good UI paths",
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421ec2196a67f959a83dc7"
    },
    {
      "sections": [
        "Collapsers",
        "Collapser 1",
        "Collapser 2",
        "Create a collapser",
        "Collapsers triggers"
      ],
      "title": "Collapsers",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "ac7812b80a10eac9124576320ae479d131182095",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/collapsers/",
      "published_at": "2021-06-25T17:06:38Z",
      "updated_at": "2021-05-21T16:41:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Collapsers are expandable elements that hide page content until you trigger it open. We use collapsers to hide content in very long documents, out of consideration for our readers. Each collapser has a title (what we show to readers), but also an id that we use for deep \"anchor\" links to specific collapsers. Here's an example collapser: Collapser 1 This is our first example collapser. Collapser 2 This is our second example collapser. Here are some examples of when to use collapsers in your document. Collapsers are useful for... Example Long lists Here are examples when you have a long list of definitions, such as configuration values, API calls, or parameters: Writing scripted browsers .NET agent configuration Multiple options Here's an example when you have multiple options, such as a procedure with steps that vary depending on your application environment: Collecting PMI metrics. Large code blocks Here's an example when you have a code block that is longer than about one screen height: Writing API tests. Subdividing H2s Here's an example when you want a cleaner substitute for h3 tags when subdividing an h2 header: Installing the PHP agent manually. Unlike an h3, collapsers allow users to see all the options within a section at a glance without having to scroll. Create a collapser To create a collapser, you'll need to use our collapser code. Here's an example of the collapser source: <CollapserGroup> <Collapser id=\"collapser-source\" title=\"Collapser source\" > <dl class=\"collapser-list\"> <dt id=\"collapser-1\">Collapser 1</dt> <dd> <p>This is the first example collapser.</p> </dd> <dt id=\"collapser-2\">Collapser 2</dt> <dd> <p>This is the second example collapser.</p> </dd> </dl> </Collapser> </CollapserGroup> Copy Collapsers triggers To open or close a collapser: Click the open buttons or Show/Hide All. Arrive at an individual collapser via an anchor ID. For example, go directly to Collapser 1 in the example above. Type the shortcut key s to show (open) all collapsers on the page. Use CMD+F (or CTRL+F) to find in page and all the collapsers will open automatically.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.80048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "604220b2e7b9d2f2402a07fa"
    }
  ],
  "/docs/style-guide/writer-workflow/github-intro": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Important",
        "Reset the 'build the docs site' build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-26T04:00:15Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Important The only checks needed to merge a PR are the checks marked as required on the PR. These are run linter, run tests, license/cla, and unpaired translations removed for merges to develop, and build the docs site for merges to main. If a required check fails, the failure must be addressed in order for the PR to be merged. If an optional check fails, reach out in the help channel so that the hero can look into the failure, but feel free to merge the PR since optional checks don't block releases. Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the 'build the docs site' build check Caution This adds a LOT of time to the build check. There are times when this check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.9155,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>GitHub</em> troubleshooting",
        "sections": "<em>GitHub</em> troubleshooting",
        "body": " conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can <em>get</em> out-of-date pretty fast. If you see changes to this file show up in <em>GitHub</em> Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file."
      },
      "id": "60c6a94f64441f5ac491f8a7"
    },
    {
      "sections": [
        "Using Terraform Modules and Remote Storage",
        "Before you begin",
        "Creating a Terraform Module",
        "Create a Variable",
        "Passing a variable into a module",
        "Adding default values",
        "Pass variable values using module block",
        "Reusing a module",
        "Connecting an existing alert policy",
        "Store a module in Github",
        "Create a new Github repo",
        "Using a module saved on Github",
        "Manage state remotely in Amazon S3",
        "Conclusion"
      ],
      "title": "Using Terraform Modules and Remote Storage",
      "type": "developer",
      "tags": [
        "notification channel",
        "alerts",
        "terraform"
      ],
      "external_id": "9199eee78d8b5a488366c74b6b4e683dd010b51d",
      "image": "",
      "url": "https://developer.newrelic.com/terraform/terraform-modules/",
      "published_at": "2021-06-27T01:44:24Z",
      "updated_at": "2021-06-25T01:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn how to use [Terraform](https://www.terraform.io/) modules in your configurations and store them remotely.",
      "body": "Terraform is a popular infrastructure-as-code software tool built by HashiCorp. You use it to provision all kinds of infrastructure and services, including New Relic dashboards and alerts. In this guide, you learn to use Terraform modules in your New Relic configurations. Specifically, you will create modules, import data, store modules on Github, and manage state remotely Amazon S3. In the video, we review additional steps installing Terraform and set up New Relic alerts. If you need help getting started with Terraform, the Getting started with New Relic and Terraform guide shows how to install Terraform, set up New Relic alerts and a notification channel. Before you begin To use this guide, you should have some basic knowledge of both New Relic and Terraform. If you haven't deployed a New Relic open source agent yet, install New Relic for your application. Also, install the Terraform CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config && cd terraform-config To follow the examples in this gude, the accompanying example code is available on GitHub bash Copy $ git clone https://github.com/jsbnr/nr-terraform-intro-example.git Step 1 of 5 Creating a Terraform Module Terraform modules allow you to reuse, share, and store your Terraform configurations using version control like Github. In the next steps, you will move your New Relic configurations into a reusable module. First, in your project root, create a new directory to store your modules named modules: bash Copy $ mkdir modules && cd modules In the modules directory, create a new directory for a new module called HostConditions and create a new file named main.tf: bash Copy $ mkdir HostConditions && cd HostConditions $ touch main.tf Remove the two alert conditions from the root project's main.tf file and copy it to the new main.tf file in the HostConditions directory. In the root directory's main.tf file call the new module using a module block: module \"HostConditions\" { source = \"./modules/HostConditions\" } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Initializing modules... $ [output]- HostConditions in $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. You see an error in your console due to the lack of provider details in your modules directory. To fix the error, create a copy of the root provider.tf in your HostConditions directory : provider \"newrelic\" { account_id = 12345 # Your New Relic account ID api_key = \"NRAK-zzzzzz\" # Your New Relic user key region = \"US\" # US or EU (defaults to US) } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 2, in resource \"newrelic_infra_alert_condition\" $ [output]\"cpuhot\": 2: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 24, in resource \"newrelic_infra_alert_condition\" $ [output]\"highDiskUsage\": 24: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. Terraform init no longer shows an error, but running terraform plan still causes an error to occur. The error is due to the policy id used in the ./modules/HostConditions/provider.tf doesn't exist. A variable is needed to pass into the module. Step 2 of 5 Create a Variable Variables pass details into your module and set default values. First, at the top of your HostConditions provider.tf create a new variable: variable \"providerId\" {} Copy Next, in the resource block, replace the existing policyId with the new variable: var.policy Copy Passing a variable into a module To make a module dynamic, you will pass your variables into the module using the module resource block. In the root directory main.tf, update the module block to add the policyId variable: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id } Copy Run terraform plan after adding your variable to the module. bash Copy $ terraform plan Now, add more variables and replace the values CPU critical, CPU warning, and disk percent. Then, pass the new variables into the module. Add the new variables to HostConditions main.tf: variable cpu_warning {} variable cpu_critical {} variable diskPercent {} Copy Update the alert conditions to use the new variables added in the HostConditons main.tf: resource \"newrelic_infra_alert_condition\" \"cpuhot\" { policy_id = var.policyId name = \"CPU hot!\" type = \"infra_metric\" event = \"SystemSample\" select = \"cpuPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.cpu_critical time_function = \"all\" } warning { duration = 5 value = var.cpu_warning time_function = \"all\" } } resource \"newrelic_infra_alert_condition\" \"highDiskUsage\" { policy_id = var.policyId name = \"high disk usage\" type = \"infra_metric\" event = \"SystemSample\" select = \"diskUsedPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.diskPercent time_function = \"all\" } } Copy Run terraform plan after adding your variables to the module. An error message displays due to the missing variable values. Values can be added in the module block or as default values. bash Copy $ terraform plan Adding default values Add default variable values to HostConditions main.tf: variable cpu_warning { default=80} variable cpu_critical { default=90} variable diskPercent { default=60 } Copy Pass variable values using module block In the root directory main.tf, update the module block to add the cpu_critical, cpu_warning, and diskPercentage variables: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } Copy Run terraform plan after adding your variables to the module. bash Copy $ terraform plan Step 3 of 5 Reusing a module You can reuse your module connecting to a New Relic policy that already exists. Before you start, in your New Relic account, create a new alert policy named Preexisting Policy. Connecting an existing alert policy First, In your root main.tf file add the data block to import an existing policy: data \"newrelic_alert_policy\" \"ExistingPolicy\" { name = \"Preexisting Policy\" } Copy Next, create a second module block name HostConditions2. Add the alert conditions to the Preexisting Policy. module \"HostConditions2\" { source = \"./modules/HostConditions\" policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module and run 'terraform apply' to apply the changes to your New Relic account. The terraform scripts create a new alert policy and two conditions, but it also applies the alert conditions to the Preexisting Policy. Look in your New Relic account at the Preexisting Policy and see alerts conditions added for CPU Hot and High Disk Usage. Step 4 of 5 Store a module in Github After you have created a module, if you want to store the module somewhere other people can use, Github is how you can do it. Create a new Github repo First, inside of your HostModules directory, initialize a new Github repo. Add your main.tf and provider.tf to the stage for commit: bash Copy $ git add main.tf provider.tf $ git commit -m \"init\" Next, using the commands provided in your new repo, push your commit to Github: bash Copy $ git remote add origin <repo_url> $ git branch -M main $ git push -u origin main Using a module saved on Github Check the Github repo and see the main.tf and provider.tf are now in your repo. Copy the GitHub repo's web URL to clone your repo. Update the root main.tf file using GitHub as the source for the HostConditions: module \"HostConditions\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } module \"HostConditions2\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module. When you run terraform init, Terraform clones the repository locally. Run terraform plan If you need to update your local module with updates made to the git repo, run terraform get -update Step 5 of 5 Manage state remotely in Amazon S3 The state file is the representation that terraform holds about the created resources. The state file is in the root directory, but if deleted or corrupted would cause trouble. Storing the state file remote provides security and allows sharing and remote access. In the provider.tf in the root directory, add a terraform backend block for Amazon S3: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" } } Copy Variables are needed to provide the correct S3 bucket details, and access is required. To give access to the S3 bucket in your Amazon account, create an IAM user. Give the IAM user access to the S3 bucket storing the terraform state. Add the profile to the terraform backend block: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" profile = \"<iam_user_profile_name>\" } } Copy Before saving your state to Amazon S3, destroy the current configurations to start from a clean slate: bash Copy $ terraform destroy Initialize Terraform, run Terraform init: bash Copy $ terraform init In the terminal, the output shows the backend initialized as S3. Delete the local state as it is not needed bash Copy $ rm terraform.* Run terraform apply to apply your Terraform configuration changes. bash Copy $ terraform apply The state file is now stored in S3 instead of locally. Look in your S3 bucket and see the terraform state exists. Conclusion Congratulations! You're using modules to make your terraform configuratiions more flexible. Review the New Relic Terraform provider documentation to learn how you can take your configuration to the next level.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.32999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Store a module in <em>Github</em>",
        "body": " CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config &amp;&amp; cd terraform-config To follow the examples in this gude, the accompanying example code is available on <em>GitHub</em> bash Copy $ <em>git</em> clone https:&#x2F;&#x2F;<em>github</em>.com&#x2F;jsbnr&#x2F;nr-terraform-intro-example.<em>git</em> Step 1 of 5 Creating"
      },
      "id": "6091fa98e7b9d2063e506919"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-26T04:05:47Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.70596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great <em>GitHub</em> integrations <em>GitHub</em> account <em>GitHub</em> Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    }
  ],
  "/docs/style-guide/writer-workflow/github-troubleshooting": [
    {
      "sections": [
        "Diagnostics CLI (nrdiag)",
        "Compatibility",
        "Get started"
      ],
      "title": "Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "973501f4752e56caf3d68e37bf21b823d0e42078",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag/",
      "published_at": "2021-06-26T08:28:19Z",
      "updated_at": "2021-03-13T05:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version The Diagnostics CLI (nrdiag) is a utility that automatically detects common problems with New Relic products. If the Diagnostics CLI detects a problem, it suggests troubleshooting steps. The Diagnostics CLI can also automatically attach troubleshooting data to a New Relic Support ticket. The Diagnostics CLI is open source and is located in GitHub. For additional troubleshooting steps for your agent, check out Not seeing data. Here's an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped troubleshooting logs that are ready to be attached to support tickets. Compatibility The Diagnostics CLI is available for Linux, macOS, and Windows. It can detect common configuration issues for: APM: Available for all APM agents except C SDK. For the Go agent, only basic connectivity checks are available. Browser monitoring: Browser agent detection Infrastructure monitoring: Linux and Windows agents Mobile agents: iOS and Android Synthetic monitoring: Containerized private minions (CPM) The Diagnostics CLI does not require superuser or admin permissions to run, although we recommend those permissions for some checks. It will return an error if it does not have permissions to read the files it scans. Get started To use the Diagnostics CLI: Run the Diagnostics CLI, including task suites and command line options as needed. Include an attachment key when you upload the results to your Support ticket. Optional: Validate your config file settings. Interpret the output. Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. For detailed information, see our Diagnostics CLI licensing and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 709.3117,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Support ticket. The Diagnostics CLI is open source and is located in <em>GitHub</em>. For additional <em>troubleshooting</em> steps for your agent, check out Not seeing data. Here&#x27;s an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates"
      },
      "id": "604469f8e7b9d2abb65799f0"
    },
    {
      "sections": [
        "Using Terraform Modules and Remote Storage",
        "Before you begin",
        "Creating a Terraform Module",
        "Create a Variable",
        "Passing a variable into a module",
        "Adding default values",
        "Pass variable values using module block",
        "Reusing a module",
        "Connecting an existing alert policy",
        "Store a module in Github",
        "Create a new Github repo",
        "Using a module saved on Github",
        "Manage state remotely in Amazon S3",
        "Conclusion"
      ],
      "title": "Using Terraform Modules and Remote Storage",
      "type": "developer",
      "tags": [
        "notification channel",
        "alerts",
        "terraform"
      ],
      "external_id": "9199eee78d8b5a488366c74b6b4e683dd010b51d",
      "image": "",
      "url": "https://developer.newrelic.com/terraform/terraform-modules/",
      "published_at": "2021-06-27T01:44:24Z",
      "updated_at": "2021-06-25T01:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn how to use [Terraform](https://www.terraform.io/) modules in your configurations and store them remotely.",
      "body": "Terraform is a popular infrastructure-as-code software tool built by HashiCorp. You use it to provision all kinds of infrastructure and services, including New Relic dashboards and alerts. In this guide, you learn to use Terraform modules in your New Relic configurations. Specifically, you will create modules, import data, store modules on Github, and manage state remotely Amazon S3. In the video, we review additional steps installing Terraform and set up New Relic alerts. If you need help getting started with Terraform, the Getting started with New Relic and Terraform guide shows how to install Terraform, set up New Relic alerts and a notification channel. Before you begin To use this guide, you should have some basic knowledge of both New Relic and Terraform. If you haven't deployed a New Relic open source agent yet, install New Relic for your application. Also, install the Terraform CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config && cd terraform-config To follow the examples in this gude, the accompanying example code is available on GitHub bash Copy $ git clone https://github.com/jsbnr/nr-terraform-intro-example.git Step 1 of 5 Creating a Terraform Module Terraform modules allow you to reuse, share, and store your Terraform configurations using version control like Github. In the next steps, you will move your New Relic configurations into a reusable module. First, in your project root, create a new directory to store your modules named modules: bash Copy $ mkdir modules && cd modules In the modules directory, create a new directory for a new module called HostConditions and create a new file named main.tf: bash Copy $ mkdir HostConditions && cd HostConditions $ touch main.tf Remove the two alert conditions from the root project's main.tf file and copy it to the new main.tf file in the HostConditions directory. In the root directory's main.tf file call the new module using a module block: module \"HostConditions\" { source = \"./modules/HostConditions\" } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Initializing modules... $ [output]- HostConditions in $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. You see an error in your console due to the lack of provider details in your modules directory. To fix the error, create a copy of the root provider.tf in your HostConditions directory : provider \"newrelic\" { account_id = 12345 # Your New Relic account ID api_key = \"NRAK-zzzzzz\" # Your New Relic user key region = \"US\" # US or EU (defaults to US) } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 2, in resource \"newrelic_infra_alert_condition\" $ [output]\"cpuhot\": 2: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 24, in resource \"newrelic_infra_alert_condition\" $ [output]\"highDiskUsage\": 24: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. Terraform init no longer shows an error, but running terraform plan still causes an error to occur. The error is due to the policy id used in the ./modules/HostConditions/provider.tf doesn't exist. A variable is needed to pass into the module. Step 2 of 5 Create a Variable Variables pass details into your module and set default values. First, at the top of your HostConditions provider.tf create a new variable: variable \"providerId\" {} Copy Next, in the resource block, replace the existing policyId with the new variable: var.policy Copy Passing a variable into a module To make a module dynamic, you will pass your variables into the module using the module resource block. In the root directory main.tf, update the module block to add the policyId variable: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id } Copy Run terraform plan after adding your variable to the module. bash Copy $ terraform plan Now, add more variables and replace the values CPU critical, CPU warning, and disk percent. Then, pass the new variables into the module. Add the new variables to HostConditions main.tf: variable cpu_warning {} variable cpu_critical {} variable diskPercent {} Copy Update the alert conditions to use the new variables added in the HostConditons main.tf: resource \"newrelic_infra_alert_condition\" \"cpuhot\" { policy_id = var.policyId name = \"CPU hot!\" type = \"infra_metric\" event = \"SystemSample\" select = \"cpuPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.cpu_critical time_function = \"all\" } warning { duration = 5 value = var.cpu_warning time_function = \"all\" } } resource \"newrelic_infra_alert_condition\" \"highDiskUsage\" { policy_id = var.policyId name = \"high disk usage\" type = \"infra_metric\" event = \"SystemSample\" select = \"diskUsedPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.diskPercent time_function = \"all\" } } Copy Run terraform plan after adding your variables to the module. An error message displays due to the missing variable values. Values can be added in the module block or as default values. bash Copy $ terraform plan Adding default values Add default variable values to HostConditions main.tf: variable cpu_warning { default=80} variable cpu_critical { default=90} variable diskPercent { default=60 } Copy Pass variable values using module block In the root directory main.tf, update the module block to add the cpu_critical, cpu_warning, and diskPercentage variables: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } Copy Run terraform plan after adding your variables to the module. bash Copy $ terraform plan Step 3 of 5 Reusing a module You can reuse your module connecting to a New Relic policy that already exists. Before you start, in your New Relic account, create a new alert policy named Preexisting Policy. Connecting an existing alert policy First, In your root main.tf file add the data block to import an existing policy: data \"newrelic_alert_policy\" \"ExistingPolicy\" { name = \"Preexisting Policy\" } Copy Next, create a second module block name HostConditions2. Add the alert conditions to the Preexisting Policy. module \"HostConditions2\" { source = \"./modules/HostConditions\" policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module and run 'terraform apply' to apply the changes to your New Relic account. The terraform scripts create a new alert policy and two conditions, but it also applies the alert conditions to the Preexisting Policy. Look in your New Relic account at the Preexisting Policy and see alerts conditions added for CPU Hot and High Disk Usage. Step 4 of 5 Store a module in Github After you have created a module, if you want to store the module somewhere other people can use, Github is how you can do it. Create a new Github repo First, inside of your HostModules directory, initialize a new Github repo. Add your main.tf and provider.tf to the stage for commit: bash Copy $ git add main.tf provider.tf $ git commit -m \"init\" Next, using the commands provided in your new repo, push your commit to Github: bash Copy $ git remote add origin <repo_url> $ git branch -M main $ git push -u origin main Using a module saved on Github Check the Github repo and see the main.tf and provider.tf are now in your repo. Copy the GitHub repo's web URL to clone your repo. Update the root main.tf file using GitHub as the source for the HostConditions: module \"HostConditions\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } module \"HostConditions2\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module. When you run terraform init, Terraform clones the repository locally. Run terraform plan If you need to update your local module with updates made to the git repo, run terraform get -update Step 5 of 5 Manage state remotely in Amazon S3 The state file is the representation that terraform holds about the created resources. The state file is in the root directory, but if deleted or corrupted would cause trouble. Storing the state file remote provides security and allows sharing and remote access. In the provider.tf in the root directory, add a terraform backend block for Amazon S3: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" } } Copy Variables are needed to provide the correct S3 bucket details, and access is required. To give access to the S3 bucket in your Amazon account, create an IAM user. Give the IAM user access to the S3 bucket storing the terraform state. Add the profile to the terraform backend block: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" profile = \"<iam_user_profile_name>\" } } Copy Before saving your state to Amazon S3, destroy the current configurations to start from a clean slate: bash Copy $ terraform destroy Initialize Terraform, run Terraform init: bash Copy $ terraform init In the terminal, the output shows the backend initialized as S3. Delete the local state as it is not needed bash Copy $ rm terraform.* Run terraform apply to apply your Terraform configuration changes. bash Copy $ terraform apply The state file is now stored in S3 instead of locally. Look in your S3 bucket and see the terraform state exists. Conclusion Congratulations! You're using modules to make your terraform configuratiions more flexible. Review the New Relic Terraform provider documentation to learn how you can take your configuration to the next level.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.87198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Store a module in <em>Github</em>",
        "body": " CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config &amp;&amp; cd terraform-config To follow the examples in this gude, the accompanying example code is available on <em>GitHub</em> bash Copy $ <em>git</em> clone https:&#x2F;&#x2F;<em>github</em>.com&#x2F;jsbnr&#x2F;nr-terraform-intro-example.<em>git</em> Step 1 of 5 Creating"
      },
      "id": "6091fa98e7b9d2063e506919"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Github labels",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Get around GitHub",
      "updated_at": "2021-06-20T21:50:17Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of our organization. If you're not sure, treat someone as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review issues and PRs in this column, then drag them to the appropriate column. If the issue/PR is labeled eng, go ahead and click its ellipses icon to archive it. For other issues and PRs, add the correct labels. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jiras, but reference Jiras by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a Browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Github labels Every issue needs these labels: Always add content Add one of the pg_* labels (see this internal doc ) Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optional: Jira’d: Issues that have a corresponding Jira ticket. Every pull request needs these labels: Always add content Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer. Optional: Jira’d: Issues that have a corresponding Jira ticket. Check the edit history of a doc or file There are two options two check the history of a file: Option 1: githistory.xy Go to a specific file in GitHub itself. Example: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx In the url, replace github.com with github.githistory.xyz. Example: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx It will take you to a site with the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 2: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.66632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get around <em>GitHub</em>",
        "sections": "Get around <em>GitHub</em>",
        "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team <em>GitHub</em> board to track the status of issues and pull requests (PR). Who is who in an issue&#x2F;PR? <em>GitHub</em> keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR"
      },
      "id": "60c6a916196a67e82b5e1604"
    }
  ],
  "/docs/style-guide/writer-workflow/peer-editor-workflow": [
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-06-25T22:58:39Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 106.20239,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "&#x2F;ssl&#x2F;certs&#x2F;ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509&#x2F;name $ActionSendStreamDriverPermitted<em>Peer</em> *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl"
      },
      "id": "603e7d6764441f1a774e88a0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-26T04:05:47Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.01772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tech Writer <em>workflow</em>",
        "sections": "Tech Writer <em>workflow</em>",
        "body": "This document will guide you through the entire <em>workflow</em> for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text <em>editor</em>) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Github labels",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Get around GitHub",
      "updated_at": "2021-06-20T21:50:17Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of our organization. If you're not sure, treat someone as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review issues and PRs in this column, then drag them to the appropriate column. If the issue/PR is labeled eng, go ahead and click its ellipses icon to archive it. For other issues and PRs, add the correct labels. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jiras, but reference Jiras by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a Browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Github labels Every issue needs these labels: Always add content Add one of the pg_* labels (see this internal doc ) Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optional: Jira’d: Issues that have a corresponding Jira ticket. Every pull request needs these labels: Always add content Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer. Optional: Jira’d: Issues that have a corresponding Jira ticket. Check the edit history of a doc or file There are two options two check the history of a file: Option 1: githistory.xy Go to a specific file in GitHub itself. Example: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx In the url, replace github.com with github.githistory.xyz. Example: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx It will take you to a site with the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 2: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.86669,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "As tech doc writers (TW) we edit docs, do <em>peer</em> edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue&#x2F;PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR"
      },
      "id": "60c6a916196a67e82b5e1604"
    }
  ],
  "/docs/style-guide/writer-workflow/tech-writer-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1236.2538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Peer editor <em>workflow</em>",
        "sections": "Peer editor <em>workflow</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the <em>Tech</em> <em>Writer</em> <em>workflow</em> doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing <em>workflow</em> in GitHub If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Github labels",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Get around GitHub",
      "updated_at": "2021-06-20T21:50:17Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of our organization. If you're not sure, treat someone as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review issues and PRs in this column, then drag them to the appropriate column. If the issue/PR is labeled eng, go ahead and click its ellipses icon to archive it. For other issues and PRs, add the correct labels. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jiras, but reference Jiras by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a Browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Github labels Every issue needs these labels: Always add content Add one of the pg_* labels (see this internal doc ) Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optional: Jira’d: Issues that have a corresponding Jira ticket. Every pull request needs these labels: Always add content Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer. Optional: Jira’d: Issues that have a corresponding Jira ticket. Check the edit history of a doc or file There are two options two check the history of a file: Option 1: githistory.xy Go to a specific file in GitHub itself. Example: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx In the url, replace github.com with github.githistory.xyz. Example: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx It will take you to a site with the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 2: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 119.58271,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: <em>Writer</em> needs PR review PRs from <em>Tech</em> Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers"
      },
      "id": "60c6a916196a67e82b5e1604"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-25T17:04:43Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.71175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6042220e64441f28b64e8843"
    }
  ],
  "/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark": [
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-03-16T09:10:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.36235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Code</em> examples",
        "sections": "<em>Code</em> examples",
        "body": " Markdown-style indented <em>code</em> <em>formatting</em>, as this can cause unexpected <em>formatting</em> problems. Highlight user input with &lt;<em>var</em>&gt; Use the &lt;<em>var</em>&gt; tag to highlight areas of a <em>code</em> block where a user is expected to supply their own value. For more context on when to use &lt;<em>var</em>&gt; tags, see &lt; <em>var</em>&gt; <em>formatting</em> <em>guidelines</em>"
      },
      "id": "6042212b28ccbc7c9eeba772"
    },
    {
      "sections": [
        "Bold or code, not italics",
        "Tip"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-06-25T17:04:42Z",
      "updated_at": "2021-03-16T14:49:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths. Tip If you have a UI object (page, tab, etc.) that also has link formatting, then you don't need to add the bold formatting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.86308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bold or <em>code</em>, not italics",
        "sections": "Bold or <em>code</em>, not italics",
        "body": " <em>format</em> text in our docs with italics. Here are more specific <em>guidelines</em> our team uses. For this... Bold <em>Code</em> Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Custom instrumentation via attributes (.NET)",
        "Requirements and recommendations",
        "Transactions called within transactions",
        "Example: Calling Transaction in an already-started transaction",
        "Create a new non-web transaction",
        "Create a new web transaction",
        "Add detail to existing transactions with Trace",
        "Properties for [Transaction]",
        "Web",
        "Read forum posts about instrumentation",
        "Use other API functions"
      ],
      "title": "Custom instrumentation via attributes (.NET)",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Custom instrumentation"
      ],
      "external_id": "68ae52e48b04bfe2279bcd038778cc5eebf53d1d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/custom-instrumentation/custom-instrumentation-attributes-net/",
      "published_at": "2021-06-26T04:11:24Z",
      "updated_at": "2021-05-15T18:25:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's .NET agent provides several options for custom instrumentation. Custom instrumentation allows you to instrument parts of your app that are not instrumented automatically. This document describes how to instrument your app by decorating the methods in your app code with attributes. Use the Transaction attribute to create a custom transaction. You can also mark the custom transaction as a web transaction with the attribute's Web property. Use the Trace attribute to add custom instrumentation to methods that are invoked within a preexisting transaction. Requirements and recommendations Requirements include: .NET agent version 6.16.178.0 or higher. You must be willing to modify your source code. If you cannot or do not want to modify your source code, use custom instrumentation via XML. Your project must have a reference to NewRelic.Api.Agent.dll (for example, installing the package and placing using NewRelic.Api.Agent; in your code). This package is in the NuGet gallery. The Transaction and Trace attributes must be applied to concrete implementations of methods. They cannot be applied on interfaces or super class method definitions. Transactions called within transactions Methods decorated with the [Transaction] attribute will only create a new transaction when one does not already exist. When a method decorated with [Transaction] is called from within a previously started transaction, it will be treated as the [Trace] attribute instead, and will provide more information about the existing transaction. Example: Calling Transaction in an already-started transaction During the execution of this console application, OuterMethod will be called first and create a new transaction. The InnerMethod is called from within the transaction started by OuterMethod, so it will not create a new transaction. Instead, information about the execution of InnerMethod will be tracked as if the [Trace] attribute had been applied. static void Main(string[] args) { OuterMethod(); } [Transaction] public void OuterMethod() { InnerMethod(); } [Transaction] public void InnerMethod() { } Copy Create a new non-web transaction To start a non-web transaction (also known as a background request) with the Transaction attribute: [Transaction] public void Run() { // your background task } Copy For details about why to use either web or non-web, see Classify as web or non-web. Create a new web transaction To tell the agent to mark a non-web task as a web browser transaction, use either of these options: Set the Web property of the Transaction attribute to true. Set the transaction's URI with SetTransactionUri(). [Transaction(Web = true)] public void Run() { var uri = new Uri(\"http://www.mydomain.com/path\"); NewRelic.Api.Agent.NewRelic.SetTransactionUri(uri); // your web task } Copy When used inside a previously started transaction, this will be treated as a [Trace] attribute. For details about why to use either web or non-web, see Classify as web or non-web. Add detail to existing transactions with Trace If your transaction traces show large blocks of un-instrumented time and you want to include additional methods within the trace, you can use the Trace attribute: [Trace] protected void MethodWithinTransaction() { // your app code } Copy Properties for [ Transaction] The Transaction attribute supports the following properties: Web Type: Boolean Default: false If true, the agent starts a web transaction when it reaches this Transaction attribute. If a transaction is in progress, then that transaction will continue. If false (default), the agent starts a non-web transaction when it reaches this Transaction attribute. For example: [Transaction(Web = true)] Copy Read forum posts about instrumentation For more specific recommendations, check out these posts in our Explorers Hub community: Troubleshoot attribute-based custom instrumentation issues Build custom instrumentation tracer factories from .NET agent log files Use other API functions For more about the .NET agent API and its functionality, see New Relic's .NET agent API guide. For custom instrumentation without modifying your source code, see Create transactions via XML and Add detail to transactions via XML.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.66311,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Requirements <em>and</em> recommendations",
        "body": " a new web transaction To tell the agent to <em>mark</em> a non-web task as a web browser transaction, use either of these options: Set the Web property of the Transaction attribute to true. Set the transaction&#x27;s URI with SetTransactionUri(). [Transaction(Web = true)] public void Run() { <em>var</em> uri = new Uri"
      },
      "id": "6043cd9528ccbcfe1e2c60aa"
    }
  ],
  "/docs/style-guide/writing-guidelines/create-edit-content": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-25T18:15:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 419.3278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> <em>and</em> <em>edit</em> categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and <em>edit</em> <em>content</em>. To learn how to <em>create</em> and publish release notes, see <em>Create</em> release notes. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/modal/",
      "sections": [
        "Modal",
        "Usage",
        "Examples",
        "Props"
      ],
      "published_at": "2021-06-27T01:56:18Z",
      "title": "Modal",
      "updated_at": "2021-06-25T01:50:51Z",
      "type": "developer",
      "external_id": "d0b0ddbfd4564c59b6711dcc5d6f9a17cdc5acd2",
      "document_type": "page",
      "popularity": 1,
      "body": "Modals are used for single-step create, add, edit, or delete actions. They are also used to display additional metadata about a screen or specific object on the screen. Usage import { Modal } from 'nr1' Copy Examples Props ariaLabelledBystring Pass the string of the text content which should better describe the purpose of the modal to be correctly announced by screen readers. childrennode Content to render inside the modal. classNamestring Appends class names to the component. hiddenboolean DEFAULT false If true, the modal is hidden. onCloserequiredfunction Callback fired when clicking on the Modal's close button. onHideEndfunction Callback fired when the Modal finishes the closing animation. Use this to unmount the Modal component. This ensures that the closing animation works properly. onHideStartfunction Callback fired when the Modal starts the closing animation. onShowEndfunction Callback fired when the Modal finishes the opening animation. onShowStartfunction Callback fired when the Modal starts the opening animation. styleobject Inline style for custom styling. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.955765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Modals are used for single-step <em>create</em>, add, <em>edit</em>, or delete actions. They are also used to display additional metadata about a screen or specific object on the screen. Usage import { Modal } from &#x27;nr1&#x27; Copy Examples Props ariaLabelledBystring Pass the string of the text <em>content</em> which should better"
      },
      "id": "6091f8ce28ccbc5e71a2689c"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Issues with content",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-06-25T22:29:11Z",
      "updated_at": "2021-06-20T14:34:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Issues with content When adding charts you may come across these issues: Error message Description Something went wrong while executing your query. There was an unexpected error while fetching the data. Try again in a few minutes. If this persists, contact support. Your query either timed out or we're under heavy load. Navigate to https://support.newrelic.com/ for further assistance. NRDB is experiencing heavy loads, which cause intermittent time-outs. Try again in a few minutes. You are not authorized to query account 2022412 You don’t have access to this account. Contact your admin for further assistance. External Service 'NRDB' execution resulted in 400 - cause: TIMESERIES step size is larger than the current time window. The TIMESERIES step size is larger than the selected time window. Modify the step and run the query again. NerdGraphGetAuthorizedAccountsCommand short-circuited and fallback disabled. Communication failed while we were authorizing the request. Try again in a few minutes. TIMESERIES supports a maximum of 366 buckets The TIMESERIES bucket size is too low to span all the selected time window. Modify the bucket size and run the query again. Query rejected due to inspected count limit exceeded by this query group. You’ve exceeded your querying limits. Check out our data usage limits and policies per account. No application was matched (did you specify appId, appName or entity.guid?) No entity matched the query. Review the specified appId, appName or entity.guid and run the query again. External Service 'NRDB' execution resulted in 400 - cause: Your query's start time must be before its end time. The provided startTime of the query must be before the endTime. Modify it and run the query again. Validation error on 'nrql': a query must be specified You need to provide a valid NRQL query. Learn more about our query language. NRQL Syntax Error: Error at line 1 position 15, unexpected 'FROM' FACET and TIMESERIES are not supported on events. Your query has syntax issues. Review it in the query builder to find the error. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.1152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Add custom <em>content</em> using the markdown <em>editor</em>",
        "tags": "Explore <em>and</em> query data",
        "body": " the dashboard&#x27;s guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: <em>Edit</em> your dashboard Use the <em>edit</em> button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. <em>Create</em> new <em>content</em> by clicking"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/style-guide/writing-guidelines/docs-translation": [
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-06-25T22:33:39Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.735737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Translation</em> from PromQL-style queries",
        "body": ", or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy <em>Translation</em> from PromQL-style queries When applicable"
      },
      "id": "603e8a2528ccbc56e5eba774"
    },
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-06-25T18:17:02Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 54.73046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "You can&#x27;t just hit the edit button <em>docs</em>.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home page changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    },
    {
      "sections": [
        "iOS and tvOS crash reporting",
        "dSYM files",
        "Debug the crash reporter",
        "Disable crash reporting"
      ],
      "title": "iOS and tvOS crash reporting",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "b2b79e6f9e78f6113bb20032c674996c746e14d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/ios-tvos-crash-reporting/",
      "published_at": "2021-06-25T23:14:20Z",
      "updated_at": "2021-03-16T09:52:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For Mobile version 4 or higher, New Relic produces crash reports for your mobile applications. When an iOS or tvOS application crashes, the operating system creates a crash report and stores it on the device. New Relic uploads this report the next time the app launches. Using this report and any relevant dSYM files, the crash report includes the complete stack trace with human-readable information. You can then log into New Relic and see each crash, including the method and line where it crashed, plus device and environment details. dSYM files When you create a release build of an iOS or tvOS application, the names of methods and classes are stripped, leaving only machine-readable memory addresses. When the application crashes, the stack trace consists of this machine-readable code. A dSYM file is an Xcode project file for debug symbols. It contains the debugging symbols that allow for translation of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more information, see Retrieve and download dSYMs or Upload dSYM files. Debug the crash reporter Crash reporting is enabled by default, but there are some circumstances where it will be disabled: If the debugger is enabled: There can only be one uncaught exception handler registered at a time per application. If running with the debugger attached, New Relic will not capture and report crashes. If another crash reporter is enabled: If another uncaught exception handler is registered after New Relic starts, this error message is logged: The New Relic exception handler has been replaced. This may result in crashes no longer reporting to New Relic. Copy Disable crash reporting To disable New Relic crash reporting, call the following API method: Language Procedure Objective-C Call prior to [NewRelic startWithApplicationToken:...]; [NewRelic disableFeatures:NRFeatureFlag_CrashReporting]; Copy Swift Call prior to NewRelic.start(withApplicationToken:) NewRelic.disableFeatures(NRMAFeatureFlags.NRFeatureFlag_CrashReporting) Copy For more information about this call, see the NewRelic.h file. For more on applicable feature flags, see the NewRelicFeatureFlags.h file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 42.84096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for <em>translation</em> of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more"
      },
      "id": "603ec58128ccbc9b51eba7d2"
    }
  ],
  "/docs/style-guide/writing-guidelines/five-questions-help-write-docs": [
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if you’re looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You won’t have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and there’ll be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.46048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send Prometheus metric data <em>to</em> New Relic",
        "sections": "Prometheus OpenMetrics or remote <em>write</em> integration?",
        "body": "This page provides an overview of New Relic&#x27;s Prometheus integration options and how they work. The information here will <em>help</em> you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote <em>write</em> integration? We currently offer two"
      },
      "id": "603ea41964441f0d824e8874"
    },
    {
      "sections": [
        "Alert quality management tutorial",
        "The Problem",
        "Desired Outcome",
        "Overview",
        "Key Performance Metrics",
        "Incident Volume",
        "Summary",
        "Volume - Incident Count",
        "Volume - Accumulated Incident Duration",
        "Volume - Mean-Time-To-Close (MTTC)",
        "Volume - Percent Under Five Minutes",
        "User Engagement",
        "User Engagement - Percentage Incidents Acknowledged",
        "User Engagement - Mean Time to Investigate",
        "Required Knowledge",
        "Establishing Current State",
        "Install and configure incident event webhook.",
        "Install the AQM Dashboard",
        "Perform Initial AQM Orientation / Enablement",
        "Accumulate AQM Data",
        "Perform Second Enablement Session",
        "Improvement Process",
        "Value Realization",
        "KPI Reference",
        "Volume - Incidents Duration",
        "Volume - Mean-Time-to-Close",
        "Incident Engagement"
      ],
      "title": "Alert quality management tutorial",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Tutorials",
        "Alerts and Applied Intelligence"
      ],
      "external_id": "f6197aa3a2ce7e8bad779c94fea9c36ee4bcdf22",
      "image": "https://docs.newrelic.com/static/0670e81749bd4d12599dec1868e2f4f7/5b481/aqm-tutorial-webhook.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/alerts-applied-intelligence/alert-quality-management-tutorial/",
      "published_at": "2021-06-25T23:50:10Z",
      "updated_at": "2021-06-25T12:03:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Problem Teams suffer from alert fatigue when they are subject to high alert volumes and alerts that are not aligned to business impact. This situation will condition responders to believe that most alerts are false, will cause them to prioritize easy to resolve alerts over others, and may drive them to close unresolved incidents so they can stay within their SLA targets. Overall, these behaviors will result in slower incident response, which will magnify issue scope and severity when true business impacting issues occur. Alert Quality Management (AQM) focuses on reducing the number of nuisance incidents so that only alerts with true business impact are asserted. This reduces alert fatigue and ensures that attention is focused on the right places at the right times. You are a good candidate for AQM if any of the following are true: You have too many alerts. You have alerts that are asserted for long time periods. Your alerts are not relevant. You perceive that customers discover your issues before your monitoring tools do. You can’t see the value of your observability tool(s). Desired Outcome Overview An alert strategy based on measuring business impact will result in faster response times and greater proactive awareness of critical events. An improved alert signal to noise ratio reduces confusion and improves rapid identification and problem isolation. AQM’s overall goal is to ensure that fewer, more valuable, incidents are created, resulting in increased uptime and availability and reduced MTTR. As you move towards this goal, alert volume will decrease and alerts that are not valuable will be identified and either made valuable or removed. The AQM process described in this guide will generate the key performance metrics that you will use to measure progress towards these goals. Those KPIs will be used to drive a continuous improvement process that identifies and reduces nuisance alerts and increases user engagement in incident investigation. Those business metrics are measured in real time in the AQM dashboard. AQM is intended to improve the value of existing alert configurations and to detect known or expected modes of failure. It does not encompass anomaly detection or AIOps, which are designed to detect unknown or unexpected modes of failure. The two practices (AQM and ML/AI) work hand in hand, they are not mutually exclusive. Key Performance Metrics AQM measures the following KPIs: Incident volume: Incident Count Accumulated incident time Mean Time to Close (MTTC) Percent Under 5 Minutes User Engagement: Mean Time to Investigate (MTTI) % of Incidents Investigated Detailed information on each metric follows. Incident Volume Summary Incidents (with or without alerts) should be treated like a queue of tasks and, just like a queue, the number of alerts should spend time near zero. For each incident, an action should be taken to resolve the condition. If an alert does not result in action, then the value of the alert condition should be questioned. If you see a constant rate of incidents or specific incidents that are “always-on”, you should question why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs help you to answer those questions and to measure progress towards a healthy state of high quality alerting. Volume - Incident Count Description Incident Count is the number of incidents generated over a period of time. Typically you should compare the current and previous weeks. Goal Reduce the number of low value / nuisance incidents. Best Practices Ensure condition settings are intended to detect real business impact. See “Service Level Objectives” [link tbd] . Ensure condition settings are detecting abnormal behavior. Communicate that the incident details “Acknowledge” feature helps measure meaningful and actionable alerts. See “Percent Investigated KPI” [link tbd] . Report AQM KPIs to all stakeholders. Volume - Accumulated Incident Duration Description Accumulated incident duration is the total sum of minutes that all the incidents accumulated over a period of time. Typically you should compare the current and previous weeks. Goal Reduce the total accumulated minutes of incidents. Best Practices Do not manually close incidents. Manual closure will skew the real duration of incident length. Eliminate alerts that do not result in any remediation actions from the recipients. Improve percent investigated and mean-time-to-investigate KPIs (below) by communicating their importance in improving detection and response time. Report AQM KPIs to all stakeholders. Volume - Mean-Time-To-Close (MTTC) Description Average duration of incidents within the period of time measured. Goal Reduce MTTC. Best Practices Do not manually close incidents. Manual closure will skew the real duration of incident length. Improve Reliability Engineering skills [link tbd] . Report AQM KPIs to all stakeholders. Volume - Percent Under Five Minutes Description Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. Goal Minimize percentage of incidents with short durations. Best Practices Ensure that conditions are detecting legitimate deviations from expected behavior. See Baselining and Service Level Management [links tbd] . Ensure that conditions are detecting legitimate deviations that correlate to business impact or impending business impact. User Engagement Summary The value of an incident is measured by whether or not it engages the attention of the relevant incident response team(s). Engagement in this context is measured by whether or not an incident has been acknowledged. The amount of engagement an individual alert receives is a direct measurement of its value. More engagement implies a valuable alert, less (or zero) engagement implies a nuisance alert that should be modified or disabled. It is important to understand that there is a significant difference between measuring the moment of incident awareness vs. acknowledging the moment resolution activity begins. If you are using an integration with New Relic Alerting, be sure that the “acknowledge” event that is sent to New Relic is triggered when resolution activity begins, not when the incident is sent to the external incident management tool. For more information regarding the standard Incident Management process, see Incident Management Process: 5 Steps to Effective Resolution Posted on August 31, 2020 by OnPage Corporation. -- in reference to ITIL4. User Engagement - Percentage Incidents Acknowledged Description Incidents acknowledged identifies the percentage of incidents that had their acknowledged property set to true. Typically you should compare the current and previous weeks. Goal Increase the percentage of users engaging incident details. Best Practices Educate the DevOps team on when it is appropriate to acknowledge an incident alert. Gamify alert acknowledgement to drive usage. Discourage mass acknowledgement exercises. User Engagement - Mean Time to Investigate Description Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. Goal Reduce the mean time to investigate. Best Practices Work at building incident responder’s confidence in alerts. Ensure that valuable alerts are acknowledged. Incentivize response teams to respond quickly to alerts. Required Knowledge Implementers of this use case should have basic knowledge of the topics itemized below. NR1 Alert Policy and Conditions configuration NR1 Incident Notification Channel Webhook configuration NR1 NRQL NR1 Alerting Best Practices NR1 APM & Infrastructure How to baseline data in order to determine anomalies vs. normal behavior. NOTE: It’s highly recommended that all attendees complete the New Relic University (NRU) Overview Course or have equivalent experience. Establishing Current State As with any continuous improvement process, the first step of AQM is to establish the current state of your KPIs. To do so, perform the following tasks: Install and configure incident event webhook. In this task, you should do the following: Identify your primary production account and each of your accounts that you will be analyzing with the AQM process. Install the Incident Event webhook into each account that will participate in the AQM process and configure the webhook to report nrAQMIncident events to your primary production account. Assign the webhook as a notification channel to every alert policy in each account. This example shows a webhook notification for each account. The webhook will create New Relic events corresponding to each incident as it proceeds through its lifecycle (open, acknowledge, close). It is critical that this webhook be associated as a notification channel for each and every alert policy. Failure to do so will reduce or eliminate the value of the AQM process. NOTE: AQM requires the use of incident, not violation data. The out of box NrAiIncident event provides violation data only and must not be used to drive this process. As of December 2020, the NR Detection Team has not yet integrated acknowledged events into NrAiIncident. It’s anticipated that the NrAiIssue event type will contain this required event at some point in 2021. In the meantime, we must still manually establish a webhook to send the required data to New Relic. Full webhook instructions can be found at: https://source.datanerd.us/amazzarellafaria/observability-maturity (VPN Required). Install the AQM Dashboard Install the AQM dashboard into the primary production account you identified in the task above. The AQM dashboard is the primary asset that drives the AQM process. To achieve this, do the following: Download the dashboard definition JSON file. Import the definition into your primary production account. For more details on importing dashboards, see the New Relic documentation at this link. Perform Initial AQM Orientation / Enablement During this phase, your incident management team(s) and other stakeholders will learn the goals of the AQM process and the scope of their involvement in it. The most critical portion of this task is that your team is properly educated on the importance of acknowledging incident alerts, since that is how the alert’s value is determined. In general, they should be instructed to follow these guidelines: If you look at an alert and decide to take any sort of further investigative action, it should be acknowledged. If there are alerts that you normally close without doing anything else, they should NOT be acknowledged Do not start closing or acknowledging incident alerts that are “always-on”. For further details, see Second Enablement Session below. Training materials can be found at this link. Accumulate AQM Data The overall process requires at least two weeks of data before it can proceed. You should periodically check the following items: Confirm that incident alert event data is accumulating. Confirm that the webhook is attached to every alert policy. Ensure that DevOps teams are following the alert acknowledgement guidelines. Perform Second Enablement Session During this phase, you will introduce incident management teams and other stakeholders to the initial AQM data and the ongoing continuous improvement process you’ll be following. The process consists of four activities: Review AQM Dashboard and KPI Trending - Here you and the stakeholders will look at the AQM KPIs and identify their week over week trends. The team should identify areas where KPIs are not improving and develop strategies to drive improvement. Identify Achievements, Challenges, and Opportunities - Here you and the stakeholders will map the current state of alert quality to business impact, identifying areas where improvement has resulted in better business outcomes and areas where problems are impacting business outcomes Incident Policy Review - Using the AQM dashboard, you and the stakeholders will identify the noisiest incident policies. Once identified, those policies should be evaluated as detailed in step 4 below. Recommendations - In this step, you and the stakeholders will review the noisiest policies using the following criteria: a. Do the alerts have any business impact? b. Are the policies properly configured? i. Are they telling us something about the resource that needs to be fixed? ii. Are the policies necessary? (i.e. do they have business impact) iii. Are the thresholds set properly? c. Have any technical issues been discovered? i. Are there application / system problems for engineering to review? ii. Are there poorly constructed policies that need to be fixed? iii. Are there instrumentation gaps? Further enablement for this step can be found.... Improvement Process This is the ongoing phase of the continuous improvement process where the AQM data is reviewed as outlined above and adjustments are made to alert policies. The KPIs should be reported each week to upper management to ensure that the stakeholder teams are appropriately prioritizing the work and to show that progress towards the promised business outcomes are being reached. Weekly KPIs should be recorded and retained over periods of months to years to establish a baseline and to show the rate of improvement. Value Realization At the end of the AQM process, you should see significant reductions in the volume of alerts while reliability and stability remain the same or improve. In addition, alerts that are asserted should have a clear and unambiguous business impact. The AQM KPIs should bear out these improvements. Once you are firmly on the path to AQM’s goals, you should consider moving to other OMA workflows within the UPR value stream (such as Service Level Management) or to new OMA value streams, such as Customer Experience. KPI Reference Following are the descriptions of each KPI as well as sample NRQL queries that will extract them from the New Relic platform. Incident Volume Volume - Incident Count Description Incident Count is the number of incidents generated over a period of time. By default we look at one week compared with the previous week. NRQL FROM nrAQMIncident SELECT count(*) AS 'Incident Count' WHERE current_state='open' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy Volume - Incidents Duration Description Incident Duration is the total sum of minutes that all the incidents accumulated over a period of time. The default is one week compared with the previous week. NRQL FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy Volume - Mean-Time-to-Close Description Average duration of incidents within the period of time measured. NRQL FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy Volume - Percent Under Five Minutes Description Percentage of incidents where the duration of the incident is under five minutes. This can be an indicator of incident flapping. NRQL FROM nrAQMIncident SELECT sum(duration)/(1000*60) AS 'Incident Minutes' WHERE current_state='closed' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy Incident Engagement User Engagement - Percentage Incidents Acknowledged Description Incidents acknowledged identifies the percentage of incidents that had their acknowledged property set to true. Typically you should compare the current and previous weeks. NRQL FROM nrAQMIncident SELECT filter(count(*), WHERE current_state='acknowledged')/filter(count(*), WHERE current_state='open')*100 AS '% Investigated' WHERE severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy User Engagement - Mean Time to Investigate Description Mean time to investigate identifies the average time it takes for an incident to be triaged. Typically you should compare the current and previous weeks. NRQL FROM nrAQMIncident SELECT average(duration/(1000*60)) AS 'Incident MTTI (minutes)' WHERE current_state='acknowledged' AND severity='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.397285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Volume - Percent Under <em>Five</em> Minutes",
        "body": " be questioned. If you see a constant rate of incidents or specific incidents that are “always-on”, you should <em>question</em> why. Are you in a constant state of business impact, or do you simply have a large volume of noise? The alert volume KPIs <em>help</em> you to answer those <em>questions</em> and to measure progress towards"
      },
      "id": "60d5c61c28ccbcb90171b43b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/prometheus-remote-write-integration/",
      "sections": [
        "Prometheus remote write integration",
        "Why it matters",
        "Compatibility",
        "Scale your data and get moving quickly",
        "What's next",
        "For more help"
      ],
      "published_at": "2021-06-25T16:03:03Z",
      "title": "Prometheus remote write integration",
      "updated_at": "2021-03-16T13:34:27Z",
      "type": "docs",
      "external_id": "d8ceefcb13b66e0a17973b0aca68ea3cc71ca403",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the Prometheus remote write integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about five minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which scrape data from Prometheus endpoints, the remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. You can leverage the full range of options for setup and management, from raw data to queries and dashboards and beyond. With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional) Compatibility New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Scale your data and get moving quickly Once logged in to New Relic, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. View your data. What's next Ready to get started? Read the setup documentation. Configure a Prometheus data source in Grafana. Set up the integration on New Relic US EU For more help Recommendations for learning more: See the Docs site's landing page for Infrastructure integrations documentation. Browse New Relic's Explorers Hub for community discussions about our Infrastructure integrations. Find additional help or file a support ticket. Review New Relic's licenses, attributions, data usage limits, and other notices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.35179,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Prometheus remote <em>write</em> integration",
        "sections": "Prometheus remote <em>write</em> integration",
        "body": "You can use the Prometheus remote <em>write</em> integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about <em>five</em> minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which"
      },
      "id": "603e94dee7b9d2dfd22a07f9"
    }
  ],
  "/docs/style-guide/writing-guidelines/formatting-terminal-commands": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Important",
        "Reset the 'build the docs site' build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-26T04:00:15Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Important The only checks needed to merge a PR are the checks marked as required on the PR. These are run linter, run tests, license/cla, and unpaired translations removed for merges to develop, and build the docs site for merges to main. If a required check fails, the failure must be addressed in order for the PR to be merged. If an optional check fails, reach out in the help channel so that the hero can look into the failure, but feel free to merge the PR since optional checks don't block releases. Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the 'build the docs site' build check Caution This adds a LOT of time to the build check. There are times when this check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.58393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the <em>command</em> line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this <em>command</em> prompts you for a passphrase, your SSH was somehow confused. By entering your"
      },
      "id": "60c6a94f64441f5ac491f8a7"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark/",
      "sections": [
        "Code formatting guidelines: var and mark",
        "var: Highlight user-specific values in procedural code snippets",
        "var format examples",
        "Important",
        "mark: Emphasize non-procedure code snippets"
      ],
      "published_at": "2021-06-26T04:05:46Z",
      "title": "Code formatting guidelines: var and mark",
      "updated_at": "2021-05-16T11:16:42Z",
      "type": "docs",
      "external_id": "dc9b222917947481942168f4004e4401f517b9dd",
      "document_type": "page",
      "popularity": 1,
      "body": "This document serves as a supplement to the basic <var> and <mark> documentation. It gives a longer explanation of when to use the <var> and <mark> formatting styles, and reasons for not using them. var: Highlight user-specific values in procedural code snippets The <var> tag is used for user-input values in code snippets that customers would be using in procedural/functional ways. For example, you would use the <var> tag when explaining how to do some specific task. A <var> tag would not be used for: Example code: If the code is meant to be an example, to show the format/structure of the code, and there is not an actual procedure the customer is following, var tags are not needed. Examples: Example configuration file (or this Java agent config template): if you are showing an example config file that isn't part of a procedure, you shouldn't use the <var> tag. Several reasons for this: 1) The important part of showing an example config file is to show the overall structure of the file, 2) Usually the number of config options present in a file will vary based on whatever the customer wishes to use, so using <var> tags can actually be confusing as it implies that these values must be present. Instrumentation procedure (at bottom of the Java section): the var tag wouldn't be necessary because it's an example, not part of a procedure, and the main goal is seeing the general structure. Also, because it's an example of app code, the concept of user-specific values doesn't have much meaning, because the entire code will vary dependent on how the customer has written their code. (If anything, this would be a potential for using <mark> format to emphasize the New Relic functions.) Response/output code: If the code is meant to show an expected return, and is not related to a procedure, then var tags shouldn't be used. Here's a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both <var> formatting and without it, see the Synthetics monitors REST API example. The first block shows a command they might choose to run, hence it uses a <var> tag. The second block is just an example output, showing the structure that would be returned; it doesn't require a <var> tag. For some use cases, highlighting may be a better choice than a var tag. var format examples Below are some general style recommendations for formatting user-specific <var> values. <var> tag formatting may vary based on language- or system-specific expectations, so be sure check the style used in the documentation section in question, and to ask relevant SMEs what they think of the style. Account IDs and other IDs/#s: YOUR_ACCOUNT_ID, YOUR_API_CODE, etc. This should be the general style used. URLs: example.com, or maybe YOUR_URL Paths: PATH/TO/SOMETHING.exe or maybe PATH_TO_FILE Emails: datanerd@example.com or maybe YOUR_EMAIL Bash variables for REST API code: Some <var> tagged code values on the docs site have the form $ { API_KEY}. This is a format used for variables in bash scripts, where users assign values to specific variable names and then call those variables later in the script by using the $VARIABLE_NAME. For more info, see this explanation of bash variables. Important The bash variable style is currently used in the REST API docs and in some Synthetics docs and that's fine. But going forward we should use the general variable style (without the $ and &lt; >). mark: Emphasize non-procedure code snippets Highlighting (<mark>) is used for when you want to draw attention to a variable or value, but it's not something directly procedural related. Here are two examples of highlighting: Highlighting values in code response that are meant for later use: Activate Azure integrations doc. Highlighting the commands in a large code block example that are New Relic-specific commands, with explanations below: Java API doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.56428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Code <em>formatting</em> guidelines: var and mark",
        "sections": "Code <em>formatting</em> guidelines: var and mark",
        "body": " to a procedure, then var tags shouldn&#x27;t be used. Here&#x27;s a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both &lt;var&gt; <em>formatting</em> and without it, see the Synthetics monitors REST API example. The first block shows a <em>command</em> they might choose to run, hence"
      },
      "id": "6042219c64441f52d94e889e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-26T04:05:47Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.2864,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " was cloned by navigating to your local GitHub folder (the default is ~&#x2F;Documents&#x2F;github). Once you have cloned the repo, you don&#x27;t need to clone it again in the future. Run the site locally Build the site locally using the <em>terminal</em> to preview changes before opening a Pull Request. While it&#x27;s highly"
      },
      "id": "60c6a91764441f404d91f8c6"
    }
  ],
  "/docs/style-guide/writing-guidelines/hyperlinks": [
    {
      "sections": [
        "Link your applications to Kubernetes",
        "Tip",
        "Compatibility and requirements",
        "Kubernetes requirements",
        "Network requirements",
        "APM agent compatibility",
        "Openshift requirements",
        "Important",
        "Configure the injection of metadata",
        "Default configuration",
        "Custom configuration",
        "Manage custom certificates",
        "Validate the injection of metadata",
        "Disable the injection of metadata",
        "Troubleshooting"
      ],
      "title": "Link your applications to Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "2ae58989813695b48f4924529d6fd6ea17e5f6c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes/",
      "published_at": "2021-06-26T14:09:48Z",
      "updated_at": "2021-05-28T06:30:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can surface Kubernetes metadata and link it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which is currently a beta release. This Pixie integration into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our Kubernetes metadata injection project is open source. Here's the code to link APM and infrastructure data and the code to automatically manage certificates. Compatibility and requirements Before linking Kubernetes metadata to your APM agents, make sure you meet the following requirements: Kubernetes requirements Network requirements APM agent compatibility OpenShift requirements Kubernetes requirements To link your applications and Kubernetes, your cluster must have the MutatingAdmissionWebhook controller enabled, which requires Kubernetes 1.9 or higher. To verify that your cluster is compatible, run the following command: kubectl api-versions | grep admissionregistration.k8s.io/v1beta1 admissionregistration.k8s.io/v1beta1 Copy If you see a different result, follow the Kubernetes documentation to enable admission control in your cluster. Network requirements For Kubernetes to speak to our MutatingAdmissionWebhook, the master node (or the API server container, depending on how the cluster is set up) should be allowed egress for HTTPS traffic on port 443 to pods in all of the other nodes in the cluster. This might require specific configuration depending on how the infrastructure is set up (on-premises, AWS, Google Cloud, etc). Tip Until Kubernetes v1.14, users were only allowed to register admission webhooks on port 443. Since v1.15 it's possible to register them on different ports. To ensure backward compatibility, the webhook is registered by default on port 443 in the YAML config file we distribute. APM agent compatibility The following New Relic agents collect Kubernetes metadata: Go 2.3.0 or higher Java 4.10.0 or higher Node.js 5.3.0 or higher Python 4.14.0 or higher Ruby 6.1.0 or higher .NET 8.17.438 or higher Openshift requirements To link Openshift and Kubernetes you must enable mutating admission webhooks, which requires Openshift 3.9 or higher. During the process, install a resource that requires admin permissions to the cluster. Run this to log in as admin: oc login -u system:admin Copy Check that webhooks are correctly configured. If they are not, update the master-config.yaml file. admissionConfig: pluginConfig: MutatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission ValidatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission location: \"\" Copy Important Add kubeConfigFile: /dev/null to address some issues in Openshift. Enable certificate signing by editing the YAML file and updating your configuration: kubernetesMasterConfig: controllerArguments: cluster-signing-cert-file: - \"/etc/origin/master/ca.crt\" cluster-signing-key-file: - \"/etc/origin/master/ca.key\" Copy Restart the Openshift services in the master node. Configure the injection of metadata By default, all the pods you create that include APM agents have the correct environment variables set and the metadata injection applies to the entire cluster. To check that the environment variables have been set, any container that is running must be stopped, and a new instance started (see Validate the injection of metadata). This default configuration also uses the Kubernetes certificates API to automatically manage the certificates required for the injection. If needed, you can limit the injection of metadata to specific namespaces in your cluster or self-manage your certificates. Default configuration To proceed with the default injection of metadata, follow these steps: Download the YAML file: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-latest.yaml Copy Custom configuration You can limit the injection of metadata only to specific namespaces by using labels. To enable this feature, edit your YAML file by finding and uncommenting the following lines: # namespaceSelector: # matchLabels: # newrelic-metadata-injection: enabled Copy With this option, injection is only applied to those namespaces that have the newrelic-metadata-injection label set to enabled: kubectl label namespace YOUR_NAMESPACE newrelic-metadata-injection=enabled Copy Manage custom certificates To use custom certificates you need a specific YAML file: Download the YAML file without automatic certificate management: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-custom-certs-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-custom-certs-latest.yaml Copy Once you have the correct YAML file, you can proceed with the custom certificate management option. You need your certificate, server key, and Certification Authority (CA) bundle encoded in PEM format. If you have them in the standard certificate format (X.509), install openssl, and run the following: openssl x509 -in CERTIFICATE_FILENAME -outform PEM -out CERTIFICATE_FILENAME.pem openssl x509 -in SERVER_KEY_FILENAME -outform PEM -out SERVER_KEY_FILENAME.pem openssl x509 -in CA_BUNDLE_FILENAME -outform PEM -out BUNDLE_FILENAME.pem Copy If your certificate/key pair are in another format, see the Digicert knowledgebase for more help. Create the TLS secret with the signed certificate/key pair, and patch the mutating webhook configuration with the CA using the following commands: kubectl create secret tls newrelic-metadata-injection-secret \\ --key=PEM_ENCODED_SERVER_KEY \\ --cert=PEM_ENCODED_CERTIFICATE \\ --dry-run -o yaml | kubectl -n default apply -f - caBundle=$(cat PEM_ENCODED_CA_BUNDLE | base64 | td -d '\\n') kubectl patch mutatingwebhookconfiguration newrelic-metadata-injection-cfg --type='json' -p \"[{'op': 'replace', 'path': '/webhooks/0/clientConfig/caBundle', 'value':'${caBundle}'}]\" Copy Important Certificates signed by Kubernetes have an expiration of one year. For more information, see the Kubernetes source code in GitHub. Validate the injection of metadata In order to validate that the webhook (responsible for injecting the metadata) was installed correctly, deploy a new pod and check for the New Relic environment variables. Create a dummy pod containing Busybox by running: kubectl create -f https://git.io/vPieo Copy Check if New Relic environment variables were injected: kubectl exec busybox0 -- env | grep NEW_RELIC_METADATA_KUBERNETES NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME=fsi NEW_RELIC_METADATA_KUBERNETES_NODE_NAME=nodea NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME=default NEW_RELIC_METADATA_KUBERNETES_POD_NAME=busybox0 NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME=busybox Copy Disable the injection of metadata To disable/uninstall the injection of metadata, use the following commands: Delete the Kubernetes objects using the yaml file: kubectl delete -f k8s-metadata-injection-latest.yaml Copy Delete the TLS secret containing the certificate/key pair: kubectl delete secret/newrelic-metadata-injection-secret Copy Troubleshooting Follow these troubleshooting tips as needed. No Kubernetes metadata in APM or distributed tracing transactions Problem The creation of the secret by the k8s-webhook-cert-manager job used to fail due to the kubectl version used by the image when running in Kubernetes version 1.19.x, The new version 1.3.2 fixes this issue, therefore it is enough to run again the job using an update version of the image to fix the issue. Solution Update the image k8s-webhook-cert-manager (to a version >= 1.3.2) and re-run the job. The secret will be correctly created and the k8s-metadata-injection pod will be able to start. Note that the new version of the manifest and of the nri-bundle are already updated with the correct version of the image. Problem In OpenShift version 4.x, the CA that is used in order to patch the mutatingwebhookconfiguration resource is not the one used when signing the certificates. This is a known issue currently tracked here. In the logs of the Pod nri-metadata-injection, you'll see the following error message: TLS handshake error from 10.131.0.29:37428: remote error: tls: unknown certificate authority TLS handshake error from 10.129.0.1:49314: remote error: tls: bad certificate Copy Workaround Manually update the certificate stored in the mutatingwebhookconfiguration object. The correct CA locations might change according to the cluster configuration. However, you can usually find the CA in the secret csr-signer in the namespace openshift-kube-controller-manager. Problem There is no Kubernetes metadata included in the transactions' attributes of your APM agent or in distributed tracing. Solution Verify that the environment variables are being correctly injected by following the instructions described in the Validate your installation step. If they are not present, get the name of the metadata injection pod by running: kubectl get pods | grep newrelic-metadata-injection-deployment kubectl logs -f pod/podname Copy In another terminal, create a new pod (for example, see Validate your installation), and inspect the logs of the metadata injection deployment for errors. For every created pod there should be a set of 4 new entries in the logs like: {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.107Z\",\"caller\":\"server/main.go:139\",\"msg\":\"POST https://newrelic-metadata-injection-svc.default.svc:443/mutate?timeout=30s HTTP/2.0\\\" from 10.11.49.2:32836\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.110Z\",\"caller\":\"server/webhook.go:168\",\"msg\":\"received admission review\",\"kind\":\"/v1, Kind=Pod\",\"namespace\":\"default\",\"name\":\"\",\"pod\":\"busybox1\",\"UID\":\"6577519b-7a61-11ea-965e-0e46d1c9335c\",\"operation\":\"CREATE\",\"userinfo\":{\"username\":\"admin\",\"uid\":\"admin\",\"groups\":[\"system:masters\",\"system:authenticated\"]}} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:182\",\"msg\":\"admission response created\",\"response\":\"[{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env\\\",\\\"value\\\":[{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME\\\",\\\"value\\\":\\\"adn_kops\\\"}]},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NODE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"spec.nodeName\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME\\\",\\\"value\\\":\\\"busybox\\\"}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_IMAGE_NAME\\\",\\\"value\\\":\\\"busybox\\\"}}]\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:257\",\"msg\":\"writing response\"} Copy If there are no new entries on the logs, it means that the apiserver is not being able to communicate with the webhook service, this could be due to networking rules or security groups rejecting the communication. To check if the apiserver is not being able to communicate with the webhook you should inspect the apiserver logs for errors like: failed calling webhook \"metadata-injection.newrelic.com\": ERROR_REASON Copy To get the apiserver logs: Start a proxy to the Kubernetes API server by the executing the following command in a terminal window and keep it running. kubectl proxy --port=8001 Copy Create a new pod in your cluster, this will make the apiserver try to communicate with the webhook. The following command will create a busybox. kubectl create -f https://git.io/vPieo Copy Retrieve the apiserver logs. curl localhost:8001/logs/kube-apiserver.log > apiserver.log Copy Delete the busybox container. kubectl delete -f https://git.io/vPieo Copy Inspect the logs for errors. grep -E 'failed calling webhook' apiserver.log Copy Remember that one of the requirements for the metadata injection is that the apiserver must be allowed egress to the pods running on the cluster. If you encounter errors regarding connection timeouts or failed connections, make sure to check the security groups and firewall rules of the cluster. If there are no log entries in either the apiserver logs or the metadata injection deployment, it means that the webhook was not properly registered. Ensure the metadata injection setup job ran successfully by inspecting the output of: kubectl get job newrelic-metadata-setup Copy If the job is not completed, investigate the logs of the setup job: kubectl logs job/newrelic-metadata-setup Copy Ensure the CertificateSigningRequest is approved and issued by running: kubectl get csr newrelic-metadata-injection-svc.default Copy Ensure the TLS secret is present by running: kubectl get secret newrelic-metadata-injection-secret Copy Ensure the CA bundle is present in the mutating webhook configuration: kubectl get mutatingwebhookconfiguration newrelic-metadata-injection-cfg -o json Copy Ensure the TargetPort of the Service resource matches the Port of the Deployment's container: kubectl describe service/newrelic-metadata-injection-svc kubectl describe deployment/newrelic-metadata-injection-deployment Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.15028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Link</em> your applications to Kubernetes",
        "sections": "<em>Link</em> your applications to Kubernetes",
        "tags": "<em>Link</em> apps and services",
        "body": "You can surface Kubernetes metadata and <em>link</em> it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which"
      },
      "id": "603ebb94196a674fd1a83df3"
    },
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "41eee9dfacd933b49935d7bd4d32cb76476c29ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-06-25T18:13:15Z",
      "updated_at": "2021-03-10T23:41:36Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.82778,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "URL <em>guidelines</em>",
        "tags": "API writing <em>guidelines</em>",
        "body": "Syntax newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name[, integer $optional_param]) newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the &quot;View all methods&quot; page. Requirements Agent"
      },
      "id": "60441b8d28ccbc0ab22c60b3"
    },
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "a3fb036bc32f2dbc39c252acc9306e5ae0d5b7bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/api-tutorial-template/",
      "published_at": "2021-06-25T18:13:15Z",
      "updated_at": "2021-03-10T23:40:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What NR products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.82773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "API writing <em>guidelines</em>",
        "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content <em>link</em> in the Page tools box. Delete all content up to Introduction (this heading won&#x27;t be visible"
      },
      "id": "60441b4a64441f7766378f09"
    }
  ],
  "/docs/style-guide/writing-guidelines/levels-headings": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-25T18:15:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 482.3803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " it. Describe any limitations with user permissions or subscription <em>levels</em> that would prevent them from using the feature. If the feature is available for any user or subscription <em>level</em>, don&#x27;t bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting"
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.56033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use sentence case in <em>headings</em>",
        "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document&#x27;s title, <em>headings</em>, products, features, and other elements"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/five-questions-help-write-docs/",
      "sections": [
        "Five questions to help write docs",
        "There's really only 1Q",
        "5Qs and sub-questions",
        "1. Did you use or observe the thing you are writing about?",
        "2. Is this the best place to put this information?",
        "3. Can readers tell in ten seconds if they are in the right place?",
        "4. Is the information in the best possible format?",
        "5. Is the language approachable, expert, and visionary?"
      ],
      "published_at": "2021-06-26T04:08:04Z",
      "title": "Five questions to help write docs",
      "updated_at": "2021-06-14T18:19:44Z",
      "type": "docs",
      "external_id": "14fd5c4efd0e8aa26e04d97ae61da33eef9489ee",
      "document_type": "page",
      "popularity": 1,
      "body": "Our five questions form the core of how our Tech Docs team thinks about writing excellent technical documentation. Informally, we call these our 5Qs. Anyone can contribute to our Docs site. We want you to feel confident and proud that your contributions provide valuable content and quality. We also want our readers to trust and easily use the information in our docs. To help you plan, write, and edit excellent docs, ask yourself the questions in this doc. There's really only 1Q The 5Qs exist to help answer one question. Whenever you write a doc, ask yourself: What problem are we trying to solve? It's critical you know what you're trying to do and why that goal matters to your readers. Asking the five questions (and the sub-questions!) will help you ensure you're building the right thing. 5Qs and sub-questions Each of the five questions includes sub-questions to help guide your thinking. 1. Did you use or observe the thing you are writing about? Think about who your audience is and the level of complexity they need. End users' point of view Ask yourself: Audience Do you know who is reading your document (dev/ops teams, support personnel, non-technical staff, etc.)? Can you articulate what this thing is (feature, procedure) and why it matters to our customers? For conceptual info, did you interview multiple stakeholders? Testing Put yourself in the user's shoes. For example: Did you use the thing on your own? Did you watch a subject matter expert use the thing? If you can't do it on your own or observe, did you send the draft to at least three SMEs? Before publishing Did you compare the final version of your text against the thing you're writing about? 2. Is this the best place to put this information? Think about where this information belongs. Where does this information belong? Ask yourself: What problem are you trying to solve? Is text always the best answer? Does this doc need to exist at all? For example: Are we duplicating content from somewhere else in the Docs site? Are we duplicating content already in the UI? Could customers have a better experience if we modified the UI design or copy instead of creating a doc? Would another web property be a better home for this information? For example: The Explorers Hub? NRU course? NRU video embedded into the doc? The public New Relic blog? The public New Relic website? 3. Can readers tell in ten seconds if they are in the right place? Think about what the content is and what you can do to make the information easy to skim to find information. Can users skim to find information? Ask yourself: Title and headings Does the title accurately represent what's in the doc? Do the headings accurately represent what's in the doc? Do the title and headings use words the way your readers do? Do the title and headings avoid New Relic jargon? Structure Does the overall structure of the doc help readers find what they're looking for? Is the doc trying to address too many topics? When you glance at the doc, do you see short paragraphs, short sentences, and other visual aids? Or do you see a dense wall of text? Introduction Does the intro give a concise synopsis of what's in the doc? Does the intro give readers an alternate path if they're in the wrong place? 4. Is the information in the best possible format? Think about how to present the information visually. Presentation of information Ask yourself: Visual formats Did you use visual formats appropriately? Would a screenshot make any of the information easier to understand? Does your image caption clearly explain what matters so that the user does not necessarily even need to read the surrounding text? Would a diagram make any of the information easier to understand? Is there a video we could embed to make things clearer? Can step-by-step UI procedures be replaced with a \"show me\" video? Procedures Are your procedures well-structured? Do step-by-step UI procedures even need to be documented? Did you limit the procedural text to action steps and omit detailed explanatory text or edge cases? If detailed explanations need to enhance a procedure, have you organized the info in a way that expert users can skip the details? Text flow Read your draft more than once. Is the documentation direct and to the point? Did you use bullets, tables, or clamshells to improve flow? 5. Is the language approachable, expert, and visionary? Think about why the information matters and why readers will trust and use it. For tips to make it easier for users to read, understand, and use documentation, go to plainlanguage.gov. Also, if you are a New Relic employee, we encourage you to review the corporate brand guidelines. For more information, contact Marketing. Effective language Ask yourself: Readers' point of view Did you tell users why as well as how? Can you articulate not only what this thing is (feature, procedure) and also why it matters to our customers? Did you include useful examples or use cases? Did you include information about relationships this feature has to other New Relic platform tools? Style guide resources Did you follow our style guide? Did you use our edit checklist? Did you use pronouns, contractions, and a conversational tone throughout? Did you review the usage dictionary and other resources in the style guide to make sure that terms are used correctly? Readability Is the text easy to read? Is the language clear? Do you have to reread any sentences or paragraphs to understand them? If so, can you simplify the wording and sentence structure? Does the doc score 40 or better on the Flesch-Kinkaid reading ease scale? If not, try taking another pass at the prose. But don't chase the Flesch-Kincaid score in itself: we're not out to frustrate ourselves, but to write docs that are a pleasure to read. Where to go from here Did you offer readers a clear \"next step\" in each section? If it is necessary to tell a user not to do something, did you also tell them what to do instead? Is the topic complete? Is the doc actionable?",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.12208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". 1. Did you use or observe the thing you are writing about? Think about who your audience is and the <em>level</em> of complexity they need. End users&#x27; point of view Ask yourself: Audience Do you know who is reading your document (dev&#x2F;ops teams, support personnel, non-technical staff, etc.)? Can you"
      },
      "id": "60421ef3196a676926a83d81"
    }
  ],
  "/docs/style-guide/writing-guidelines/more-help-section": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/dropdown-section/",
      "sections": [
        "DropdownSection",
        "Usage",
        "Props",
        "Type definitions",
        "Cursor"
      ],
      "published_at": "2021-06-27T02:04:03Z",
      "title": "DropdownSection",
      "updated_at": "2021-06-25T01:58:30Z",
      "type": "developer",
      "external_id": "013f52f99c588b0e1205778bf08efcece91c363c",
      "document_type": "page",
      "popularity": 1,
      "body": "Section of <Dropdown> component. Usage import { DropdownSection } from 'nr1' Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed inside (or returned by the render callback) are of type <DropdownItem>. The recommendation is to use the render callback when a large number of items is provided, since the item list will be virtualized by the component, thus increasing the performance. classNamestring Appends class names to the component. Should be used only for positioning and spacing purposes. itemsarray Items to render, in the shape of a list of objects. Usually, each item in the items array contains the required data to generate the corresponding <DropdownItem>. This prop is required when rendering items with the render callback (function as children). onLoadMorefunction Callback fired when more items must be loaded. This happens when you're lazy loading the items and the items that are about to render cannot be found in the items array. This callback should be used to fetch/load the missing items from the backend or other sources. The returned Promise should be resolved once item data has finished loading. It will be used to determine when to refresh the list with the newly-loaded data. This callback may be called multiple times in reaction to a single scroll event. function ( cursor : Cursor // Items to load. ) rowCountnumber Number of rows. By default it's equal to length of array passed in the items prop. You should specify the rowCount when you know the total number of items but you want to lazy load them while scrolling. styleobject Inline style for custom styling. Should be used only for positioning and spacing purposes. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests. titlestring DEFAULT \"\" Section title. Type definitions Cursor { startIndex : number, // First index of the range of items to load. stopIndex : number, // Last index of the range of items to load. }",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 76.431915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "<em>Section</em> of &lt;Dropdown&gt; component. Usage import { Dropdown<em>Section</em> } from &#x27;nr1&#x27; Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed"
      },
      "id": "6091f874e7b9d283a05068f0"
    },
    {
      "sections": [
        "Install the browser monitoring agent",
        "Tip",
        "Select a deployment option",
        "Important",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Troubleshoot Browser agent installation"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-06-25T17:43:53Z",
      "updated_at": "2021-06-14T21:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet (or \"agent\") to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. Tip To use Browser and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Select a deployment option No matter which option you use to deploy browser monitoring, the end result is to inject the browser agent's JavaScript snippet into your pages for browser monitoring. The method you select depends on your preferences and business needs. To view the procedure to install and enable the browser agent, click the link for the option you want to use. You can also use the Browser Application settings page to update settings. Important The following configuration options refer only to the browser monitoring agent. These are not the same as the New Relic user roles and editions. Browser deployment option Description Use the APM agent to inject the JavaScript You can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that already is being monitored by APM. (APM-monitored apps are listed on your APM Applications index.) Paste the JavaScript snippet into a webpage This allows you to control the exact placement of the JavaScript into your app's webpage(s) by copying and pasting the browser agent's JavaScript snippet. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Enable single-page app (SPA) monitoring Enabling SPA requires a Pro + SPA browser agent subscription, and you may need to re-deploy the browser JavaScript agent. Use the REST API The REST API lets you manage deployment outside the browser UI. This is useful for large organizations deploying multiple apps. Use an APM agent API to manually instrument the JavaScript snippet For apps that are monitored by APM, you can use the APM agent's API to inject the JavaScript manually instead of automatically. Enable an APM-monitored app Use this procedure to automatically deploy the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Enable via New Relic APM. In the Choose your instrumentation section, select Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Select your application section, type or use the search window to find an app's name. Click Enable. Important Node.js: To finish enabling the browser agent for a Node.js app, follow the additional procedure to insert the JavaScript header into the beginning of your HTML page's head tag. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. Enable with copy/paste Use this procedure to insert browser's JavaScript snippet for browser monitoring into your app's webpages yourself. This option is useful for monitoring static sites (such as Jekyll) or cached pages delivered by CDN. Tip Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Copy/Paste JavaScript Code. In the Choose your instrumentation section, select the type of agent: Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Name your app section, name your app: If your app is monitored by APM, select Yes, then type or use the search window to find the app's name. If you have a standalone app for Browser (not monitored by APM), select No, then type the app's name. Click Enable. A new section, Instrument the agent, opens on the page with JavaScript code for your project. Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. If you use the copy/paste method, but don't finish the setup process, you can still view and copy the generated JavaScript snippet from your app's Browser Application settings page or by using the REST API (v2). Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. New Relic's agents can instrument webpages with the required JavaScript for page load timing. If you use the APM agent to add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Troubleshoot Browser agent installation When you enable browser Pro features for session traces, AJAX calls, or JavaScript errors, it may take approximately five minutes before information becomes available. If you have problems with your browser installation or if no data appears after five minutes, refer to the troubleshooting tips, and restart your agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 60.708405,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add <em>more</em> data. In the Back-end, front-end, and mobile applications <em>section</em>, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "sections": [
        "Incident Intelligence destination examples",
        "Destination template examples",
        "Suggested OpsGenie template example",
        "Suggested ServiceNow template example",
        "Suggested Slack template example",
        "Suggested VictorOps template example",
        "Webhook and JSON format examples",
        "Webhook Names and Descriptions",
        "Jinja2 Default Payload",
        "Jinja2 Useful Syntax"
      ],
      "title": "Incident Intelligence destination examples",
      "type": "docs",
      "tags": [
        "Alerts and Applied Intelligence",
        "Applied intelligence",
        "Incident intelligence"
      ],
      "external_id": "a516d04f8b75541a6dc9338fa3ce9645ba87d620",
      "image": "",
      "url": "https://docs.newrelic.com/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/incident-intelligence-destination-examples/",
      "published_at": "2021-06-25T19:05:31Z",
      "updated_at": "2021-06-25T19:05:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Destinations are the data outputs to Applied Intelligence, where you can view your automatically correlated incidents. You can configure Incident Intelligence destinations to send data to PagerDuty or webhooks. This document gives examples of destination templates, webhook formats, and JSON formats. Destination template examples The following template example destinations are formatted in Jinja2. Suggested OpsGenie template example { \"alias\": {{ id }}, \"message\": {{ ui_name }}, \"source\": '{{ sources }}', \"priority\": {{ priority }}, \"details\": { \"self_url\": {{ url }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"is_correlated\": {{ is_correlated }} }, \"description\": \"\"\"Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]\"\"\" } Copy Suggested ServiceNow template example { \"short_description\": {{ ui_name }}, \"description\": 'Issue Id: {{ id }}, \\n Description: {{ description }}, \\n Sources: {{ sources }}, \\n Priority: {{ priority }}, \\n Details: { \\n self_url: {{ url }}, \\n state: {{ state }}, \\n is_correlated: {{ is_correlated }}, \\n created_on: {{ created_on }}, \\n modified_on: {{ modified_on }}, \\n activated_on: {{ active_since }}, \\n closed_on: {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \\n is_correlated: {{is_correlated}} }, \\n\\n incidents: {{ incidents }}, \\n\\n pathways: {{ pathways }}' } Copy Suggested Slack template example Go to Slack incoming WebHooks Choose the right Slack workspace and click \"Add to Slack\" Select the destination channel to receive the notifications to Click “Add Incoming WebHooks Integration” Copy the WebHook URL In the next screen, click “Save settings” at the bottom. In New Relic Applied Intelligence, under Incident Intelligence click Destinations Add a WebHook In the end point paste the WebHook url from slack. In the custom payload, paste the following JSON: { \"blocks\": [ { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*New Relic Incident Intelligence Alert*\" } }, { \"type\": \"divider\" }, { \"type\": \"section\", \"text\": { \"type\": \"mrkdwn\", \"text\": \"*CUSTOM FIELDS*:\" }, \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue ID*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Issue Title*\" }, { \"type\": \"plain_text\", \"text\": {{ id }} }, { \"type\": \"plain_text\", \"text\": {{ ui_name }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Issue URL*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Description*\" }, { \"type\": \"mrkdwn\", \"text\": {{ url }} }, { \"type\": \"plain_text\", \"text\": {{ description }} } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*State*\" }, { \"type\": \"mrkdwn\", \"text\": \"*is_correlated*\" }, { \"type\": \"plain_text\", \"text\": {{ state }} }, { \"type\": \"plain_text\", \"text\": \"{{ is_correlated }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Created On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Modified On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ created_on }}\" }, { \"type\": \"plain_text\", \"text\": \"{{ modified_on }}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Activated On*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Closed On*\" }, { \"type\": \"plain_text\", \"text\": \"{{ active_since }}\" }, { \"type\": \"plain_text\", \"text\": \"{% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}\" } ] }, { \"type\": \"section\", \"fields\": [ { \"type\": \"mrkdwn\", \"text\": \"*Aggregated Incidents*\" }, { \"type\": \"mrkdwn\", \"text\": \"*Monitoring Tool*\" }, { \"type\": \"plain_text\", \"text\": \"{{ incident_count }}\" }, { \"type\": \"plain_text\", \"text\": {{ sources|join(', ') }} } ] } ] } Copy Suggested VictorOps template example { \"monitoring_tool\": {{ sources }}, {% if state == 'closed' %} \"message_type\": \"OK\", {% else %} \"message_type\": {{ priority }}, {% endif %} \"custom_fields\": { \"issue_url\": {{ url }}, \"description\": {{ description }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"activated_on\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"related_incidents\": [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %} {% endfor %} ] }, \"state_message\": {{ description }}, \"entity_id\": {{ id }}, \"entity_display_name\": {{ ui_name }}, \"vo_annotate.u.NRAI_Link\": {{ url }} } Copy Webhook and JSON format examples Applied Intelligence will send the event body in JSON format via HTTPS POST. The system expects the endpoint to return a successful HTTP code (2xx). If you use webhooks to configure Incident Intelligence destinations, use these examples of the webhook body and JSON format. Webhook Names and Descriptions Webhook format: Name Description url Href A link to the UI where the issue can be seen. id String Unique identifier for the issue. title String The issue title. description String The description of the issue. priority Enum The issue priority. Can be Critical, High, Medium, or Low. state Enum The issue status. Can be Active, Closed, or Acknowledged. is_correlated Boolean True if the issue is based on correlated data. created_on String The date and time the issue was created (in ISO format). modified_on String The date and time the issue was modified (in ISO format). active_since String The date and time the issue was activated (in ISO format). closed_on String The date and time the issue was closed (in ISO format). sources List(String) List of the different sources that were used to send the events into Applied Intelligence (for example: PagerDuty). pathways List(Pathways) List of pathways that are associated with the issue. Each pathway contains an id and name: [{“id”: “pathway id”, “name”: “pathway name”}]. pathways[].id String The pathway ID. pathways[].name String The pathway name. incidents List(Incident) List of incidents that are attached to the issue. The list contains only the latest 100 incidents. incidents[].id String The incident ID. incidents[].events_count Integer The number of events used to create the incident. incidents[].title String The incident title. incidents[].description String The incident description. incidents[].labels Dictionary (String) A string to string mapping of the incident labels. Labels represent the unique entities that are used to describe the incident. incidents[].priority Enum The incident priority. Can be Critical, High, Medium, or Low. incidents[].sources List(String) The incident source. incidents[].state Enum(open, closed) The incident state. incidents[].opened_on String The date and time the incident was opened (in ISO format). incidents[].closed_on String The date and time the incident was closed (in ISO format). ui_name String Issue title. accumulations['alert/signal'] String Issue analysis summary golden signal/s (if applicable). accumulations['alert/components'] String Issue analysis summary golden components (if applicable). Jinja2 Default Payload Applied Intelligence uses a templating framework called Jinja2 in the Webhook interface. Here is a default Jinja2 payload to use: { \"id\": {{ id }}, \"url\": {{ url }}, \"ui_name\": {{ ui_name }}, \"description\": {{ description }}, \"priority\": {{ priority }}, \"state\": {{ state }}, \"is_correlated\": {{ is_correlated }}, \"created_on\": {{ created_on }}, \"modified_on\": {{ modified_on }}, \"active_since\": {{ active_since }}, \"closed_on\": {% if closed_on is defined %} {{ closed_on }} {% else %} None {% endif %}, \"sources\": {{ sources }}, \"incidents\": {{ incidents }}, \"pathways\": {{ pathways }}, } Copy Jinja2 Useful Syntax Below are a few useful Jinja2 commands to help you format your output. Casting a value to integer Example: “severity”: {{ priority | int }} Copy If clause to check if an attribute’s value is set Example: \"golden_signals\": {% if accumulations['alert/signal'] is defined %} {{ accumulations['alert/signal'] }} {% else %} None {% endif %} Copy For loop to iterate of an array of values: Example: \"description\": 'Incidents [ {% for incident in incidents %} { \"id\": {{ incident.id }}, \"events_count\": {{ incident.events_count }}, \"labels\": {{ incident.labels }}, \"title\": {{ incident.title }}, \"description\": {{ incident.description }}, \"state\": {{ incident.state }}, \"sources\": {{ incident.sources }}, \"modified_on\": {{ incident.modified_on }}, \"opened_on\": {{ incident.opened_on }}, \"closed_on\": {{ incident.closed_on }} } {% if not loop.last %},{% endif %}{% endfor %} ]' Copy Check if an array attribute's value is set: Example: \"hostname_field\": {% if incidents[0].labels['newrelic/tag/hostname'] is defined %} {{ incidents[0].labels['newrelic/tag/hostname'] }} {% else %} None {% endif %} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 60.074696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Webhook and JSON <em>format</em> examples",
        "body": " from slack. In the custom payload, paste the following JSON: { &quot;blocks&quot;: [ { &quot;type&quot;: &quot;<em>section</em>&quot;, &quot;text&quot;: { &quot;type&quot;: &quot;mrkdwn&quot;, &quot;text&quot;: &quot;*New Relic Incident Intelligence Alert*&quot; } }, { &quot;type&quot;: &quot;divider&quot; }, { &quot;type&quot;: &quot;<em>section</em>&quot;, &quot;text&quot;: { &quot;type&quot;: &quot;mrkdwn&quot;, &quot;text&quot;: &quot;*CUSTOM FIELDS*:&quot; }, &quot;fields&quot;: [ { &quot;type"
      },
      "id": "6044280d64441f4af5378ed3"
    }
  ],
  "/docs/style-guide/writing-guidelines/pricing-language-guidelines": [
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and account/user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "Account/user models explained",
        "Requirements for new account/user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-06-26T03:56:04Z",
      "updated_at": "2021-06-26T03:56:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer account/user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained Account/user models explained How to switch to the new models Overview of how pricing plan and account/user model relate In 2020, we released both a new, improved pricing plan and a new, improved account/user model. These models represent the future, and eventually all New Relic organizations will be on these models. But currently, our older customers may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new account/user model. This table shows how pricing and user model relate to each other: Pricing plan factors Account/user model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One account/user model. If you have an older organization, you have users on the original account/user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (e.g., APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some customers are able to switch to new pricing. Learn more about switching your pricing plan. Account/user models explained In this context, the term \"account/user model\" (or simply \"user model\") refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two account/user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new account/user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and customers using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be surprising or unintuitive to our existing customers: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic customers are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 146.18192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> and user model",
        "sections": "Overview of how <em>pricing</em> plan and account&#x2F;user model <em>relate</em>",
        "tags": "Original accounts and <em>billing</em>",
        "body": " remain on our original user model. Determine <em>pricing</em> plan To determine which <em>pricing</em> plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see <em>billing</em> information about data ingested and the number of billable users, you’re on the new <em>pricing</em> plan"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Tip",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-06-25T16:56:59Z",
      "updated_at": "2021-06-20T02:16:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Tip To use our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, defined as users with access to Full Stack Observability features. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. More user-related billing details: You can see your full user count in the UI. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. For organizations on our original account/user model that have a master/sub-account structure, the count of billable users in the UI may differ from the list of users you see. For more on this, see User count discrepancy. A user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. The Standard edition of the New Relic One pricing plan includes one free full user. Users with duplicate email addresses are only counted once. For organizations on our original user model, a user may be set as a basic user in one account, and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition for Full Stack Observability, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise Full Stack Observability editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.67859,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>pricing</em> and <em>billing</em> ",
        "sections": "New Relic One <em>pricing</em> and <em>billing</em>",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": " of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month <em>bill</em>. For how to query user-<em>related</em> usage, see Query and alert on usage. Usage plan details There are two New Relic One <em>pricing</em> usage plans: Pay-as-you-go: This plan bills"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Query and alert on billing/usage data",
        "Available data types",
        "Query examples",
        "Data usage queries",
        "Daily data usage",
        "Daily usage by source",
        "Metrics ingest by source",
        "Month-to-date data usage",
        "Month-to-date estimated data cost",
        "User count queries",
        "Month-to-date full users",
        "Projected monthly full user count",
        "Count full users and basic users",
        "Set usage alerts",
        "Caution",
        "Ingested gigabytes exceed a fixed value",
        "Usage exceeds fixed threshold for GBs",
        "Usage exceeds fixed threshold for users",
        "Usage exceeds fixed threshold for estimated cost",
        "Available attributes"
      ],
      "title": "Query and alert on billing/usage data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "a214c27cab73c790ac6ce947a0c189db9677d215",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-users/usage-queries-alerts/",
      "published_at": "2021-06-25T16:56:57Z",
      "updated_at": "2021-05-21T14:40:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For accounts on our New Relic One pricing plan, we provide a UI for understanding your New Relic usage and managing your data. Additionally, you can: Query your usage data to get more detail than is available in the UI Set up NRQL alert conditions to get notifications about changes in your usage. Note that account hierarchy may affect queried data. See Account structure. Available data types Usage data is attached to these events: NrConsumption records usage every hour, and is the equivalent of \"real-time\" usage. Use this event to observe usage trends over time. NrMTDConsumption generates aggregate values from the NrConsumption event. Use this event to see usage or estimated cost for a billing period. NrUsage records usage every hour and is used to see usage reported per product. To see changes made to your account (for example, user management changes), you can query NrAuditEvent. Query examples The usage UI displays your data usage and billable user count. But to get more detail, you can use these NRQL queries. For definitions of some of the attributes used in these queries, see Attributes. Data usage queries Here are some data usage query examples: Daily data usage This query totals your billable ingested data, and displays a daily value for the past three months: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago TIMESERIES 1 day Copy Daily usage by source This query totals your billable ingested data, and displays a daily value for the past three months faceted by the source: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago FACET usageMetric TIMESERIES 1 day Copy Metrics ingest by source This query breaks down Metric data by the top ten metric names. You could also facet by appName or host to adjust the analysis. FROM Metric SELECT bytecountestimate()/10e8 as 'GB Estimate' SINCE '2021-04-01' UNTIL '2021-04-08' FACET metricName LIMIT 10 TIMESERIES 1 day Copy Month-to-date data usage This query shows the current full user count. In other words, it shows how much you'd be billed for your data for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE this month Copy Month-to-date estimated data cost This query shows the estimated cost of your ingested data: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy User count queries Here are some user-related query examples. For details on how users are counted, see User count calculations. Month-to-date full users This query shows the billable full users for the month. In other words, it shows how much you'd be billed for your users for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(usersBillable) SINCE this month Copy This query shows how many full users were counted by hour. This is useful for seeing how the full user count changed over time. from NrConsumption SELECT max(FullUsers) SINCE 10 days ago TIMESERIES 1 hour Copy Projected monthly full user count This query shows a projected count of monthly users. This query would not be good for using in a dashboard; it requires values based on a) the days remaining in the month, b) the start of the month. Here's an example querying the projected end-of-month count with 10 days left in that month: FROM NrMTDConsumption SELECT predictLinear(FullUsers, 10 days) SINCE '2020-09-01' Copy Count full users and basic users The usage UI shows the count of full users and basic users. The query used is: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric Copy To see the count of full and basic users over time: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric TIMESERIES 1 hour Copy Set usage alerts To help manage your billable data, you can set alerts to notify you of unexpected increases in usage. Learn how to create alerts with NRQL queries here. Caution When creating alert conditions, you should set the Evaluation offset value to 60 minutes or your conditions may not trigger. Here are some NRQL alert condition examples. For attribute definitions, see Attributes. Ingested gigabytes exceed a fixed value This query will create an alert when your hourly usage exceeds a fixed value: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy If you have multiple sub-accounts, you may want to set threshold alerts for a specific subaccount: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' AND consumingAccountId = YOUR_SUB-ACCOUNT_ID Copy Usage exceeds fixed threshold for GBs This query will create an alert when your usage exceeds fixed monthly threshold for GBs: FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy Usage exceeds fixed threshold for users This query will create an alert when your usage exceeds fixed monthly threshold for billable users: FROM NrMTDConsumption SELECT latest(usersBillable) Copy Usage exceeds fixed threshold for estimated cost This query will create an alert when your usage exceeds fixed threshold for estimated cost: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy Available attributes Below are some of the important attributes attached to usage events. Attribute Description productLine The category of usage. There are four options: DataPlatform, FullStackObservability, IncidentIntelligence, or ProactiveDetection. For more details about these categories, see New Relic platform. metric Consolidates multiple categories of usage into a single metric. Helpful when faceting by productLine. consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. estimatedCost Calculates a cost estimate based on usage and metric cost. This is an estimate of costs to date, not your monthly invoice. For more attributes, see the data dictionary.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.93321,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query and alert on <em>billing</em>&#x2F;usage data",
        "sections": "Query and alert on <em>billing</em>&#x2F;usage data",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": "For accounts on our New Relic One <em>pricing</em> plan, we provide a UI for understanding your New Relic usage and managing your data. Additionally, you can: Query your usage data to get more detail than is available in the UI Set up NRQL alert conditions to get notifications about changes in your usage"
      },
      "id": "6043f69ae7b9d2345b579a09"
    }
  ],
  "/docs/style-guide/writing-guidelines/screenshots-images": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 917.7023,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Products <em>and</em> features",
        "body": ": Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our <em>Screenshots</em> and <em>images</em> document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don&#x27;t capitalize"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 688.0044,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Processes <em>and</em> procedures",
        "body": " sentences, or long paragraphs. Useful <em>images</em> For <em>screenshots</em> and <em>images</em>, check that: Full size <em>images</em> always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped <em>images</em> clearly show their relevance, with or without captions. In addition, make sure"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Update your Nerdpack's catalog information",
        "Update your CLI",
        "Check your permissions",
        "Publish your Nerdpack",
        "Update your Nerdpack's catalog metadata",
        "Update your Nerdpack's icons",
        "Resolve issues with submitting catalog information",
        "Resize your images",
        "Check the length of your strings"
      ],
      "title": "Update your Nerdpack's catalog information",
      "type": "developer",
      "tags": [
        "nerdpack",
        "catalog"
      ],
      "external_id": "dfee75ddee87a216eb9454abcaeabcc1ee0a8c7d",
      "image": "https://developer.newrelic.com/static/4560bce9c6a1165799e6eaf9d10f4868/0086b/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/publish-deploy/catalog/",
      "published_at": "2021-06-27T01:47:45Z",
      "updated_at": "2021-05-21T01:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn to describe your Nerdpack in the catalog",
      "body": "Add screenshots, descriptions, and other metadata to your Nerdpack, and upload it all to the New Relic One catalog. Update your CLI Before you run any commands, ensure that you have the latest version of the CLI: bash Copy $ nr1 update Check your permissions To publish your Nerdpack and update its catalog information, you need: Access to the account that published it The necessary permissions for managing Nerdpacks Publish your Nerdpack You need to publish Nerdpacks that you create before you can update their catalog information. Update your Nerdpack's catalog metadata After you've published your Nerdpack to the New Relic One catalog, update the Nerdpack's metadata to let users know all about your Nerdlets or visualizations. Step 1 of 9 Go to New Relic: Step 2 of 9 Navigate to Apps: Step 3 of 9 Find your published Nerdpack under New Relic One catalog: Notice that there is no information on the Apps or details page other than the Nerdpack's name and the brief description found in nr1.json: There are no screenshots, icons, details, or what's new features. To add these, your Nerdpack needs a catalog directory. Step 4 of 9 From the root of your Nerdpack, create a catalog directory to house your Nerdpack's screenshots and metadata: bash Copy $ nr1 create --type catalog ✔ Component created successfully! catalog is available at \"./catalog\" Inside your catalog directory, you'll find specific files and directories for portraying information about your Nerdpack to your users: bash Copy $ ls catalog README.md additionalInfo.md config.json documentation.md screenshots File Description README.md A markdown file that instructs you how to use the information and metadata in catalog config.json A JSON file that contains the following fields: tagline: A brief headline for the application. This cannot exceed 30 characters. repository: The URL for the Nerdpack's remote repository. This cannot exceed 1000 characters. details: The purpose of the Nerdpack and how to use it. This cannot exceed 1000 characters. Use newlines for formatting, and don't include any markdown or HTML. support: An object that contains: issues: A URL for the repository's issues list. For example, the Issues tab if using GitHub. email: A valid email address for the team supporting the application community: A URL for a support thread, forum, or website for troubleshooting and usage support whatsNew: A bulleted list of changes in the current release version. This cannot exceed 500 characters. Use newlines for formatting, and don't include markdown or HTML. Check out our Pageview Map application's config.json to see a real-life implementation. documentation.md A markdown file that tells users how to use the Nerdpack's Nerdlets or visualizations. This shows in the detail view's Documentation tab. additionalInfo.md An optional markdown file for any additional information about using your application screenshots A directory that contains screenshots of your Nerdlets or visualizations. This can contain no more than 6 images. All screenshots must meet the following criteria: 3:2 aspect ratio PNG format landscape orientation 1600 to 2400 pixels wide Step 5 of 9 Update your Nerdpack's documentation.md file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"\", 3 \"details\": \"\", 4 \"repository\": \"\", 5 \"whatsNew\": \"\", 6 \"support\": { 7 \"email\": { 8 \"address\": \"\" 9 }, 10 \"issues\": { 11 \"url\": \"\" 12 }, 13 \"community\": { 14 \"url\": \"\" 15 } 16 } 17 } catalog/config.json Copy Step 6 of 9 Update your config.json file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Initial commit\" 6 } catalog/config.json Copy Step 7 of 9 Include screenshots in your screenshots directory. Step 8 of 9 Submit the information to the New Relic One catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.0 Step 9 of 9 Go to the catalog to see your changes: Click your Nerdpack to see the new details: Update your Nerdpack's icons Within a Nerdpack, you can set two types of icons: One for your entire Nerdpack, which represents your Nerdpack in the catalog One for each of your launchers, which represents your Nerdlets Replace these icons and publish your Nerdpack to see the changes. Step 1 of 7 Update the icon.png in the root of your Nerdpack. This icon is used in the catalog and the Nerdpack's detail page. Step 2 of 7 If you're building a Nerdpack with one or more launchers, update the icon.png in each of your launcher's subfolders. Step 3 of 7 Update your package.json version: { \"private\": true, \"name\": \"demo-app\", \"version\": \"1.0.1\", \"scripts\": { \"start\": \"nr1 nerdpack:serve\", \"test\": \"exit 0\" }, \"nr1\": { \"uuid\": \"f2dbc999-e9a3-49b9-933d-5a704c6750bd\" }, \"dependencies\": { \"prop-types\": \"^15.6.2\", \"react\": \"^16.6.3\", \"react-dom\": \"^16.6.3\" }, \"browserslist\": [\"last 2 versions\", \"not ie < 11\", \"not dead\"] } package.json Copy This allows you to publish a new version of your Nerdpack. Step 4 of 7 Publish your Nerdpack: bash Copy $ nr1 nerdpack:publish Step 5 of 7 Update your whatsNew string in catalog/config.json: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Add new icons\" 6 } catalog/config.json Copy This will tell users what you added in the latest version of your Nerdpack. Step 6 of 7 Submit this new metadata to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.1 Step 7 of 7 Go to the catalog and subscribe to your Nerdpack to see your new icon: Resolve issues with submitting catalog information Sometimes, when you work with catalog metadata, you may run into issues. Consider some common solutions for resolving these issues. Publish your Nerdpack Remember that you can only submit catalog metadata for Nerdpacks that have already been published. If you try to submit information for a Nerdpack that hasn't been published, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 1 error while updating DemoApp 1.0.0 › › Invalid Version: Nerdpack version 1.0.0 not found. Have you run `nr1 nerdpack:publish` yet? › Code: UNKNOWN Resize your images Screenshots for the catalog must meet the criteria specified previously in this guide. If they don't, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a size ratio of 4:2. Update size ratio to 3:2. › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a width of 3054px. Update size to be between 1600px and 2400px. › Code: UNKNOWN Check the length of your strings Most of the content in config.json has string-length requirements. Make sure you review those requirements and adhere to them when you update your config.json file. Otherwise, you'll see errors when you try to submit your configuration to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/config.json › Invalid Metadata: `details` has a character length of 2204. Must be no longer than 1000 characters › › catalog/config.json › Invalid Metadata: `tagline` has a character length of 266. Must be no longer than 30 characters › Code: UNKNOWN",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.20695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Resize your <em>images</em>",
        "body": " <em>images</em> <em>Screenshots</em> for the catalog must meet the criteria specified previously in this guide. If they don&#x27;t, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading <em>screenshots</em>... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog&#x2F;<em>screenshots</em>&#x2F;<em>screenshot</em>.png › Invalid <em>Screenshot</em>"
      },
      "id": "609c868664441f2bf22f3706"
    }
  ],
  "/docs/style-guide/writing-guidelines/user-related-language-guidelines": [
    {
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new account/user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full)",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "title": "Users, roles, permissions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "published_at": "2021-06-26T13:07:15Z",
      "updated_at": "2021-06-20T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users who are on our original user model. If you were a New Relic customer before July 30 2020, you likely have users on our original user model (and not the New Relic One user model). One way to quickly check your users' user model: if you can see users in the Users and roles UI, those users are on our original user model. Want to learn more about user model changes? See Overview of user models. Updates about our new account/user model In July of 2020, we released a new account/user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more and more pre-existing organizations to the new model. Some organizations with users on the original user model are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original user model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this UI: select the account dropdown, select Account settings, and select Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. When basic users attempt to upgrade to full users, an upgrade request is sent to all admins. For more about our user types, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a master/sub-account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a master account's sub-accounts, go to a master account's Account settings UI page, click on a sub-account, and go to their Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to Full-Stack Observability features (for more details on feature access, see Capabilities). Basic users can request to become full users in the UI. They cannot self-upgrade. Basic users will see prompts when attempting to access unavailable features. Requests to upgrade are sent to all admins on that account. No matter what custom group a basic user is assigned to, they always have the capabilities of a basic user: no more and no less. Full user. Details: Full users have access to our Full-Stack Observability features, which include our curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details on what's available, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user has full user access for all accounts. For how to edit user type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a master account that has sub-accounts automatically have the same level of access for all sub-accounts. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of basic user rights for your New Relic account. Individuals on a master account with sub-accounts automatically have the same level of access for all sub-accounts. However, they will not receive email notifications for alerts or weekly reports for sub-accounts unless they are explicitly granted permission on these sub-accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete sub-accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with New Relic APM. To allow a User or Restricted User to execute any of these functions in New Relic APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions in New Relic Insights, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.65697,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, permissions (original <em>user</em> model)",
        "sections": "<em>Users</em>, <em>roles</em>, permissions (original <em>user</em> model)",
        "tags": "Original <em>users</em> and <em>roles</em>",
        "body": " or Admins To add a new <em>user</em> to your New Relic account: Go to: account dropdown &gt; Account settings &gt; <em>Users</em> and <em>roles</em> &gt; <em>Users</em>. In the upper right corner, click New <em>user</em>. Enter the appropriate name and email address. Select their base <em>role</em> as either Admin, <em>User</em>, or Restricted. Select Add <em>user</em>. The new <em>user</em>"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    },
    {
      "sections": [
        "Add and manage users, groups, and roles",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "User management definitions",
        "Example user management tasks",
        "Add, edit, and delete users",
        "Assign users access to accounts (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes"
      ],
      "title": "Add and manage users, groups, and roles",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/b1c2da968a637f68569e890c8bd72a1c/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-06-25T16:49:32Z",
      "updated_at": "2021-06-25T16:49:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user information, and approve upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts To optimally use our more advanced user management features, it's important to first understand the concept of the \"access grant.\" An access grant gives a group of users access to a) a role and b) an account. For a New Relic organization that has many accounts, groups typically require more than one access grant because users in a group usually need access to multiple accounts and roles. The diagram below explains the elements that make up an access grant. Note that if your organization is on Standard edition and want to assign a user to a default group (Admin or User), you don't need to create an access grant: you would simply add a user to that group and you're done. But for Pro and Enterprise edition, if you're trying to grant users access to a custom group, a custom role, or to other accounts, you must create an access grant. A diagram explaining how you can grant user groups access to roles and accounts. Note that this applies to users on our New Relic One user model (and not our original user model). Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? For smaller, flatter organizations that are okay with full internal transparency, you may only need a couple groups. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). For examples of some common user management tasks, see Example tasks. User management definitions Here are some definitions of our user management terms and how they relate to each other: A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles. Example user management tasks In the Organization and access UI, you can create custom groups, roles, and grant access to user groups. Here are some example user management procedures: Add, edit, and delete users To add or edit users, use the User management UI. To add users: If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Assign users access to accounts (access grants) See our user management tutorial. Create new custom groups and roles See our user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager role. Important Users cannot have only organization-scoped roles assigned; they must also be in a group that has account-scoped roles (for example, the default Admin group). You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can assign those roles to a custom group. From the Organization and access UI: Select Access grants, and choose To this organization. Create an access grant that assigns the Authentication domain manager role to a custom group. From the User management UI, add users to that group. To see a tutorial on creating new groups and roles, see Tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.80742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and manage <em>users</em>, groups, and <em>roles</em>",
        "sections": "Add and manage <em>users</em>, groups, and <em>roles</em>",
        "tags": "New Relic One <em>user</em> management",
        "body": "For <em>users</em> on our New Relic One <em>user</em> model, we provide various <em>user</em> management features, including the ability to: Use <em>role</em> based access control (RBAC) to assign default or custom <em>roles</em> to <em>user</em> groups Create custom <em>user</em> groups Grant <em>user</em> groups access to specific <em>roles</em> and accounts Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-structure/new-relic-account-structure/",
      "sections": [
        "Organization and account structure",
        "Important",
        "New Relic One account/user model",
        "How users access accounts",
        "Original account/user model"
      ],
      "published_at": "2021-06-25T16:55:12Z",
      "title": "Organization and account structure",
      "updated_at": "2021-06-25T16:55:11Z",
      "type": "docs",
      "external_id": "4f5a4cde293d0b599f489eff010f69c021ccb539",
      "document_type": "page",
      "popularity": 1,
      "body": "Depending on your account/user model, you have different options for adding and managing accounts and assigning users to them. We have two models: New Relic One account/user model Original account/user model Important Note that the account/user model is not directly related to our two pricing plans. New Relic One account/user model Important This section is about organizations on the New Relic One account/user model, not the original model. Learn more about the difference. At New Relic, an \"organization\" represents a New Relic customer. The organization contains everything relevant to a New Relic customer: its accounts, its users, and its data. A New Relic \"account\" can be considered a workspace. For example, you might have an account for a specific app, or a set of related hosts and services for a specific initiative or project, or you might have an account for a specific team. Our Standard Full Stack Observability edition allows for a single account per organization. Pro and Enterprise editions allow for multiple accounts per organizations. Currently you can't add accounts to your organization on your own. To add accounts, talk to your New Relic account representative. How users access accounts One effect of the organization structure is that you must have a separate login for each New Relic organization that's on the new model. For example, if you're a contractor requiring access to several New Relic organizations that are on the new model, you'll need to sign out of one organization and into the other. If you have multiple logins associated with a single email address, you can verify your account to see all associated logins. Users in an organization are granted access to specific accounts that are relevant to their duties and responsibilities. To manage users’ access to accounts, you create access grants, which assign a group of users to a specific role on a specific account. For example, you may assign some users the ability to manage billing on some accounts, and assign some users as non-admin full users on some accounts, and assign some users as basic users on some accounts. Our user management system allows you to create the user access you need, whether that’s a relatively simple setup with just a few roles across a few accounts, or a complex one with many roles across many accounts. Learn more about user management. Note that some features, like dashboards and workloads, can display data from across different accounts in an organization. This means that if a user isn’t granted access to all relevant accounts, they may experience missing data. To learn more about access issues, see Factors affecting access. Original account/user model See Original account/user model structure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.71063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "How <em>users</em> access accounts",
        "body": "Depending on your account&#x2F;<em>user</em> model, you have different options for adding and managing accounts and assigning <em>users</em> to them. We have two models: New Relic One account&#x2F;<em>user</em> model Original account&#x2F;<em>user</em> model Important Note that the account&#x2F;<em>user</em> model is not directly <em>related</em> to our two pricing plans"
      },
      "id": "60bee5c028ccbc2413e667e4"
    }
  ],
  "/docs/style-guide/writing-guidelines/voice-strategies-docs-sound-new-relic": [
    {
      "image": "https://developer.newrelic.com/static/developer-champions-c61b7fb3b08d228679edab34b2d15a0e.jpg",
      "url": "https://developer.newrelic.com/developer-champion/",
      "sections": [
        "New Relic Developer Champions",
        "What do Developer Champions do?",
        "Open-source contributions",
        "Content creation",
        "Community engagement",
        "Why should you join and how will we support?",
        "Developer Champions benefits:"
      ],
      "published_at": "2021-06-27T01:43:29Z",
      "title": "New Relic Developers",
      "updated_at": "2020-12-04T01:45:02Z",
      "type": "developer",
      "external_id": "2cef9996dadc081ed4331e85992a4af9defc87ff",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Champions are the voice of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to New Relic product and engineering teams. Champions solve big problems using New Relic as their toolkit and are recognized as experts and leaders in the New Relic technical community. Nominate a developer champion What do Developer Champions do? New Relic Champions demonstrate expertise in using New Relic products by solving large problems and positioning New Relic as a central force in their strategies. The New Relic Champions is a recognition and partnership program designed to acknowledge the developers that are driving innovation within their companies and making top contributions to the developer community.They also commit to making their work public by: Open-source contributions Serving as an open-source author or maintainer for an accepted public project related to New Relic One Content creation Authoring two pieces of content in the New Relic Explorers Hub / Dev website Community engagement Delivering and/or organizing two events focused on an observability platform theme in which New Relic plays a crucial role Nominate a Developer Champion Why should you join and how will we support? As a benefit of being a Developer Champion, New Relic provides unique access to our Developer Advocacy team and the resources of our product organization, as well as specialized recognition and rewards. Developer Champions benefits: Formal, specialized access to the New Relic Product organization Champions have direct access to the New Relic’s Developer Ecosystem team Custom badge to wear with pride at events Public recognition on the New Relic Developer website and badging in the New Relic Explorers Hub as a Champion Exclusive Champion-only swag Early access program for some of our products (under NDA) Priority access to off-site FutureHack events (including when Lew is participating) Increased Explorer’s Hub support SLA Access to private Developer Champion Explorer’s Hub group",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.82422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Developers",
        "sections": "<em>New</em> <em>Relic</em> Developer Champions",
        "body": "<em>New</em> <em>Relic</em> Champions are the <em>voice</em> of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to <em>New</em> <em>Relic</em> product and engineering teams. Champions solve big"
      },
      "id": "5efa993c64441fc2a25f7e65"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Collect data - any source",
        "Create custom events",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-06-27T01:40:30Z",
      "title": "Collect data",
      "updated_at": "2021-06-19T01:39:10Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes   Use custom attributes for deeper analysis Collect data - any source 15 min APIs, agents, OS emitters - get any data Create custom events 5 min Define, visualize, and get alerts on the data you want using custom events Build queries with NerdGraph 25 min Try NerdGraph and build the queries you need Query data with NRQL 10 min Query default data, custom events, and attributes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.28011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Through our opensource agents or APIs, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide <em>strategies</em> for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 62.181637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Ingest and retention <em>strategies</em>",
        "body": " it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in <em>New</em> <em>Relic</em>, all while safeguarding your data. Important This <em>doc</em> is for accounts on our <em>New</em> <em>Relic</em> One pricing plan. If you&#x27;re on our original product-based pricing plan, see Original"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/synthetics/index": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 81.86342,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": " the key for existing private location: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 58.49278,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> monitors",
        "sections": "Types of <em>synthetic</em> monitors",
        "tags": "<em>Synthetics</em>",
        "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 57.875237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> monitoring response codes",
        "sections": "<em>Synthetic</em> monitoring response codes",
        "tags": "<em>Synthetics</em>",
        "body": " timed out&quot; -9999 &quot;unknown error, error not mapped&quot; For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic <em>Synthetics</em> monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)"
      },
      "id": "6045276ee7b9d22729579a22"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/pages/synthetics-results-access-individual-monitor-runs": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1": [
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint",
        "For more help"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-06-25T17:21:59Z",
      "updated_at": "2021-03-11T11:46:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/. For more help Additional documentation resources include: Manage synthetic monitors via the REST API (API procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the REST API (REST API calls for email alerts for synthetic monitors) Use synthetics label APIs (REST API calls for labels and categories used by synthetic monitors)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.69374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;. For more help Additional documentation resources include: Manage synthetic monitors via the <em>REST</em> <em>API</em> (<em>API</em> procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the <em>REST</em> <em>API</em> (<em>REST</em> <em>API</em> calls for email alerts for synthetic monitors) Use <em>synthetics</em> label <em>APIs</em> (<em>REST</em> <em>API</em> calls for labels and categories used by synthetic monitors)"
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-06-25T18:41:06Z",
      "updated_at": "2021-03-11T10:41:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 20. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted Browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.68817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-06-25T20:18:04Z",
      "updated_at": "2021-06-02T16:33:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing plans that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API To query your data using NRQL-format queries, you can use the Query API. Note that this API is deprecated and NerdGraph is preferred for querying your data. Dashboard API See the Insights Dashboard API. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.8138,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>APIs</em>",
        "sections": "<em>REST</em> <em>APIs</em> by capability",
        "tags": "<em>APIs</em>",
        "body": " New Relic, use the Query <em>API</em>. Account management <em>APIs</em> For account-related <em>APIs</em>, see Account <em>APIs</em>. Synthetic monitoring <em>Synthetics</em> <em>API</em> resources include: Resource Details <em>Synthetics</em> <em>REST</em> <em>API</em> The <em>Synthetics</em> <em>REST</em> <em>API</em> functionality includes: Create and manage <em>synthetics</em> monitors. Manage <em>synthetics</em> alert"
      },
      "id": "609fa5cf196a67066022b194"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/identify-synthetic-monitoring-requests-your-app": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:07Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing plans, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.66226,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22728,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:07Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing plans, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.66225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.22714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.46298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.59781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.95644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:58Z",
      "updated_at": "2021-03-13T02:11:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. Tt does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.4944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.59781,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.95644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Tip",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:59Z",
      "updated_at": "2021-03-09T03:46:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.31555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific problems. Comparative charts with browser <em>monitoring</em> Use New Relic"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.95633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:58Z",
      "updated_at": "2021-03-13T02:11:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. Tt does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.4944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Tip",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:59Z",
      "updated_at": "2021-03-09T03:46:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.31555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific problems. Comparative charts with browser <em>monitoring</em> Use New Relic"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1938,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Troubleshoot downtime",
        "View the failures page",
        "View individual downtimes",
        "Use page functions",
        "For more help"
      ],
      "title": "Synthetic monitoring: Troubleshoot downtime",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "fd938ba2389afeb1fe8d8dcf03d91a516f9c983b",
      "image": "https://docs.newrelic.com/static/fc64706d910027f9c05840423fa74fdd/c1b63/failures.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-16T18:41:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Failures page to locate and troubleshoot downtime incidents or other errors. A downtime incident occurs whenever a monitor fails to completely execute. For example, a Ping monitor is \"down\" when the GET request fails, while a Scripted Browser monitor is \"down\" if any part of the script fails to execute. After locating an interesting downtime, select it to view detailed results from that downtime incident and troubleshoot. View the failures page To access your monitor's failures: Go to one.newrelic.com > Synthetics > (select a monitor) > Failures. Hover the mouse over a failure to get quick data about it. Click on the dot to open a detailed report of the failure. You can also click Run check to recheck the failed monitors. View individual downtimes You can select individual downtime incidents to view them in more detail. Depending on the specific failure, a downtime result could include only the server error message (such as Server replied with \"HTTP 500\" error), or a full or partial waterfall view. Downtime results include waterfalls when only part of a monitor executed correctly. For example, a 301 redirect could link to a failing web page. The browser correctly executes the redirect, but the destination web page returns an error. Use the error message or waterfall to troubleshoot the downtime incident. Use page functions The Failures page supports the following features: If you want to... Do this... Sort the list of downtimes In the table header, select Time or Message to sort the list. Select Time or Message again to change from ascending sort to descending sort order. Filter by location Select a location label to hide downtime incidents from that location. Select the location label again to unhide those results. To view results from only one location, hide every other location. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary page (view an overview of your simple or scripted monitor's performance) Results page (full list of monitor results) Resources page (view load times for each element on a monitored page) Response codes (list of response codes specific to synthetic monitoring)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.59976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary <em>page</em> (view an overview of your simple or scripted <em>monitor</em>&#x27;s performance) Results <em>page</em> (full list of <em>monitor</em> results) Resources <em>page</em> (view load times for each element on a monitored <em>page</em>) Response codes (list of response codes specific to <em>synthetic</em> <em>monitoring</em>)"
      },
      "id": "603e9efd64441faf344e8865"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1938,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-understand-load-times": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1937,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.37114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Synthetic monitoring: Troubleshoot downtime",
        "View the failures page",
        "View individual downtimes",
        "Use page functions",
        "For more help"
      ],
      "title": "Synthetic monitoring: Troubleshoot downtime",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "fd938ba2389afeb1fe8d8dcf03d91a516f9c983b",
      "image": "https://docs.newrelic.com/static/fc64706d910027f9c05840423fa74fdd/c1b63/failures.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-16T18:41:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Failures page to locate and troubleshoot downtime incidents or other errors. A downtime incident occurs whenever a monitor fails to completely execute. For example, a Ping monitor is \"down\" when the GET request fails, while a Scripted Browser monitor is \"down\" if any part of the script fails to execute. After locating an interesting downtime, select it to view detailed results from that downtime incident and troubleshoot. View the failures page To access your monitor's failures: Go to one.newrelic.com > Synthetics > (select a monitor) > Failures. Hover the mouse over a failure to get quick data about it. Click on the dot to open a detailed report of the failure. You can also click Run check to recheck the failed monitors. View individual downtimes You can select individual downtime incidents to view them in more detail. Depending on the specific failure, a downtime result could include only the server error message (such as Server replied with \"HTTP 500\" error), or a full or partial waterfall view. Downtime results include waterfalls when only part of a monitor executed correctly. For example, a 301 redirect could link to a failing web page. The browser correctly executes the redirect, but the destination web page returns an error. Use the error message or waterfall to troubleshoot the downtime incident. Use page functions The Failures page supports the following features: If you want to... Do this... Sort the list of downtimes In the table header, select Time or Message to sort the list. Select Time or Message again to change from ascending sort to descending sort order. Filter by location Select a location label to hide downtime incidents from that location. Select the location label again to unhide those results. To view results from only one location, hide every other location. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary page (view an overview of your simple or scripted monitor's performance) Results page (full list of monitor results) Resources page (view load times for each element on a monitored page) Response codes (list of response codes specific to synthetic monitoring)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.59976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary <em>page</em> (view an overview of your simple or scripted <em>monitor</em>&#x27;s performance) Results <em>page</em> (full list of <em>monitor</em> results) Resources <em>page</em> (view load times for each element on a monitored <em>page</em>) Response codes (list of response codes specific to <em>synthetic</em> <em>monitoring</em>)"
      },
      "id": "603e9efd64441faf344e8865"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.6062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.49133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.57568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.6062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.33594,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.49133,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.3359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.49132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.57568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.60596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.3359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.57568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.60596,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.3359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.49132,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/troubleshoot-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.6057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.33588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.4913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.6057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.33588,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.4913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Scripted browser examples",
        "Tip",
        "Monitor a URL",
        "Navigate to a link",
        "Search a website",
        "Wait for a page to load",
        "Wait for a page element",
        "Log in to a website",
        "For more help"
      ],
      "title": "Scripted browser examples",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "0570086ad8b7348b717d983073c037c896a5492b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples/",
      "published_at": "2021-06-26T00:18:24Z",
      "updated_at": "2021-03-18T16:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Using scripted browsers, you can build complex monitoring workflows using a JavaScript-like scripting language driven by Selenium WebDriver. For a detailed guide to all the available functions, see Synthetic's scripted browser reference. Tip To view other scripted browser examples, check out the Quickstarts Synthetics library in New Relic’s Github repository. You may also view tips from New Relic support engineers in the Level Up Relic Solutions section of the New Relic Online Technical Community. Monitor a URL In this example, the monitor visits http://telco.nrdemo-sandbox.com/: //Visit http://telco.nrdemo-sandbox.com/ $browser.get(\"http://telco.nrdemo-sandbox.com/\"); Copy This scripting action is the foundation for nearly all scripted browsers. For more information, see Visit a URL. Navigate to a link In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/. Finds the About page via link text and clicks the link. Finds the Acme Telco Home link by searching for the partial string Home and clicks the link. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ //Find a link whose display text is `About` and click that link. return $browser.findElement($driver.By.linkText(\"About\")).click(); }).then(function(){ return $browser.findElement($driver.By.partialLinkText(\"Home\")).click(); }); Copy These steps are ordered by a sequencing function. For detailed instructions and other methods of locating elements, see Locate elements. For a list of all locators, see Locators: Find page elements. Search a website In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/static/companyBlog.jsp. Locates the search box via its XPath and types relic. Locates the submit button via its XPath and clicks it to submit the search. $browser.get(\"http://telco.nrdemo-sandbox.com/static/companyBlog.jsp\").then(function(){ //Find the search field by specifying its id, then enter `relic`. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div/input\")).sendKeys(\"relic\"); }).then(function(){ //Click the search button. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div//button\")).click(); }); Copy For more information about sending text to a field, see Enter text. Wait for a page to load In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/browse/phones. Finds the Details button for the Acme Standard phone via its XPath and clicks on it. Waits up to 10 seconds for the HTML page title to match Acme Commerce Company. Finds the Add to Cart button via its XPath and clicks on it. $browser.get(\"http://telco.nrdemo-sandbox.com/browse/phones\").then(function(){ return $browser.findElement($driver.By.xpath(\"(//a[text()='Details'])[3]\")).click(); }); //Call the wait function. $browser.wait(function() { //Tell the monitor to get the page title, then run a function on that title. return $browser.getTitle().then(function(title) { //Ensure that the title matches `Acme Commerce Company`. return title === \"Acme Commerce Company\"; }); //If the condition isn't satisfied within 10000 milliseconds (10 seconds), proceed anyway. }, 10000); //Find the `Add to Cart` button via its XPath and click it. $browser.findElement($driver.By.xpath(\"//input[@value='Add to Cart']\")).click(); Copy For more information about setting wait conditions that will pause the script, see Wait for page title. Wait for a page element In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/. Finds the Support dropdown via HTML ID and clicks on it. Waits up to 20 seconds for the FAQ button to appear and clicks on it. //Navigate to the Acme Telco Homepage and clicks on the Support dropdown. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ return $browser.findElement($driver.By.id(\"supportDropDown\")).click(); }).then(function(){ //Call the wait function to wait until the FAQ button appears. return $browser.waitForAndFindElement($driver.By.id(\"supportFAQLink\"), 2000).then(function(aboutPage){ return aboutPage.click(); }) }); Copy For more information, see Wait for a specific element and Conditions: Pause and wait for conditions. Log in to a website In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/login.jsp. Finds the username field through element name and submits a secure username via our secure credentials feature. Finds the password field through the element name and submits a secure password. Finds the login button via its XPath and clicks to submit the account information. $browser.get(\"http://telco.nrdemo-sandbox.com/login.jsp\").then(function(){ //Find the user name field by specifying its name, then submits a secured username. return $browser.findElement($driver.By.name(\"username\")).sendKeys($secure.SECURE_USERNAME); }).then(function(){ //Find the password field by specifying its name, then submits a secured password. return $browser.findElement($driver.By.name(\"password\")).sendKeys($secure.SECURE_PASSWORD); }).then(function(){ //Find and click the login button. return $browser.findElement($driver.By.xpath(\"//input[@value='Login']\")).click(); }); Copy For more information about using secure credentials, see Store secure credentials. Tip What credentials should I use? Just like you shouldn't reuse a password across multiple websites, we recommend that you create new credentials unique to your script. Don't use your personal credentials or reuse credentials. For more help Additional resources include: Write scripted browsers (build WebDriverJS scripts for multi-step monitoring) Synthetic's scripted browser reference (detailed list of all available functions) Add and edit monitors (how to create synthetic monitors, including configuration options)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.2255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Scripted</em> browser examples",
        "sections": "<em>Scripted</em> browser examples",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Using scripted browsers, you can build complex <em>monitoring</em> workflows using a Java<em>Script</em>-like <em>scripting</em> language driven by Selenium WebDriver. For a detailed guide to all the available functions, see <em>Synthetic</em>&#x27;s scripted browser reference. Tip To view other scripted browser examples, check out"
      },
      "id": "60452664196a676354960f31"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/import-nodejs-modules": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/introduction-scripted-browser-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90956,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetics-scripted-browser-reference-monitor-versions-050": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19293,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.90955,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.83914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Scripted browser examples",
        "Tip",
        "Monitor a URL",
        "Navigate to a link",
        "Search a website",
        "Wait for a page to load",
        "Wait for a page element",
        "Log in to a website",
        "For more help"
      ],
      "title": "Scripted browser examples",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "0570086ad8b7348b717d983073c037c896a5492b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples/",
      "published_at": "2021-06-26T00:18:24Z",
      "updated_at": "2021-03-18T16:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Using scripted browsers, you can build complex monitoring workflows using a JavaScript-like scripting language driven by Selenium WebDriver. For a detailed guide to all the available functions, see Synthetic's scripted browser reference. Tip To view other scripted browser examples, check out the Quickstarts Synthetics library in New Relic’s Github repository. You may also view tips from New Relic support engineers in the Level Up Relic Solutions section of the New Relic Online Technical Community. Monitor a URL In this example, the monitor visits http://telco.nrdemo-sandbox.com/: //Visit http://telco.nrdemo-sandbox.com/ $browser.get(\"http://telco.nrdemo-sandbox.com/\"); Copy This scripting action is the foundation for nearly all scripted browsers. For more information, see Visit a URL. Navigate to a link In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/. Finds the About page via link text and clicks the link. Finds the Acme Telco Home link by searching for the partial string Home and clicks the link. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ //Find a link whose display text is `About` and click that link. return $browser.findElement($driver.By.linkText(\"About\")).click(); }).then(function(){ return $browser.findElement($driver.By.partialLinkText(\"Home\")).click(); }); Copy These steps are ordered by a sequencing function. For detailed instructions and other methods of locating elements, see Locate elements. For a list of all locators, see Locators: Find page elements. Search a website In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/static/companyBlog.jsp. Locates the search box via its XPath and types relic. Locates the submit button via its XPath and clicks it to submit the search. $browser.get(\"http://telco.nrdemo-sandbox.com/static/companyBlog.jsp\").then(function(){ //Find the search field by specifying its id, then enter `relic`. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div/input\")).sendKeys(\"relic\"); }).then(function(){ //Click the search button. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div//button\")).click(); }); Copy For more information about sending text to a field, see Enter text. Wait for a page to load In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/browse/phones. Finds the Details button for the Acme Standard phone via its XPath and clicks on it. Waits up to 10 seconds for the HTML page title to match Acme Commerce Company. Finds the Add to Cart button via its XPath and clicks on it. $browser.get(\"http://telco.nrdemo-sandbox.com/browse/phones\").then(function(){ return $browser.findElement($driver.By.xpath(\"(//a[text()='Details'])[3]\")).click(); }); //Call the wait function. $browser.wait(function() { //Tell the monitor to get the page title, then run a function on that title. return $browser.getTitle().then(function(title) { //Ensure that the title matches `Acme Commerce Company`. return title === \"Acme Commerce Company\"; }); //If the condition isn't satisfied within 10000 milliseconds (10 seconds), proceed anyway. }, 10000); //Find the `Add to Cart` button via its XPath and click it. $browser.findElement($driver.By.xpath(\"//input[@value='Add to Cart']\")).click(); Copy For more information about setting wait conditions that will pause the script, see Wait for page title. Wait for a page element In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/. Finds the Support dropdown via HTML ID and clicks on it. Waits up to 20 seconds for the FAQ button to appear and clicks on it. //Navigate to the Acme Telco Homepage and clicks on the Support dropdown. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ return $browser.findElement($driver.By.id(\"supportDropDown\")).click(); }).then(function(){ //Call the wait function to wait until the FAQ button appears. return $browser.waitForAndFindElement($driver.By.id(\"supportFAQLink\"), 2000).then(function(aboutPage){ return aboutPage.click(); }) }); Copy For more information, see Wait for a specific element and Conditions: Pause and wait for conditions. Log in to a website In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/login.jsp. Finds the username field through element name and submits a secure username via our secure credentials feature. Finds the password field through the element name and submits a secure password. Finds the login button via its XPath and clicks to submit the account information. $browser.get(\"http://telco.nrdemo-sandbox.com/login.jsp\").then(function(){ //Find the user name field by specifying its name, then submits a secured username. return $browser.findElement($driver.By.name(\"username\")).sendKeys($secure.SECURE_USERNAME); }).then(function(){ //Find the password field by specifying its name, then submits a secured password. return $browser.findElement($driver.By.name(\"password\")).sendKeys($secure.SECURE_PASSWORD); }).then(function(){ //Find and click the login button. return $browser.findElement($driver.By.xpath(\"//input[@value='Login']\")).click(); }); Copy For more information about using secure credentials, see Store secure credentials. Tip What credentials should I use? Just like you shouldn't reuse a password across multiple websites, we recommend that you create new credentials unique to your script. Don't use your personal credentials or reuse credentials. For more help Additional resources include: Write scripted browsers (build WebDriverJS scripts for multi-step monitoring) Synthetic's scripted browser reference (detailed list of all available functions) Add and edit monitors (how to create synthetic monitors, including configuration options)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.2255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Scripted</em> browser examples",
        "sections": "<em>Scripted</em> browser examples",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Using scripted browsers, you can build complex <em>monitoring</em> workflows using a Java<em>Script</em>-like <em>scripting</em> language driven by Selenium WebDriver. For a detailed guide to all the available functions, see <em>Synthetic</em>&#x27;s scripted browser reference. Tip To view other scripted browser examples, check out"
      },
      "id": "60452664196a676354960f31"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/monitor-produces-no-traffic": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.30838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.30809,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.30838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.1758,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/private-location-hmac-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.30838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.30808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19261,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.308075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.17578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.308365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.308075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.0855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/alerts-synthetic-monitoring": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.0855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/collect-synthetic-transaction-traces": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/handle-sites-authentication": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.1924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/manage-monitor-runtimes": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19229,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/recheck-failed-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08539,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19217,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70348,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.87013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.87013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-simple-scripted-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.08533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.19196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.70346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.12683,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.1264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-06-25T16:18:54Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in the account that includes: The rule details A message about having too many facets A newRelicFeature of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.90167,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.12662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.12622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-25T16:18:05Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.9022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.12662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.12622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-25T16:18:05Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.9022,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.48224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.48224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 868.2146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": ". Record <em>custom</em> <em>events</em> and <em>attributes</em> You can add your own <em>custom</em> APM <em>events</em> and <em>attributes</em>, which you can then use for querying and charting. This is one of several ways to <em>report</em> <em>custom</em> data. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> <em>attributes</em>"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-06-25T22:42:55Z",
      "updated_at": "2021-06-03T12:15:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest New Relic Mobile SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges New Relic Mobile aggregates performance for various methods into summary metrics that appear in New Relic Mobile's Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic Mobile. - (void)myMethod { NR_TRACE_METHOD_START(0); // … existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) // … existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 377.39325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> <em>and</em> <em>events</em>",
        "body": " record arbitrary numerical data and named <em>events</em> with Objective-C and Swift. You can also use several API calls to record <em>custom</em> metrics that provide different levels of detail. Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> and <em>events</em> Use methods in the NewRelic object to <em>report</em> <em>custom</em> <em>attributes</em> and <em>events</em>"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 366.14352,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and <em>attributes</em>. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 280.48212,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.28033,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/intro-custom-data": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data/",
      "sections": [
        "Report custom events and attributes",
        "Requirements",
        "Avoid rate limits",
        "Example use cases",
        "Using custom attributes",
        "Using custom events",
        "Send custom events and attributes",
        "Extend data retention"
      ],
      "published_at": "2021-06-26T08:19:30Z",
      "title": "Report custom events and attributes",
      "updated_at": "2021-05-15T10:44:11Z",
      "type": "docs",
      "external_id": "e50a9be8b3df5859c6307c8642942006f537578d",
      "document_type": "page",
      "popularity": 1,
      "body": "One of the ways to report custom data to New Relic is with custom events and attributes. Have questions about why you'd use custom data? See Introduction to custom data. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits Reporting a large number of custom events and/or attributes can cause degraded query performance. It may also result in approaching or passing data collection rate limits. For optimal performance, first think about what data you want to analyze, and then create only the events and/or attributes necessary to meet these specific goals. Be aware of the following data and subscription requirements for inserting and accessing custom data: Ensure you follow limits and requirements around event/attribute data types, naming syntax, and size. The amount of data you have access to over time depends on your data retention policy. Example use cases Two popular custom data solutions are custom events and custom attributes. There are several ways to accomplish this (more on that later in this doc), depending on your New Relic implementation and tools. Here are some common use cases for implementing custom events and attributes. Using custom attributes Custom attributes are often used to add important business and operational context to existing events. Business context might include: Customer token Customer market segment Customer value classification Workflow control values not obvious in the URIStem User/product/account privilege context Operational context might include: Which feature flags were used What datastore was accessed What cache was accessed What errors were detected and ignored (fault partitioning) Using custom events Event data is one of New Relic's four core data types. We recommend reading that definition to understand what we mean by \"event\" and why that data type is most used for reporting specific types of activity. The use cases for custom events varies widely: basically they are used for any type of activity that an organization deems important and that is not already being monitored. A couple examples: An event might represent an activity involving multiple actions, like a customer purchasing a certain combination of products. An event might record backup activity. For example, they might set up reporting of events that represent production backups of their SOLR instances into an event table, with a timestamp of when it occurred, which cluster, and the duration. Send custom events and attributes Methods for sending custom events and attributes include: Source How to send custom data APM agent Use APM agent APIs to report custom events and custom attributes. Browser monitoring agent Add custom attributes to the PageView event via the Browser API call addCustomAttribute. Send PageAction event and attributes via Browser API. Forward APM agent custom attributes to PageView event. Event API To report custom events not associated with other New Relic products, use the Event API. Infrastructure monitoring agent Add custom attributes to default Infrastructure events. Use the Flex integration tool to report your own custom event data. Mobile monitoring agent Use the mobile agent API to send custom events and attributes. Synthetic monitoring Add custom attributes to the SyntheticCheck event via the $util.insights tools. For ways to report other types of custom data, see: Metric API Logs Trace API Extend data retention To learn how to extend how long events are retained in your account, see our documentation about event data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 558.03656,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>custom</em> events and attributes",
        "sections": "Report <em>custom</em> events and attributes",
        "body": "One of the ways to report <em>custom</em> <em>data</em> to New Relic is with <em>custom</em> events and attributes. Have questions about why you&#x27;d use <em>custom</em> <em>data</em>? See <em>Introduction</em> to <em>custom</em> <em>data</em>. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits"
      },
      "id": "609fa5fb64441f9ebfd2a1db"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.44568,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> events and attributes",
        "sections": "Forward <em>custom</em> attributes from APM <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": " that contains the action name and any <em>custom</em> attribute names and values you capture along with it. The PageAction event also contains any <em>custom</em> attributes you added to the PageView event. Add <em>custom</em> attributes to the PageView event so you can query or filter your <em>data</em> to answer more questions about your"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.226654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>data</em> coming into New Relic",
        "sections": "Break down <em>data</em> <em>to</em> see what&#x27;s contributing <em>to</em> your ingest",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": ". The <em>Data</em> ingestion page shows your ingest rates for a period you specify on the top-right of the <em>Data</em> management hub. Since 30 days ago is the default setting, but you can also set a <em>custom</em> date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Agent APIs",
        "Telemetry SDKs",
        "APIs for sending metrics, traces, logs, and events",
        "New Relic One applications"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-06-25T19:51:32Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. To browse all New Relic-built tools and solutions, see New Relic integrations. Agent APIs Some of our monitoring solutions come with APIs and/or SDKs that allow you to customize the data reported and how it reports. For more information, see the relevant product: APM agent APIs Browser API Mobile API Infrastructure monitoring: the Flex integration tool Telemetry SDKs If our more curated solutions don't work for you, our open source Telemetry SDKs let you build your own solution. These SDKs are language wrappers for our data-ingest APIs (below) that let you send telemetry data to New Relic without requiring install of an agent. APIs for sending metrics, traces, logs, and events If our more curated solutions don't work for you, we also have data-ingest APIs: Trace API Event API Metric API Log API To learn about the differences between these data types, see Data types. New Relic One applications You can build entirely custom applications that reside in New Relic One and make use of any data you want. You can use existing open source New Relic One apps, or share your own with the open source community. For details, see New Relic One applications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.36406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>data</em> into New Relic",
        "sections": "<em>Get</em> <em>data</em> into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to <em>get</em> <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "Tip",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-06-25T16:18:53Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. Tip To use telemetry data and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.36406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " with confidence. Tip To use <em>telemetry</em> <em>data</em> and the rest of our observability <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. The value of New Relic The <em>Telemetry</em> <em>Data</em> <em>Platform</em>: Provides an elastic"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/get-started/nrdb-horsepower-under-hood": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "Tip",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-06-25T16:18:53Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. Tip To use telemetry data and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.36404,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " with confidence. Tip To use <em>telemetry</em> <em>data</em> and the rest of our observability <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. The value of New Relic The <em>Telemetry</em> <em>Data</em> <em>Platform</em>: Provides an elastic"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/index": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1287.9299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>data</em> coming into New Relic",
        "sections": "Manage <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "When you connect your <em>data</em> to New Relic, we process what we receive and apply <em>data</em> dropping and transformation rules. Then we count the bytes needed to represent your <em>data</em> in a standard format, like JSON. If you&#x27;re on our New Relic One pricing plan, you&#x27;re charged by the number of bytes written"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1287.9282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 847.67566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Problem You sent metric <em>data</em> points to the Metric API, and are not seeing what you expect when querying the <em>data</em>. Use the following checklist to determine the root cause: Make sure you are querying the <em>data</em> correctly. Check the HTTP status codes returned by the API. Issues like authorization"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-event-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.75305,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-metric-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.75302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.75302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/report-metrics-metric-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.753,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 313.99854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-26T13:10:44Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.75296,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph": [
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2693.5342,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": " most essential, we have a strategy for you. Learn about reducing the amount of <em>data</em> that comes into NRDB in Manage <em>data</em> coming into New Relic. Learn about customizing storage so you only store the <em>data</em> you want, for the period you want in Manage <em>data</em> stored in New Relic. Learn about dropping <em>data</em> in <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. And for dropping log <em>data</em>, see <em>Drop</em> <em>data</em> with <em>drop</em> filter rules."
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Data privacy with New Relic",
        "Personal data transfer (Privacy Shield and SCC)",
        "Compliance with legal requirements",
        "Privacy by design and by default",
        "Personal data requests (GDPR, CCPA, etc.)",
        "Events and attributes",
        "Dropping data at ingest",
        "Technical security controls",
        "Organizational security controls",
        "Account security",
        "Retention of your data",
        "New Relic account emails",
        "Account changes (NrAuditEvent)",
        "Account usage (NrDailyUsage)",
        "Security for products and services",
        "Alerts and Applied Intelligence",
        "APIs",
        "APM",
        "Browser monitoring",
        "Diagnostics",
        "Infrastructure monitoring",
        "Insights",
        "Integrations and serverless monitoring",
        "Logs management",
        "Mobile monitoring",
        "New Relic One",
        "Plugins",
        "Synthetic monitoring"
      ],
      "title": "Data privacy with New Relic",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Data privacy"
      ],
      "external_id": "d46953520476285467540433180d483815efecc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/",
      "published_at": "2021-06-26T00:47:04Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. We understand your concerns when you entrust us with your data, and we always strive to embrace your expectations and preferences. This document provides links to detailed information about the privacy and security measures we take to protect you and your customers' data privacy. Our monitoring tools are data-agnostic; they don't require sensitive materials, and many of them don't require any personal data. You are responsible for ensuring that your systems are appropriately set up and configured so that they don't send inappropriate personal data or sensitive materials to New Relic monitoring tools. For additional information about policies, credentials, audits, and other resources, see our New Relic security website. Personal data transfer (Privacy Shield and SCC) The Schrems case ruling invalidates Privacy Shield. However, it explicitly reaffirms the validity of Standard Contractual Clauses (SCC) as an appropriate legal mechanism to transfer personal data outside of the European Union. You can find more information in How the Demise of Privacy Shield Affects Your New Relic Account. If you want to send personal data from the EU, we offer an appropriate data processing agreement (DPA) with SCC to govern the transfer of that data in accordance with the Schrems decision. For more information, consult our Data Processing Addendum FAQ, or download our pre-signed DPA (PDF|697 KB). Compliance with legal requirements We always strive to comply with all applicable laws as they take effect. This includes the European Union's General Data Protection Regulation (GDPR) and all relevant US State laws, such as the California Consumer Privacy Act (CCPA). Our disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). In addition, we are authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. For privacy-related details about New Relic's contractual and regulatory commitments for services, see: Terms of Service or Master Subscription Agreement Data Protection Agreement Services Privacy Notice For more information about annual audits, see Regulatory audits for New Relic services. Privacy by design and by default New Relic follows \"privacy by design\" principles as part of our overarching security program. For example, when New Relic agents capture a webpage or referrer URL, all query parameters are stripped by default. Here are examples of how we incorporate privacy considerations into our data and security practices. Personal data requests (GDPR, CCPA, etc.) New Relic strives to comply with all applicable laws as they take effect. This includes the European Union's GDPR and ePrivacy Directive and all applicable privacy laws, such as the California Consumer Privacy Act (CCPA) in the US. For more information about our process when responding to requests to access or delete personal data, see New Relic personal data requests. Events and attributes You can query events and attributes, as well as create charts and alert conditions about this data. For a complete list of all events and attributes tracked by New Relic agents, see our data dictionary. Events and attributes example: If you use the Infrastructure ProcessSample event's commandLine attribute, by default we strip options and arguments from the full command line to prevent accidental leakage of sensitive information. Dropping data at ingest Dropping data gives you control over the data that you send to New Relic, including any personal data that you configured to be collected. By dropping specific events or attributes from events, you determine what data New Relic ultimately stores so that you can query, alert on, and analyze it. For more information, see Drop data using NerdGraph. When our agents refer to data obfuscation, the agent actually removes the data before sending it to New Relic. The data cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences and then replaces them with the ? character. You can mask sensitive information in HTTP or HTTPS requests. For example, queries about distributed traces and transaction traces are obfuscated by default, in which case they cannot be recovered. For more information, see the documentation for specific New Relic services, including: APM transaction traces Distributed tracing Technical security controls We use a comprehensive set of technical controls to support general security needs as well as security for data we receive. For more information, see our documentation about data security, data encryption, and high security mode for APM agents. Organizational security controls New Relic maintains a number of internal policies and procedures to guide employees in privacy-related subjects such as data classification and handling, data retention, handling of personal data, fulfilling personal data requests, incident response, etc. All employees must complete the security and privacy training upon hiring and renew this training annually. Account security Our role-based account structure gives you direct control over who can access or change your account settings. For more information, see Users and roles. Retention of your data Our Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. This platform stores different types of data for different periods of time. The Data retention page in our UI provides information on how long your data will be stored in the New Relic database (NRDB). For more information, see Manage data retention. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product engagement, support, alert notifications, updates, billings, etc. Individual users can unsubscribe from certain communications. General email preferences are managed through the account user interface. For more information, see Account email settings. Alert notification emails are managed through the alerting UI. Account changes (NrAuditEvent) To view changes made to your account's users or to record configuration changes, query NrAuditEvent events. To be notified about account changes, create NRQL alert conditions. For more information about available NrAuditEvent attributes, see our data dictionary. Account usage (NrDailyUsage) To view daily usage of New Relic for your selected account for billing purposes, query NrDailyUsage events. For more information about available NrDailyUsageattributes, see our data dictionary. Security for products and services We publish security bulletins with detailed information about vulnerabilities, remediation strategies, and applicable updates for affected software. To receive notifications for future advisories, use either of these options: Subscribe to our security bulletins RSS feed. Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. The following summarizes how individual New Relic products and components ensure security, with links to additional details. Alerts and Applied Intelligence By default, our alerting services do not record any personal data. In addition, they automatically set default permissions for individual account users and access levels within account structures. For more information, see our documentation about Applied Intelligence, as well as our rules and limits for alerts. APIs APIs simply are interfaces for data exchange automation. APIs have no knowledge of the content being transferred. We require authorized users to provide their API keys to monitor subscription usage, manage account user permissions, query data, and perform other automated tasks. For more information, see Introduction to New Relic APIs. APM APM agents monitor your applications' performance. By default, APM agents do not record any personal data. For more information, see our APM security documentation. Browser monitoring Our browser monitoring agent allows you to monitor the performance of their websites. For more information, see: Browser security documentation Visitor's IP address New Relic cookies used by Browser Enabling or disabling cookie collection for session tracking Diagnostics The New Relic Diagnostics service inspects relevant system information and any other necessary information (such as logs and config files) to perform diagnostic checks that assess configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information, see the Diagnostics security documentation. Infrastructure monitoring The Infrastructure agent allows you to monitor the performance of components in your ecosystem, such as servers, platforms, operating systems, databases, etc. Infrastructure may record the userID and username of users connecting to Infrastructure resources. For more information, see the security documentation for infrastructure monitoring. Insights The Insights service reports on data recorded by other New Relic products and services. It doesn’t record data on its own. For more information, see the Insights documentation about default data from other products and services. Integrations and serverless monitoring Our integrations services allow you to retrieve and load data into the New Relic database from a variety of sources, including: Cloud-based integrations On-host integrations in containerized environments, such as Kubernetes On-host integrations built by New Relic On-host integrations built by the open-source community On-host integrations built by you Depending on the integration, different types of data may be recorded so that you can monitor the integrations in New Relic. The integration services are data agnostic. They will have no knowledge of whether the imported data contains any personal information. For more information, see the documentation for the specific integration, including: Amazon Web Services (AWS) Google Cloud Platform (GCP) Kubernetes Microsoft Azure On-host integrations Open source on-host integrations Serverless function monitoring Logs management Due to the nature of our Logs management service, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls or log forwarder configuration. All data for the Logs service is then reported to New Relic over HTTPS. The Logs service does mask number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see the Logs security documentation. Mobile monitoring By default, our mobile monitoring service collects two pieces of personal data: The IP address is used to derive high-level geographical data, and then is discarded. A device ID is generated by New Relic and is used for billing purposes. For more information, see our security documentation for mobile monitoring. New Relic One New Relic One is a connected, unified UI that gathers all the data you already monitor with New Relic in one place. It is not a product, but rather, it's a way to interact with all your New Relic data more easily. For more information, see the introduction and security documentation for New Relic One. Plugins The plugins service allows you to publish publicly accessible plugins within (Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher in Plugin Central. For plugins in Plugin Central that are not created by New Relic, the plugin publisher must follow specific guidelines. For more information, see the Plugins security documentation. Synthetic monitoring The synthetic monitoring service uses monitors distributed throughout data centers around the world. It captures what is essentially performance data of simulated traffic. By default, it does not capture any personal data. For more information, see the data privacy and security documentation for synthetic monitoring. If you configure the synthetic service to monitor areas of websites that are located behind a login page, take care to create a non-personal login dedicated to this purpose. This will reduce the risk of unintended personal data exposure. For example, to securely store sensitive information, such as passwords, API keys, and user names, you can use secured credentials for scripted browsers and API tests. The synthetic monitoring service also supports a variety of authentication mechanisms. Depending on the type of monitor you choose, this includes Basic, Digest, NTLM, and NTLMv2. You can also control which of your users can access your monitors and private locations. For more information, see our documentation about user role-based permissions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 634.6418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> privacy with New Relic",
        "sections": "<em>Dropping</em> <em>data</em> at ingest",
        "tags": "<em>Data</em> privacy",
        "body": " <em>data</em> <em>using</em> <em>NerdGraph</em>. When our agents refer to <em>data</em> obfuscation, the agent actually removes the <em>data</em> before sending it to New Relic. The <em>data</em> cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences"
      },
      "id": "603ec2d4e7b9d22fba2a07c6"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/nerd-graph-query/",
      "sections": [
        "NerdGraphQuery",
        "Usage",
        "Examples",
        "Props",
        "Methods",
        "NerdGraphQuery.query",
        "Type definitions",
        "PromiseQueryResult",
        "QueryResult"
      ],
      "published_at": "2021-06-27T01:41:15Z",
      "title": "NerdGraphQuery",
      "updated_at": "2021-06-25T01:48:19Z",
      "type": "developer",
      "external_id": "1ada6e056e031c141b2bb989e4ec200b3a7ce988",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One SDK provides Query components based on ApolloClient's query components. These components are an abstraction layer making it easier to query NerdGraph without worrying about configuring Apollo Client and, for the most common use cases, without having to write GraphQL queries. A generic NerdGraph Query component that allows you to query anything from NerdGraph. Usage import { NerdGraphQuery } from 'nr1' Copy Examples Props childrenfunction Render prop function as a child. function ( queryResult : QueryResult // Results of the query. ) => React.ReactNode fetchPolicyTypeenum DEFAULT NerdGraphQuery . FETCH_POLICY_TYPE . CACHE_AND_NETWORK Allows you to specify how you want your query to interact with the cached data. CACHE_AND_NETWORK: The query returns your initial data from the cache if available. However, regardless of whether or not the full data is in your cache, the query always makes a request using your network interface and returns the updated data. This option is not available when using the static query() method of the component. CACHE_FIRST: The query makes a request using your network interface only if the data for your query is not already in the cache. CACHE_ONLY: The query never makes a request using your network interface. Instead it returns the data available in the cache. If the data for your query does not exist in the cache, then an error is thrown. NETWORK_ONLY: The query never returns your initial data from the cache. Instead it always makes a request using your network interface. NO_CACHE: The query never returns your initial data from the cache. Instead it always makes a request using your network interface. Unlike the NETWORK_ONLY policy, it does not write any data to the cache after the query completes. <One of NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_AND_NETWORK , NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_FIRST , NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_ONLY , NerdGraphQuery.FETCH_POLICY_TYPE.NETWORK_ONLY , NerdGraphQuery.FETCH_POLICY_TYPE.NO_CACHE , > pollIntervalnumber DEFAULT 0 Interval in milliseconds to poll for new data. Set to zero to avoid any kind of regular polling. queryrequiredstring|object GraphQL query, either as a string or a GraphQL document parsed into an AST by the gql method of nr1. skipboolean DEFAULT false When set to true, the query will be skipped entirely from rendering. variablesobject DEFAULT {} Object containing all of the variables your query needs to execute. Methods NerdGraphQuery.query Static method to use NerdGraphQuery as a Promise instead of as a React component. function ( props : Object // Object containing the query options. Any NerdGraphQuery prop is a valid option except children and pollInterval. ) Type definitions PromiseQueryResult { error : ApolloClient.ApolloError, // Runtime error with graphQLErrors and networkError properties. data : Object, // Object containing the result of your query. fetchMore : function|null, // If not null, fetchMore allows you to load more results for your query. New data is merged with previous data. refetch : function, // Refetch the query. } QueryResult { loading : boolean, // Indicates that the request is in flight. error : ApolloClient.ApolloError, // Runtime error with graphQLErrors and networkError properties. data : Object, // Object containing the result of your query. fetchMore : function|null, // If not null, fetchMore allows you to load more results for your query. New data is merged with previous data. refetch : function, // Refetch the query. }",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 501.90338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraphQuery</em>",
        "sections": "<em>NerdGraphQuery</em>",
        "body": "New Relic One SDK provides Query components based on ApolloClient&#x27;s query components. These components are an abstraction layer making it easier to query <em>NerdGraph</em> without worrying about configuring Apollo Client and, for the most common <em>use</em> cases, without having to write <em>Graph</em>QL queries. A generic"
      },
      "id": "6091f8cee7b9d213095068a2"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic": [
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.22958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.2178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a <em>data</em> dropping rule to remove attributes at <em>ingest</em> time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-26T13:10:44Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.2178,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ]
}