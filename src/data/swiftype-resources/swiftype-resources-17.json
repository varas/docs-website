{
  "/docs/style-guide/writer-workflow/github-intro": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Important",
        "Reset the 'build the docs site' build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-26T04:00:15Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Important The only checks needed to merge a PR are the checks marked as required on the PR. These are run linter, run tests, license/cla, and unpaired translations removed for merges to develop, and build the docs site for merges to main. If a required check fails, the failure must be addressed in order for the PR to be merged. If an optional check fails, reach out in the help channel so that the hero can look into the failure, but feel free to merge the PR since optional checks don't block releases. Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the 'build the docs site' build check Caution This adds a LOT of time to the build check. There are times when this check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.10695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>GitHub</em> troubleshooting",
        "sections": "<em>GitHub</em> troubleshooting",
        "body": " conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can <em>get</em> out-of-date pretty fast. If you see changes to this file show up in <em>GitHub</em> Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file."
      },
      "id": "60c6a94f64441f5ac491f8a7"
    },
    {
      "sections": [
        "Using Terraform Modules and Remote Storage",
        "Before you begin",
        "Creating a Terraform Module",
        "Create a Variable",
        "Passing a variable into a module",
        "Adding default values",
        "Pass variable values using module block",
        "Reusing a module",
        "Connecting an existing alert policy",
        "Store a module in Github",
        "Create a new Github repo",
        "Using a module saved on Github",
        "Manage state remotely in Amazon S3",
        "Conclusion"
      ],
      "title": "Using Terraform Modules and Remote Storage",
      "type": "developer",
      "tags": [
        "notification channel",
        "alerts",
        "terraform"
      ],
      "external_id": "9199eee78d8b5a488366c74b6b4e683dd010b51d",
      "image": "",
      "url": "https://developer.newrelic.com/terraform/terraform-modules/",
      "published_at": "2021-06-30T01:44:03Z",
      "updated_at": "2021-06-25T01:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn how to use [Terraform](https://www.terraform.io/) modules in your configurations and store them remotely.",
      "body": "Terraform is a popular infrastructure-as-code software tool built by HashiCorp. You use it to provision all kinds of infrastructure and services, including New Relic dashboards and alerts. In this guide, you learn to use Terraform modules in your New Relic configurations. Specifically, you will create modules, import data, store modules on Github, and manage state remotely Amazon S3. In the video, we review additional steps installing Terraform and set up New Relic alerts. If you need help getting started with Terraform, the Getting started with New Relic and Terraform guide shows how to install Terraform, set up New Relic alerts and a notification channel. Before you begin To use this guide, you should have some basic knowledge of both New Relic and Terraform. If you haven't deployed a New Relic open source agent yet, install New Relic for your application. Also, install the Terraform CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config && cd terraform-config To follow the examples in this gude, the accompanying example code is available on GitHub bash Copy $ git clone https://github.com/jsbnr/nr-terraform-intro-example.git Step 1 of 5 Creating a Terraform Module Terraform modules allow you to reuse, share, and store your Terraform configurations using version control like Github. In the next steps, you will move your New Relic configurations into a reusable module. First, in your project root, create a new directory to store your modules named modules: bash Copy $ mkdir modules && cd modules In the modules directory, create a new directory for a new module called HostConditions and create a new file named main.tf: bash Copy $ mkdir HostConditions && cd HostConditions $ touch main.tf Remove the two alert conditions from the root project's main.tf file and copy it to the new main.tf file in the HostConditions directory. In the root directory's main.tf file call the new module using a module block: module \"HostConditions\" { source = \"./modules/HostConditions\" } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Initializing modules... $ [output]- HostConditions in $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. You see an error in your console due to the lack of provider details in your modules directory. To fix the error, create a copy of the root provider.tf in your HostConditions directory : provider \"newrelic\" { account_id = 12345 # Your New Relic account ID api_key = \"NRAK-zzzzzz\" # Your New Relic user key region = \"US\" # US or EU (defaults to US) } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 2, in resource \"newrelic_infra_alert_condition\" $ [output]\"cpuhot\": 2: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 24, in resource \"newrelic_infra_alert_condition\" $ [output]\"highDiskUsage\": 24: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. Terraform init no longer shows an error, but running terraform plan still causes an error to occur. The error is due to the policy id used in the ./modules/HostConditions/provider.tf doesn't exist. A variable is needed to pass into the module. Step 2 of 5 Create a Variable Variables pass details into your module and set default values. First, at the top of your HostConditions provider.tf create a new variable: variable \"providerId\" {} Copy Next, in the resource block, replace the existing policyId with the new variable: var.policy Copy Passing a variable into a module To make a module dynamic, you will pass your variables into the module using the module resource block. In the root directory main.tf, update the module block to add the policyId variable: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id } Copy Run terraform plan after adding your variable to the module. bash Copy $ terraform plan Now, add more variables and replace the values CPU critical, CPU warning, and disk percent. Then, pass the new variables into the module. Add the new variables to HostConditions main.tf: variable cpu_warning {} variable cpu_critical {} variable diskPercent {} Copy Update the alert conditions to use the new variables added in the HostConditons main.tf: resource \"newrelic_infra_alert_condition\" \"cpuhot\" { policy_id = var.policyId name = \"CPU hot!\" type = \"infra_metric\" event = \"SystemSample\" select = \"cpuPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.cpu_critical time_function = \"all\" } warning { duration = 5 value = var.cpu_warning time_function = \"all\" } } resource \"newrelic_infra_alert_condition\" \"highDiskUsage\" { policy_id = var.policyId name = \"high disk usage\" type = \"infra_metric\" event = \"SystemSample\" select = \"diskUsedPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.diskPercent time_function = \"all\" } } Copy Run terraform plan after adding your variables to the module. An error message displays due to the missing variable values. Values can be added in the module block or as default values. bash Copy $ terraform plan Adding default values Add default variable values to HostConditions main.tf: variable cpu_warning { default=80} variable cpu_critical { default=90} variable diskPercent { default=60 } Copy Pass variable values using module block In the root directory main.tf, update the module block to add the cpu_critical, cpu_warning, and diskPercentage variables: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } Copy Run terraform plan after adding your variables to the module. bash Copy $ terraform plan Step 3 of 5 Reusing a module You can reuse your module connecting to a New Relic policy that already exists. Before you start, in your New Relic account, create a new alert policy named Preexisting Policy. Connecting an existing alert policy First, In your root main.tf file add the data block to import an existing policy: data \"newrelic_alert_policy\" \"ExistingPolicy\" { name = \"Preexisting Policy\" } Copy Next, create a second module block name HostConditions2. Add the alert conditions to the Preexisting Policy. module \"HostConditions2\" { source = \"./modules/HostConditions\" policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module and run 'terraform apply' to apply the changes to your New Relic account. The terraform scripts create a new alert policy and two conditions, but it also applies the alert conditions to the Preexisting Policy. Look in your New Relic account at the Preexisting Policy and see alerts conditions added for CPU Hot and High Disk Usage. Step 4 of 5 Store a module in Github After you have created a module, if you want to store the module somewhere other people can use, Github is how you can do it. Create a new Github repo First, inside of your HostModules directory, initialize a new Github repo. Add your main.tf and provider.tf to the stage for commit: bash Copy $ git add main.tf provider.tf $ git commit -m \"init\" Next, using the commands provided in your new repo, push your commit to Github: bash Copy $ git remote add origin <repo_url> $ git branch -M main $ git push -u origin main Using a module saved on Github Check the Github repo and see the main.tf and provider.tf are now in your repo. Copy the GitHub repo's web URL to clone your repo. Update the root main.tf file using GitHub as the source for the HostConditions: module \"HostConditions\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } module \"HostConditions2\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module. When you run terraform init, Terraform clones the repository locally. Run terraform plan If you need to update your local module with updates made to the git repo, run terraform get -update Step 5 of 5 Manage state remotely in Amazon S3 The state file is the representation that terraform holds about the created resources. The state file is in the root directory, but if deleted or corrupted would cause trouble. Storing the state file remote provides security and allows sharing and remote access. In the provider.tf in the root directory, add a terraform backend block for Amazon S3: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" } } Copy Variables are needed to provide the correct S3 bucket details, and access is required. To give access to the S3 bucket in your Amazon account, create an IAM user. Give the IAM user access to the S3 bucket storing the terraform state. Add the profile to the terraform backend block: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" profile = \"<iam_user_profile_name>\" } } Copy Before saving your state to Amazon S3, destroy the current configurations to start from a clean slate: bash Copy $ terraform destroy Initialize Terraform, run Terraform init: bash Copy $ terraform init In the terminal, the output shows the backend initialized as S3. Delete the local state as it is not needed bash Copy $ rm terraform.* Run terraform apply to apply your Terraform configuration changes. bash Copy $ terraform apply The state file is now stored in S3 instead of locally. Look in your S3 bucket and see the terraform state exists. Conclusion Congratulations! You're using modules to make your terraform configuratiions more flexible. Review the New Relic Terraform provider documentation to learn how you can take your configuration to the next level.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.82452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Store a module in <em>Github</em>",
        "body": " CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config &amp;&amp; cd terraform-config To follow the examples in this gude, the accompanying example code is available on <em>GitHub</em> bash Copy $ <em>git</em> clone https:&#x2F;&#x2F;<em>github</em>.com&#x2F;jsbnr&#x2F;nr-terraform-intro-example.<em>git</em> Step 1 of 5 Creating"
      },
      "id": "6091fa98e7b9d2063e506919"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/students/",
      "sections": [
        "New Relic Student Edition",
        "Access the New Relic Student Edition",
        "Signup for FREE Account",
        "Verify Your Student Status",
        "Enjoy Using New Relic",
        "What does the Student Edition offer?",
        "Three full users",
        "500 GB/month of data ingest",
        "Free-tier AI",
        "Frequently Asked Questions"
      ],
      "published_at": "2021-06-29T02:02:11Z",
      "title": "New Relic Developers",
      "updated_at": "2021-06-10T01:42:21Z",
      "type": "developer",
      "external_id": "1aa172dae81cd4ca2fd159ec5ff81049c8206e41",
      "document_type": "page",
      "popularity": 1,
      "body": "Traditional computer sciences are great, but hands-on experience with modern platforms positions you as a more competitive candidate. The New Relic Student Edition gives you access to the same industry tools that observability professionals use--for free. Whether you’re just getting started with your engineering journey, looking to pivot into a career in tech, or an educator ready to share the value of modern technology, we’ve got you covered. With our training, certifications, and best-in-class observability platform you'll have everything you need to compete in the market. We're excited to announce the New Relic Student Edition as an exclusive offer in the GitHub Student Developer Pack. GitHub created the Student Developer Pack to help students ship software like pros, and the New Relic Student Edition contributes to that goal. To access the Student Edition, sign up for a free account and verify your student status using the GitHub Student Developer Pack Access the New Relic Student Edition 1 Signup for FREE Account To access the Student Edition, create a free New Relic account. After that, verify your student status. Sign up for a free account 2 Verify Your Student Status The Student Edition is offered through the GitHub Student Developer Pack. If you don't have access to GitHub Students, sign up and verify your account. GitHub Student Developer Pack 3 Enjoy Using New Relic After your status is verified, your account is upgraded to the Student Edition, giving you three full users and 500GB of data ingest. Access New Relic One What does the Student Edition offer? There's no substitute for hands-on experience. That’s why we designed the New Relic Student Edition, which gives students and educators full access to New Relic One, including: Three full users Work with your friends and classmates like a real-world production team 500 GB/month of data ingest Collect, analyze, and alert on all your metrics, events, logs, and traces from any source Free-tier AI Instantly detect, diagnose, and resolve issues before they become a problem Sign up for a free account Frequently Asked Questions How do I access New Relic Student Edition? New Relic offers the Student Edition exclusively through the GitHub Student Pack. To verify your account's eligibility, authorize your GitHub account. Learn more about GitHub Education if you don't have GitHub Student Developer Pack yet. Sign up for Student Edition. You'll be prompted to create or log in to your GitHub account Apply for the GitHub Student Developer Pack, which requires proof of enrollment in an accredited institution Once you’re verified through GitHub, sign in to the Student Edition with the token emailed to you to get started Can I purchase Student Edition? New Relic offers the Student Edition for FREE to students and educators. Can I share my Student Edition with friends? The student edition comes with three full users. Your friends and classmates are also welcome to sign up for their own free account. Where can I check the status of my student verification with GitHub? In your GitHub account settings, visit Applications > Authorized OAuth Apps to check if you have authorized the New Relic OAuth app. If you granted this application access to your GitHub account, you should hear back from GitHub as soon as they have verified your student status. What if I already have a New Relic free account? No problem! Just upgrade your account to the Student Edition. In the main menu, look for Student Edition and follow the instructions. What is the difference between the Student Edition and New Relic free account? Check out this quick comparison chart Feature Student Edition Free Tier Free Full Users 3 users 1 user Free Data 500 GB/mo 100 GB/mo Production Use No Yes I’m having trouble verifying my student status with GitHub. Troubleshoot any GitHub verification related issues here, or contact GitHub directly. Does my Student Edition expire? You'll have access to the Student Edition for as long as you’re an active student in the GitHub Student pack. Can I upgrade my Student Edition account to a paid account? Yes! Just enter your information and credit card details into the ‘Manage Plan’ screen, and you’ll convert your account to a paid account! (Note: Depending on your usage monthly charges may apply)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.22742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " to announce the New Relic Student Edition as an exclusive offer in the <em>GitHub</em> Student Developer Pack. <em>GitHub</em> created the Student Developer Pack to help students ship software like pros, and the New Relic Student Edition contributes to that goal. To access the Student Edition, sign up for a free account"
      },
      "id": "60afaa1f64441f933ce2cb5a"
    }
  ],
  "/docs/style-guide/writer-workflow/github-troubleshooting": [
    {
      "sections": [
        "Diagnostics CLI (nrdiag)",
        "Compatibility",
        "Get started"
      ],
      "title": "Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "973501f4752e56caf3d68e37bf21b823d0e42078",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag/",
      "published_at": "2021-06-26T08:28:19Z",
      "updated_at": "2021-03-13T05:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version The Diagnostics CLI (nrdiag) is a utility that automatically detects common problems with New Relic products. If the Diagnostics CLI detects a problem, it suggests troubleshooting steps. The Diagnostics CLI can also automatically attach troubleshooting data to a New Relic Support ticket. The Diagnostics CLI is open source and is located in GitHub. For additional troubleshooting steps for your agent, check out Not seeing data. Here's an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped troubleshooting logs that are ready to be attached to support tickets. Compatibility The Diagnostics CLI is available for Linux, macOS, and Windows. It can detect common configuration issues for: APM: Available for all APM agents except C SDK. For the Go agent, only basic connectivity checks are available. Browser monitoring: Browser agent detection Infrastructure monitoring: Linux and Windows agents Mobile agents: iOS and Android Synthetic monitoring: Containerized private minions (CPM) The Diagnostics CLI does not require superuser or admin permissions to run, although we recommend those permissions for some checks. It will return an error if it does not have permissions to read the files it scans. Get started To use the Diagnostics CLI: Run the Diagnostics CLI, including task suites and command line options as needed. Include an attachment key when you upload the results to your Support ticket. Optional: Validate your config file settings. Interpret the output. Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. For detailed information, see our Diagnostics CLI licensing and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 705.96216,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Support ticket. The Diagnostics CLI is open source and is located in <em>GitHub</em>. For additional <em>troubleshooting</em> steps for your agent, check out Not seeing data. Here&#x27;s an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates"
      },
      "id": "604469f8e7b9d2abb65799f0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-intro/",
      "sections": [
        "Get around GitHub",
        "Who is who in an issue/PR?",
        "Track issues in the board",
        "Deal with references in GitHub (and the style guide)",
        "Merge from develop into main work (or, when do we publish?)",
        "Github labels",
        "Check the edit history of a doc or file"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Get around GitHub",
      "updated_at": "2021-06-20T21:50:17Z",
      "type": "docs",
      "external_id": "d691040a18c70d6cd84f6a12546e39099547ab5e",
      "document_type": "page",
      "popularity": 1,
      "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team GitHub board to track the status of issues and pull requests (PR). Who is who in an issue/PR? GitHub keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR is filed, check on the filer’s username and see if they're listed as a member of our organization. If you're not sure, treat someone as external until you know otherwise. People in an issue/PR include: Creator: The person who opened the issue or PR. This could be a writer, a Relic, or an external user. We'll label the issue or PR differently depending on who created it. If you're not sure if a user is a Relic, a good trick is to click on their profile and see if they're a member of the New Relic GitHub org. Assignee: The person taking responsibility for a PR or issue. This will usually be used by the Hero or Sidekick to assign non-TW PRs and issues to themselves. It can also be used to take a TW’s PR or issue over from them. Reviewer: The person who reviews or peer edits the code/document and approves the changes. Not necessarily the person responsible for that area or responsible for merging the commit. You can pre-assign up to 100 reviewers to a given issue. Track issues in the board The docs board has the following columns: Column Description Needs triage The Hero or Sidekick review issues and PRs in this column, then drag them to the appropriate column. If the issue/PR is labeled eng, go ahead and click its ellipses icon to archive it. For other issues and PRs, add the correct labels. Hero: to do PRs that the Hero needs to review, publish, and follow up with SMEs as needed. Hero: Assign yourself as Assignee. In review (Hero or any TW) Drag PRs to this column when they are being reviewed. This shows who is reviewing and what is being reviewed, so two writers don’t mistakenly work on the same PR. Any TW: Writer needs PR review PRs from Tech Docs team members that need a light edit pass to make sure everything in GitHub is correct. This should be checked by other writers every few hours so PRs don’t get stale. If you have a PR that’s been lingering here too long, ask for a reviewer in #doc_sprint_talk. Whoever takes it: assign yourself as Reviewer. Any TW: needs peer edit Like our Needs Peer Edit column in Jira: A writer has requested a review of their PR. Review their PR in GitHub and leave comments. Whoever takes it: assign yourself as Reviewer. Waiting on SME/Blocked For PRs that are blocked by need for SME info or confirmation (for example, as Hero you are waiting on an answer from the person who sent in a Hero pull request). Waiting on TW to merge All reviews are complete. The TW who created the PR (or who is assigned the issue) needs to merge this work into develop. Drafts A draft is a way to open a PR while indicating that the work is still in progress, and not necessarily ready to merge immediately. You can't merge a Draft PR directly—you have to move it out of draft first. When you see a draft PR (especially from outside the team!), treat it as though it's a working draft and reach out to the creator to discuss. Read more on GitHub's drafts. As a Hero or Sidekick, make sure you attend to the following throughout your day: Check in with the Hero/Sidekick at the start of your day (especially on Monday at the start of the week). Don’t forget to sync with the BCN hero if necessary. Watch for incoming PRs in #docs_deploys, and review everything in the Needs triage column. Drag cards from that column to the appropriate column. Work through the cards in the Hero: to do column. Everyone on the team helps keep things moving: All writers should keep an eye on both Any TW columns. There's one column for PRs that need a simpler review before merging (typo fixes, drive-by edits, etc), and another column for PRs that need a peer edit. There are also two blocked columns: One for PRs blocked on a SME, and another column where we're waiting on the TW who created the PR to review feedback and/or merge. After merging, remove your ticket from the board. Deal with references in GitHub (and the style guide) Don't link to anything non-public from a public place. You can reference Jiras, but reference Jiras by issue key (DOC-1234 is ok) rather than a link (https://newrelic.atlassian.net/browse/DOC-1234 is not). Don't mention traffic or usage numbers publicly. Don't reference internal people by name. If they have a GH account, @mention their GH handle. If they don't, talk instead about teams (\"talk to a Browser team engineer\" or \"Support Engineer\") rather than people. You can mention the #documentation channel and hero. Merge from develop into main work (or, when do we publish?) The Hero currently merges three times a day: At 9 AM, noon, and 3 PM Pacific. Slackbot will remind us about this in #docs_deploys. The hero (or delegate) is the one who should create a PR for this and merge it. Github labels Every issue needs these labels: Always add content Add one of the pg_* labels (see this internal doc ) Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). Optional: Jira’d: Issues that have a corresponding Jira ticket. Every pull request needs these labels: Always add content Add one of: from_internal: A Relic created it. from_external: A user opened it in the repo OR it came in through #customer-feedback process. from_tw: One of us created it (unless we were passing along #customer-feedback). If the PR fixes an external issue, label it as from_tw since the work was done by a tech writer. Optional: Jira’d: Issues that have a corresponding Jira ticket. Check the edit history of a doc or file There are two options two check the history of a file: Option 1: githistory.xy Go to a specific file in GitHub itself. Example: https://github.com/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx In the url, replace github.com with github.githistory.xyz. Example: https://github.githistory.xyz/newrelic/docs-website/blob/develop/src/content/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action.mdx It will take you to a site with the visual history of that specific file. You can view changes by clicking through the commit history at the top of your page. Option 2: Git blame Follow Github's documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.54968,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get around <em>GitHub</em>",
        "sections": "Get around <em>GitHub</em>",
        "body": "As tech doc writers (TW) we edit docs, do peer edits, or use the Docs Team <em>GitHub</em> board to track the status of issues and pull requests (PR). Who is who in an issue&#x2F;PR? <em>GitHub</em> keeps track of all activity concerning an issue or PR, including, of course, the people involved. When a new issue or PR"
      },
      "id": "60c6a916196a67e82b5e1604"
    },
    {
      "sections": [
        "Using Terraform Modules and Remote Storage",
        "Before you begin",
        "Creating a Terraform Module",
        "Create a Variable",
        "Passing a variable into a module",
        "Adding default values",
        "Pass variable values using module block",
        "Reusing a module",
        "Connecting an existing alert policy",
        "Store a module in Github",
        "Create a new Github repo",
        "Using a module saved on Github",
        "Manage state remotely in Amazon S3",
        "Conclusion"
      ],
      "title": "Using Terraform Modules and Remote Storage",
      "type": "developer",
      "tags": [
        "notification channel",
        "alerts",
        "terraform"
      ],
      "external_id": "9199eee78d8b5a488366c74b6b4e683dd010b51d",
      "image": "",
      "url": "https://developer.newrelic.com/terraform/terraform-modules/",
      "published_at": "2021-06-30T01:44:03Z",
      "updated_at": "2021-06-25T01:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn how to use [Terraform](https://www.terraform.io/) modules in your configurations and store them remotely.",
      "body": "Terraform is a popular infrastructure-as-code software tool built by HashiCorp. You use it to provision all kinds of infrastructure and services, including New Relic dashboards and alerts. In this guide, you learn to use Terraform modules in your New Relic configurations. Specifically, you will create modules, import data, store modules on Github, and manage state remotely Amazon S3. In the video, we review additional steps installing Terraform and set up New Relic alerts. If you need help getting started with Terraform, the Getting started with New Relic and Terraform guide shows how to install Terraform, set up New Relic alerts and a notification channel. Before you begin To use this guide, you should have some basic knowledge of both New Relic and Terraform. If you haven't deployed a New Relic open source agent yet, install New Relic for your application. Also, install the Terraform CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config && cd terraform-config To follow the examples in this gude, the accompanying example code is available on GitHub bash Copy $ git clone https://github.com/jsbnr/nr-terraform-intro-example.git Step 1 of 5 Creating a Terraform Module Terraform modules allow you to reuse, share, and store your Terraform configurations using version control like Github. In the next steps, you will move your New Relic configurations into a reusable module. First, in your project root, create a new directory to store your modules named modules: bash Copy $ mkdir modules && cd modules In the modules directory, create a new directory for a new module called HostConditions and create a new file named main.tf: bash Copy $ mkdir HostConditions && cd HostConditions $ touch main.tf Remove the two alert conditions from the root project's main.tf file and copy it to the new main.tf file in the HostConditions directory. In the root directory's main.tf file call the new module using a module block: module \"HostConditions\" { source = \"./modules/HostConditions\" } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Initializing modules... $ [output]- HostConditions in $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. $ [output]Error: Unreadable module directory $ [output]Unable to evaluate directory symlink: lstat modules/HostConditions: no such $ [output]file or directory $ [output]Error: Failed to read module directory $ [output]Module directory does not exist or cannot be read. You see an error in your console due to the lack of provider details in your modules directory. To fix the error, create a copy of the root provider.tf in your HostConditions directory : provider \"newrelic\" { account_id = 12345 # Your New Relic account ID api_key = \"NRAK-zzzzzz\" # Your New Relic user key region = \"US\" # US or EU (defaults to US) } Copy Try testing your configurations, run terraform plan and terraform init: bash Copy # Example output ------------------------------------------------------------------------ $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 2, in resource \"newrelic_infra_alert_condition\" $ [output]\"cpuhot\": 2: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. $ [output]Error: Reference to undeclared resource on modules/HostConditions/main.tf line 24, in resource \"newrelic_infra_alert_condition\" $ [output]\"highDiskUsage\": 24: policy_id = newrelic_alert_policy.DemoPolicy.id $ [output]A managed resource \"newrelic_alert_policy\" \"DemoPolicy\" has not been declared $ [output]in module.HostConditions. Terraform init no longer shows an error, but running terraform plan still causes an error to occur. The error is due to the policy id used in the ./modules/HostConditions/provider.tf doesn't exist. A variable is needed to pass into the module. Step 2 of 5 Create a Variable Variables pass details into your module and set default values. First, at the top of your HostConditions provider.tf create a new variable: variable \"providerId\" {} Copy Next, in the resource block, replace the existing policyId with the new variable: var.policy Copy Passing a variable into a module To make a module dynamic, you will pass your variables into the module using the module resource block. In the root directory main.tf, update the module block to add the policyId variable: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id } Copy Run terraform plan after adding your variable to the module. bash Copy $ terraform plan Now, add more variables and replace the values CPU critical, CPU warning, and disk percent. Then, pass the new variables into the module. Add the new variables to HostConditions main.tf: variable cpu_warning {} variable cpu_critical {} variable diskPercent {} Copy Update the alert conditions to use the new variables added in the HostConditons main.tf: resource \"newrelic_infra_alert_condition\" \"cpuhot\" { policy_id = var.policyId name = \"CPU hot!\" type = \"infra_metric\" event = \"SystemSample\" select = \"cpuPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.cpu_critical time_function = \"all\" } warning { duration = 5 value = var.cpu_warning time_function = \"all\" } } resource \"newrelic_infra_alert_condition\" \"highDiskUsage\" { policy_id = var.policyId name = \"high disk usage\" type = \"infra_metric\" event = \"SystemSample\" select = \"diskUsedPercent\" comparison = \"above\" where = \"(hostname LIKE '%myhost%')\" critical { duration = 5 value = var.diskPercent time_function = \"all\" } } Copy Run terraform plan after adding your variables to the module. An error message displays due to the missing variable values. Values can be added in the module block or as default values. bash Copy $ terraform plan Adding default values Add default variable values to HostConditions main.tf: variable cpu_warning { default=80} variable cpu_critical { default=90} variable diskPercent { default=60 } Copy Pass variable values using module block In the root directory main.tf, update the module block to add the cpu_critical, cpu_warning, and diskPercentage variables: module \"HostConditions\" { source = \"./modules/HostConditions\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } Copy Run terraform plan after adding your variables to the module. bash Copy $ terraform plan Step 3 of 5 Reusing a module You can reuse your module connecting to a New Relic policy that already exists. Before you start, in your New Relic account, create a new alert policy named Preexisting Policy. Connecting an existing alert policy First, In your root main.tf file add the data block to import an existing policy: data \"newrelic_alert_policy\" \"ExistingPolicy\" { name = \"Preexisting Policy\" } Copy Next, create a second module block name HostConditions2. Add the alert conditions to the Preexisting Policy. module \"HostConditions2\" { source = \"./modules/HostConditions\" policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module and run 'terraform apply' to apply the changes to your New Relic account. The terraform scripts create a new alert policy and two conditions, but it also applies the alert conditions to the Preexisting Policy. Look in your New Relic account at the Preexisting Policy and see alerts conditions added for CPU Hot and High Disk Usage. Step 4 of 5 Store a module in Github After you have created a module, if you want to store the module somewhere other people can use, Github is how you can do it. Create a new Github repo First, inside of your HostModules directory, initialize a new Github repo. Add your main.tf and provider.tf to the stage for commit: bash Copy $ git add main.tf provider.tf $ git commit -m \"init\" Next, using the commands provided in your new repo, push your commit to Github: bash Copy $ git remote add origin <repo_url> $ git branch -M main $ git push -u origin main Using a module saved on Github Check the Github repo and see the main.tf and provider.tf are now in your repo. Copy the GitHub repo's web URL to clone your repo. Update the root main.tf file using GitHub as the source for the HostConditions: module \"HostConditions\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercentage = 66 } module \"HostConditions2\" { source = \"git::https://github.com/<your_username>/<your_repo_name>\" # Add your repo URL policyId = data.newrelic_alert_policy.ExistingPolicy.id cpu_critical = 87 cpu_warning = 77 diskPercentage = 67 } Copy Run terraform init to initialize the new module. When you run terraform init, Terraform clones the repository locally. Run terraform plan If you need to update your local module with updates made to the git repo, run terraform get -update Step 5 of 5 Manage state remotely in Amazon S3 The state file is the representation that terraform holds about the created resources. The state file is in the root directory, but if deleted or corrupted would cause trouble. Storing the state file remote provides security and allows sharing and remote access. In the provider.tf in the root directory, add a terraform backend block for Amazon S3: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" } } Copy Variables are needed to provide the correct S3 bucket details, and access is required. To give access to the S3 bucket in your Amazon account, create an IAM user. Give the IAM user access to the S3 bucket storing the terraform state. Add the profile to the terraform backend block: terraform { backend \"s3\" { bucket = \"<s3_bucket_name>\" key = \"<s3_bucket_key>\" region = \"<s3_bucket_region>\" profile = \"<iam_user_profile_name>\" } } Copy Before saving your state to Amazon S3, destroy the current configurations to start from a clean slate: bash Copy $ terraform destroy Initialize Terraform, run Terraform init: bash Copy $ terraform init In the terminal, the output shows the backend initialized as S3. Delete the local state as it is not needed bash Copy $ rm terraform.* Run terraform apply to apply your Terraform configuration changes. bash Copy $ terraform apply The state file is now stored in S3 instead of locally. Look in your S3 bucket and see the terraform state exists. Conclusion Congratulations! You're using modules to make your terraform configuratiions more flexible. Review the New Relic Terraform provider documentation to learn how you can take your configuration to the next level.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.40714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Store a module in <em>Github</em>",
        "body": " CLI. Start by initializing a working directory: bash Copy $ mkdir terraform-config &amp;&amp; cd terraform-config To follow the examples in this gude, the accompanying example code is available on <em>GitHub</em> bash Copy $ <em>git</em> clone https:&#x2F;&#x2F;<em>github</em>.com&#x2F;jsbnr&#x2F;nr-terraform-intro-example.<em>git</em> Step 1 of 5 Creating"
      },
      "id": "6091fa98e7b9d2063e506919"
    }
  ],
  "/docs/style-guide/writer-workflow/peer-editor-workflow": [
    {
      "sections": [
        "Use TCP endpoint to forward logs to New Relic",
        "Compatibility and requirements",
        "Important",
        "Configure rsyslog",
        "Legacy config file for rsyslog 7 or earlier",
        "Configure syslog-ng",
        "Tip"
      ],
      "title": "Use TCP endpoint to forward logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "3f572fe998dd7f72516a7b654295b779ff290176",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic/",
      "published_at": "2021-06-25T22:58:39Z",
      "updated_at": "2021-06-25T22:58:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a wide range of solutions to get your log data into New Relic. But in other situations where you don't have log forwarders (such as CDNs, hardware devices, or managed services), you can use syslog protocols via a TCP endpoint. You can forward your logs to New Relic using syslog clients such as rsyslog and syslog-ng. Compatibility and requirements To forward logs to New Relic using a syslog client, you need: A valid Insights API Insert key Some minor changes to the syslog client's configuration, as explained in this document Important Currently, our syslog endpoint only supports accounts in our US data center. Configure rsyslog To forward logs to New Relic with rsyslog: Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: module(load=\"imfile\" PollingInterval=\"10\" statefile.directory=\"/var/spool/rsyslog\" ) Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: include(file=\"/etc/rsyslog.conf.d/newrelic.conf\") Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Specify each of the files to be tailed in case step 1 is done input(type=\"imfile\" ruleset=\"infiles\" Tag=\"<YOUR_FILE_TAG>\" File=\"<PATH_TO_FILE>\" StateFile=\"<UNIQUE_STATEFILE_NAME >\") ## Template expected by the New Relic Syslog endpoint template(name=\"newrelic-rfc5424\" type=\"string\" string=\"<YOUR_INSERT_KEY> <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ) ## Configure TLS and log forwarding global(DefaultNetstreamDriver=\"gtls\" DefaultNetstreamDriverCAFile=\"/etc/ssl/certs/ca-certificates.crt\" ) action(type=\"omfwd\" Target=\"newrelic.syslog.nr-data.net\" Port=\"6514\" Protocol=\"tcp\" Template=\"newrelic-rfc5424\" ResendLastMSGOnReconnect=\"on\" StreamDriver=\"gtls\" StreamDriverAuthMode=\"x509/name\" StreamDriverPermittedPeers=\"*.syslog.nr-data.net\" StreamDriverMode=\"1\" ) Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Legacy config file for rsyslog 7 or earlier If you are using rsyslog version 7 or below, the configuration files need to be adapted to the obsolete legacy format. This format is only kept for retro compatibility purposes. We strongly recommend to avoid using it, as stated in the rsyslog documentation. Install packages required to allow rsyslog to send logs using TLS encryption: sudo yum install rsyslog-gnutls ca-certificates Copy Optional: Configure rsyslog to tail log files and forward their contents to New Relic. Add the following to the /etc/rsyslog.conf file in order to enable its text file input module: $ModLoad imfile $InputFilePollInterval 10 $PrivDropToGroup adm $WorkDirectory /var/spool/rsyslog Copy In the /etc/rsyslog.d/ directory, create a text file named newrelic.conf. Explicitly include the newly created newrelic.conf to the /etc/rsyslog.d/ file: $IncludeConfig /etc/rsyslog.conf.d/newrelic.conf Copy Add the following to newrelic.conf, replacing YOUR_INSERT_KEY with your New Relic Insights API Insert key: ## Template expected by the New Relic Syslog endpoint $template NRLogFormat,\"YOUR_INSERT_KEY <%pri%>%protocol-version% %timestamp:::date-rfc3339% %hostname% %app-name% %procid% %msgid% %structured-data% %msg%\\n\" ## Specify each of the files to be tailed in case step 1 is done $InputFileName /path/to/file $InputFileTag <YOUR_FILE_TAG> $InputFileStateFile <UNIQUE_STATEFILE_NAME> $InputFileSeverity info $InputRunFileMonitor ## Configure TLS and log forwarding $DefaultNetstreamDriverCAFile /etc/ssl/certs/ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509/name $ActionSendStreamDriverPermittedPeer *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl restart rsyslog Copy Check your New Relic account for logs. Configure syslog-ng To forward logs to New Relic with syslog-ng: Install ca-certificates required to allow syslog-ng to send logs using TLS encryption: sudo yum install ca-certificates Copy Open the syslog-ng configuration file (/etc/syslog-ng/syslog-ng.conf) in a text editor. Define the sources to be monitored by adding: source s_src { internal(); }; Copy Optional: Configure syslog-ng to tail files by adding the following to the Sources configuration block: source s_files { file(\"<PATH_TO_FILE>\"); }; Copy Define the New Relic syslog format and add your New Relic Insights API Insert key: template NRFormat { template(\"YOUR_INSERT_KEY ${PRI}>1 ${ISODATE} ${HOST:--} ${PROGRAM:--} ${PID:--} ${MSGID:--} ${SDATA:--} $MSG\\n\"); template_escape(no); }; Copy Add the New Relic Syslog endpoint: destination d_newrelic { network(\"newrelic.syslog.nr-data.net\" port(6514) transport(\"tls\") tls(peer-verify(no)) template(NRFormat) ); }; Copy Add the following output to the log path configuration block: log { source(s_src); source(s_files); ## in case step 4 is implemented. destination(d_newrelic); }; Copy Restart syslog-ng by running: sudo service syslog-ng restart Copy Check your New Relic account for logs. Tip If you are running syslog-ng from a Docker container and experience issues, check balait/syslog image documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.00695,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "&#x2F;ssl&#x2F;certs&#x2F;ca-certificates.crt $ActionSendStreamDriver gtls $ActionSendStreamDriverMode 1 $ActionSendStreamDriverAuthMode x509&#x2F;name $ActionSendStreamDriverPermitted<em>Peer</em> *.syslog.nr-data.net *.* @@newrelic.syslog.nr-data.net:6514;NRLogFormat Copy Restart the rsyslog service by running: sudo systemctl"
      },
      "id": "603e7d6764441f1a774e88a0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-26T04:05:47Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.46349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tech Writer <em>workflow</em>",
        "sections": "Tech Writer <em>workflow</em>",
        "body": "This document will guide you through the entire <em>workflow</em> for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text <em>editor</em>) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-06-25T18:15:27Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 80.17734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and discuss your reasoning with your <em>peer</em> <em>editor</em>. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn&#x27;t solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/writer-workflow/tech-writer-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1183.4277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Peer editor <em>workflow</em>",
        "sections": "Peer editor <em>workflow</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the <em>Tech</em> <em>Writer</em> <em>workflow</em> doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing <em>workflow</em> in GitHub If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-06-25T17:04:43Z",
      "updated_at": "2021-05-10T12:35:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). The title is also shown in the sidebar. Try to keep your titles as short as possible. The title will automatically be converted to a file name, lower case, punctuation removed, with dashes between words. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. watermark We use watermarks for things like beta content or to show that something is an internal New Relic doc. Commonly used watermarks are: BETA, Legacy, Deprecated, NR ONLY, etc. Watermarks look like large, faded text behind the doc's content. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.37608,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6042220e64441f28b64e8843"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-06-25T18:15:27Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.26076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark": [
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-03-16T09:10:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.01666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Code</em> examples",
        "sections": "<em>Code</em> examples",
        "body": " Markdown-style indented <em>code</em> <em>formatting</em>, as this can cause unexpected <em>formatting</em> problems. Highlight user input with &lt;<em>var</em>&gt; Use the &lt;<em>var</em>&gt; tag to highlight areas of a <em>code</em> block where a user is expected to supply their own value. For more context on when to use &lt;<em>var</em>&gt; tags, see &lt; <em>var</em>&gt; <em>formatting</em> <em>guidelines</em>"
      },
      "id": "6042212b28ccbc7c9eeba772"
    },
    {
      "sections": [
        "Bold or code, not italics",
        "Tip"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-06-25T17:04:42Z",
      "updated_at": "2021-03-16T14:49:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths. Tip If you have a UI object (page, tab, etc.) that also has link formatting, then you don't need to add the bold formatting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 94.533714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bold or <em>code</em>, not italics",
        "sections": "Bold or <em>code</em>, not italics",
        "body": " <em>format</em> text in our docs with italics. Here are more specific <em>guidelines</em> our team uses. For this... Bold <em>Code</em> Example APM Agent lists C SDK Go Java .NET Node.js PHP Python Ruby Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Custom instrumentation via attributes (.NET)",
        "Requirements and recommendations",
        "Transactions called within transactions",
        "Example: Calling Transaction in an already-started transaction",
        "Create a new non-web transaction",
        "Create a new web transaction",
        "Add detail to existing transactions with Trace",
        "Properties for [Transaction]",
        "Web",
        "Read forum posts about instrumentation",
        "Use other API functions"
      ],
      "title": "Custom instrumentation via attributes (.NET)",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Custom instrumentation"
      ],
      "external_id": "68ae52e48b04bfe2279bcd038778cc5eebf53d1d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/custom-instrumentation/custom-instrumentation-attributes-net/",
      "published_at": "2021-06-26T04:11:24Z",
      "updated_at": "2021-05-15T18:25:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's .NET agent provides several options for custom instrumentation. Custom instrumentation allows you to instrument parts of your app that are not instrumented automatically. This document describes how to instrument your app by decorating the methods in your app code with attributes. Use the Transaction attribute to create a custom transaction. You can also mark the custom transaction as a web transaction with the attribute's Web property. Use the Trace attribute to add custom instrumentation to methods that are invoked within a preexisting transaction. Requirements and recommendations Requirements include: .NET agent version 6.16.178.0 or higher. You must be willing to modify your source code. If you cannot or do not want to modify your source code, use custom instrumentation via XML. Your project must have a reference to NewRelic.Api.Agent.dll (for example, installing the package and placing using NewRelic.Api.Agent; in your code). This package is in the NuGet gallery. The Transaction and Trace attributes must be applied to concrete implementations of methods. They cannot be applied on interfaces or super class method definitions. Transactions called within transactions Methods decorated with the [Transaction] attribute will only create a new transaction when one does not already exist. When a method decorated with [Transaction] is called from within a previously started transaction, it will be treated as the [Trace] attribute instead, and will provide more information about the existing transaction. Example: Calling Transaction in an already-started transaction During the execution of this console application, OuterMethod will be called first and create a new transaction. The InnerMethod is called from within the transaction started by OuterMethod, so it will not create a new transaction. Instead, information about the execution of InnerMethod will be tracked as if the [Trace] attribute had been applied. static void Main(string[] args) { OuterMethod(); } [Transaction] public void OuterMethod() { InnerMethod(); } [Transaction] public void InnerMethod() { } Copy Create a new non-web transaction To start a non-web transaction (also known as a background request) with the Transaction attribute: [Transaction] public void Run() { // your background task } Copy For details about why to use either web or non-web, see Classify as web or non-web. Create a new web transaction To tell the agent to mark a non-web task as a web browser transaction, use either of these options: Set the Web property of the Transaction attribute to true. Set the transaction's URI with SetTransactionUri(). [Transaction(Web = true)] public void Run() { var uri = new Uri(\"http://www.mydomain.com/path\"); NewRelic.Api.Agent.NewRelic.SetTransactionUri(uri); // your web task } Copy When used inside a previously started transaction, this will be treated as a [Trace] attribute. For details about why to use either web or non-web, see Classify as web or non-web. Add detail to existing transactions with Trace If your transaction traces show large blocks of un-instrumented time and you want to include additional methods within the trace, you can use the Trace attribute: [Trace] protected void MethodWithinTransaction() { // your app code } Copy Properties for [ Transaction] The Transaction attribute supports the following properties: Web Type: Boolean Default: false If true, the agent starts a web transaction when it reaches this Transaction attribute. If a transaction is in progress, then that transaction will continue. If false (default), the agent starts a non-web transaction when it reaches this Transaction attribute. For example: [Transaction(Web = true)] Copy Read forum posts about instrumentation For more specific recommendations, check out these posts in our Explorers Hub community: Troubleshoot attribute-based custom instrumentation issues Build custom instrumentation tracer factories from .NET agent log files Use other API functions For more about the .NET agent API and its functionality, see New Relic's .NET agent API guide. For custom instrumentation without modifying your source code, see Create transactions via XML and Add detail to transactions via XML.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.12144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Requirements <em>and</em> recommendations",
        "body": " a new web transaction To tell the agent to <em>mark</em> a non-web task as a web browser transaction, use either of these options: Set the Web property of the Transaction attribute to true. Set the transaction&#x27;s URI with SetTransactionUri(). [Transaction(Web = true)] public void Run() { <em>var</em> uri = new Uri"
      },
      "id": "6043cd9528ccbcfe1e2c60aa"
    }
  ],
  "/docs/style-guide/writing-guidelines/create-edit-content": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-25T18:15:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 418.26624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> <em>and</em> <em>edit</em> categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and <em>edit</em> <em>content</em>. To learn how to <em>create</em> and publish release notes, see <em>Create</em> release notes. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/modal/",
      "sections": [
        "Modal",
        "Usage",
        "Examples",
        "Props"
      ],
      "published_at": "2021-06-29T01:57:00Z",
      "title": "Modal",
      "updated_at": "2021-06-25T01:50:51Z",
      "type": "developer",
      "external_id": "d0b0ddbfd4564c59b6711dcc5d6f9a17cdc5acd2",
      "document_type": "page",
      "popularity": 1,
      "body": "Modals are used for single-step create, add, edit, or delete actions. They are also used to display additional metadata about a screen or specific object on the screen. Usage import { Modal } from 'nr1' Copy Examples Props ariaLabelledBystring Pass the string of the text content which should better describe the purpose of the modal to be correctly announced by screen readers. childrennode Content to render inside the modal. classNamestring Appends class names to the component. hiddenboolean DEFAULT false If true, the modal is hidden. onCloserequiredfunction Callback fired when clicking on the Modal's close button. onHideEndfunction Callback fired when the Modal finishes the closing animation. Use this to unmount the Modal component. This ensures that the closing animation works properly. onHideStartfunction Callback fired when the Modal starts the closing animation. onShowEndfunction Callback fired when the Modal finishes the opening animation. onShowStartfunction Callback fired when the Modal starts the opening animation. styleobject Inline style for custom styling. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 104.82468,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Modals are used for single-step <em>create</em>, add, <em>edit</em>, or delete actions. They are also used to display additional metadata about a screen or specific object on the screen. Usage import { Modal } from &#x27;nr1&#x27; Copy Examples Props ariaLabelledBystring Pass the string of the text <em>content</em> which should better"
      },
      "id": "6091f8ce28ccbc5e71a2689c"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Issues with content",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/129e7a553450c47847a969c79a2f7f89/c1b63/Dashboards_conf.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-06-25T22:29:11Z",
      "updated_at": "2021-06-20T14:34:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Add a new page. Pages allow you to better organize your dashboards. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Issues with content When adding charts you may come across these issues: Error message Description Something went wrong while executing your query. There was an unexpected error while fetching the data. Try again in a few minutes. If this persists, contact support. Your query either timed out or we're under heavy load. Navigate to https://support.newrelic.com/ for further assistance. NRDB is experiencing heavy loads, which cause intermittent time-outs. Try again in a few minutes. You are not authorized to query account 2022412 You don’t have access to this account. Contact your admin for further assistance. External Service 'NRDB' execution resulted in 400 - cause: TIMESERIES step size is larger than the current time window. The TIMESERIES step size is larger than the selected time window. Modify the step and run the query again. NerdGraphGetAuthorizedAccountsCommand short-circuited and fallback disabled. Communication failed while we were authorizing the request. Try again in a few minutes. TIMESERIES supports a maximum of 366 buckets The TIMESERIES bucket size is too low to span all the selected time window. Modify the bucket size and run the query again. Query rejected due to inspected count limit exceeded by this query group. You’ve exceeded your querying limits. Check out our data usage limits and policies per account. No application was matched (did you specify appId, appName or entity.guid?) No entity matched the query. Review the specified appId, appName or entity.guid and run the query again. External Service 'NRDB' execution resulted in 400 - cause: Your query's start time must be before its end time. The provided startTime of the query must be before the endTime. Modify it and run the query again. Validation error on 'nrql': a query must be specified You need to provide a valid NRQL query. Learn more about our query language. NRQL Syntax Error: Error at line 1 position 15, unexpected 'FROM' FACET and TIMESERIES are not supported on events. Your query has syntax issues. Review it in the query builder to find the error. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Access the query builder to see or edit the query associated to the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.758896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Add custom <em>content</em> using the markdown <em>editor</em>",
        "tags": "Explore <em>and</em> query data",
        "body": " the dashboard&#x27;s guid, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: <em>Edit</em> your dashboard Use the <em>edit</em> button to: Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. <em>Create</em> new <em>content</em> by clicking"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/style-guide/writing-guidelines/docs-translation": [
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-06-25T22:33:39Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.8369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Translation</em> from PromQL-style queries",
        "body": ", or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy <em>Translation</em> from PromQL-style queries When applicable"
      },
      "id": "603e8a2528ccbc56e5eba774"
    },
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-06-25T18:17:02Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 54.797264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "You can&#x27;t just hit the edit button <em>docs</em>.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home page changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    },
    {
      "sections": [
        "iOS and tvOS crash reporting",
        "dSYM files",
        "Debug the crash reporter",
        "Disable crash reporting"
      ],
      "title": "iOS and tvOS crash reporting",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "b2b79e6f9e78f6113bb20032c674996c746e14d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/configuration/ios-tvos-crash-reporting/",
      "published_at": "2021-06-25T23:14:20Z",
      "updated_at": "2021-03-16T09:52:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For Mobile version 4 or higher, New Relic produces crash reports for your mobile applications. When an iOS or tvOS application crashes, the operating system creates a crash report and stores it on the device. New Relic uploads this report the next time the app launches. Using this report and any relevant dSYM files, the crash report includes the complete stack trace with human-readable information. You can then log into New Relic and see each crash, including the method and line where it crashed, plus device and environment details. dSYM files When you create a release build of an iOS or tvOS application, the names of methods and classes are stripped, leaving only machine-readable memory addresses. When the application crashes, the stack trace consists of this machine-readable code. A dSYM file is an Xcode project file for debug symbols. It contains the debugging symbols that allow for translation of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more information, see Retrieve and download dSYMs or Upload dSYM files. Debug the crash reporter Crash reporting is enabled by default, but there are some circumstances where it will be disabled: If the debugger is enabled: There can only be one uncaught exception handler registered at a time per application. If running with the debugger attached, New Relic will not capture and report crashes. If another crash reporter is enabled: If another uncaught exception handler is registered after New Relic starts, this error message is logged: The New Relic exception handler has been replaced. This may result in crashes no longer reporting to New Relic. Copy Disable crash reporting To disable New Relic crash reporting, call the following API method: Language Procedure Objective-C Call prior to [NewRelic startWithApplicationToken:...]; [NewRelic disableFeatures:NRFeatureFlag_CrashReporting]; Copy Swift Call prior to NewRelic.start(withApplicationToken:) NewRelic.disableFeatures(NRMAFeatureFlags.NRFeatureFlag_CrashReporting) Copy For more information about this call, see the NewRelic.h file. For more on applicable feature flags, see the NewRelicFeatureFlags.h file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 42.958385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " for <em>translation</em> of the initial crash report to human-readable information. This process is known as symbolication. New Relic has dynamic framework support for dSYM uploading. If your app uses a dynamic framework with multiple dSYM files, New Relic automatically uploads and uses those files. For more"
      },
      "id": "603ec58128ccbc9b51eba7d2"
    }
  ],
  "/docs/style-guide/writing-guidelines/five-questions-help-write-docs": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/prometheus-remote-write-integration/",
      "sections": [
        "Prometheus remote write integration",
        "Why it matters",
        "Compatibility",
        "Scale your data and get moving quickly",
        "What's next",
        "For more help"
      ],
      "published_at": "2021-06-25T16:03:03Z",
      "title": "Prometheus remote write integration",
      "updated_at": "2021-03-16T13:34:27Z",
      "type": "docs",
      "external_id": "d8ceefcb13b66e0a17973b0aca68ea3cc71ca403",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the Prometheus remote write integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about five minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which scrape data from Prometheus endpoints, the remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. You can leverage the full range of options for setup and management, from raw data to queries and dashboards and beyond. With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional) Compatibility New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Scale your data and get moving quickly Once logged in to New Relic, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. View your data. What's next Ready to get started? Read the setup documentation. Configure a Prometheus data source in Grafana. Set up the integration on New Relic US EU For more help Recommendations for learning more: See the Docs site's landing page for Infrastructure integrations documentation. Browse New Relic's Explorers Hub for community discussions about our Infrastructure integrations. Find additional help or file a support ticket. Review New Relic's licenses, attributions, data usage limits, and other notices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.154106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Prometheus remote <em>write</em> integration",
        "sections": "Prometheus remote <em>write</em> integration",
        "body": "You can use the Prometheus remote <em>write</em> integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about <em>five</em> minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which"
      },
      "id": "603e94dee7b9d2dfd22a07f9"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-25T22:11:45Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 63.282394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "How <em>to</em> enable",
        "body": ": baseurl: https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;linux&#x2F;yum&#x2F;el&#x2F;6&#x2F;x86_64 gpgkey: https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;gpg&#x2F;newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure <em>write</em>_files: - content: | --- # New Relic config file"
      },
      "id": "60450959e7b9d2475c579a0f"
    },
    {
      "sections": [
        "Send Prometheus metric data to New Relic",
        "Prometheus OpenMetrics or remote write integration?",
        "Prometheus remote write integration",
        "Scale your data and get moving quickly",
        "How it works",
        "Remote write compatibility and requirements",
        "Prometheus OpenMetrics integrations",
        "Reduce overhead and scale your data",
        "Kubernetes",
        "Docker",
        "OpenMetrics integrations compatibility and requirements",
        "Important",
        "What's next"
      ],
      "title": "Send Prometheus metric data to New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Get started"
      ],
      "external_id": "c43eafc49c9c82cbf8642897c868c9602cecc6b9",
      "image": "https://docs.newrelic.com/static/3b6e65cd4f0d292124399b59a6195a0a/8c557/Prometheus-remote-write-dashboard.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic/",
      "published_at": "2021-06-26T14:26:55Z",
      "updated_at": "2021-06-26T14:26:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This page provides an overview of New Relic's Prometheus integration options and how they work. The information here will help you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote write integration? We currently offer two integration options: Prometheus remote write integration and Prometheus OpenMetrics integration for Kubernetes or Docker. We recommend getting started with the remote write integration if you already have a Prometheus server install base. If you find it hard to manage your Prometheus cluster, or if you are getting started with integrating Prometheus Metrics, you should use OpenMetrics. Prometheus remote write integration Prometheus OpenMetrics for Kubernetes or Docker Benefits Use this if you currently have Prometheus servers and want an easy way to access your combined metrics from New Relic. It only takes one line of yaml in your Prometheus configuration. You'll be able to access your metrics through both New Relic and Prometheus. You don't need to make any additional adjustments for data to remain available in Prometheus. Federation: Allows you to combine data from multiple servers into a single source. Prometheus High Availability support: We de-duplicate data from HA-pairs on ingest. Use this if you’re looking for an alternative or replacement to a Prometheus server that stores all your metrics directly in New Relic. You won’t have to manage any Prometheus servers yourself. You don't need local storage. Keep in mind You will still need to manage your Prometheus servers, although you should be able to reduce your storage retention, and there’ll be fewer query loads to the server. Slightly more complex setup. No support for High Availability replicas. The Kubernetes operator is not available for enhanced operations automation. Recommendations Evaluate your observability needs to manage your data volumes better: The scrape interval is the biggest factor influencing data volumes: select it based on your observability needs. For example, changing from 15s (default value) to 30s can reduce data volumes by 50%. Set your filters and configure data to target (see metrics or targets). Balance remote write(s) between one or more new relic accounts or sub-accounts to manage rate limits. Regardless of the option you chose, with our Prometheus integrations: You can use Grafana or other query tools via New Relic's Prometheus' API. You benefit from more nuanced security and user management options as part of New Relic One. The New Relic Telemetry Data Platform can be the centralized long-term data store for all your Prometheus metrics, allowing you to observe all your data in one place. You can execute queries to scale, supported by New Relic. Prometheus remote write integration The Prometheus remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. Once integrated, you can leverage the full range of options for setup and management, from raw data to queries, dashboards, and more. Scale your data and get moving quickly With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional). Prometheus remote write dashboard How it works Signup for New Relic is fast and free — we won't even ask for a credit card number. Once logged in, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. Check for your data. Query and explore! Read the setup docs Add Prometheus data Remote write compatibility and requirements New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Prometheus OpenMetrics integrations New Relic’s Prometheus OpenMetrics integrations for Docker and Kubernetes allow you to scrape Prometheus endpoints and send the data to New Relic, so you can store and visualize crucial metrics on one platform. With these integrations, you can: Automatically identify a static list of endpoints. Collect metrics that are important to your business. Query and visualize this data in the New Relic UI. Connect your Grafana dashboards (optional). Kubernetes OpenMetrics dashboard Reduce overhead and scale your data Collect, analyze, and visualize your metrics data from any source, alongside your telemetry data, so you can correlate issues all in one place. Out-of-the-box integrations for open-source tools like Prometheus make it easy to get started, and eliminate the cost and complexity of hosting, operating, and managing additional monitoring systems. Prometheus OpenMetrics integrations gather all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. To learn more about how to scale your data without the hassles of managing Prometheus and a separate dashboard tool, see New Relic's Prometheus OpenMetrics integration blog post. Kubernetes In a Kubernetes environment, New Relic automatically discovers the endpoints in the same way that the Prometheus Kubernetes collector does it. The integration looks for the prometheus.io/scrape annotation or label. You can also identify additional static endpoints in the configuration. Docker The Prometheus OpenMetrics integration gathers all your data in one place, and New Relic stores the metrics from Prometheus. This integration helps remove the overhead of managing storage and availability of the Prometheus server. OpenMetrics integrations compatibility and requirements For Kubernetes and Docker OpenMetrics integrations, you should be aware of the following compatibility and requirements information. Kubernetes New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2 and Kubernetes versions 1.9 or higher. The integration was tested using Kubernetes 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For more details, see the metrics API documentation. Important Recommendation: Always run the scraper with one replica. Adding more replicas will result in duplicated data. Docker New Relic has contributed the Prometheus integration to the open source community under an Apache 2.0 license. This integration supports Prometheus protocol version 2. The integration was tested using Docker 1.9, 1.11, and 1.13 on kops, GKE, and minikube. Limits apply to the metrics you send. For details, see the metrics API documentation. What's next Ready to get moving? Here are some suggested next steps: Read the how-to for completing the remote write integration. Read the how-to for completing the Prometheus OpenMetrics integration. Both integration options generate dimensional metrics that are subject to the same rate limits described in the Metric API. Learn about Grafana support options. Explore the range of other options available as part of the Telemetry Data Platform.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 62.91048,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Send Prometheus metric data <em>to</em> New Relic",
        "sections": "Prometheus OpenMetrics or remote <em>write</em> integration?",
        "body": "This page provides an overview of New Relic&#x27;s Prometheus integration options and how they work. The information here will <em>help</em> you choose from among our options based on which one best fits your unique business needs. Prometheus OpenMetrics or remote <em>write</em> integration? We currently offer two"
      },
      "id": "603ea41964441f0d824e8874"
    }
  ],
  "/docs/style-guide/writing-guidelines/formatting-terminal-commands": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/github-troubleshooting/",
      "sections": [
        "GitHub troubleshooting",
        "GitHub authentication fails",
        "My build is failing mysteriously",
        "Issues with the local site",
        "Stop and restart yarn",
        "Ensure the problem isn't with your branch",
        "Clean your local cache",
        "Remove corrupted cache files",
        "Start a build from start",
        "Run your local build in private mode",
        "My redirect throws a 404 error when testing it locally",
        "A check fails in the PR",
        "Important",
        "Reset the 'build the docs site' build check",
        "Caution",
        "Troubleshoot merging conflicts",
        "What’s new related merge conflicts"
      ],
      "published_at": "2021-06-26T04:00:15Z",
      "title": "GitHub troubleshooting",
      "updated_at": "2021-06-26T04:00:15Z",
      "type": "docs",
      "external_id": "09ae591aa87a3d512d1c62005589dbd88f23f699",
      "document_type": "page",
      "popularity": 1,
      "body": "Are you having problems working on a doc in GitHub? Check out the following common issues. GitHub authentication fails If you suddenly find that you can no longer push to your remote branch in GitHub Desktop, you may have developed a problem with SSH. If logging out of GitHub Desktop via Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the command line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this command prompts you for a passphrase, your SSH was somehow confused. By entering your passphrase, you should be back in business. If you can’t remember your passphrase, check out this article. My build is failing mysteriously Here’s a few things you can check if your build is failing: Indenting in the nav files Front matter If there's apostrophes and colons in frontmatter fields, surround them with quotes to avoid problems. Missing closed brackets or tags Poorly formatted image links Be careful when renaming images and their filename paths. A mismatch can cause the entire local build to fail. Be especially careful when dealing with image files that are imported. Image filenames Image filenames are case-sensitive. Using the wrong capitalization results in a missing image in the doc. Images with encoded values (like %) in the filename can be especially tricky, try to avoid them. Issues with the local site If you're running with issues with your local build, try these options: Stop and restart yarn In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to interrupt the yarn process, if necessary. Run yarn && yarn start. Ensure the problem isn't with your branch In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. In GitHub Desktop, commit any changes needed on your branch, and then switch to the Develop branch. 4 Back in the terminal, run yarn && yarn start. If the site now builds correctly, the issue is with the changes in your branch. Stop Yarn again, go back to your branch, and troubleshoot. Clean your local cache Run yarn clean to blow away your local cache. This will make your next build slower, so make sure you have time! In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Begin a new build by running yarn clean && yarn && yarn start. Remove corrupted cache files There may be times when your .cache directory has been corrupted. This directory is ignored by Git, which means that it travels with you from branch to branch. This might be the problem if your local builds are failing regardless of which branch you’re on. To solve this, run rm -rf .cache. Start a build from start Blow away all your node modules, hidden .cache folder, and local cache and start a build from scratch. This takes a long time to run, around 10–20 minutes. In the terminal, ensure you're in the docs-website directory. Hit CONTROL+C to stop yarn, if necessary. Blow away modules and cache and start from scratch running rm -rf node_modules && rm -rf .cache && yarn && yarn clean. When everything completes, start the site yarn start. You may need to add sudo at the start of the rm commands. Run your local build in private mode Sometimes the local site builds, but pages within the site don't. Running the local build in a private/incognito session may to fix this issue. You can also try clearing out your browser's cache. My redirect throws a 404 error when testing it locally Redirects are a bit strange on local builds. To test them, navigate to the page that is being redirected, wait until it throws a 404, and then wait ~1-2 minutes. It should redirect you after a while. If it doesn’t, ensure you set up the redirect correctly. A check fails in the PR Important The only checks needed to merge a PR are the checks marked as required on the PR. These are run linter, run tests, license/cla, and unpaired translations removed for merges to develop, and build the docs site for merges to main. If a required check fails, the failure must be addressed in order for the PR to be merged. If an optional check fails, reach out in the help channel so that the hero can look into the failure, but feel free to merge the PR since optional checks don't block releases. Rarely, a build or check will fail due to some internal error. You can re-run the check by going to the PR, clicking Details, and then clicking Re-run jobs. If that doesn't fix it, you probably have genuine build errors. Pull down locally and troubleshoot. Reset the 'build the docs site' build check Caution This adds a LOT of time to the build check. There are times when this check fails. If this happens after your local builds have built successfully, you may need to force a rebuild of the cache. In your local repo, find the file gatsby-config.js (use CMD-P to jump to it fast in VSCode). Swap the first and second line of code. It doesn’t matter what order these lines are in, except to make the Gatsby Build check rebuild the cache. const fs = require('fs'); const parse = require('rehype-parse'); Save the file and commit the change to your PR. Re-run the build checks. Wait a LOOOOONG time. Troubleshoot merging conflicts Merge conflicts can seem pretty scary, but it’s ultimately just deciding between two different versions of a doc. Here are some tips on how to get through it. Fix your merge conflict as soon as possible. Especially if you’re working on taxonomy changes. If your branch lingers for a while it can get outdated from develop pretty fast and that can cause some unexpected issues. Check your fix locally to make sure that it looks good there. Ask your PR approver to review your PR after you fix the merge conflict. Here are two options to resolve conflicts: When you see the conflicts in GitHub desktop, click the option to resolve these in VS Code. Use the GitHub website editor (click the Resolve conflict button) to fix these. What’s new related merge conflicts Merge conflicts pop up pretty often with what’s new posts because the whats-new-ids.json file that’s automatically updated when the site builds can get out-of-date pretty fast. If you see changes to this file show up in GitHub Desktop, make sure to discard them, rather than push them up to your branch. This will make it less likely that other people will have to deal with merge conflicts related to this file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 105.75175,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Preferences doesn’t seem to help, you can confirm if you have an SSH issue by switching to the <em>command</em> line and trying to push manually. For example: git push --set-upstream origin second-kafka-pr-for-issue-1123 If this <em>command</em> prompts you for a passphrase, your SSH was somehow confused. By entering your"
      },
      "id": "60c6a94f64441f5ac491f8a7"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark/",
      "sections": [
        "Code formatting guidelines: var and mark",
        "var: Highlight user-specific values in procedural code snippets",
        "var format examples",
        "Important",
        "mark: Emphasize non-procedure code snippets"
      ],
      "published_at": "2021-06-26T04:05:46Z",
      "title": "Code formatting guidelines: var and mark",
      "updated_at": "2021-05-16T11:16:42Z",
      "type": "docs",
      "external_id": "dc9b222917947481942168f4004e4401f517b9dd",
      "document_type": "page",
      "popularity": 1,
      "body": "This document serves as a supplement to the basic <var> and <mark> documentation. It gives a longer explanation of when to use the <var> and <mark> formatting styles, and reasons for not using them. var: Highlight user-specific values in procedural code snippets The <var> tag is used for user-input values in code snippets that customers would be using in procedural/functional ways. For example, you would use the <var> tag when explaining how to do some specific task. A <var> tag would not be used for: Example code: If the code is meant to be an example, to show the format/structure of the code, and there is not an actual procedure the customer is following, var tags are not needed. Examples: Example configuration file (or this Java agent config template): if you are showing an example config file that isn't part of a procedure, you shouldn't use the <var> tag. Several reasons for this: 1) The important part of showing an example config file is to show the overall structure of the file, 2) Usually the number of config options present in a file will vary based on whatever the customer wishes to use, so using <var> tags can actually be confusing as it implies that these values must be present. Instrumentation procedure (at bottom of the Java section): the var tag wouldn't be necessary because it's an example, not part of a procedure, and the main goal is seeing the general structure. Also, because it's an example of app code, the concept of user-specific values doesn't have much meaning, because the entire code will vary dependent on how the customer has written their code. (If anything, this would be a potential for using <mark> format to emphasize the New Relic functions.) Response/output code: If the code is meant to show an expected return, and is not related to a procedure, then var tags shouldn't be used. Here's a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both <var> formatting and without it, see the Synthetics monitors REST API example. The first block shows a command they might choose to run, hence it uses a <var> tag. The second block is just an example output, showing the structure that would be returned; it doesn't require a <var> tag. For some use cases, highlighting may be a better choice than a var tag. var format examples Below are some general style recommendations for formatting user-specific <var> values. <var> tag formatting may vary based on language- or system-specific expectations, so be sure check the style used in the documentation section in question, and to ask relevant SMEs what they think of the style. Account IDs and other IDs/#s: YOUR_ACCOUNT_ID, YOUR_API_CODE, etc. This should be the general style used. URLs: example.com, or maybe YOUR_URL Paths: PATH/TO/SOMETHING.exe or maybe PATH_TO_FILE Emails: datanerd@example.com or maybe YOUR_EMAIL Bash variables for REST API code: Some <var> tagged code values on the docs site have the form $ { API_KEY}. This is a format used for variables in bash scripts, where users assign values to specific variable names and then call those variables later in the script by using the $VARIABLE_NAME. For more info, see this explanation of bash variables. Important The bash variable style is currently used in the REST API docs and in some Synthetics docs and that's fine. But going forward we should use the general variable style (without the $ and &lt; >). mark: Emphasize non-procedure code snippets Highlighting (<mark>) is used for when you want to draw attention to a variable or value, but it's not something directly procedural related. Here are two examples of highlighting: Highlighting values in code response that are meant for later use: Activate Azure integrations doc. Highlighting the commands in a large code block example that are New Relic-specific commands, with explanations below: Java API doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.16032,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Code <em>formatting</em> guidelines: var and mark",
        "sections": "Code <em>formatting</em> guidelines: var and mark",
        "body": " to a procedure, then var tags shouldn&#x27;t be used. Here&#x27;s a doc section (the returned JSON) where var tags are not needed. For an example of a doc section with both &lt;var&gt; <em>formatting</em> and without it, see the Synthetics monitors REST API example. The first block shows a <em>command</em> they might choose to run, hence"
      },
      "id": "6042219c64441f52d94e889e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the UI vs local build",
        "Work on a branch, not a fork",
        "Set up your local environment",
        "Run the site locally",
        "Prerequisites",
        "Build the site",
        "Edit a doc",
        "Commit your changes",
        "Publish your commits",
        "Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging"
      ],
      "published_at": "2021-06-26T04:05:47Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-06-14T00:55:51Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the UI vs local build Need to edit a doc? Use this table to decide where to work! Use the UI for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. Work on a branch, not a fork Some teams work on branches, some teams work on forks; the docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title. Set up your local environment Install GitHub Desktop, and then navigate to GitHub Desktop's preferences. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Once GitHub Desktop is set up, navigate to the Docs Site repository on GitHub. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you are merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) Once you are satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. To request a review from another Tech Writer: in GitHub open the PR, navigate to the conversation Conversation, and then select or type in a reviewer name in the Reviewer section. At the bottom the pull request page, you will see a Checks section. These checks ensure your PR does not break the build process of the site. Ensure all these checks pass before proceeding. The checks should finish within twenty minutes. If the Pull Request is urgent, you can skip the AWS Amplify Console Web Preview check. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Amplify: Full preview of the live site with no overhead, although it takes a long time (from 30 minutes tp up to 1.5 hours!) to build on a PR. It's easily shareable with SMEs and others. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.91832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " was cloned by navigating to your local GitHub folder (the default is ~&#x2F;Documents&#x2F;github). Once you have cloned the repo, you don&#x27;t need to clone it again in the future. Run the site locally Build the site locally using the <em>terminal</em> to preview changes before opening a Pull Request. While it&#x27;s highly"
      },
      "id": "60c6a91764441f404d91f8c6"
    }
  ],
  "/docs/style-guide/writing-guidelines/hyperlinks": [
    {
      "sections": [
        "Link your applications to Kubernetes",
        "Tip",
        "Compatibility and requirements",
        "Kubernetes requirements",
        "Network requirements",
        "APM agent compatibility",
        "Openshift requirements",
        "Important",
        "Configure the injection of metadata",
        "Default configuration",
        "Custom configuration",
        "Manage custom certificates",
        "Validate the injection of metadata",
        "Disable the injection of metadata",
        "Troubleshooting"
      ],
      "title": "Link your applications to Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "2ae58989813695b48f4924529d6fd6ea17e5f6c5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes/",
      "published_at": "2021-06-26T14:09:48Z",
      "updated_at": "2021-05-28T06:30:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can surface Kubernetes metadata and link it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which is currently a beta release. This Pixie integration into New Relic does not require a language agent. Learn more about Auto-telemetry with Pixie here. Tip Our Kubernetes metadata injection project is open source. Here's the code to link APM and infrastructure data and the code to automatically manage certificates. Compatibility and requirements Before linking Kubernetes metadata to your APM agents, make sure you meet the following requirements: Kubernetes requirements Network requirements APM agent compatibility OpenShift requirements Kubernetes requirements To link your applications and Kubernetes, your cluster must have the MutatingAdmissionWebhook controller enabled, which requires Kubernetes 1.9 or higher. To verify that your cluster is compatible, run the following command: kubectl api-versions | grep admissionregistration.k8s.io/v1beta1 admissionregistration.k8s.io/v1beta1 Copy If you see a different result, follow the Kubernetes documentation to enable admission control in your cluster. Network requirements For Kubernetes to speak to our MutatingAdmissionWebhook, the master node (or the API server container, depending on how the cluster is set up) should be allowed egress for HTTPS traffic on port 443 to pods in all of the other nodes in the cluster. This might require specific configuration depending on how the infrastructure is set up (on-premises, AWS, Google Cloud, etc). Tip Until Kubernetes v1.14, users were only allowed to register admission webhooks on port 443. Since v1.15 it's possible to register them on different ports. To ensure backward compatibility, the webhook is registered by default on port 443 in the YAML config file we distribute. APM agent compatibility The following New Relic agents collect Kubernetes metadata: Go 2.3.0 or higher Java 4.10.0 or higher Node.js 5.3.0 or higher Python 4.14.0 or higher Ruby 6.1.0 or higher .NET 8.17.438 or higher Openshift requirements To link Openshift and Kubernetes you must enable mutating admission webhooks, which requires Openshift 3.9 or higher. During the process, install a resource that requires admin permissions to the cluster. Run this to log in as admin: oc login -u system:admin Copy Check that webhooks are correctly configured. If they are not, update the master-config.yaml file. admissionConfig: pluginConfig: MutatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission ValidatingAdmissionWebhook: configuration: apiVersion: apiserver.config.k8s.io/v1alpha1 kubeConfigFile: /dev/null kind: WebhookAdmission location: \"\" Copy Important Add kubeConfigFile: /dev/null to address some issues in Openshift. Enable certificate signing by editing the YAML file and updating your configuration: kubernetesMasterConfig: controllerArguments: cluster-signing-cert-file: - \"/etc/origin/master/ca.crt\" cluster-signing-key-file: - \"/etc/origin/master/ca.key\" Copy Restart the Openshift services in the master node. Configure the injection of metadata By default, all the pods you create that include APM agents have the correct environment variables set and the metadata injection applies to the entire cluster. To check that the environment variables have been set, any container that is running must be stopped, and a new instance started (see Validate the injection of metadata). This default configuration also uses the Kubernetes certificates API to automatically manage the certificates required for the injection. If needed, you can limit the injection of metadata to specific namespaces in your cluster or self-manage your certificates. Default configuration To proceed with the default injection of metadata, follow these steps: Download the YAML file: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-latest.yaml Copy Custom configuration You can limit the injection of metadata only to specific namespaces by using labels. To enable this feature, edit your YAML file by finding and uncommenting the following lines: # namespaceSelector: # matchLabels: # newrelic-metadata-injection: enabled Copy With this option, injection is only applied to those namespaces that have the newrelic-metadata-injection label set to enabled: kubectl label namespace YOUR_NAMESPACE newrelic-metadata-injection=enabled Copy Manage custom certificates To use custom certificates you need a specific YAML file: Download the YAML file without automatic certificate management: curl -O http://download.newrelic.com/infrastructure_agent/integrations/kubernetes/k8s-metadata-injection-custom-certs-latest.yaml Copy Replace YOUR_CLUSTER_NAME with the name of your cluster in the YAML file. Apply the YAML file to your Kubernetes cluster: kubectl apply -f k8s-metadata-injection-custom-certs-latest.yaml Copy Once you have the correct YAML file, you can proceed with the custom certificate management option. You need your certificate, server key, and Certification Authority (CA) bundle encoded in PEM format. If you have them in the standard certificate format (X.509), install openssl, and run the following: openssl x509 -in CERTIFICATE_FILENAME -outform PEM -out CERTIFICATE_FILENAME.pem openssl x509 -in SERVER_KEY_FILENAME -outform PEM -out SERVER_KEY_FILENAME.pem openssl x509 -in CA_BUNDLE_FILENAME -outform PEM -out BUNDLE_FILENAME.pem Copy If your certificate/key pair are in another format, see the Digicert knowledgebase for more help. Create the TLS secret with the signed certificate/key pair, and patch the mutating webhook configuration with the CA using the following commands: kubectl create secret tls newrelic-metadata-injection-secret \\ --key=PEM_ENCODED_SERVER_KEY \\ --cert=PEM_ENCODED_CERTIFICATE \\ --dry-run -o yaml | kubectl -n default apply -f - caBundle=$(cat PEM_ENCODED_CA_BUNDLE | base64 | td -d '\\n') kubectl patch mutatingwebhookconfiguration newrelic-metadata-injection-cfg --type='json' -p \"[{'op': 'replace', 'path': '/webhooks/0/clientConfig/caBundle', 'value':'${caBundle}'}]\" Copy Important Certificates signed by Kubernetes have an expiration of one year. For more information, see the Kubernetes source code in GitHub. Validate the injection of metadata In order to validate that the webhook (responsible for injecting the metadata) was installed correctly, deploy a new pod and check for the New Relic environment variables. Create a dummy pod containing Busybox by running: kubectl create -f https://git.io/vPieo Copy Check if New Relic environment variables were injected: kubectl exec busybox0 -- env | grep NEW_RELIC_METADATA_KUBERNETES NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME=fsi NEW_RELIC_METADATA_KUBERNETES_NODE_NAME=nodea NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME=default NEW_RELIC_METADATA_KUBERNETES_POD_NAME=busybox0 NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME=busybox Copy Disable the injection of metadata To disable/uninstall the injection of metadata, use the following commands: Delete the Kubernetes objects using the yaml file: kubectl delete -f k8s-metadata-injection-latest.yaml Copy Delete the TLS secret containing the certificate/key pair: kubectl delete secret/newrelic-metadata-injection-secret Copy Troubleshooting Follow these troubleshooting tips as needed. No Kubernetes metadata in APM or distributed tracing transactions Problem The creation of the secret by the k8s-webhook-cert-manager job used to fail due to the kubectl version used by the image when running in Kubernetes version 1.19.x, The new version 1.3.2 fixes this issue, therefore it is enough to run again the job using an update version of the image to fix the issue. Solution Update the image k8s-webhook-cert-manager (to a version >= 1.3.2) and re-run the job. The secret will be correctly created and the k8s-metadata-injection pod will be able to start. Note that the new version of the manifest and of the nri-bundle are already updated with the correct version of the image. Problem In OpenShift version 4.x, the CA that is used in order to patch the mutatingwebhookconfiguration resource is not the one used when signing the certificates. This is a known issue currently tracked here. In the logs of the Pod nri-metadata-injection, you'll see the following error message: TLS handshake error from 10.131.0.29:37428: remote error: tls: unknown certificate authority TLS handshake error from 10.129.0.1:49314: remote error: tls: bad certificate Copy Workaround Manually update the certificate stored in the mutatingwebhookconfiguration object. The correct CA locations might change according to the cluster configuration. However, you can usually find the CA in the secret csr-signer in the namespace openshift-kube-controller-manager. Problem There is no Kubernetes metadata included in the transactions' attributes of your APM agent or in distributed tracing. Solution Verify that the environment variables are being correctly injected by following the instructions described in the Validate your installation step. If they are not present, get the name of the metadata injection pod by running: kubectl get pods | grep newrelic-metadata-injection-deployment kubectl logs -f pod/podname Copy In another terminal, create a new pod (for example, see Validate your installation), and inspect the logs of the metadata injection deployment for errors. For every created pod there should be a set of 4 new entries in the logs like: {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.107Z\",\"caller\":\"server/main.go:139\",\"msg\":\"POST https://newrelic-metadata-injection-svc.default.svc:443/mutate?timeout=30s HTTP/2.0\\\" from 10.11.49.2:32836\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.110Z\",\"caller\":\"server/webhook.go:168\",\"msg\":\"received admission review\",\"kind\":\"/v1, Kind=Pod\",\"namespace\":\"default\",\"name\":\"\",\"pod\":\"busybox1\",\"UID\":\"6577519b-7a61-11ea-965e-0e46d1c9335c\",\"operation\":\"CREATE\",\"userinfo\":{\"username\":\"admin\",\"uid\":\"admin\",\"groups\":[\"system:masters\",\"system:authenticated\"]}} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:182\",\"msg\":\"admission response created\",\"response\":\"[{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env\\\",\\\"value\\\":[{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CLUSTER_NAME\\\",\\\"value\\\":\\\"adn_kops\\\"}]},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NODE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"spec.nodeName\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_NAMESPACE_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_NAME\\\",\\\"value\\\":\\\"busybox\\\"}},{\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/spec/containers/0/env/-\\\",\\\"value\\\":{\\\"name\\\":\\\"NEW_RELIC_METADATA_KUBERNETES_CONTAINER_IMAGE_NAME\\\",\\\"value\\\":\\\"busybox\\\"}}]\"} {\"level\":\"info\",\"ts\":\"2020-04-09T12:55:32.111Z\",\"caller\":\"server/webhook.go:257\",\"msg\":\"writing response\"} Copy If there are no new entries on the logs, it means that the apiserver is not being able to communicate with the webhook service, this could be due to networking rules or security groups rejecting the communication. To check if the apiserver is not being able to communicate with the webhook you should inspect the apiserver logs for errors like: failed calling webhook \"metadata-injection.newrelic.com\": ERROR_REASON Copy To get the apiserver logs: Start a proxy to the Kubernetes API server by the executing the following command in a terminal window and keep it running. kubectl proxy --port=8001 Copy Create a new pod in your cluster, this will make the apiserver try to communicate with the webhook. The following command will create a busybox. kubectl create -f https://git.io/vPieo Copy Retrieve the apiserver logs. curl localhost:8001/logs/kube-apiserver.log > apiserver.log Copy Delete the busybox container. kubectl delete -f https://git.io/vPieo Copy Inspect the logs for errors. grep -E 'failed calling webhook' apiserver.log Copy Remember that one of the requirements for the metadata injection is that the apiserver must be allowed egress to the pods running on the cluster. If you encounter errors regarding connection timeouts or failed connections, make sure to check the security groups and firewall rules of the cluster. If there are no log entries in either the apiserver logs or the metadata injection deployment, it means that the webhook was not properly registered. Ensure the metadata injection setup job ran successfully by inspecting the output of: kubectl get job newrelic-metadata-setup Copy If the job is not completed, investigate the logs of the setup job: kubectl logs job/newrelic-metadata-setup Copy Ensure the CertificateSigningRequest is approved and issued by running: kubectl get csr newrelic-metadata-injection-svc.default Copy Ensure the TLS secret is present by running: kubectl get secret newrelic-metadata-injection-secret Copy Ensure the CA bundle is present in the mutating webhook configuration: kubectl get mutatingwebhookconfiguration newrelic-metadata-injection-cfg -o json Copy Ensure the TargetPort of the Service resource matches the Port of the Deployment's container: kubectl describe service/newrelic-metadata-injection-svc kubectl describe deployment/newrelic-metadata-injection-deployment Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.26586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Link</em> your applications to Kubernetes",
        "sections": "<em>Link</em> your applications to Kubernetes",
        "tags": "<em>Link</em> apps and services",
        "body": "You can surface Kubernetes metadata and <em>link</em> it to your APM agents as distributed traces to explore performance issues and troubleshoot transaction errors. For more information, see this New Relic blog post. You can quickly start monitoring Kubernetes clusters using Auto-telemetry with Pixie, which"
      },
      "id": "603ebb94196a674fd1a83df3"
    },
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "41eee9dfacd933b49935d7bd4d32cb76476c29ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-06-25T18:13:15Z",
      "updated_at": "2021-03-10T23:41:36Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.97827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "URL <em>guidelines</em>",
        "tags": "API writing <em>guidelines</em>",
        "body": "Syntax newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name[, integer $optional_param]) newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the &quot;View all methods&quot; page. Requirements Agent"
      },
      "id": "60441b8d28ccbc0ab22c60b3"
    },
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "a3fb036bc32f2dbc39c252acc9306e5ae0d5b7bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/api-tutorial-template/",
      "published_at": "2021-06-25T18:13:15Z",
      "updated_at": "2021-03-10T23:40:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What NR products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in New Relic APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.97822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "API writing <em>guidelines</em>",
        "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content <em>link</em> in the Page tools box. Delete all content up to Introduction (this heading won&#x27;t be visible"
      },
      "id": "60441b4a64441f7766378f09"
    }
  ],
  "/docs/style-guide/writing-guidelines/levels-headings": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-06-25T18:15:28Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 478.11237,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " it. Describe any limitations with user permissions or subscription <em>levels</em> that would prevent them from using the feature. If the feature is available for any user or subscription <em>level</em>, don&#x27;t bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting"
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.689896,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use sentence case in <em>headings</em>",
        "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document&#x27;s title, <em>headings</em>, products, features, and other elements"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 78.72916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Headings</em> (H2s)",
        "body": " that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they&#x27;ve found the right doc. It provides a short, readable overview of the doc&#x27;s contents. <em>Headings</em> (H2s) Check that: Heading names are concise, yet provide information that helps readers"
      },
      "id": "604220b2196a6775f5a83dc0"
    }
  ],
  "/docs/style-guide/writing-guidelines/more-help-section": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/pricing-language-guidelines/",
      "sections": [
        "Pricing/billing-related guidelines",
        "Explanations of philosophy",
        "New Relic One pricing plan",
        "Pro and Enterprise editions",
        "Guidelines for mentioning pricing edition"
      ],
      "published_at": "2021-06-29T09:22:32Z",
      "title": "Pricing/billing-related guidelines",
      "updated_at": "2021-06-29T09:22:31Z",
      "type": "docs",
      "external_id": "e01bd50120150589df9dca0e6131221872d50b65",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains required styles and recommended phrasings for pricing-related requirements. Explanations of philosophy If you haven't already, please read Overview of pricing plans to understand our two different pricing plans, as it helps understand our pricing language guidelines. We should attempt to minimize reference to pricing and billing impacts in the docs, with these two main exceptions: We put a good amount of pricing and billing detail in the pricing/billing-related docs. When a feature requires a Full Stack Observability pricing edition (Standard, Pro, Enterprise), we should place that in the requirements of a feature's doc. Learn more about documenting pricing edition. Here are some reasons behind this philosophy of minimizing pricing-related docs mentions: New Relic One pricing plan For the New Relic One pricing plan, there are several pricing factors involved. As a general approach, the only pricing factor we document is that related to the editions (Standard, Pro, and Enterprise). This is because the New Relic platform is much more open on the New Relic One pricing plan. The user type (basic user versus full user) or roles/capability limitations are the main factors in gating platform functionality. And in those cases, it should usually be fairly obvious (via UI upsells, or general knowledge that product gating is often due to roles/permissions) why things are off-limits. Pro and Enterprise editions The main exception to New Relic One pricing factors is for features provided by Pro and Enterprise editions; for example: Admin functionalities like SAML SSO set up, or the ability to create custom user roles More synthetic monitor checks Increased data retention periods Because there are only a few things in the Pro and Enterprise editions, this should be an infrequent need. Guidelines for mentioning pricing edition When you document a pricing edition-related restriction, use the following approach: Requirements section: When documenting features that require the Pro or Enterprise edition, add edition requirements in a \"requirements\" section of the doc, with wording like: \"This requires Pro or Enterprise edition.\" Only add pricing-related wording for the specific features that Pro and Enterprise edition give access to; this is a fairly small set of features. Pricing requirements in one section: As a general rule, attempt to place any pricing edition requirement in a single location and avoid putting it in multiple paragraphs. Original pricing plan: At this point, only add edition-related requirements for the New Relic One pricing plan editions, not original pricing plan editions. The original pricing plan will be more and more de-emphasized over time, as more customers get on the new pricing plan, so there shouldn't be much need to mention original pricing aspects or edit those docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.50452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Guidelines <em>for</em> mentioning pricing edition",
        "body": " place that in the requirements of a feature&#x27;s doc. Learn <em>more</em> about documenting pricing edition. Here are some reasons behind this philosophy of minimizing pricing-related docs mentions: New Relic One pricing plan For the New Relic One pricing plan, there are several pricing factors involved"
      },
      "id": "60dae658196a678cb15e15c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/user-related-language-guidelines/",
      "sections": [
        "Users/roles-related language guidelines",
        "Note about user models",
        "Styles and formatting",
        "General philosophy for user permissions/roles language",
        "Document role-related requirements",
        "Don't document user type or group restrictions",
        "Original user model permissions"
      ],
      "published_at": "2021-06-29T09:23:44Z",
      "title": "Users/roles-related language guidelines",
      "updated_at": "2021-06-29T09:23:44Z",
      "type": "docs",
      "external_id": "432131e2159509833ae5f540e8be2e77c0600dfd",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains required styles and recommended phrasings for user-related terminology on the New Relic One user model. Note about user models This style guide applies to the New Relic One user model, not the original user model. Even though both user models share certain terms (such as Admin), this is an entirely different user model with a very different structure, recommended phrasings, and style. To understand user model differences, see Overview of user model changes. The original user model will be increasingly deprecated, so we shouldn't need to talk much about that user model or update those docs. Styles and formatting Here are some user-related styles and formats for user-related language for the New Relic One user model: Category Example use Styles and tips User type (basic user vs full user) \"If you’re a full user...\" Lower case, no style. Note that it can sometimes be awkward when \"basic user\" is in front of a noun. For example: \"To learn about basic user capabilities...\" can sound like you're talking about user capabilities that are basic. To avoid this, rephrase to be more clear and/or link to the user type doc section from \"basic user\" or \"full user.\" Roles \"You must be in a group that has the Billing user role.\" Sentence case, bold. This phrasing is meant to cover all cases where a user is in a group that has that role, whether that group is a default group (Admin or User) or a custom group that has had that role assigned. We recommend linking to the standard roles doc, which lists and defines the roles, and also explains how these roles are related to the default groups (Admin and User). Default groups \"When adding a user, add them to the Admin group.\" Sentence case, bold. We recommend linking to the explanation of default groups for more context. General philosophy for user permissions/roles language Our general philosophy is summed up in these points: Document role-related requirements For most docs (with exception of API docs, explained in this section), we should only document role-related requirements. If there is a specific standard role required to use a feature/functionality, explain that in a requirements section so that customers will understand what user role they need to use that feature. This approach means that our user-related restriction mentions should be fairly infrequent, as there are only a few features that are gated by a specific standard role. These apply mainly to the organization and user management areas, such as the ability to manage users or manage billing). API docs exception: Because APIs are not as obvious and transparent as the product UI, we should document any requirements that SMEs think are relevant, which may also include user type. Attempt to list any API requirements in a single location, and not spread them throughout the docs. Don't document user type or group restrictions We don't document restrictions related to user type (basic vs. full user) or default groups. For more about role language guidelines, see the styles table. Basic vs. full users: We don't document restrictions related to user type (basic vs. full). This is because things that are off limits to basic users in the product are also places they are given upsell notes. And because those limitations are so widespread, we would be documenting that everywhere. Default user groups: We don't explain restrictions related to default user groups (Admin and User). This is because, while the group does impact what you can access, the actual mechanism causing the restriction is due to a standard role, not to the group. If you have questions about how user type, user group, and user roles relate, see the User model docs. Original user model permissions Sometimes it's necessary to explain how access works for users on both user models. This should be less and less required over time because customers will be migrating to the new pricing plan and new user model, and we should attempt to avoid it unless completely necessary. But if this is deemed required, you can explain this using the following approach: User role requirements: • Users on the [original user model](link): the [**Data retention manager** role](link). • Users on [New Relic One user model](link): the [**Billing user** role](link). Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.06644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Styles and <em>formatting</em>",
        "body": " be awkward when &quot;basic user&quot; is in front of a noun. For example: &quot;To learn about basic user capabilities...&quot; can sound like you&#x27;re talking about user capabilities that are basic. To avoid this, rephrase to be <em>more</em> clear and&#x2F;or link to the user type doc <em>section</em> from &quot;basic user&quot; or &quot;full user.&quot; Roles &quot;You"
      },
      "id": "60dae6a028ccbc539271b451"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/dropdown-section/",
      "sections": [
        "DropdownSection",
        "Usage",
        "Props",
        "Type definitions",
        "Cursor"
      ],
      "published_at": "2021-06-29T02:03:23Z",
      "title": "DropdownSection",
      "updated_at": "2021-06-25T01:58:30Z",
      "type": "developer",
      "external_id": "013f52f99c588b0e1205778bf08efcece91c363c",
      "document_type": "page",
      "popularity": 1,
      "body": "Section of <Dropdown> component. Usage import { DropdownSection } from 'nr1' Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed inside (or returned by the render callback) are of type <DropdownItem>. The recommendation is to use the render callback when a large number of items is provided, since the item list will be virtualized by the component, thus increasing the performance. classNamestring Appends class names to the component. Should be used only for positioning and spacing purposes. itemsarray Items to render, in the shape of a list of objects. Usually, each item in the items array contains the required data to generate the corresponding <DropdownItem>. This prop is required when rendering items with the render callback (function as children). onLoadMorefunction Callback fired when more items must be loaded. This happens when you're lazy loading the items and the items that are about to render cannot be found in the items array. This callback should be used to fetch/load the missing items from the backend or other sources. The returned Promise should be resolved once item data has finished loading. It will be used to determine when to refresh the list with the newly-loaded data. This callback may be called multiple times in reaction to a single scroll event. function ( cursor : Cursor // Items to load. ) rowCountnumber Number of rows. By default it's equal to length of array passed in the items prop. You should specify the rowCount when you know the total number of items but you want to lazy load them while scrolling. styleobject Inline style for custom styling. Should be used only for positioning and spacing purposes. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests. titlestring DEFAULT \"\" Section title. Type definitions Cursor { startIndex : number, // First index of the range of items to load. stopIndex : number, // Last index of the range of items to load. }",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 67.43614,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "<em>Section</em> of &lt;Dropdown&gt; component. Usage import { Dropdown<em>Section</em> } from &#x27;nr1&#x27; Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed"
      },
      "id": "6091f874e7b9d283a05068f0"
    }
  ],
  "/docs/style-guide/writing-guidelines/pricing-language-guidelines": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/user-related-language-guidelines/",
      "sections": [
        "Users/roles-related language guidelines",
        "Note about user models",
        "Styles and formatting",
        "General philosophy for user permissions/roles language",
        "Document role-related requirements",
        "Don't document user type or group restrictions",
        "Original user model permissions"
      ],
      "published_at": "2021-06-29T09:23:44Z",
      "title": "Users/roles-related language guidelines",
      "updated_at": "2021-06-29T09:23:44Z",
      "type": "docs",
      "external_id": "432131e2159509833ae5f540e8be2e77c0600dfd",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains required styles and recommended phrasings for user-related terminology on the New Relic One user model. Note about user models This style guide applies to the New Relic One user model, not the original user model. Even though both user models share certain terms (such as Admin), this is an entirely different user model with a very different structure, recommended phrasings, and style. To understand user model differences, see Overview of user model changes. The original user model will be increasingly deprecated, so we shouldn't need to talk much about that user model or update those docs. Styles and formatting Here are some user-related styles and formats for user-related language for the New Relic One user model: Category Example use Styles and tips User type (basic user vs full user) \"If you’re a full user...\" Lower case, no style. Note that it can sometimes be awkward when \"basic user\" is in front of a noun. For example: \"To learn about basic user capabilities...\" can sound like you're talking about user capabilities that are basic. To avoid this, rephrase to be more clear and/or link to the user type doc section from \"basic user\" or \"full user.\" Roles \"You must be in a group that has the Billing user role.\" Sentence case, bold. This phrasing is meant to cover all cases where a user is in a group that has that role, whether that group is a default group (Admin or User) or a custom group that has had that role assigned. We recommend linking to the standard roles doc, which lists and defines the roles, and also explains how these roles are related to the default groups (Admin and User). Default groups \"When adding a user, add them to the Admin group.\" Sentence case, bold. We recommend linking to the explanation of default groups for more context. General philosophy for user permissions/roles language Our general philosophy is summed up in these points: Document role-related requirements For most docs (with exception of API docs, explained in this section), we should only document role-related requirements. If there is a specific standard role required to use a feature/functionality, explain that in a requirements section so that customers will understand what user role they need to use that feature. This approach means that our user-related restriction mentions should be fairly infrequent, as there are only a few features that are gated by a specific standard role. These apply mainly to the organization and user management areas, such as the ability to manage users or manage billing). API docs exception: Because APIs are not as obvious and transparent as the product UI, we should document any requirements that SMEs think are relevant, which may also include user type. Attempt to list any API requirements in a single location, and not spread them throughout the docs. Don't document user type or group restrictions We don't document restrictions related to user type (basic vs. full user) or default groups. For more about role language guidelines, see the styles table. Basic vs. full users: We don't document restrictions related to user type (basic vs. full). This is because things that are off limits to basic users in the product are also places they are given upsell notes. And because those limitations are so widespread, we would be documenting that everywhere. Default user groups: We don't explain restrictions related to default user groups (Admin and User). This is because, while the group does impact what you can access, the actual mechanism causing the restriction is due to a standard role, not to the group. If you have questions about how user type, user group, and user roles relate, see the User model docs. Original user model permissions Sometimes it's necessary to explain how access works for users on both user models. This should be less and less required over time because customers will be migrating to the new pricing plan and new user model, and we should attempt to avoid it unless completely necessary. But if this is deemed required, you can explain this using the following approach: User role requirements: • Users on the [original user model](link): the [**Data retention manager** role](link). • Users on [New Relic One user model](link): the [**Billing user** role](link). Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.45871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Users&#x2F;roles-<em>related</em> language <em>guidelines</em>",
        "sections": "Users&#x2F;roles-<em>related</em> language <em>guidelines</em>",
        "body": " language <em>guidelines</em>, see the styles table. Basic vs. full users: We don&#x27;t document restrictions <em>related</em> to user type (basic vs. full). This is because things that are off limits to basic users in the product are also places they are given upsell notes. And because those limitations are so widespread"
      },
      "id": "60dae6a028ccbc539271b451"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Tip",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-06-25T16:56:59Z",
      "updated_at": "2021-06-20T02:16:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Tip To use our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, defined as users with access to Full Stack Observability features. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. More user-related billing details: You can see your full user count in the UI. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. For organizations on our original account/user model that have a master/sub-account structure, the count of billable users in the UI may differ from the list of users you see. For more on this, see User count discrepancy. A user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. The Standard edition of the New Relic One pricing plan includes one free full user. Users with duplicate email addresses are only counted once. For organizations on our original user model, a user may be set as a basic user in one account, and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition for Full Stack Observability, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise Full Stack Observability editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.141,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>pricing</em> and <em>billing</em> ",
        "sections": "New Relic One <em>pricing</em> and <em>billing</em>",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": " of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month <em>bill</em>. For how to query user-<em>related</em> usage, see Query and alert on usage. Usage plan details There are two New Relic One <em>pricing</em> usage plans: Pay-as-you-go: This plan bills"
      },
      "id": "6043f69a64441f7b26378eda"
    },
    {
      "sections": [
        "Overview of changes to pricing and user model",
        "Overview of how pricing plan and account/user model relate",
        "Pricing plans explained",
        "Determine pricing plan",
        "Convert to new pricing",
        "Account/user models explained",
        "Requirements for new account/user model",
        "Determine which user model you're on",
        "Feature impacts of user model",
        "Transition to new models"
      ],
      "title": "Overview of changes to pricing and user model",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original product-based pricing"
      ],
      "external_id": "b19d61b5a0c65ca352e2ce0e260e2b53391b94fc",
      "image": "https://docs.newrelic.com/static/1461470cc1ef0be91120c84d76a7ccdd/c1b63/new-relic-one-pricing-plan-billing-ui.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-product-based-pricing/overview-changes-pricing-user-model/",
      "published_at": "2021-06-26T03:56:04Z",
      "updated_at": "2021-06-26T03:56:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In 2020, New Relic released both a newer pricing plan and a newer account/user model. Keep reading to learn about: How the pricing plan and the user model relate to each other Pricing plans explained Account/user models explained How to switch to the new models Overview of how pricing plan and account/user model relate In 2020, we released both a new, improved pricing plan and a new, improved account/user model. These models represent the future, and eventually all New Relic organizations will be on these models. But currently, our older customers may have one of several combinations of these as they either switch to the new pricing or migrate their users to the new account/user model. This table shows how pricing and user model relate to each other: Pricing plan factors Account/user model factors Original pricing If your organization was created before July 30 2020, you remain on our original pricing plan until you transition to New Relic One pricing. For original pricing accounts, you have users on the original user model unless you've migrated your users to the new model. Note that if you've added users via automated user management, they're on the new model. This means it's possible to have some users on both models. New Relic One pricing An organization is on the New Relic One pricing plan: If it was created on or after July 30 2020, or If it's an older organization but has switched to New Relic One pricing. If your organization was created on or after July 30 2020, your users are on the New Relic One account/user model. If you have an older organization, you have users on the original account/user model unless you've migrated your users to the new model. Pricing plans explained New Relic organizations are on one of two pricing plans: New Relic One pricing: Our new pricing plan is simpler. It bills on a) which edition you're on (Standard, Pro, or Enterprise), b) the GBs of data ingested, and c) how many billable full users you have. All organizations created on or after July 30 2020 are on this pricing plan, as are older organizations that have switched to this pricing. There are two versions of this pricing plan. Our original product-based pricing plan: this is based on subscriptions to specific products (e.g., APM, Browser, Mobile, Infrastructure). Some organizations have the option to transition to the newer pricing plan: in that case, their users remain on our original user model. Determine pricing plan To determine which pricing plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see billing information about data ingested and the number of billable users, you’re on the new pricing plan. If you're on New Relic One pricing, you'll see a billing UI like this. Convert to new pricing Some customers are able to switch to new pricing. Learn more about switching your pricing plan. Account/user models explained In this context, the term \"account/user model\" (or simply \"user model\") refers to the structure of a New Relic user record and how it interacts with the broader New Relic organization that it's in. Our two account/user models are: New Relic One user model: this newer, improved user model has these major differences from the original user model: All your accounts and users are contained under a top-level organization. This gives an organization stronger control over managing users and what they can access. One impact of this is that users who work with multiple New Relic organizations may have an email address associated with multiple logins. Users on this model have a different system for managing permissions and account access. Using access grants, you assign users access to specific roles on specific accounts. Original user model: some aspects of this older model that are different from our newer model: There wasn't as much organization-level control over users. For example, a New Relic user had the ability to access multiple accounts they'd been granted access to using a single login. Users on the original user model have a different user management system. To learn more about benefits of the new model, see our blog post about user model changes and an explanation of the new account structure. For impacts and limitations, see Feature impacts. Requirements for new account/user model Here's a synopsis of the factors governing what organizations use the new model: All New Relic organizations that signed up after July 30 2020 have users on this model, and also have the new pricing plan. Some older New Relic organizations have had their users migrated to the new model by New Relic or by using the user migration procedure. Note that switching to the new pricing plan is independent from migrating users. Partner accounts (resellers, managed service providers), and customers using the partnership account structure, cannot yet migrate their users to the new model. Determine which user model you're on To determine what user model you're on, from the account dropdown select User preferences. If you see the UI below, you're on the New Relic One user model. If you see a different UI with more content displayed, you're on the original user model (see original user docs). To determine if you can manage users on the New Relic One user model, see Manage users. The user model is independent of your pricing plan. For how user model relates to pricing, see the Pricing and user model table. Feature impacts of user model The new user model offers many benefits. Here are some feature impacts of being on the New Relic One user model that may be surprising or unintuitive to our existing customers: More separation of organizations/accounts: If you have an email address associated with multiple New Relic accounts, this may mean you need to log out and log back in. Learn more about account access. Adding accounts: Pro and Enterprise edition can have more than one account in their organization. Currently users in these organizations cannot, on their own, add accounts. They must get help from their New Relic account representative. To learn about adding users to accounts, see Manage users. Alerts-related impacts: Policy actions: For alert policies and conditions, some UI locations display the user that made the last modification. For users on the new model, it will display their user ID and not their user name. For example, a policy might read Last modified Sep 7, '20 4:26 pm by user 1234567 instead of by John Doe. If you have user management permissions, you can determine what user this is by going to the User management UI. Notifications: Users on the new model won’t show up as an option when choosing users to receive alert notifications. The result of this is that these users will not get New Relic mobile app push notifications. As a workaround, you can instead use their email address as the notification channel. Changing account name: These users cannot change the name of their organization after it has been created. Transition to new models Some New Relic customers are able to transition to the new models. To learn more about this, see Transition to new models.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.405945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of changes to <em>pricing</em> and user model",
        "sections": "Overview of how <em>pricing</em> plan and account&#x2F;user model <em>relate</em>",
        "tags": "Original accounts and <em>billing</em>",
        "body": " remain on our original user model. Determine <em>pricing</em> plan To determine which <em>pricing</em> plan you’re on: go to one.newrelic.com, select the account dropdown, and select Manage your plan. If you see <em>billing</em> information about data ingested and the number of billable users, you’re on the new <em>pricing</em> plan"
      },
      "id": "603e97fa28ccbcb7c2eba754"
    }
  ],
  "/docs/style-guide/writing-guidelines/screenshots-images": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-25T17:05:40Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 851.7698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Products <em>and</em> features",
        "body": ": Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our <em>Screenshots</em> and <em>images</em> document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don&#x27;t capitalize"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-06-25T18:16:21Z",
      "updated_at": "2021-04-05T08:33:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or Docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the Docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 687.238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Processes <em>and</em> procedures",
        "body": " sentences, or long paragraphs. Useful <em>images</em> For <em>screenshots</em> and <em>images</em>, check that: Full size <em>images</em> always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped <em>images</em> clearly show their relevance, with or without captions. In addition, make sure"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Update your Nerdpack's catalog information",
        "Update your CLI",
        "Check your permissions",
        "Publish your Nerdpack",
        "Update your Nerdpack's catalog metadata",
        "Update your Nerdpack's icons",
        "Resolve issues with submitting catalog information",
        "Resize your images",
        "Check the length of your strings"
      ],
      "title": "Update your Nerdpack's catalog information",
      "type": "developer",
      "tags": [
        "nerdpack",
        "catalog"
      ],
      "external_id": "dfee75ddee87a216eb9454abcaeabcc1ee0a8c7d",
      "image": "https://developer.newrelic.com/static/4560bce9c6a1165799e6eaf9d10f4868/0086b/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/publish-deploy/catalog/",
      "published_at": "2021-06-30T01:46:06Z",
      "updated_at": "2021-05-21T01:48:59Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn to describe your Nerdpack in the catalog",
      "body": "Add screenshots, descriptions, and other metadata to your Nerdpack, and upload it all to the New Relic One catalog. Update your CLI Before you run any commands, ensure that you have the latest version of the CLI: bash Copy $ nr1 update Check your permissions To publish your Nerdpack and update its catalog information, you need: Access to the account that published it The necessary permissions for managing Nerdpacks Publish your Nerdpack You need to publish Nerdpacks that you create before you can update their catalog information. Update your Nerdpack's catalog metadata After you've published your Nerdpack to the New Relic One catalog, update the Nerdpack's metadata to let users know all about your Nerdlets or visualizations. Step 1 of 9 Go to New Relic: Step 2 of 9 Navigate to Apps: Step 3 of 9 Find your published Nerdpack under New Relic One catalog: Notice that there is no information on the Apps or details page other than the Nerdpack's name and the brief description found in nr1.json: There are no screenshots, icons, details, or what's new features. To add these, your Nerdpack needs a catalog directory. Step 4 of 9 From the root of your Nerdpack, create a catalog directory to house your Nerdpack's screenshots and metadata: bash Copy $ nr1 create --type catalog ✔ Component created successfully! catalog is available at \"./catalog\" Inside your catalog directory, you'll find specific files and directories for portraying information about your Nerdpack to your users: bash Copy $ ls catalog README.md additionalInfo.md config.json documentation.md screenshots File Description README.md A markdown file that instructs you how to use the information and metadata in catalog config.json A JSON file that contains the following fields: tagline: A brief headline for the application. This cannot exceed 30 characters. repository: The URL for the Nerdpack's remote repository. This cannot exceed 1000 characters. details: The purpose of the Nerdpack and how to use it. This cannot exceed 1000 characters. Use newlines for formatting, and don't include any markdown or HTML. support: An object that contains: issues: A URL for the repository's issues list. For example, the Issues tab if using GitHub. email: A valid email address for the team supporting the application community: A URL for a support thread, forum, or website for troubleshooting and usage support whatsNew: A bulleted list of changes in the current release version. This cannot exceed 500 characters. Use newlines for formatting, and don't include markdown or HTML. Check out our Pageview Map application's config.json to see a real-life implementation. documentation.md A markdown file that tells users how to use the Nerdpack's Nerdlets or visualizations. This shows in the detail view's Documentation tab. additionalInfo.md An optional markdown file for any additional information about using your application screenshots A directory that contains screenshots of your Nerdlets or visualizations. This can contain no more than 6 images. All screenshots must meet the following criteria: 3:2 aspect ratio PNG format landscape orientation 1600 to 2400 pixels wide Step 5 of 9 Update your Nerdpack's documentation.md file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"\", 3 \"details\": \"\", 4 \"repository\": \"\", 5 \"whatsNew\": \"\", 6 \"support\": { 7 \"email\": { 8 \"address\": \"\" 9 }, 10 \"issues\": { 11 \"url\": \"\" 12 }, 13 \"community\": { 14 \"url\": \"\" 15 } 16 } 17 } catalog/config.json Copy Step 6 of 9 Update your config.json file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Initial commit\" 6 } catalog/config.json Copy Step 7 of 9 Include screenshots in your screenshots directory. Step 8 of 9 Submit the information to the New Relic One catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.0 Step 9 of 9 Go to the catalog to see your changes: Click your Nerdpack to see the new details: Update your Nerdpack's icons Within a Nerdpack, you can set two types of icons: One for your entire Nerdpack, which represents your Nerdpack in the catalog One for each of your launchers, which represents your Nerdlets Replace these icons and publish your Nerdpack to see the changes. Step 1 of 7 Update the icon.png in the root of your Nerdpack. This icon is used in the catalog and the Nerdpack's detail page. Step 2 of 7 If you're building a Nerdpack with one or more launchers, update the icon.png in each of your launcher's subfolders. Step 3 of 7 Update your package.json version: { \"private\": true, \"name\": \"demo-app\", \"version\": \"1.0.1\", \"scripts\": { \"start\": \"nr1 nerdpack:serve\", \"test\": \"exit 0\" }, \"nr1\": { \"uuid\": \"f2dbc999-e9a3-49b9-933d-5a704c6750bd\" }, \"dependencies\": { \"prop-types\": \"^15.6.2\", \"react\": \"^16.6.3\", \"react-dom\": \"^16.6.3\" }, \"browserslist\": [\"last 2 versions\", \"not ie < 11\", \"not dead\"] } package.json Copy This allows you to publish a new version of your Nerdpack. Step 4 of 7 Publish your Nerdpack: bash Copy $ nr1 nerdpack:publish Step 5 of 7 Update your whatsNew string in catalog/config.json: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Add new icons\" 6 } catalog/config.json Copy This will tell users what you added in the latest version of your Nerdpack. Step 6 of 7 Submit this new metadata to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded ✔ Updated metadata for DemoApp 1.0.1 Step 7 of 7 Go to the catalog and subscribe to your Nerdpack to see your new icon: Resolve issues with submitting catalog information Sometimes, when you work with catalog metadata, you may run into issues. Consider some common solutions for resolving these issues. Publish your Nerdpack Remember that you can only submit catalog metadata for Nerdpacks that have already been published. If you try to submit information for a Nerdpack that hasn't been published, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 1 error while updating DemoApp 1.0.0 › › Invalid Version: Nerdpack version 1.0.0 not found. Have you run `nr1 nerdpack:publish` yet? › Code: UNKNOWN Resize your images Screenshots for the catalog must meet the criteria specified previously in this guide. If they don't, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a size ratio of 4:2. Update size ratio to 3:2. › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a width of 3054px. Update size to be between 1600px and 2400px. › Code: UNKNOWN Check the length of your strings Most of the content in config.json has string-length requirements. Make sure you review those requirements and adhere to them when you update your config.json file. Otherwise, you'll see errors when you try to submit your configuration to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/config.json › Invalid Metadata: `details` has a character length of 2204. Must be no longer than 1000 characters › › catalog/config.json › Invalid Metadata: `tagline` has a character length of 266. Must be no longer than 30 characters › Code: UNKNOWN",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.84283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Resize your <em>images</em>",
        "body": " <em>images</em> <em>Screenshots</em> for the catalog must meet the criteria specified previously in this guide. If they don&#x27;t, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading <em>screenshots</em>... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog&#x2F;<em>screenshots</em>&#x2F;<em>screenshot</em>.png › Invalid <em>Screenshot</em>"
      },
      "id": "609c868664441f2bf22f3706"
    }
  ],
  "/docs/style-guide/writing-guidelines/user-related-language-guidelines": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/pricing-language-guidelines/",
      "sections": [
        "Pricing/billing-related guidelines",
        "Explanations of philosophy",
        "New Relic One pricing plan",
        "Pro and Enterprise editions",
        "Guidelines for mentioning pricing edition"
      ],
      "published_at": "2021-06-29T09:22:32Z",
      "title": "Pricing/billing-related guidelines",
      "updated_at": "2021-06-29T09:22:31Z",
      "type": "docs",
      "external_id": "e01bd50120150589df9dca0e6131221872d50b65",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains required styles and recommended phrasings for pricing-related requirements. Explanations of philosophy If you haven't already, please read Overview of pricing plans to understand our two different pricing plans, as it helps understand our pricing language guidelines. We should attempt to minimize reference to pricing and billing impacts in the docs, with these two main exceptions: We put a good amount of pricing and billing detail in the pricing/billing-related docs. When a feature requires a Full Stack Observability pricing edition (Standard, Pro, Enterprise), we should place that in the requirements of a feature's doc. Learn more about documenting pricing edition. Here are some reasons behind this philosophy of minimizing pricing-related docs mentions: New Relic One pricing plan For the New Relic One pricing plan, there are several pricing factors involved. As a general approach, the only pricing factor we document is that related to the editions (Standard, Pro, and Enterprise). This is because the New Relic platform is much more open on the New Relic One pricing plan. The user type (basic user versus full user) or roles/capability limitations are the main factors in gating platform functionality. And in those cases, it should usually be fairly obvious (via UI upsells, or general knowledge that product gating is often due to roles/permissions) why things are off-limits. Pro and Enterprise editions The main exception to New Relic One pricing factors is for features provided by Pro and Enterprise editions; for example: Admin functionalities like SAML SSO set up, or the ability to create custom user roles More synthetic monitor checks Increased data retention periods Because there are only a few things in the Pro and Enterprise editions, this should be an infrequent need. Guidelines for mentioning pricing edition When you document a pricing edition-related restriction, use the following approach: Requirements section: When documenting features that require the Pro or Enterprise edition, add edition requirements in a \"requirements\" section of the doc, with wording like: \"This requires Pro or Enterprise edition.\" Only add pricing-related wording for the specific features that Pro and Enterprise edition give access to; this is a fairly small set of features. Pricing requirements in one section: As a general rule, attempt to place any pricing edition requirement in a single location and avoid putting it in multiple paragraphs. Original pricing plan: At this point, only add edition-related requirements for the New Relic One pricing plan editions, not original pricing plan editions. The original pricing plan will be more and more de-emphasized over time, as more customers get on the new pricing plan, so there shouldn't be much need to mention original pricing aspects or edit those docs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.17757,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Pricing&#x2F;billing-<em>related</em> <em>guidelines</em>",
        "sections": "Pricing&#x2F;billing-<em>related</em> <em>guidelines</em>",
        "body": "This doc explains required styles and recommended phrasings for pricing-<em>related</em> requirements. Explanations of philosophy If you haven&#x27;t already, please read Overview of pricing plans to understand our two different pricing plans, as it helps understand our pricing <em>language</em> <em>guidelines</em>. We should"
      },
      "id": "60dae658196a678cb15e15c6"
    },
    {
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new account/user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full)",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "title": "Users, roles, permissions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "published_at": "2021-06-26T13:07:15Z",
      "updated_at": "2021-06-20T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users who are on our original user model. If you were a New Relic customer before July 30 2020, you likely have users on our original user model (and not the New Relic One user model). One way to quickly check your users' user model: if you can see users in the Users and roles UI, those users are on our original user model. Want to learn more about user model changes? See Overview of user models. Updates about our new account/user model In July of 2020, we released a new account/user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more and more pre-existing organizations to the new model. Some organizations with users on the original user model are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original user model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this UI: select the account dropdown, select Account settings, and select Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. When basic users attempt to upgrade to full users, an upgrade request is sent to all admins. For more about our user types, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a master/sub-account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a master account's sub-accounts, go to a master account's Account settings UI page, click on a sub-account, and go to their Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to Full-Stack Observability features (for more details on feature access, see Capabilities). Basic users can request to become full users in the UI. They cannot self-upgrade. Basic users will see prompts when attempting to access unavailable features. Requests to upgrade are sent to all admins on that account. No matter what custom group a basic user is assigned to, they always have the capabilities of a basic user: no more and no less. Full user. Details: Full users have access to our Full-Stack Observability features, which include our curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details on what's available, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user has full user access for all accounts. For how to edit user type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a master account that has sub-accounts automatically have the same level of access for all sub-accounts. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of basic user rights for your New Relic account. Individuals on a master account with sub-accounts automatically have the same level of access for all sub-accounts. However, they will not receive email notifications for alerts or weekly reports for sub-accounts unless they are explicitly granted permission on these sub-accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete sub-accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with New Relic APM. To allow a User or Restricted User to execute any of these functions in New Relic APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions in New Relic Insights, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.29398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, permissions (original <em>user</em> model)",
        "sections": "<em>Users</em>, <em>roles</em>, permissions (original <em>user</em> model)",
        "tags": "Original <em>users</em> and <em>roles</em>",
        "body": " or Admins To add a new <em>user</em> to your New Relic account: Go to: account dropdown &gt; Account settings &gt; <em>Users</em> and <em>roles</em> &gt; <em>Users</em>. In the upper right corner, click New <em>user</em>. Enter the appropriate name and email address. Select their base <em>role</em> as either Admin, <em>User</em>, or Restricted. Select Add <em>user</em>. The new <em>user</em>"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    },
    {
      "sections": [
        "Add and manage users, groups, and roles",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "User management definitions",
        "Example user management tasks",
        "Add, edit, and delete users",
        "Assign users access to accounts (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes"
      ],
      "title": "Add and manage users, groups, and roles",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/b1c2da968a637f68569e890c8bd72a1c/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-06-25T16:49:32Z",
      "updated_at": "2021-06-25T16:49:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user information, and approve upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts To optimally use our more advanced user management features, it's important to first understand the concept of the \"access grant.\" An access grant gives a group of users access to a) a role and b) an account. For a New Relic organization that has many accounts, groups typically require more than one access grant because users in a group usually need access to multiple accounts and roles. The diagram below explains the elements that make up an access grant. Note that if your organization is on Standard edition and want to assign a user to a default group (Admin or User), you don't need to create an access grant: you would simply add a user to that group and you're done. But for Pro and Enterprise edition, if you're trying to grant users access to a custom group, a custom role, or to other accounts, you must create an access grant. A diagram explaining how you can grant user groups access to roles and accounts. Note that this applies to users on our New Relic One user model (and not our original user model). Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? For smaller, flatter organizations that are okay with full internal transparency, you may only need a couple groups. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). For examples of some common user management tasks, see Example tasks. User management definitions Here are some definitions of our user management terms and how they relate to each other: A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles. Example user management tasks In the Organization and access UI, you can create custom groups, roles, and grant access to user groups. Here are some example user management procedures: Add, edit, and delete users To add or edit users, use the User management UI. To add users: If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Assign users access to accounts (access grants) See our user management tutorial. Create new custom groups and roles See our user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager role. Important Users cannot have only organization-scoped roles assigned; they must also be in a group that has account-scoped roles (for example, the default Admin group). You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can assign those roles to a custom group. From the Organization and access UI: Select Access grants, and choose To this organization. Create an access grant that assigns the Authentication domain manager role to a custom group. From the User management UI, add users to that group. To see a tutorial on creating new groups and roles, see Tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.61548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and manage <em>users</em>, groups, and <em>roles</em>",
        "sections": "Add and manage <em>users</em>, groups, and <em>roles</em>",
        "tags": "New Relic One <em>user</em> management",
        "body": "For <em>users</em> on our New Relic One <em>user</em> model, we provide various <em>user</em> management features, including the ability to: Use <em>role</em> based access control (RBAC) to assign default or custom <em>roles</em> to <em>user</em> groups Create custom <em>user</em> groups Grant <em>user</em> groups access to specific <em>roles</em> and accounts Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    }
  ],
  "/docs/style-guide/writing-guidelines/voice-strategies-docs-sound-new-relic": [
    {
      "image": "https://developer.newrelic.com/static/developer-champions-c61b7fb3b08d228679edab34b2d15a0e.jpg",
      "url": "https://developer.newrelic.com/developer-champion/",
      "sections": [
        "New Relic Developer Champions",
        "What do Developer Champions do?",
        "Open-source contributions",
        "Content creation",
        "Community engagement",
        "Why should you join and how will we support?",
        "Developer Champions benefits:"
      ],
      "published_at": "2021-06-30T01:45:00Z",
      "title": "New Relic Developers",
      "updated_at": "2020-12-04T01:45:02Z",
      "type": "developer",
      "external_id": "2cef9996dadc081ed4331e85992a4af9defc87ff",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Champions are the voice of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to New Relic product and engineering teams. Champions solve big problems using New Relic as their toolkit and are recognized as experts and leaders in the New Relic technical community. Nominate a developer champion What do Developer Champions do? New Relic Champions demonstrate expertise in using New Relic products by solving large problems and positioning New Relic as a central force in their strategies. The New Relic Champions is a recognition and partnership program designed to acknowledge the developers that are driving innovation within their companies and making top contributions to the developer community.They also commit to making their work public by: Open-source contributions Serving as an open-source author or maintainer for an accepted public project related to New Relic One Content creation Authoring two pieces of content in the New Relic Explorers Hub / Dev website Community engagement Delivering and/or organizing two events focused on an observability platform theme in which New Relic plays a crucial role Nominate a Developer Champion Why should you join and how will we support? As a benefit of being a Developer Champion, New Relic provides unique access to our Developer Advocacy team and the resources of our product organization, as well as specialized recognition and rewards. Developer Champions benefits: Formal, specialized access to the New Relic Product organization Champions have direct access to the New Relic’s Developer Ecosystem team Custom badge to wear with pride at events Public recognition on the New Relic Developer website and badging in the New Relic Explorers Hub as a Champion Exclusive Champion-only swag Early access program for some of our products (under NDA) Priority access to off-site FutureHack events (including when Lew is participating) Increased Explorer’s Hub support SLA Access to private Developer Champion Explorer’s Hub group",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.76421,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Developers",
        "sections": "<em>New</em> <em>Relic</em> Developer Champions",
        "body": "<em>New</em> <em>Relic</em> Champions are the <em>voice</em> of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to <em>New</em> <em>Relic</em> product and engineering teams. Champions solve big"
      },
      "id": "5efa993c64441fc2a25f7e65"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/user-related-language-guidelines/",
      "sections": [
        "Users/roles-related language guidelines",
        "Note about user models",
        "Styles and formatting",
        "General philosophy for user permissions/roles language",
        "Document role-related requirements",
        "Don't document user type or group restrictions",
        "Original user model permissions"
      ],
      "published_at": "2021-06-29T09:23:44Z",
      "title": "Users/roles-related language guidelines",
      "updated_at": "2021-06-29T09:23:44Z",
      "type": "docs",
      "external_id": "432131e2159509833ae5f540e8be2e77c0600dfd",
      "document_type": "page",
      "popularity": 1,
      "body": "This doc explains required styles and recommended phrasings for user-related terminology on the New Relic One user model. Note about user models This style guide applies to the New Relic One user model, not the original user model. Even though both user models share certain terms (such as Admin), this is an entirely different user model with a very different structure, recommended phrasings, and style. To understand user model differences, see Overview of user model changes. The original user model will be increasingly deprecated, so we shouldn't need to talk much about that user model or update those docs. Styles and formatting Here are some user-related styles and formats for user-related language for the New Relic One user model: Category Example use Styles and tips User type (basic user vs full user) \"If you’re a full user...\" Lower case, no style. Note that it can sometimes be awkward when \"basic user\" is in front of a noun. For example: \"To learn about basic user capabilities...\" can sound like you're talking about user capabilities that are basic. To avoid this, rephrase to be more clear and/or link to the user type doc section from \"basic user\" or \"full user.\" Roles \"You must be in a group that has the Billing user role.\" Sentence case, bold. This phrasing is meant to cover all cases where a user is in a group that has that role, whether that group is a default group (Admin or User) or a custom group that has had that role assigned. We recommend linking to the standard roles doc, which lists and defines the roles, and also explains how these roles are related to the default groups (Admin and User). Default groups \"When adding a user, add them to the Admin group.\" Sentence case, bold. We recommend linking to the explanation of default groups for more context. General philosophy for user permissions/roles language Our general philosophy is summed up in these points: Document role-related requirements For most docs (with exception of API docs, explained in this section), we should only document role-related requirements. If there is a specific standard role required to use a feature/functionality, explain that in a requirements section so that customers will understand what user role they need to use that feature. This approach means that our user-related restriction mentions should be fairly infrequent, as there are only a few features that are gated by a specific standard role. These apply mainly to the organization and user management areas, such as the ability to manage users or manage billing). API docs exception: Because APIs are not as obvious and transparent as the product UI, we should document any requirements that SMEs think are relevant, which may also include user type. Attempt to list any API requirements in a single location, and not spread them throughout the docs. Don't document user type or group restrictions We don't document restrictions related to user type (basic vs. full user) or default groups. For more about role language guidelines, see the styles table. Basic vs. full users: We don't document restrictions related to user type (basic vs. full). This is because things that are off limits to basic users in the product are also places they are given upsell notes. And because those limitations are so widespread, we would be documenting that everywhere. Default user groups: We don't explain restrictions related to default user groups (Admin and User). This is because, while the group does impact what you can access, the actual mechanism causing the restriction is due to a standard role, not to the group. If you have questions about how user type, user group, and user roles relate, see the User model docs. Original user model permissions Sometimes it's necessary to explain how access works for users on both user models. This should be less and less required over time because customers will be migrating to the new pricing plan and new user model, and we should attempt to avoid it unless completely necessary. But if this is deemed required, you can explain this using the following approach: User role requirements: • Users on the [original user model](link): the [**Data retention manager** role](link). • Users on [New Relic One user model](link): the [**Billing user** role](link). Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 64.42963,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Styles and <em>formatting</em>",
        "body": "This <em>doc</em> explains required styles and recommended phrasings for user-related terminology on the <em>New</em> <em>Relic</em> One user model. Note about user models This style guide applies to the <em>New</em> <em>Relic</em> One user model, not the original user model. Even though both user models share certain terms (such as Admin"
      },
      "id": "60dae6a028ccbc539271b451"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Collect data - any source",
        "Create custom events",
        "Build queries with NerdGraph",
        "Query data with NRQL"
      ],
      "published_at": "2021-06-30T01:39:54Z",
      "title": "Collect data",
      "updated_at": "2021-06-19T01:39:10Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes   Use custom attributes for deeper analysis Collect data - any source 15 min APIs, agents, OS emitters - get any data Create custom events 5 min Define, visualize, and get alerts on the data you want using custom events Build queries with NerdGraph 25 min Try NerdGraph and build the queries you need Query data with NRQL 10 min Query default data, custom events, and attributes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 63.790306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Through our opensource agents or APIs, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide <em>strategies</em> for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    }
  ],
  "/docs/synthetics/index": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.59088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": " the key for existing private location: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.135857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> monitors",
        "sections": "Types of <em>synthetic</em> monitors",
        "tags": "<em>Synthetics</em>",
        "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 55.665443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> monitoring response codes",
        "sections": "<em>Synthetic</em> monitoring response codes",
        "tags": "<em>Synthetics</em>",
        "body": " timed out&quot; -9999 &quot;unknown error, error not mapped&quot; For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic <em>Synthetics</em> monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)"
      },
      "id": "6045276ee7b9d22729579a22"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/pages/synthetics-results-access-individual-monitor-runs": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93869,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1": [
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint",
        "For more help"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-06-25T17:21:59Z",
      "updated_at": "2021-03-11T11:46:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/. For more help Additional documentation resources include: Manage synthetic monitors via the REST API (API procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the REST API (REST API calls for email alerts for synthetic monitors) Use synthetics label APIs (REST API calls for labels and categories used by synthetic monitors)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.28218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;. For more help Additional documentation resources include: Manage synthetic monitors via the <em>REST</em> <em>API</em> (<em>API</em> procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the <em>REST</em> <em>API</em> (<em>REST</em> <em>API</em> calls for email alerts for synthetic monitors) Use <em>synthetics</em> label <em>APIs</em> (<em>REST</em> <em>API</em> calls for labels and categories used by synthetic monitors)"
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-06-25T18:41:06Z",
      "updated_at": "2021-03-11T10:41:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 20. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted Browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.27686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Use synthetic monitoring secure credentials APIs",
        "Requirements and rules",
        "API examples",
        "Add a secure credential",
        "Get all secure credentials",
        "Get a specific secure credential",
        "Update an existing secure credential",
        "Delete an existing secure credential",
        "For more help"
      ],
      "title": "Use synthetic monitoring secure credentials APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Secure credentials examples"
      ],
      "external_id": "bd66e43160c1fd4c9f66bfdfa2d9a3223eb5d4d7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/secure-credentials-examples/use-synthetics-secure-credentials-apis/",
      "published_at": "2021-06-25T19:33:18Z",
      "updated_at": "2021-03-13T05:09:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Synthetics REST API, you can make API calls to change or retrieve secure credentials data. This document explains the API requirements and contains API curl command examples. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials. Requirements and rules For general rules about this feature, see the secure credentials requirements. API requirements and rules include: See general Synthetics REST API requirements. An account's rate of requests is limited to three requests per second. Requests that exceed this threshold will return a 429 response code. A key's value cannot be accessed via the API; an unauthorized user would not have access to the secure key values. API examples Add a secure credential To send a secure credential to your New Relic account, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials with a JSON payload that describes the secure credential. Here's an example: { \"key\": string [required, 1-64 characters uppercase], \"value\": string [required, 1-3,000 characters], \"description\": string [optional] } Copy Here's an example of doing this with a curl command: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy A successful request will return a 201 Created response, with the URI of the newly-created secure credential specified in the location header. Possible error codes include: 303 See Other: The specified key already exists. The returned location header will contain the URI to the key. 400 Bad Request: Key too long or missing, value too long or missing, non-parsable JSON payload. Get all secure credentials To view a list of all the secure credentials in your New Relic account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials. For example: curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"secureCredentials\": [ { \"key\": \"MYKEY1\", \"description\": \"Description of MYKEY1\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" }, { \"key\": \"MYKEY2\", \"description\": \"Description of MYKEY2\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" } ], \"count\": 2 } Copy Get a specific secure credential To view a single secure credential, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"key\": string, \"description\": string, \"createdAt\": date,​ \"lastUpdated\": date } Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Update an existing secure credential To update an existing credential in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Delete an existing secure credential To delete an existing credential in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy Please note that if the specified key does not exist, no error will occur. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.897194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "sections": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": "With the <em>Synthetics</em> <em>REST</em> <em>API</em>, you can make <em>API</em> calls to change or retrieve secure credentials data. This document explains the <em>API</em> requirements and contains <em>API</em> curl command <em>examples</em>. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials"
      },
      "id": "6044070d196a67b171960f76"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69601,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.14372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.9682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/identify-synthetic-monitoring-requests-your-app": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.14372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.9682,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.14372,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:07Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing plans, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.31012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.1437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.96819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.96819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    },
    {
      "sections": [
        "User roles in synthetic monitoring",
        "Users on original user model",
        "Default access",
        "Customize access",
        "Users on New Relic One user model"
      ],
      "title": "User roles in synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "955d31ad885f2de3218e6d6c5963eba857bd5fa6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:07Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access to synthetic monitoring features varies whether a user is on the newer New Relic One user model or our original user model. For an explanation of user models and how they relate to our pricing plans, see Overview of pricing and user changes. Users on original user model For users on our original user model, access will vary depending on whether you have default roles or custom roles: Default access Admins have full access to all synthetic monitoring features on an account. Users have access to all synthetic monitoring features except secure credentials and the ability to delete monitors, monitor downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all synthetic monitoring features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users with this role do not have access to all create, edit, and delete capabilities for synthetic monitoring features (as well as view capability for secure credentials) until they are given a role with the appropriate capabilities. Customize access To get started, follow standard procedures to create a custom role. You can add View and Edit capabilities to any role for the following: Monitors Monitor scripts Private locations Monitor downtimes Secure credentials Users on New Relic One user model For users on the New Relic One user model, full users have the ability to use the synthetic monitoring UI to create and manage synthetic monitors, while basic users cannot do that. For limitations related to API usage, see User limitations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.3101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "sections": "User roles in <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " monitors, <em>monitor</em> downtime, and private locations. Restricted Users on accounts with original product-based pricing have view-only access to all <em>synthetic</em> <em>monitoring</em> features except: Secure credentials Private locations (although they can query a limited amount of data via NRQL) This means that users"
      },
      "id": "603eab2e64441f63844e88b2"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.69586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-04-05T21:07:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, New Relic will attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.1437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-06-26T00:43:16Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.96819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.92078,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.22658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:58Z",
      "updated_at": "2021-03-13T02:11:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. Tt does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.91307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring": [
    {
      "sections": [
        "Types of synthetic monitors",
        "Tip",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-06-26T01:07:56Z",
      "updated_at": "2021-06-15T15:13:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.92078,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.22658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Tip",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:59Z",
      "updated_at": "2021-03-09T03:46:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.55441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific problems. Comparative charts with browser <em>monitoring</em> Use New Relic"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.2265,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:58Z",
      "updated_at": "2021-03-13T02:11:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. Tt does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.91307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Tip",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-06-26T01:06:59Z",
      "updated_at": "2021-03-09T03:46:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Tip To use synthetic monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.55441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific problems. Comparative charts with browser <em>monitoring</em> Use New Relic"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93837,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Troubleshoot downtime",
        "View the failures page",
        "View individual downtimes",
        "Use page functions",
        "For more help"
      ],
      "title": "Synthetic monitoring: Troubleshoot downtime",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "fd938ba2389afeb1fe8d8dcf03d91a516f9c983b",
      "image": "https://docs.newrelic.com/static/fc64706d910027f9c05840423fa74fdd/c1b63/failures.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-16T18:41:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Failures page to locate and troubleshoot downtime incidents or other errors. A downtime incident occurs whenever a monitor fails to completely execute. For example, a Ping monitor is \"down\" when the GET request fails, while a Scripted Browser monitor is \"down\" if any part of the script fails to execute. After locating an interesting downtime, select it to view detailed results from that downtime incident and troubleshoot. View the failures page To access your monitor's failures: Go to one.newrelic.com > Synthetics > (select a monitor) > Failures. Hover the mouse over a failure to get quick data about it. Click on the dot to open a detailed report of the failure. You can also click Run check to recheck the failed monitors. View individual downtimes You can select individual downtime incidents to view them in more detail. Depending on the specific failure, a downtime result could include only the server error message (such as Server replied with \"HTTP 500\" error), or a full or partial waterfall view. Downtime results include waterfalls when only part of a monitor executed correctly. For example, a 301 redirect could link to a failing web page. The browser correctly executes the redirect, but the destination web page returns an error. Use the error message or waterfall to troubleshoot the downtime incident. Use page functions The Failures page supports the following features: If you want to... Do this... Sort the list of downtimes In the table header, select Time or Message to sort the list. Select Time or Message again to change from ascending sort to descending sort order. Filter by location Select a location label to hide downtime incidents from that location. Select the location label again to unhide those results. To view results from only one location, hide every other location. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary page (view an overview of your simple or scripted monitor's performance) Results page (full list of monitor results) Resources page (view load times for each element on a monitored page) Response codes (list of response codes specific to synthetic monitoring)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.10733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary <em>page</em> (view an overview of your simple or scripted <em>monitor</em>&#x27;s performance) Results <em>page</em> (full list of <em>monitor</em> results) Resources <em>page</em> (view load times for each element on a monitored <em>page</em>) Response codes (list of response codes specific to <em>synthetic</em> <em>monitoring</em>)"
      },
      "id": "603e9efd64441faf344e8865"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-understand-load-times": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:52:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors: Go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-30T19:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Synthetics > (select a monitor). You can also access it from one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (New Relic Browser) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.79028,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Synthetic monitoring: Troubleshoot downtime",
        "View the failures page",
        "View individual downtimes",
        "Use page functions",
        "For more help"
      ],
      "title": "Synthetic monitoring: Troubleshoot downtime",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "fd938ba2389afeb1fe8d8dcf03d91a516f9c983b",
      "image": "https://docs.newrelic.com/static/fc64706d910027f9c05840423fa74fdd/c1b63/failures.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime/",
      "published_at": "2021-06-26T01:08:45Z",
      "updated_at": "2021-03-16T18:41:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Failures page to locate and troubleshoot downtime incidents or other errors. A downtime incident occurs whenever a monitor fails to completely execute. For example, a Ping monitor is \"down\" when the GET request fails, while a Scripted Browser monitor is \"down\" if any part of the script fails to execute. After locating an interesting downtime, select it to view detailed results from that downtime incident and troubleshoot. View the failures page To access your monitor's failures: Go to one.newrelic.com > Synthetics > (select a monitor) > Failures. Hover the mouse over a failure to get quick data about it. Click on the dot to open a detailed report of the failure. You can also click Run check to recheck the failed monitors. View individual downtimes You can select individual downtime incidents to view them in more detail. Depending on the specific failure, a downtime result could include only the server error message (such as Server replied with \"HTTP 500\" error), or a full or partial waterfall view. Downtime results include waterfalls when only part of a monitor executed correctly. For example, a 301 redirect could link to a failing web page. The browser correctly executes the redirect, but the destination web page returns an error. Use the error message or waterfall to troubleshoot the downtime incident. Use page functions The Failures page supports the following features: If you want to... Do this... Sort the list of downtimes In the table header, select Time or Message to sort the list. Select Time or Message again to change from ascending sort to descending sort order. Filter by location Select a location label to hide downtime incidents from that location. Select the location label again to unhide those results. To view results from only one location, hide every other location. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary page (view an overview of your simple or scripted monitor's performance) Results page (full list of monitor results) Resources page (view load times for each element on a monitored page) Response codes (list of response codes specific to synthetic monitoring)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.10733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Troubleshoot downtime",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " to adjust the number of downtime incidents returned. For more help Additional documentation resources include: Summary <em>page</em> (view an overview of your simple or scripted <em>monitor</em>&#x27;s performance) Results <em>page</em> (full list of <em>monitor</em> results) Resources <em>page</em> (view load times for each element on a monitored <em>page</em>) Response codes (list of response codes specific to <em>synthetic</em> <em>monitoring</em>)"
      },
      "id": "603e9efd64441faf344e8865"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.40067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.11734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.40067,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms": [
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14238,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.11734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.4005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Containerized private minion (CPM) maintenance and monitoring",
        "Tip",
        "Check CPM status using HTTP",
        "Check if your private location requires more minions",
        "Review logs",
        "Review Docker logs",
        "Review Kubernetes logs",
        "Enable debug logs",
        "Enable Docker debug logs",
        "Enable Kubernetes debug logs",
        "Retrieve Kubernetes debugging information",
        "Monitor CPMs with New Relic Infrastructure"
      ],
      "title": "Containerized private minion (CPM) maintenance and monitoring ",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "414f8966a290006d662010c910fc540018c0bf51",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring/",
      "published_at": "2021-06-26T01:11:10Z",
      "updated_at": "2021-05-09T18:11:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After installing your containerized private minion (CPM), you can keep track of its maintenance and monitoring in several ways: Check if the CPM is healthy and working with the CPM status endpoint. See if a private location is under-provisioned and needs more minions. Review your Docker logs or Kubernetes logs. Tip You can also get notified of monitor failures with New Relic's alerts. Check CPM status using HTTP Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: 8080 and 8180. You can check the CPM with the following endpoints: :8080/status/check: provides details about internal health checks that the minion performs. HTTP 200 means the status is healthy. :8080/status: provides details about a minion's status, which is the same data published in Insights as SyntheticsPrivateMinion event. :8180/: provides JVM application admin endpoints. This is an advanced view of a minion's Java Development Kit (JDK) internal state. Check if your private location requires more minions If your private location has multiple monitor checks queued up and you experience delays, you may need more minions available to execute the monitor checks. To learn how to verify this, see Does my private location need more minions? Review logs You can monitor your minion's health by looking at CPM container logs. Review Docker logs This is an example of a CPM log indicating that the minion is working properly in a Docker container system environment: $docker logs [YOUR_CONTAINER_NAME] 2018-10-10 11:33:29,856 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy... 2018-10-10 11:33:43,471 - Launching in PRIVATE Location: 123456-example_private_loc-480 2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads 2018-10-10 11:33:43,796 - 2018-10-10 11:33:43,796 - ************************************************************************** 2018-10-10 11:33:43,796 - * Synthetics Minion is ready and servicing location 'example_private_location' 2018-10-10 11:33:43,796 - ************************************************************************** ... logging continues ... Copy Review Kubernetes logs This is an example of a CPM log indicating that the minion is working properly in a Kubernetes container orchestration system environment: First, get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: $ kubectl logs -n YOUR_NAMESPACE YOUR_CPM_NAME 2020-05-11 22:57:24,084 - Minion will use 2 heavy workers 2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers 2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES 2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES 2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot 2020-05-11 22:57:30,284 - Minion ID: a21f6d7f-4f65-4dec-92fb-88cb975d2a19 2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status 2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy... 2020-05-11 22:57:35,457 - Launching in PRIVATE Location: 123456-example_private_loc-480 2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16 2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads 2020-05-11 22:57:36,087 - 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location 'example_private_location' 2020-05-11 22:57:36,087 - ************************************************************************** 2020-05-11 22:57:36,087 - ... logging continues ... Copy Enable debug logs If you experience issues with your CPM, you can enable debug logs to help troubleshoot issues. The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the MINION_LOG_LEVEL environment variable. Enable Docker debug logs Tip Adding -f to the Docker logs makes the command follow logs. docker run ... -e MINION_LOG_LEVEL=DEBUG ... docker logs -f YOUR_CONTAINER_NAME ... verbose logging continues ... Copy Enable Kubernetes debug logs Tip Adding -f to the Kubernetes logs makes the command follow logs. To enable DEBUG logs add the --set synthetics.minionLogLevel=DEBUG option when running your helm install: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionLogLevel=DEBUG Copy Get the name of the CPM pod you want to review logs for: kubectl get pods -n YOUR_NAMESPACE Copy Then, interact with that CPM pod: kubectl logs -f -n YOUR_NAMESPACE YOUR_CPM_POD_NAME ... verbose logging continues ... Copy Retrieve Kubernetes debugging information If you experience issues with your CPM in a Kubernetes container orchestration system environment, you can retrieve information about the CPM pod and the node it is running on to help troubleshoot. To retrieve information for the CPM pod: kubectl describe pod -n YOUR_NAMESPACE YOUR_CPM_POD_NAME Copy To retrieve information for the node the CPM pod is running on, identify the node, and then: kubectl describe node NODE_ASSOCIATED_WITH_YOUR_CPM_POD_NAME Copy Monitor CPMs with New Relic Infrastructure New Relic's infrastructure monitoring supports advanced Docker monitoring and advanced Kubernetes monitoring. To add support for this, synthetic monitoring labels the containers spawned by CPM with a series of informative labels, all prefixed with synthetics-minion-. The CPM spawns containers called \"runners\" which process non-ping monitors like: simple browser, scripted browser, api test, and step function. You can use these labels to identify these runner containers. Example labels include: synthetics-minion-runner-role synthetics-minion-runner-version synthetics-minion-container-id synthetics-minion-id synthetics-minion-build-number synthetics-minion-job synthetics-minion-account synthetics-minion-monitor synthetics-minion-monitor-version synthetics-minion-monitor-type synthetics-minion-monitor-type-label Runner containers last a short time. One runner container is created to process one non-ping monitor job. The runner is created, processes the job, and is quickly deleted. A runner container exists for only a few seconds and will be created only if there is a non-ping monitor job to process. Ping monitors will not trigger runner container creation, so the above labels will not be present. If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the docker inspect of the container before it is deleted. Note: the synthetics-minion-id label refers to the ID of the minion which spawned this particular runner container. The ID of the runner itself is not tracked.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.11734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em> ",
        "sections": "Containerized <em>private</em> minion (CPM) maintenance and <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " CPMs with New Relic Infrastructure New Relic&#x27;s infrastructure <em>monitoring</em> supports advanced Docker <em>monitoring</em> and advanced Kubernetes <em>monitoring</em>. To add support for this, <em>synthetic</em> <em>monitoring</em> labels the containers spawned by CPM with a series of informative labels, all prefixed with <em>synthetics</em>-minion"
      },
      "id": "603eac96196a67a833a83db8"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.4005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73816,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14236,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/troubleshoot-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 297.4004,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-06-26T01:09:36Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.73814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    },
    {
      "sections": [
        "Monitor private locations",
        "Prerequisites",
        "Private Minion dashboard JSON",
        "Are my private minions online?",
        "Does my private location need more minions?",
        "Can I check the status of a specific minion directly?"
      ],
      "title": "Monitor private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "d38b5c957ec41b25199f4d093eb2f6083a5ff351",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations/",
      "published_at": "2021-06-26T03:46:39Z",
      "updated_at": "2021-06-03T02:27:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When using synthetic monitoring's private locations with New Relic's alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding private location health by using New Relic dashboards and NRQL alerts: Are my private minions online? Does my private location need more minions? Can I check the status of a specific minion directly? Prerequisites Before following the instructions in this guide, ensure you have: A synthetic private location At least one private minion installed at that location Checks scheduled to run at that location An alert policy for the private location, with a configured notification channel to notify your team when a violation occurs The Private Minion dashboard example can be imported to your account using the Dashboard API with the following JSON: Private Minion dashboard JSON { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"permissions\": \"PUBLIC_READ_WRITE\", \"pages\": [ { \"name\": \"Synthetics Private Minions\", \"description\": \"Synthetics Private Minions Dashboard\", \"widgets\": [ { \"visualization\": { \"id\": \"viz.billboard\" }, \"layout\": { \"column\": 1, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Location\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionLocation) as 'Location' from SyntheticsPrivateMinion since 30 minutes ago\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 5, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Minions reporting\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT uniques(minionId) from SyntheticsPrivateMinion since 30 minutes ago limit 500\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.table\" }, \"layout\": { \"column\": 9, \"row\": 1, \"height\": 3, \"width\": 4 }, \"title\": \"Alive since\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT latest(minionStartTimestamp) as 'Birthday' from SyntheticsPrivateMinion since 30 minutes ago facet minionId limit 200\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 1, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"CPU load %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionProcessorsUsagePercentage) as 'CPU load %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 5, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Used memory %\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryUsedPercentage) as 'Used memory %' from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null }, { \"visualization\": { \"id\": \"viz.line\" }, \"layout\": { \"column\": 9, \"row\": 4, \"height\": 3, \"width\": 4 }, \"title\": \"Free memory GB\", \"rawConfiguration\": { \"nrqlQueries\": [ { \"accountId\": 1, \"query\": \"SELECT max(minionPhysicalMemoryFreeBytes / 1e9) from SyntheticsPrivateMinion since 30 minutes ago timeseries 1 minute facet minionId\" } ] }, \"linkedEntityGuids\": null } ] } ] } Copy Are my private minions online? To answer this question, you can rely on attributes from the SyntheticsPrivateMinionevent. Private minions send this event to New Relic every 30 seconds. A simple way to check if your minions are online is to compare the unique count of minion IDs with the number of minions you expect to be online. To understand how many minions are reporting, run this example NRQL query: SELECT uniqueCount(minionId) FROM SyntheticsPrivateMinion WHERE minionLocation = '1-acme_okc_dc-309' Copy Using this query, you can create an alert condition to notify your team when fewer minions are reporting than expected. This condition is configured with a static threshold of 2 units, which means you will receive an alert if any of your minions are offline. You can verify that the alert policy works as expected by manually stopping one of your minions. Then, when the alert violation occurs, you will be notified by any notification channels that have been set up. Once the minion is restarted and it comes back online, the alert will recover. There are more robust ways to check whether minions are functioning correctly, but this query and condition simply and successfully handle the case where a machine fails, is accidentally decommissioned, or the minion process crashes. It also ensures that the minion can communicate with New Relic. Does my private location need more minions? To answer this question, you can use the checksPending attribute of the SyntheticsPrivateLocationStatus event. The checksPending attribute reflects the number of monitor checks that are scheduled (or \"queued\") but have yet to be accepted by a minion in the designated location. For a location with scheduled checks and no minions, this graph would grow linearly up and to the right. This metric is more complicated to monitor than uniqueCount(minionId) because a high value does not necessarily mean the location is in a bad state. As long as the metric is not growing linearly up and to the right (and checks are being run on schedule), the location is in a good state. This use case is perfect for baseline NRQL alert conditions, which allow you to monitor the deviation of a metric rather than its static value. For example: SELECT average(checksPending) FROM SyntheticsPrivateLocationStatus WHERE name = '1-acme_tokyo_dc-512' Copy To test this alert condition, schedule one-minute, browser-based monitors to run from your location. Browser-based jobs consume more resources than ping jobs, which is why they are a better fit for load simulation. New Relic will quickly notify you of a growing number of pending checks. After doubling the number of minions to handle the load, the alert recovers. For example, using the Synthetics private location dashboard example, notice the growth and decline of pending checks over the course of the incident and recovery. By using the NRQL condition, New Relic will notify you if and when the location needs more minion capacity. Can I check the status of a specific minion directly? You can also check how a minion is operating by contacting it directly. You can use a set of HTTP endpoints exposed by the minion to determine what the application is doing. In order to access these endpoints, bind ports 8080 and 8180 to ports on the host. For example, for Docker, use docker run -p 80:8080 -p 81:8180 ...): :8080/status/check: Details about internal health-checks the minion performs; HTTP 200 means \"healthy.\" :8080/status: Details about a minion's status; the same data is then published to Insights as a SyntheticsPrivateMinion event. :8180/: JVM application admin endpoints; an advanced view of a minion's internal state. This approach is not as automated or flexible as the checksPending example. However, if you have total network connectivity failure, this manual approach can help troubleshoot the situation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 206.14235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "sections": "<em>Monitor</em> <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "When using <em>synthetic</em> <em>monitoring</em>&#x27;s <em>private</em> <em>locations</em> with New Relic&#x27;s alerts, you can be notified if a location is under-provisioned, mis-configured, or generally misbehaving. This guide will help you answer the following basic questions regarding <em>private</em> location health by using New Relic"
      },
      "id": "604525f164441f7fd7378ef9"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Scripted browser examples",
        "Tip",
        "Monitor a URL",
        "Navigate to a link",
        "Search a website",
        "Wait for a page to load",
        "Wait for a page element",
        "Log in to a website",
        "For more help"
      ],
      "title": "Scripted browser examples",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "0570086ad8b7348b717d983073c037c896a5492b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples/",
      "published_at": "2021-06-26T00:18:24Z",
      "updated_at": "2021-03-18T16:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Using scripted browsers, you can build complex monitoring workflows using a JavaScript-like scripting language driven by Selenium WebDriver. For a detailed guide to all the available functions, see Synthetic's scripted browser reference. Tip To view other scripted browser examples, check out the Quickstarts Synthetics library in New Relic’s Github repository. You may also view tips from New Relic support engineers in the Level Up Relic Solutions section of the New Relic Online Technical Community. Monitor a URL In this example, the monitor visits http://telco.nrdemo-sandbox.com/: //Visit http://telco.nrdemo-sandbox.com/ $browser.get(\"http://telco.nrdemo-sandbox.com/\"); Copy This scripting action is the foundation for nearly all scripted browsers. For more information, see Visit a URL. Navigate to a link In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/. Finds the About page via link text and clicks the link. Finds the Acme Telco Home link by searching for the partial string Home and clicks the link. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ //Find a link whose display text is `About` and click that link. return $browser.findElement($driver.By.linkText(\"About\")).click(); }).then(function(){ return $browser.findElement($driver.By.partialLinkText(\"Home\")).click(); }); Copy These steps are ordered by a sequencing function. For detailed instructions and other methods of locating elements, see Locate elements. For a list of all locators, see Locators: Find page elements. Search a website In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/static/companyBlog.jsp. Locates the search box via its XPath and types relic. Locates the submit button via its XPath and clicks it to submit the search. $browser.get(\"http://telco.nrdemo-sandbox.com/static/companyBlog.jsp\").then(function(){ //Find the search field by specifying its id, then enter `relic`. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div/input\")).sendKeys(\"relic\"); }).then(function(){ //Click the search button. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div//button\")).click(); }); Copy For more information about sending text to a field, see Enter text. Wait for a page to load In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/browse/phones. Finds the Details button for the Acme Standard phone via its XPath and clicks on it. Waits up to 10 seconds for the HTML page title to match Acme Commerce Company. Finds the Add to Cart button via its XPath and clicks on it. $browser.get(\"http://telco.nrdemo-sandbox.com/browse/phones\").then(function(){ return $browser.findElement($driver.By.xpath(\"(//a[text()='Details'])[3]\")).click(); }); //Call the wait function. $browser.wait(function() { //Tell the monitor to get the page title, then run a function on that title. return $browser.getTitle().then(function(title) { //Ensure that the title matches `Acme Commerce Company`. return title === \"Acme Commerce Company\"; }); //If the condition isn't satisfied within 10000 milliseconds (10 seconds), proceed anyway. }, 10000); //Find the `Add to Cart` button via its XPath and click it. $browser.findElement($driver.By.xpath(\"//input[@value='Add to Cart']\")).click(); Copy For more information about setting wait conditions that will pause the script, see Wait for page title. Wait for a page element In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/. Finds the Support dropdown via HTML ID and clicks on it. Waits up to 20 seconds for the FAQ button to appear and clicks on it. //Navigate to the Acme Telco Homepage and clicks on the Support dropdown. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ return $browser.findElement($driver.By.id(\"supportDropDown\")).click(); }).then(function(){ //Call the wait function to wait until the FAQ button appears. return $browser.waitForAndFindElement($driver.By.id(\"supportFAQLink\"), 2000).then(function(aboutPage){ return aboutPage.click(); }) }); Copy For more information, see Wait for a specific element and Conditions: Pause and wait for conditions. Log in to a website In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/login.jsp. Finds the username field through element name and submits a secure username via our secure credentials feature. Finds the password field through the element name and submits a secure password. Finds the login button via its XPath and clicks to submit the account information. $browser.get(\"http://telco.nrdemo-sandbox.com/login.jsp\").then(function(){ //Find the user name field by specifying its name, then submits a secured username. return $browser.findElement($driver.By.name(\"username\")).sendKeys($secure.SECURE_USERNAME); }).then(function(){ //Find the password field by specifying its name, then submits a secured password. return $browser.findElement($driver.By.name(\"password\")).sendKeys($secure.SECURE_PASSWORD); }).then(function(){ //Find and click the login button. return $browser.findElement($driver.By.xpath(\"//input[@value='Login']\")).click(); }); Copy For more information about using secure credentials, see Store secure credentials. Tip What credentials should I use? Just like you shouldn't reuse a password across multiple websites, we recommend that you create new credentials unique to your script. Don't use your personal credentials or reuse credentials. For more help Additional resources include: Write scripted browsers (build WebDriverJS scripts for multi-step monitoring) Synthetic's scripted browser reference (detailed list of all available functions) Add and edit monitors (how to create synthetic monitors, including configuration options)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.79692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Scripted</em> browser examples",
        "sections": "<em>Scripted</em> browser examples",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Using scripted browsers, you can build complex <em>monitoring</em> workflows using a Java<em>Script</em>-like <em>scripting</em> language driven by Selenium WebDriver. For a detailed guide to all the available functions, see <em>Synthetic</em>&#x27;s scripted browser reference. Tip To view other scripted browser examples, check out"
      },
      "id": "60452664196a676354960f31"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/import-nodejs-modules": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/introduction-scripted-browser-monitors": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetics-scripted-browser-reference-monitor-versions-050": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Insights POST example",
        "Validate results",
        "Insights validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-06-26T08:08:00Z",
      "updated_at": "2021-05-15T18:15:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Insights POST example This example POSTs a custom Insights event containing static integers: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Insights validation example This example POSTs to the Insights API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myInsertKey = '{INSERT_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define insert key and expected data type. headers: { 'X-Insert-Key': myInsertKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.37566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests": [
    {
      "sections": [
        "Add custom attributes to synthetic monitoring data",
        "Important",
        "Compatibility",
        "Functions",
        "Example"
      ],
      "title": "Add custom attributes to synthetic monitoring data",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "3c0ab7825c5a9668a0b6399fbfe3c0bfc435acc1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data/",
      "published_at": "2021-06-26T03:16:26Z",
      "updated_at": "2021-03-30T20:31:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's $util.insights is a set of tools to set and manipulate events reported from synthetic monitoring. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom attributes, with the prefix custom, to the SyntheticCheck event. These attributes are in addition to the event's default attributes. Compatibility This functionality is available for monitor versions 0.2.0 or later. Functions Function Return value $util.insights.set(key: string, value: ?) Sets a key/value pair. void $util.insights.get(key: string) Returns the value for the provided key. object $util.insights.getKeys() Returns an array of keys currently set. object $util.insights.has(key: string) Returns true if the key exists in the data. boolean $util.insights.unset(key: string) Removes the key/value pair. void $util.insights.unsetAll() Removes all custom data. void Example The example obtains the latest incident from New Relic's RSS status feed and saves the details for this event. var parseString = require('xml2js').parseString; // Get the New Relic status RSS feed $http.get('https://status.newrelic.com/history.rss', function(err, response, body) { parseString(body, function(err, result){ // Parse the RSS, and get the latest incident var latestIncident = result.rss.channel[0].item[0]; // Push the incident details to New Relic $util.insights.set('Incident', latestIncident.title[0]); $util.insights.set('Description', latestIncident.description[0]); $util.insights.set('Date', latestIncident.pubDate[0]); }); }); Copy To view the incident data sent to New Relic in this example, use this query: FROM SyntheticCheck SELECT latest(custom.Date), latest(custom.Incident), latest(custom.Description) WHERE monitorName = \"Monitor Name Here\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.32993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "sections": "Add custom attributes to <em>synthetic</em> <em>monitoring</em> data",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " our Explorers Hub post. New Relic&#x27;s $util.insights is a set of tools to set and manipulate events reported from <em>synthetic</em> <em>monitoring</em>. The $util.insights toolset includes the word insights because Insights was historically how New Relic saved queryable event data. You can add custom data as custom"
      },
      "id": "60452627196a6736f0960f7a"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.9378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Scripted browser examples",
        "Tip",
        "Monitor a URL",
        "Navigate to a link",
        "Search a website",
        "Wait for a page to load",
        "Wait for a page element",
        "Log in to a website",
        "For more help"
      ],
      "title": "Scripted browser examples",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "0570086ad8b7348b717d983073c037c896a5492b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples/",
      "published_at": "2021-06-26T00:18:24Z",
      "updated_at": "2021-03-18T16:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Using scripted browsers, you can build complex monitoring workflows using a JavaScript-like scripting language driven by Selenium WebDriver. For a detailed guide to all the available functions, see Synthetic's scripted browser reference. Tip To view other scripted browser examples, check out the Quickstarts Synthetics library in New Relic’s Github repository. You may also view tips from New Relic support engineers in the Level Up Relic Solutions section of the New Relic Online Technical Community. Monitor a URL In this example, the monitor visits http://telco.nrdemo-sandbox.com/: //Visit http://telco.nrdemo-sandbox.com/ $browser.get(\"http://telco.nrdemo-sandbox.com/\"); Copy This scripting action is the foundation for nearly all scripted browsers. For more information, see Visit a URL. Navigate to a link In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/. Finds the About page via link text and clicks the link. Finds the Acme Telco Home link by searching for the partial string Home and clicks the link. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ //Find a link whose display text is `About` and click that link. return $browser.findElement($driver.By.linkText(\"About\")).click(); }).then(function(){ return $browser.findElement($driver.By.partialLinkText(\"Home\")).click(); }); Copy These steps are ordered by a sequencing function. For detailed instructions and other methods of locating elements, see Locate elements. For a list of all locators, see Locators: Find page elements. Search a website In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/static/companyBlog.jsp. Locates the search box via its XPath and types relic. Locates the submit button via its XPath and clicks it to submit the search. $browser.get(\"http://telco.nrdemo-sandbox.com/static/companyBlog.jsp\").then(function(){ //Find the search field by specifying its id, then enter `relic`. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div/input\")).sendKeys(\"relic\"); }).then(function(){ //Click the search button. return $browser.findElement($driver.By.xpath(\"//h4[text()='Blog Search']/following-sibling::div//button\")).click(); }); Copy For more information about sending text to a field, see Enter text. Wait for a page to load In the example below, the monitor: Navigates to http://telco.nrdemo-sandbox.com/browse/phones. Finds the Details button for the Acme Standard phone via its XPath and clicks on it. Waits up to 10 seconds for the HTML page title to match Acme Commerce Company. Finds the Add to Cart button via its XPath and clicks on it. $browser.get(\"http://telco.nrdemo-sandbox.com/browse/phones\").then(function(){ return $browser.findElement($driver.By.xpath(\"(//a[text()='Details'])[3]\")).click(); }); //Call the wait function. $browser.wait(function() { //Tell the monitor to get the page title, then run a function on that title. return $browser.getTitle().then(function(title) { //Ensure that the title matches `Acme Commerce Company`. return title === \"Acme Commerce Company\"; }); //If the condition isn't satisfied within 10000 milliseconds (10 seconds), proceed anyway. }, 10000); //Find the `Add to Cart` button via its XPath and click it. $browser.findElement($driver.By.xpath(\"//input[@value='Add to Cart']\")).click(); Copy For more information about setting wait conditions that will pause the script, see Wait for page title. Wait for a page element In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/. Finds the Support dropdown via HTML ID and clicks on it. Waits up to 20 seconds for the FAQ button to appear and clicks on it. //Navigate to the Acme Telco Homepage and clicks on the Support dropdown. $browser.get(\"http://telco.nrdemo-sandbox.com/\").then(function(){ return $browser.findElement($driver.By.id(\"supportDropDown\")).click(); }).then(function(){ //Call the wait function to wait until the FAQ button appears. return $browser.waitForAndFindElement($driver.By.id(\"supportFAQLink\"), 2000).then(function(aboutPage){ return aboutPage.click(); }) }); Copy For more information, see Wait for a specific element and Conditions: Pause and wait for conditions. Log in to a website In the example below, the monitor: Loads http://telco.nrdemo-sandbox.com/login.jsp. Finds the username field through element name and submits a secure username via our secure credentials feature. Finds the password field through the element name and submits a secure password. Finds the login button via its XPath and clicks to submit the account information. $browser.get(\"http://telco.nrdemo-sandbox.com/login.jsp\").then(function(){ //Find the user name field by specifying its name, then submits a secured username. return $browser.findElement($driver.By.name(\"username\")).sendKeys($secure.SECURE_USERNAME); }).then(function(){ //Find the password field by specifying its name, then submits a secured password. return $browser.findElement($driver.By.name(\"password\")).sendKeys($secure.SECURE_PASSWORD); }).then(function(){ //Find and click the login button. return $browser.findElement($driver.By.xpath(\"//input[@value='Login']\")).click(); }); Copy For more information about using secure credentials, see Store secure credentials. Tip What credentials should I use? Just like you shouldn't reuse a password across multiple websites, we recommend that you create new credentials unique to your script. Don't use your personal credentials or reuse credentials. For more help Additional resources include: Write scripted browsers (build WebDriverJS scripts for multi-step monitoring) Synthetic's scripted browser reference (detailed list of all available functions) Add and edit monitors (how to create synthetic monitors, including configuration options)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.79692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Scripted</em> browser examples",
        "sections": "<em>Scripted</em> browser examples",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Using scripted browsers, you can build complex <em>monitoring</em> workflows using a Java<em>Script</em>-like <em>scripting</em> language driven by Selenium WebDriver. For a detailed guide to all the available functions, see <em>Synthetic</em>&#x27;s scripted browser reference. Tip To view other scripted browser examples, check out"
      },
      "id": "60452664196a676354960f31"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/monitor-produces-no-traffic": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.9378,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99182,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Troubleshoot isolated monitor failures",
        "Problem",
        "Solution",
        "Network path",
        "Timeouts",
        "Slow page load"
      ],
      "title": "Troubleshoot isolated monitor failures",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "df2f127b5fd7587b0d395ceb2ff72974af1a3e36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-03-13T02:33:36Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your New Relic synthetic monitor reported a failure from a single location, but the application appears to be up and running, so you're not able to identify the problem. Solution A single failure from synthetic monitoring is not as limited as it may seem. It represents three consecutive failures of the same monitor. When a monitor fails, New Relic immediately queues two additional checks for the same monitor and location. New Relic reports a failure only when all three jobs fail. (Only the third monitor run is visible in the Synthetics UI.) The failures do not need to be the same error type. This further reinforces limitations on false positives. Synthetic monitors may sometimes fail from a single location when the site appears to be running properly from other locations. While these failures are isolated, being able to identify issues specific to a particular location can be very valuable. Here are some techniques to diagnose possible issues behind isolated monitor failures. Network path The monitor that failed may have a different network path to your site than other synthetic monitoring locations or from locations you are testing. If there is a problem at the location, or on the network between the location and your site, a single location may fail to return a result. This indicates that some users on similar network paths may have experienced issues. If you see Connect timed out or Read timed out, this typically indicates that the site was unavailable or so slow to respond such that the monitor could not retrieve any data. This usually indicates an issue along the network path. Timeouts There may be requests that timed out or requests that are missing. You may see timeout messages such as TimeoutError: URL {YOUR_DOMAIN} was unable to finish all network requests before reaching the maximum time limit Copy or TimeoutError: Page load timed-out (unable to finish all network requests on time) Copy These requests could not complete before the page load timeout or the end of the script. To solve the problem, try drilling into the resource to see when and where it responds poorly. Some resources may intermittently return slowly. Slow page load If the page frequently is unable to fully load within 60 seconds and you are using a simple browser monitor, try a scripted browser monitor and set a configurable page load timeout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.71777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> isolated <em>monitor</em> failures",
        "sections": "<em>Troubleshoot</em> isolated <em>monitor</em> failures",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Problem Your New Relic <em>synthetic</em> <em>monitor</em> reported a failure from a single location, but the application appears to be up and running, so you&#x27;re not able to identify the problem. Solution A single failure from <em>synthetic</em> <em>monitoring</em> is not as limited as it may seem. It represents three consecutive"
      },
      "id": "6045271028ccbcabff2c6085"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/private-location-hmac-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93774,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    },
    {
      "sections": [
        "Troubleshoot isolated monitor failures",
        "Problem",
        "Solution",
        "Network path",
        "Timeouts",
        "Slow page load"
      ],
      "title": "Troubleshoot isolated monitor failures",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "df2f127b5fd7587b0d395ceb2ff72974af1a3e36",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-03-13T02:33:36Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your New Relic synthetic monitor reported a failure from a single location, but the application appears to be up and running, so you're not able to identify the problem. Solution A single failure from synthetic monitoring is not as limited as it may seem. It represents three consecutive failures of the same monitor. When a monitor fails, New Relic immediately queues two additional checks for the same monitor and location. New Relic reports a failure only when all three jobs fail. (Only the third monitor run is visible in the Synthetics UI.) The failures do not need to be the same error type. This further reinforces limitations on false positives. Synthetic monitors may sometimes fail from a single location when the site appears to be running properly from other locations. While these failures are isolated, being able to identify issues specific to a particular location can be very valuable. Here are some techniques to diagnose possible issues behind isolated monitor failures. Network path The monitor that failed may have a different network path to your site than other synthetic monitoring locations or from locations you are testing. If there is a problem at the location, or on the network between the location and your site, a single location may fail to return a result. This indicates that some users on similar network paths may have experienced issues. If you see Connect timed out or Read timed out, this typically indicates that the site was unavailable or so slow to respond such that the monitor could not retrieve any data. This usually indicates an issue along the network path. Timeouts There may be requests that timed out or requests that are missing. You may see timeout messages such as TimeoutError: URL {YOUR_DOMAIN} was unable to finish all network requests before reaching the maximum time limit Copy or TimeoutError: Page load timed-out (unable to finish all network requests on time) Copy These requests could not complete before the page load timeout or the end of the script. To solve the problem, try drilling into the resource to see when and where it responds poorly. Some resources may intermittently return slowly. Slow page load If the page frequently is unable to fully load within 60 seconds and you are using a simple browser monitor, try a scripted browser monitor and set a configurable page load timeout.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.71777,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Troubleshoot</em> isolated <em>monitor</em> failures",
        "sections": "<em>Troubleshoot</em> isolated <em>monitor</em> failures",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Problem Your New Relic <em>synthetic</em> <em>monitor</em> reported a failure from a single location, but the application appears to be up and running, so you&#x27;re not able to identify the problem. Solution A single failure from <em>synthetic</em> <em>monitoring</em> is not as limited as it may seem. It represents three consecutive"
      },
      "id": "6045271028ccbcabff2c6085"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and <em>synthetic</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-06-26T08:09:37Z",
      "updated_at": "2021-05-15T18:17:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a Synthetics Scripted Browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer Synthetics monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in Scripted API monitors) or Chrome browser ($browser in Scripted Browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99207,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-06-26T08:09:35Z",
      "updated_at": "2021-05-15T18:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple/Browser based monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.99181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/alerts-synthetic-monitoring": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15434,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/collect-synthetic-transaction-traces": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/handle-sites-authentication": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/manage-monitor-runtimes": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93756,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.1543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.9375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/recheck-failed-monitors": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.1543,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.9375,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15427,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.98979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-06-26T08:10:54Z",
      "updated_at": "2021-04-17T02:05:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your Scripted Browser or API Test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 127.98979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-simple-scripted-monitor-results": [
    {
      "sections": [
        "Synthetic monitoring response codes",
        "Response codes",
        "For more help"
      ],
      "title": "Synthetic monitoring response codes",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ea5ea3ee3a21a108db952a861421c11e092e2611",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes/",
      "published_at": "2021-06-26T08:15:10Z",
      "updated_at": "2021-06-15T00:51:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium's response codes and give you more detail on the behavior of your monitors. Response codes Synthetic monitoring returns the following additional response codes: Response Code Definition -2 net::ERR_FAILED, \"Generic network error\" -3 net::ERR_ABORTED, \"An operation was aborted (due to user action)\" A Chrome-specific response code when the script hits a timeout and the runner is shutting down. To do that, the runner ends all pending requests. -7 net::ERR_TIMED_OUT, \"Timed out\" -10 net::ERR_ACCESS_DENIED, \"Access denied\" -20 net::ERR_BLOCKED_BY_CLIENT, \"Blocked\" -100 net::ERR_CONNECTION_CLOSED, \"Connection was closed (TCP FIN)\" -101 net::ERR_CONNECTION_RESET, \"Connection was reset (TCP RST)\" -102 net::ERR_CONNECTION_REFUSED, \"Connection was refused\" -103 net::ERR_CONNECTION_ABORTED, \"Connection was aborted (no ACK received)\" -104 net::ERR_CONNECTION_FAILED, \"Connection attempt failed\" -105 net::ERR_NAME_NOT_RESOLVED, \"Host name could not be resolved\" -106 net::ERR_INTERNET_DISCONNECTED, \"Internet connection lost\" -107 net::ERR_SSL_PROTOCOL_ERROR, \"SSL protocol error\" -108 net::ERR_ADDRESS_INVALID, \"Invalid IP address and/or port number\" -109 net::ERR_ADDRESS_UNREACHABLE, \"Unreachable IP address\" -110 net::ERR_SSL_CLIENT_AUTH_CERT_NEEDED, \"Server requested a client certificate for SSL client authentication\" -112 net::ERR_NO_SSL_VERSIONS_ENABLED, \"No SSL protocol versions are enabled\" -113 net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH, \"Client and server don't support a common SSL protocol version or cipher suite\" -114 net::ERR_SSL_RENEGOTIATION_REQUESTED, \"Server requested a renegotiation (re-handshake)\" -116 net::ERR_CERT_ERROR_IN_SSL_RENEGOTIATION, \"During SSL renegotiation (re-handshake), the server sent a certificate with an error\" -117 net::ERR_BAD_SSL_CLIENT_AUTH_CERT, \"SSL handshake failed because of a bad or missing client certificate\" -118 net::ERR_CONNECTION_TIMED_OUT, \"Timed out\" -123 net::ERR_SSL_NO_RENEGOTIATION, \"Peer sent an SSL no_renegotiation alert message\" -138 net::ERR_ACCESS_DENIED, \"Access denied\" -141 net::ERR_SSL_CLIENT_AUTH_SIGNATURE_FAILED, \"Unable to sign the CertificateVerify data of an SSL client auth handshake with the client certificate's private key\" -145 net::ERR_WS_PROTOCOL_ERROR, \"WebSocket protocol error - connection terminated due to a malformed frame or other protocol violation\" -147 net::ERR_ADDRESS_IN_USE, \"Failed to bind to an address because already in use\" -148 net::ERR_SSL_HANDSHAKE_NOT_COMPLETED, \"SSL handshake has not completed\" -149 net::ERR_SSL_BAD_PEER_PUBLIC_KEY, \"SSL peer's public key is invalid\" -150 net::ERR_SSL_PINNED_KEY_NOT_IN_CERT_CHAIN, \"Certificate didn't match built-in public key pins for the host name\" -151 net::ERR_CLIENT_AUTH_CERT_TYPE_UNSUPPORTED, \"Server request for client certificate did not contain any types we support\" -152 net::ERR_ORIGIN_BOUND_CERT_GENERATION_TYPE_MISMATCH, \"Server requested one type of cert, then requested a different type while the first was still being generated\" -153 net::ERR_SSL_DECRYPT_ERROR_ALERT, \"SSL peer sent us a fatal decrypt_error alert\" -156 net::ERR_SSL_SERVER_CERT_CHANGED, \"SSL server certificate changed in a renegotiation\" -157 net::ERR_SSL_INAPPROPRIATE_FALLBACK, \"SSL server indicated that an unnecessary TLS version fallback was performed\" -158 net::ERR_CT_NO_SCTS_VERIFIED_OK, \"All Signed Certificate Timestamps failed to verify\" -159 net::ERR_SSL_UNRECOGNIZED_NAME_ALERT, \"SSL server sent us a fatal unrecognized_name alert\" -164 net::ERR_SSL_CLIENT_AUTH_CERT_BAD_FORMAT, \"Failed to import a client certificate from the platform store into the SSL library\" -165 net::ERR_SSL_FALLBACK_BEYOND_MINIMUM_VERSION\", \"SSL server requires falling back to a version older than the configured minimum fallback version\" -166 net::ERR_ICANN_NAME_COLLISION\", \"Resolving a hostname to an IP address list included the IPv4 address \\\"127.0.53.53\\\". This is a special IP address which ICANN has recommended to indicate there was a name collision, and alert admins to a potential problem\" -200 net::ERR_CERT_COMMON_NAME_INVALID, \"Server responded with a certificate whose common name did not match the host name\" -201 net::ERR_CERT_DATE_INVALID\", \"Server responded with a certificate that is either expired or not valid yet\" -202 net::ERR_CERT_AUTHORITY_INVALID, \"Server responsde with a certificate signed by an untrusted authority\" -203 net::ERR_CERT_CONTAINS_ERRORS\", \"Server responded with a certificate that contains errors\" -204 net::ERR_CERT_NO_REVOCATION_MECHANISM, \"Certificate has no mechanism for determining if it is revoked\" -205 net::ERR_CERT_UNABLE_TO_CHECK_REVOCATION\", \"Revocation information for the security certificate for this site is not available\" -206 net::ERR_CERT_REVOKED, \"Server responded with a certificate that has been revoked\" -207 net::ERR_CERT_INVALID, \"Server responded with a certificate that is invalid\" -208 net::ERR_CERT_WEAK_SIGNATURE_ALGORITHM, \"server responded with a certificate that is signed using a weak signature algorithm\" -210 net::ERR_CERT_NON_UNIQUE_NAME, \"Host name specified in the certificate is not unique\" -211 net::ERR_CERT_WEAK_KEY, \"Server responded with a certificate that contains a weak key\" -212 net::ERR_CERT_NAME_CONSTRAINT_VIOLATION, \"Certificate claimed DNS names that are in violation of name constraints\" -213 net::ERR_CERT_VALIDITY_TOO_LONG, \"Certificate's validity period is too long\" -324 net::ERR_EMPTY_RESPONSE, \"Server closed the connection without sending any data\" -803 net::ERR_DNS_TIMED_OUT, \"DNS lookup timed out\" -9999 \"unknown error, error not mapped\" For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Adding and editing monitors (how to create New Relic Synthetics monitors, including configuration options) Scripted browser reference (all API options for scripted browsers)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.15424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "sections": "<em>Synthetic</em> <em>monitoring</em> response codes",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitors</em> returns a number of additional response codes beyond standard HTTP response codes, visible in the Resources page. These response codes are based on Chromium&#x27;s response codes and give you more detail on the behavior of your <em>monitors</em>. Response codes <em>Synthetic</em> <em>monitoring</em> returns"
      },
      "id": "6045276ee7b9d22729579a22"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "Tip",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-06-26T00:35:49Z",
      "updated_at": "2021-06-26T00:35:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. Tip To use CPMs and synthetic monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a Scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a Simple Browser or Scripted Browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a Runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and Memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.93738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "View ping monitor results",
        "Tip",
        "Timing details"
      ],
      "title": "View ping monitor results",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "902d04d17516a3d61f8646fb74e99656cc411cc9",
      "image": "https://docs.newrelic.com/static/eb1b7bd9ed5e280c67892fd0f4cd6aad/c1b63/entitiy_ping_monitor_page_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results/",
      "published_at": "2021-06-26T08:16:38Z",
      "updated_at": "2021-05-15T18:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring automatically records all ping monitor checks, allowing you to see the load time and response size for every run. Use the explorer and the selected ping monitor's Summary and Results pages to: Select a resource to view load timing, response and request headers, and other details. Use these details to find problems and diagnose performance issues. Tip For information on simple or scripted monitors, see View simple or scripted monitor results. View ping monitor results To access a complete list of ping monitor results: Go to one.newrelic.com > Explorer > Synthetic monitors. To find the type of result you're looking for, sort using the provided filters. For example, to view all ping monitors, sort by Monitor Type. You can also search for specific results using the New Relic One quick find, which is available across the New Relic One platform. To view specific information about a monitor, such as page load time and availability, select a ping monitor to access the selected monitor's Summary and Results pages. one.newrelic.com > Explorer > Synthetic monitors > (select a monitor): View a summary of the selected ping monitor including load time and total load size. If you want to... Do this... Get details about page resources Click on a specific ping monitor check to access Result Details view. From the Result Detail view, you can: See the exact order in which each page's resources loaded. See how long each element took to load. See detailed metrics, including HTTP status codes, timing information, response headers, and request headers. View transaction traces Make sure you have enabled Synthetic transaction traces for the ping monitor you want to view. Go to one.newrelic.com > Explorer > Synthetic monitors > (select a ping monitor). Hover over the Timeline and click APM transaction trace. Selecting a transaction trace will also reveal more details in APM. Share a result Copy the unique URL from your browser's address bar; for example: https://one.newrelic.com/launcher/nr1-core.explorer#launcher=7890wxyz-7c6c-4786-94bc-31d58fc91a73 Copy You can then share this URL with anyone else who has access to your New Relic account data. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Timing details For some monitor types, the overall monitor check duration will be larger than the individual page request durations. This is because some browser behaviors are not measured individually but still count towards the total check time. Examples of unmeasured behaviors include: JavaScript interactions Resource pre-fetching and prioritization DNS pre-resolve TCP pre-connect Page pre-rendering",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.06796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View ping <em>monitor</em> results",
        "sections": "View ping <em>monitor</em> results",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "<em>Synthetic</em> <em>monitoring</em> automatically records all ping <em>monitor</em> checks, allowing you to see the load time and response size for every run. <em>Use</em> the explorer and the selected ping <em>monitor</em>&#x27;s Summary and Results pages to: Select a resource to view load timing, response and request headers, and other"
      },
      "id": "603ea241196a67ae24a83da1"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.46094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-06-25T16:18:54Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in the account that includes: The rule details A message about having too many facets A newRelicFeature of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.19272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.46094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-25T16:18:05Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.1932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.46094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.4607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-25T16:18:05Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 267.1932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.9118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.9118,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36194,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations",
        "Deprecated methods"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:30Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default Mobile events using the New Relic Mobile SDK. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple Mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the Mobile crash event trail. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default Mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations. Deprecated methods As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create custom events. The recordEvent methods for Android and iOS are deprecated. The deprecated recordEvent events do not have their own event type; they are recorded as a Mobile event type with a category attribute value of custom. recordCustomEvent creates an event with an eventType you can assign. But the eventType should only be used for one or two high-level event types, not for naming events. For example, you might have one event type Gestures, with many different names under that one type. For more context on this, see the recordCustomEvent query example.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 858.9011,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": ". Record <em>custom</em> <em>events</em> and <em>attributes</em> You can add your own <em>custom</em> APM <em>events</em> and <em>attributes</em>, which you can then use for querying and charting. This is one of several ways to <em>report</em> <em>custom</em> data. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> <em>attributes</em>"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-06-25T22:42:55Z",
      "updated_at": "2021-06-03T12:15:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest New Relic Mobile SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges New Relic Mobile aggregates performance for various methods into summary metrics that appear in New Relic Mobile's Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic Mobile. - (void)myMethod { NR_TRACE_METHOD_START(0); // … existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) // … existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.29095,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> <em>and</em> <em>events</em>",
        "body": " record arbitrary numerical data and named <em>events</em> with Objective-C and Swift. You can also use several API calls to record <em>custom</em> metrics that provide different levels of detail. Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> and <em>events</em> Use methods in the NewRelic object to <em>report</em> <em>custom</em> <em>attributes</em> and <em>events</em>"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.5967,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and <em>attributes</em>. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 266.91174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the Browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36264,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-06-26T08:17:57Z",
      "updated_at": "2021-05-15T10:43:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.36192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ", timeseries, until, week, weeks, where, with <em>Event</em> type limits The current limit for total number of <em>event</em>Type values is 250 per sub-account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/intro-custom-data": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data/",
      "sections": [
        "Report custom events and attributes",
        "Requirements",
        "Avoid rate limits",
        "Example use cases",
        "Using custom attributes",
        "Using custom events",
        "Send custom events and attributes",
        "Extend data retention"
      ],
      "published_at": "2021-06-26T08:19:30Z",
      "title": "Report custom events and attributes",
      "updated_at": "2021-05-15T10:44:11Z",
      "type": "docs",
      "external_id": "e50a9be8b3df5859c6307c8642942006f537578d",
      "document_type": "page",
      "popularity": 1,
      "body": "One of the ways to report custom data to New Relic is with custom events and attributes. Have questions about why you'd use custom data? See Introduction to custom data. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits Reporting a large number of custom events and/or attributes can cause degraded query performance. It may also result in approaching or passing data collection rate limits. For optimal performance, first think about what data you want to analyze, and then create only the events and/or attributes necessary to meet these specific goals. Be aware of the following data and subscription requirements for inserting and accessing custom data: Ensure you follow limits and requirements around event/attribute data types, naming syntax, and size. The amount of data you have access to over time depends on your data retention policy. Example use cases Two popular custom data solutions are custom events and custom attributes. There are several ways to accomplish this (more on that later in this doc), depending on your New Relic implementation and tools. Here are some common use cases for implementing custom events and attributes. Using custom attributes Custom attributes are often used to add important business and operational context to existing events. Business context might include: Customer token Customer market segment Customer value classification Workflow control values not obvious in the URIStem User/product/account privilege context Operational context might include: Which feature flags were used What datastore was accessed What cache was accessed What errors were detected and ignored (fault partitioning) Using custom events Event data is one of New Relic's four core data types. We recommend reading that definition to understand what we mean by \"event\" and why that data type is most used for reporting specific types of activity. The use cases for custom events varies widely: basically they are used for any type of activity that an organization deems important and that is not already being monitored. A couple examples: An event might represent an activity involving multiple actions, like a customer purchasing a certain combination of products. An event might record backup activity. For example, they might set up reporting of events that represent production backups of their SOLR instances into an event table, with a timestamp of when it occurred, which cluster, and the duration. Send custom events and attributes Methods for sending custom events and attributes include: Source How to send custom data APM agent Use APM agent APIs to report custom events and custom attributes. Browser monitoring agent Add custom attributes to the PageView event via the Browser API call addCustomAttribute. Send PageAction event and attributes via Browser API. Forward APM agent custom attributes to PageView event. Event API To report custom events not associated with other New Relic products, use the Event API. Infrastructure monitoring agent Add custom attributes to default Infrastructure events. Use the Flex integration tool to report your own custom event data. Mobile monitoring agent Use the mobile agent API to send custom events and attributes. Synthetic monitoring Add custom attributes to the SyntheticCheck event via the $util.insights tools. For ways to report other types of custom data, see: Metric API Logs Trace API Extend data retention To learn how to extend how long events are retained in your account, see our documentation about event data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 546.89075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>custom</em> events and attributes",
        "sections": "Report <em>custom</em> events and attributes",
        "body": "One of the ways to report <em>custom</em> <em>data</em> to New Relic is with <em>custom</em> events and attributes. Have questions about why you&#x27;d use <em>custom</em> <em>data</em>? See <em>Introduction</em> to <em>custom</em> <em>data</em>. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits"
      },
      "id": "609fa5fb64441f9ebfd2a1db"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.34557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> events and attributes",
        "sections": "Forward <em>custom</em> attributes from APM <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": " that contains the action name and any <em>custom</em> attribute names and values you capture along with it. The PageAction event also contains any <em>custom</em> attributes you added to the PageView event. Add <em>custom</em> attributes to the PageView event so you can query or filter your <em>data</em> to answer more questions about your"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-06-26T08:17:58Z",
      "updated_at": "2021-05-15T10:44:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your New Relic APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 78.002975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> events and attributes",
        "sections": "APM: Report <em>custom</em> events and attributes",
        "tags": "Event <em>data</em> sources",
        "body": "If you have APM, you can report <em>custom</em> event <em>data</em>. You can then query and visualize your <em>data</em> in New Relic. <em>Data</em> considerations New Relic agents send event <em>data</em> to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Agent APIs",
        "Telemetry SDKs",
        "APIs for sending metrics, traces, logs, and events",
        "New Relic One applications"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-06-25T19:51:32Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. To browse all New Relic-built tools and solutions, see New Relic integrations. Agent APIs Some of our monitoring solutions come with APIs and/or SDKs that allow you to customize the data reported and how it reports. For more information, see the relevant product: APM agent APIs Browser API Mobile API Infrastructure monitoring: the Flex integration tool Telemetry SDKs If our more curated solutions don't work for you, our open source Telemetry SDKs let you build your own solution. These SDKs are language wrappers for our data-ingest APIs (below) that let you send telemetry data to New Relic without requiring install of an agent. APIs for sending metrics, traces, logs, and events If our more curated solutions don't work for you, we also have data-ingest APIs: Trace API Event API Metric API Log API To learn about the differences between these data types, see Data types. New Relic One applications You can build entirely custom applications that reside in New Relic One and make use of any data you want. You can use existing open source New Relic One apps, or share your own with the open source community. For details, see New Relic One applications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.66722,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>data</em> into New Relic",
        "sections": "<em>Get</em> <em>data</em> into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to <em>get</em> <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "Tip",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-06-25T16:18:53Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. Tip To use telemetry data and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.6672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " with confidence. Tip To use <em>telemetry</em> <em>data</em> and the rest of our observability <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. The value of New Relic The <em>Telemetry</em> <em>Data</em> <em>Platform</em>: Provides an elastic"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/get-started/nrdb-horsepower-under-hood": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "Tip",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-06-25T16:18:53Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. Tip To use telemetry data and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.6672,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " with confidence. Tip To use <em>telemetry</em> <em>data</em> and the rest of our observability <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. The value of New Relic The <em>Telemetry</em> <em>Data</em> <em>Platform</em>: Provides an elastic"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/index": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1120.197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>data</em> coming into New Relic",
        "sections": "Manage <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "When you connect your <em>data</em> to New Relic, we process what we receive and apply <em>data</em> dropping and transformation rules. Then we count the bytes needed to represent your <em>data</em> in a standard format, like JSON. If you&#x27;re on our New Relic One pricing plan, you&#x27;re charged by the number of bytes written"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1120.196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 820.4181,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Problem You sent metric <em>data</em> points to the Metric API, and are not seeing what you expect when querying the <em>data</em>. Use the following checklist to determine the root cause: Make sure you are querying the <em>data</em> correctly. Check the HTTP status codes returned by the API. Issues like authorization"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-event-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-metric-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/report-metrics-metric-api": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2786,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "sections": "Troubleshoot Metric <em>API</em> with NRIntegrationError events",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " to insights.newrelic.com &gt; <em>Manage</em> <em>data</em> &gt; <em>API</em> keys). Create an HTTP request as shown below: Tip If your account hosts <em>data</em> in the EU <em>data</em> center, ensure you&#x27;re using the proper <em>API</em> endpoints for EU region accounts. curl -H &quot;Accept: application&#x2F;json&quot; -H &quot;X-Query-Key:YOUR_<em>API</em>_KEY_HERE&quot; &quot;https:&#x2F;&#x2F;insights-<em>api</em>.newrelic.com&#x2F;v1&#x2F;accounts&#x2F;YOUR_ACCONT_HERE&#x2F;query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature=&#x27;Metrics&#x27;&quot; Copy"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27847,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-26T13:10:44Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 255.54099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "sections": "Metric <em>API</em> limits <em>and</em> restricted attributes",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "This document describes <em>data</em> requirements for the Metric <em>API</em>, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric <em>data</em>: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph": [
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 2328.3582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": " most essential, we have a strategy for you. Learn about reducing the amount of <em>data</em> that comes into NRDB in Manage <em>data</em> coming into New Relic. Learn about customizing storage so you only store the <em>data</em> you want, for the period you want in Manage <em>data</em> stored in New Relic. Learn about dropping <em>data</em> in <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. And for dropping log <em>data</em>, see <em>Drop</em> <em>data</em> with <em>drop</em> filter rules."
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Data privacy with New Relic",
        "Personal data transfer (Privacy Shield and SCC)",
        "Compliance with legal requirements",
        "Privacy by design and by default",
        "Personal data requests (GDPR, CCPA, etc.)",
        "Events and attributes",
        "Dropping data at ingest",
        "Technical security controls",
        "Organizational security controls",
        "Account security",
        "Retention of your data",
        "New Relic account emails",
        "Account changes (NrAuditEvent)",
        "Account usage (NrDailyUsage)",
        "Security for products and services",
        "Alerts and Applied Intelligence",
        "APIs",
        "APM",
        "Browser monitoring",
        "Diagnostics",
        "Infrastructure monitoring",
        "Insights",
        "Integrations and serverless monitoring",
        "Logs management",
        "Mobile monitoring",
        "New Relic One",
        "Plugins",
        "Synthetic monitoring"
      ],
      "title": "Data privacy with New Relic",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Data privacy"
      ],
      "external_id": "d46953520476285467540433180d483815efecc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/",
      "published_at": "2021-06-26T00:47:04Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. We understand your concerns when you entrust us with your data, and we always strive to embrace your expectations and preferences. This document provides links to detailed information about the privacy and security measures we take to protect you and your customers' data privacy. Our monitoring tools are data-agnostic; they don't require sensitive materials, and many of them don't require any personal data. You are responsible for ensuring that your systems are appropriately set up and configured so that they don't send inappropriate personal data or sensitive materials to New Relic monitoring tools. For additional information about policies, credentials, audits, and other resources, see our New Relic security website. Personal data transfer (Privacy Shield and SCC) The Schrems case ruling invalidates Privacy Shield. However, it explicitly reaffirms the validity of Standard Contractual Clauses (SCC) as an appropriate legal mechanism to transfer personal data outside of the European Union. You can find more information in How the Demise of Privacy Shield Affects Your New Relic Account. If you want to send personal data from the EU, we offer an appropriate data processing agreement (DPA) with SCC to govern the transfer of that data in accordance with the Schrems decision. For more information, consult our Data Processing Addendum FAQ, or download our pre-signed DPA (PDF|697 KB). Compliance with legal requirements We always strive to comply with all applicable laws as they take effect. This includes the European Union's General Data Protection Regulation (GDPR) and all relevant US State laws, such as the California Consumer Privacy Act (CCPA). Our disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). In addition, we are authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. For privacy-related details about New Relic's contractual and regulatory commitments for services, see: Terms of Service or Master Subscription Agreement Data Protection Agreement Services Privacy Notice For more information about annual audits, see Regulatory audits for New Relic services. Privacy by design and by default New Relic follows \"privacy by design\" principles as part of our overarching security program. For example, when New Relic agents capture a webpage or referrer URL, all query parameters are stripped by default. Here are examples of how we incorporate privacy considerations into our data and security practices. Personal data requests (GDPR, CCPA, etc.) New Relic strives to comply with all applicable laws as they take effect. This includes the European Union's GDPR and ePrivacy Directive and all applicable privacy laws, such as the California Consumer Privacy Act (CCPA) in the US. For more information about our process when responding to requests to access or delete personal data, see New Relic personal data requests. Events and attributes You can query events and attributes, as well as create charts and alert conditions about this data. For a complete list of all events and attributes tracked by New Relic agents, see our data dictionary. Events and attributes example: If you use the Infrastructure ProcessSample event's commandLine attribute, by default we strip options and arguments from the full command line to prevent accidental leakage of sensitive information. Dropping data at ingest Dropping data gives you control over the data that you send to New Relic, including any personal data that you configured to be collected. By dropping specific events or attributes from events, you determine what data New Relic ultimately stores so that you can query, alert on, and analyze it. For more information, see Drop data using NerdGraph. When our agents refer to data obfuscation, the agent actually removes the data before sending it to New Relic. The data cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences and then replaces them with the ? character. You can mask sensitive information in HTTP or HTTPS requests. For example, queries about distributed traces and transaction traces are obfuscated by default, in which case they cannot be recovered. For more information, see the documentation for specific New Relic services, including: APM transaction traces Distributed tracing Technical security controls We use a comprehensive set of technical controls to support general security needs as well as security for data we receive. For more information, see our documentation about data security, data encryption, and high security mode for APM agents. Organizational security controls New Relic maintains a number of internal policies and procedures to guide employees in privacy-related subjects such as data classification and handling, data retention, handling of personal data, fulfilling personal data requests, incident response, etc. All employees must complete the security and privacy training upon hiring and renew this training annually. Account security Our role-based account structure gives you direct control over who can access or change your account settings. For more information, see Users and roles. Retention of your data Our Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. This platform stores different types of data for different periods of time. The Data retention page in our UI provides information on how long your data will be stored in the New Relic database (NRDB). For more information, see Manage data retention. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product engagement, support, alert notifications, updates, billings, etc. Individual users can unsubscribe from certain communications. General email preferences are managed through the account user interface. For more information, see Account email settings. Alert notification emails are managed through the alerting UI. Account changes (NrAuditEvent) To view changes made to your account's users or to record configuration changes, query NrAuditEvent events. To be notified about account changes, create NRQL alert conditions. For more information about available NrAuditEvent attributes, see our data dictionary. Account usage (NrDailyUsage) To view daily usage of New Relic for your selected account for billing purposes, query NrDailyUsage events. For more information about available NrDailyUsageattributes, see our data dictionary. Security for products and services We publish security bulletins with detailed information about vulnerabilities, remediation strategies, and applicable updates for affected software. To receive notifications for future advisories, use either of these options: Subscribe to our security bulletins RSS feed. Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. The following summarizes how individual New Relic products and components ensure security, with links to additional details. Alerts and Applied Intelligence By default, our alerting services do not record any personal data. In addition, they automatically set default permissions for individual account users and access levels within account structures. For more information, see our documentation about Applied Intelligence, as well as our rules and limits for alerts. APIs APIs simply are interfaces for data exchange automation. APIs have no knowledge of the content being transferred. We require authorized users to provide their API keys to monitor subscription usage, manage account user permissions, query data, and perform other automated tasks. For more information, see Introduction to New Relic APIs. APM APM agents monitor your applications' performance. By default, APM agents do not record any personal data. For more information, see our APM security documentation. Browser monitoring Our browser monitoring agent allows you to monitor the performance of their websites. For more information, see: Browser security documentation Visitor's IP address New Relic cookies used by Browser Enabling or disabling cookie collection for session tracking Diagnostics The New Relic Diagnostics service inspects relevant system information and any other necessary information (such as logs and config files) to perform diagnostic checks that assess configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information, see the Diagnostics security documentation. Infrastructure monitoring The Infrastructure agent allows you to monitor the performance of components in your ecosystem, such as servers, platforms, operating systems, databases, etc. Infrastructure may record the userID and username of users connecting to Infrastructure resources. For more information, see the security documentation for infrastructure monitoring. Insights The Insights service reports on data recorded by other New Relic products and services. It doesn’t record data on its own. For more information, see the Insights documentation about default data from other products and services. Integrations and serverless monitoring Our integrations services allow you to retrieve and load data into the New Relic database from a variety of sources, including: Cloud-based integrations On-host integrations in containerized environments, such as Kubernetes On-host integrations built by New Relic On-host integrations built by the open-source community On-host integrations built by you Depending on the integration, different types of data may be recorded so that you can monitor the integrations in New Relic. The integration services are data agnostic. They will have no knowledge of whether the imported data contains any personal information. For more information, see the documentation for the specific integration, including: Amazon Web Services (AWS) Google Cloud Platform (GCP) Kubernetes Microsoft Azure On-host integrations Open source on-host integrations Serverless function monitoring Logs management Due to the nature of our Logs management service, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls or log forwarder configuration. All data for the Logs service is then reported to New Relic over HTTPS. The Logs service does mask number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see the Logs security documentation. Mobile monitoring By default, our mobile monitoring service collects two pieces of personal data: The IP address is used to derive high-level geographical data, and then is discarded. A device ID is generated by New Relic and is used for billing purposes. For more information, see our security documentation for mobile monitoring. New Relic One New Relic One is a connected, unified UI that gathers all the data you already monitor with New Relic in one place. It is not a product, but rather, it's a way to interact with all your New Relic data more easily. For more information, see the introduction and security documentation for New Relic One. Plugins The plugins service allows you to publish publicly accessible plugins within (Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher in Plugin Central. For plugins in Plugin Central that are not created by New Relic, the plugin publisher must follow specific guidelines. For more information, see the Plugins security documentation. Synthetic monitoring The synthetic monitoring service uses monitors distributed throughout data centers around the world. It captures what is essentially performance data of simulated traffic. By default, it does not capture any personal data. For more information, see the data privacy and security documentation for synthetic monitoring. If you configure the synthetic service to monitor areas of websites that are located behind a login page, take care to create a non-personal login dedicated to this purpose. This will reduce the risk of unintended personal data exposure. For example, to securely store sensitive information, such as passwords, API keys, and user names, you can use secured credentials for scripted browsers and API tests. The synthetic monitoring service also supports a variety of authentication mechanisms. Depending on the type of monitor you choose, this includes Basic, Digest, NTLM, and NTLMv2. You can also control which of your users can access your monitors and private locations. For more information, see our documentation about user role-based permissions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 629.5116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> privacy with New Relic",
        "sections": "<em>Dropping</em> <em>data</em> at ingest",
        "tags": "<em>Data</em> privacy",
        "body": " <em>data</em> <em>using</em> <em>NerdGraph</em>. When our agents refer to <em>data</em> obfuscation, the agent actually removes the <em>data</em> before sending it to New Relic. The <em>data</em> cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences"
      },
      "id": "603ec2d4e7b9d22fba2a07c6"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/nerd-graph-query/",
      "sections": [
        "NerdGraphQuery",
        "Usage",
        "Examples",
        "Props",
        "Methods",
        "NerdGraphQuery.query",
        "Type definitions",
        "PromiseQueryResult",
        "QueryResult"
      ],
      "published_at": "2021-06-30T01:44:02Z",
      "title": "NerdGraphQuery",
      "updated_at": "2021-06-25T01:48:19Z",
      "type": "developer",
      "external_id": "1ada6e056e031c141b2bb989e4ec200b3a7ce988",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic One SDK provides Query components based on ApolloClient's query components. These components are an abstraction layer making it easier to query NerdGraph without worrying about configuring Apollo Client and, for the most common use cases, without having to write GraphQL queries. A generic NerdGraph Query component that allows you to query anything from NerdGraph. Usage import { NerdGraphQuery } from 'nr1' Copy Examples Props childrenfunction Render prop function as a child. function ( queryResult : QueryResult // Results of the query. ) => React.ReactNode fetchPolicyTypeenum DEFAULT NerdGraphQuery . FETCH_POLICY_TYPE . CACHE_AND_NETWORK Allows you to specify how you want your query to interact with the cached data. CACHE_AND_NETWORK: The query returns your initial data from the cache if available. However, regardless of whether or not the full data is in your cache, the query always makes a request using your network interface and returns the updated data. This option is not available when using the static query() method of the component. CACHE_FIRST: The query makes a request using your network interface only if the data for your query is not already in the cache. CACHE_ONLY: The query never makes a request using your network interface. Instead it returns the data available in the cache. If the data for your query does not exist in the cache, then an error is thrown. NETWORK_ONLY: The query never returns your initial data from the cache. Instead it always makes a request using your network interface. NO_CACHE: The query never returns your initial data from the cache. Instead it always makes a request using your network interface. Unlike the NETWORK_ONLY policy, it does not write any data to the cache after the query completes. <One of NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_AND_NETWORK , NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_FIRST , NerdGraphQuery.FETCH_POLICY_TYPE.CACHE_ONLY , NerdGraphQuery.FETCH_POLICY_TYPE.NETWORK_ONLY , NerdGraphQuery.FETCH_POLICY_TYPE.NO_CACHE , > pollIntervalnumber DEFAULT 0 Interval in milliseconds to poll for new data. Set to zero to avoid any kind of regular polling. queryrequiredstring|object GraphQL query, either as a string or a GraphQL document parsed into an AST by the gql method of nr1. skipboolean DEFAULT false When set to true, the query will be skipped entirely from rendering. variablesobject DEFAULT {} Object containing all of the variables your query needs to execute. Methods NerdGraphQuery.query Static method to use NerdGraphQuery as a Promise instead of as a React component. function ( props : Object // Object containing the query options. Any NerdGraphQuery prop is a valid option except children and pollInterval. ) Type definitions PromiseQueryResult { error : ApolloClient.ApolloError, // Runtime error with graphQLErrors and networkError properties. data : Object, // Object containing the result of your query. fetchMore : function|null, // If not null, fetchMore allows you to load more results for your query. New data is merged with previous data. refetch : function, // Refetch the query. } QueryResult { loading : boolean, // Indicates that the request is in flight. error : ApolloClient.ApolloError, // Runtime error with graphQLErrors and networkError properties. data : Object, // Object containing the result of your query. fetchMore : function|null, // If not null, fetchMore allows you to load more results for your query. New data is merged with previous data. refetch : function, // Refetch the query. }",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 436.05322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NerdGraphQuery</em>",
        "sections": "<em>NerdGraphQuery</em>",
        "body": "New Relic One SDK provides Query components based on ApolloClient&#x27;s query components. These components are an abstraction layer making it easier to query <em>NerdGraph</em> without worrying about configuring Apollo Client and, for the most common <em>use</em> cases, without having to write <em>Graph</em>QL queries. A generic"
      },
      "id": "6091f8cee7b9d213095068a2"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic": [
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.35715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a <em>data</em> dropping rule to remove attributes at <em>ingest</em> time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-26T13:10:44Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.35715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-retention": [
    {
      "sections": [
        "Data privacy with New Relic",
        "Personal data transfer (Privacy Shield and SCC)",
        "Compliance with legal requirements",
        "Privacy by design and by default",
        "Personal data requests (GDPR, CCPA, etc.)",
        "Events and attributes",
        "Dropping data at ingest",
        "Technical security controls",
        "Organizational security controls",
        "Account security",
        "Retention of your data",
        "New Relic account emails",
        "Account changes (NrAuditEvent)",
        "Account usage (NrDailyUsage)",
        "Security for products and services",
        "Alerts and Applied Intelligence",
        "APIs",
        "APM",
        "Browser monitoring",
        "Diagnostics",
        "Infrastructure monitoring",
        "Insights",
        "Integrations and serverless monitoring",
        "Logs management",
        "Mobile monitoring",
        "New Relic One",
        "Plugins",
        "Synthetic monitoring"
      ],
      "title": "Data privacy with New Relic",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Data privacy"
      ],
      "external_id": "d46953520476285467540433180d483815efecc6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/",
      "published_at": "2021-06-26T00:47:04Z",
      "updated_at": "2021-03-16T18:10:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic takes your data privacy seriously. Our principles-based approach aims to go beyond the legal requirements for consent. We understand your concerns when you entrust us with your data, and we always strive to embrace your expectations and preferences. This document provides links to detailed information about the privacy and security measures we take to protect you and your customers' data privacy. Our monitoring tools are data-agnostic; they don't require sensitive materials, and many of them don't require any personal data. You are responsible for ensuring that your systems are appropriately set up and configured so that they don't send inappropriate personal data or sensitive materials to New Relic monitoring tools. For additional information about policies, credentials, audits, and other resources, see our New Relic security website. Personal data transfer (Privacy Shield and SCC) The Schrems case ruling invalidates Privacy Shield. However, it explicitly reaffirms the validity of Standard Contractual Clauses (SCC) as an appropriate legal mechanism to transfer personal data outside of the European Union. You can find more information in How the Demise of Privacy Shield Affects Your New Relic Account. If you want to send personal data from the EU, we offer an appropriate data processing agreement (DPA) with SCC to govern the transfer of that data in accordance with the Schrems decision. For more information, consult our Data Processing Addendum FAQ, or download our pre-signed DPA (PDF|697 KB). Compliance with legal requirements We always strive to comply with all applicable laws as they take effect. This includes the European Union's General Data Protection Regulation (GDPR) and all relevant US State laws, such as the California Consumer Privacy Act (CCPA). Our disk-based encryption provides additional security while your data is at rest (FIPS 140-2 compliant). In addition, we are authorized for Moderate Impact SaaS Services (FedRAMP Authorized Moderate) for accounts that meet specific criteria. For privacy-related details about New Relic's contractual and regulatory commitments for services, see: Terms of Service or Master Subscription Agreement Data Protection Agreement Services Privacy Notice For more information about annual audits, see Regulatory audits for New Relic services. Privacy by design and by default New Relic follows \"privacy by design\" principles as part of our overarching security program. For example, when New Relic agents capture a webpage or referrer URL, all query parameters are stripped by default. Here are examples of how we incorporate privacy considerations into our data and security practices. Personal data requests (GDPR, CCPA, etc.) New Relic strives to comply with all applicable laws as they take effect. This includes the European Union's GDPR and ePrivacy Directive and all applicable privacy laws, such as the California Consumer Privacy Act (CCPA) in the US. For more information about our process when responding to requests to access or delete personal data, see New Relic personal data requests. Events and attributes You can query events and attributes, as well as create charts and alert conditions about this data. For a complete list of all events and attributes tracked by New Relic agents, see our data dictionary. Events and attributes example: If you use the Infrastructure ProcessSample event's commandLine attribute, by default we strip options and arguments from the full command line to prevent accidental leakage of sensitive information. Dropping data at ingest Dropping data gives you control over the data that you send to New Relic, including any personal data that you configured to be collected. By dropping specific events or attributes from events, you determine what data New Relic ultimately stores so that you can query, alert on, and analyze it. For more information, see Drop data using NerdGraph. When our agents refer to data obfuscation, the agent actually removes the data before sending it to New Relic. The data cannot be recovered. For example, with APM queries, the Record SQL? value defaults to obfuscated. This strips the string literals and numeric sequences and then replaces them with the ? character. You can mask sensitive information in HTTP or HTTPS requests. For example, queries about distributed traces and transaction traces are obfuscated by default, in which case they cannot be recovered. For more information, see the documentation for specific New Relic services, including: APM transaction traces Distributed tracing Technical security controls We use a comprehensive set of technical controls to support general security needs as well as security for data we receive. For more information, see our documentation about data security, data encryption, and high security mode for APM agents. Organizational security controls New Relic maintains a number of internal policies and procedures to guide employees in privacy-related subjects such as data classification and handling, data retention, handling of personal data, fulfilling personal data requests, incident response, etc. All employees must complete the security and privacy training upon hiring and renew this training annually. Account security Our role-based account structure gives you direct control over who can access or change your account settings. For more information, see Users and roles. Retention of your data Our Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. This platform stores different types of data for different periods of time. The Data retention page in our UI provides information on how long your data will be stored in the New Relic database (NRDB). For more information, see Manage data retention. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product engagement, support, alert notifications, updates, billings, etc. Individual users can unsubscribe from certain communications. General email preferences are managed through the account user interface. For more information, see Account email settings. Alert notification emails are managed through the alerting UI. Account changes (NrAuditEvent) To view changes made to your account's users or to record configuration changes, query NrAuditEvent events. To be notified about account changes, create NRQL alert conditions. For more information about available NrAuditEvent attributes, see our data dictionary. Account usage (NrDailyUsage) To view daily usage of New Relic for your selected account for billing purposes, query NrDailyUsage events. For more information about available NrDailyUsageattributes, see our data dictionary. Security for products and services We publish security bulletins with detailed information about vulnerabilities, remediation strategies, and applicable updates for affected software. To receive notifications for future advisories, use either of these options: Subscribe to our security bulletins RSS feed. Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. The following summarizes how individual New Relic products and components ensure security, with links to additional details. Alerts and Applied Intelligence By default, our alerting services do not record any personal data. In addition, they automatically set default permissions for individual account users and access levels within account structures. For more information, see our documentation about Applied Intelligence, as well as our rules and limits for alerts. APIs APIs simply are interfaces for data exchange automation. APIs have no knowledge of the content being transferred. We require authorized users to provide their API keys to monitor subscription usage, manage account user permissions, query data, and perform other automated tasks. For more information, see Introduction to New Relic APIs. APM APM agents monitor your applications' performance. By default, APM agents do not record any personal data. For more information, see our APM security documentation. Browser monitoring Our browser monitoring agent allows you to monitor the performance of their websites. For more information, see: Browser security documentation Visitor's IP address New Relic cookies used by Browser Enabling or disabling cookie collection for session tracking Diagnostics The New Relic Diagnostics service inspects relevant system information and any other necessary information (such as logs and config files) to perform diagnostic checks that assess configuration and operability. By default, this data is not transmitted to New Relic. You do have the option to upload this information to a support ticket over HTTPS. For more information, see the Diagnostics security documentation. Infrastructure monitoring The Infrastructure agent allows you to monitor the performance of components in your ecosystem, such as servers, platforms, operating systems, databases, etc. Infrastructure may record the userID and username of users connecting to Infrastructure resources. For more information, see the security documentation for infrastructure monitoring. Insights The Insights service reports on data recorded by other New Relic products and services. It doesn’t record data on its own. For more information, see the Insights documentation about default data from other products and services. Integrations and serverless monitoring Our integrations services allow you to retrieve and load data into the New Relic database from a variety of sources, including: Cloud-based integrations On-host integrations in containerized environments, such as Kubernetes On-host integrations built by New Relic On-host integrations built by the open-source community On-host integrations built by you Depending on the integration, different types of data may be recorded so that you can monitor the integrations in New Relic. The integration services are data agnostic. They will have no knowledge of whether the imported data contains any personal information. For more information, see the documentation for the specific integration, including: Amazon Web Services (AWS) Google Cloud Platform (GCP) Kubernetes Microsoft Azure On-host integrations Open source on-host integrations Serverless function monitoring Logs management Due to the nature of our Logs management service, you have direct control over what data is reported to New Relic. To ensure data privacy and to limit the types of information New Relic receives, no customer data is captured except what you supply in your API calls or log forwarder configuration. All data for the Logs service is then reported to New Relic over HTTPS. The Logs service does mask number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see the Logs security documentation. Mobile monitoring By default, our mobile monitoring service collects two pieces of personal data: The IP address is used to derive high-level geographical data, and then is discarded. A device ID is generated by New Relic and is used for billing purposes. For more information, see our security documentation for mobile monitoring. New Relic One New Relic One is a connected, unified UI that gathers all the data you already monitor with New Relic in one place. It is not a product, but rather, it's a way to interact with all your New Relic data more easily. For more information, see the introduction and security documentation for New Relic One. Plugins The plugins service allows you to publish publicly accessible plugins within (Plugin Central. Anyone who has a New Relic account can install and use these plugins through their New Relic user interface. For some plugins, New Relic, Inc. is the publisher, and will be clearly identified as the publisher in Plugin Central. For plugins in Plugin Central that are not created by New Relic, the plugin publisher must follow specific guidelines. For more information, see the Plugins security documentation. Synthetic monitoring The synthetic monitoring service uses monitors distributed throughout data centers around the world. It captures what is essentially performance data of simulated traffic. By default, it does not capture any personal data. For more information, see the data privacy and security documentation for synthetic monitoring. If you configure the synthetic service to monitor areas of websites that are located behind a login page, take care to create a non-personal login dedicated to this purpose. This will reduce the risk of unintended personal data exposure. For example, to securely store sensitive information, such as passwords, API keys, and user names, you can use secured credentials for scripted browsers and API tests. The synthetic monitoring service also supports a variety of authentication mechanisms. Depending on the type of monitor you choose, this includes Basic, Digest, NTLM, and NTLMv2. You can also control which of your users can access your monitors and private locations. For more information, see our documentation about user role-based permissions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.21332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> privacy with New Relic",
        "sections": "<em>Retention</em> of your <em>data</em>",
        "tags": "<em>Data</em> privacy",
        "body": " information on how long your <em>data</em> will be stored in the New Relic database (NRDB). For more information, see <em>Manage</em> <em>data</em> <em>retention</em>. New Relic account emails By default, we communicate with you for a variety of purposes related to your status as New Relic subscribers. This includes product"
      },
      "id": "603ec2d4e7b9d22fba2a07c6"
    },
    {
      "sections": [
        "Overview of data retention (original pricing plan)",
        "Important",
        "Limits on editing and deleting data",
        "Product and API data retention policies",
        "APM",
        "APM data retention policies",
        "Legacy APM data retention policies",
        "Browser",
        "Infrastructure",
        "Tip",
        "Infrastructure downsampling and data retention",
        "Integration compute unit event limits",
        "Insights",
        "Logs",
        "Logs in context data retention",
        "Mobile",
        "Mobile data retention policies",
        "Standard Mobile (legacy) data retention policies",
        "Plugins",
        "Plugins data retention",
        "Legacy Plugins data retention",
        "Synthetics",
        "Synthetics data retention policies",
        "Metric API",
        "Trace API",
        "Data components",
        "Event data: reported by most products",
        "Metric timeslice data: reported by APM, Browser, and Mobile",
        "Aggregate metric timeslice data: reported by APM, Browser, and Mobile",
        "Key metrics: reported by APM, Browser, and Mobile",
        "Trace data: reported by APM, Browser, and Mobile"
      ],
      "title": "Overview of data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "22d5ab9f4d623ead28ee7bb82c118d91804dee22",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/product-based-pricing/overview-data-retention-components/",
      "published_at": "2021-06-26T13:07:16Z",
      "updated_at": "2021-03-11T13:22:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original Product-based pricing. If you're on our New Relic One pricing plan, see Manage your data. Not sure which you're on? See Overview of pricing plans. If you're on the original product-based pricing plan, you retain your existing subscriptions and data retention values. You manage these existing retention settings from the Data management hub in New Relic One. To manage your retention settings, in New Relic One, click your user name, select Manage your data, and then select Data retention. You'll see your existing retention settings. Adjust retention values by clicking the Edit retention button. New Relic stores different types of data for different periods of time. The retention period for a type of data will vary depending on the product, the subscription level, and the feature. Limits on editing and deleting data Once telemetry data (events, metrics, logs, traces) is reported to New Relic and available for querying, that data cannot be edited or deleted. This is a purposeful design decision that optimizes New Relic's speed and performance. Data will expire after its data retention ends. If you sent unwanted data or sensitive data to New Relic that must be removed, contact your account representative at New Relic, or get support at support.newrelic.com. Product and API data retention policies Select a New Relic product to see details about its data retention: APM Specific retention policies apply to each New Relic APM subscription level, including Lite, Essentials, Pro, and Enterprise. This includes metric timeslice data, key metrics, trace data, and event data. In addition to retention limits, your data is subject to aggregation (averaging) after certain elapsed time periods. For more information, see the aggregate metric data description. APM data retention policies For accounts on our original product-based pricing, APM data retention policies depend on your APM product subscription level. Component Lite Essentials Pro Metric timeslice data 24 hours 3 days 90 days Key metrics none forever forever Distributed tracing and logs in context none none 8 days Other trace data * 1 day 3 days 7 days Event data * * 1 day 3 days 8 days * If you view a transaction trace in the New Relic UI, New Relic stores that trace data for up to one year. * * Learn about how to extend the retention of event data. Legacy APM data retention policies Component Standard Startup Small Business Enterprise Metric timeslice data 7 days 14 days 30 days 90 days Key metrics none none none forever Trace data 7 days 7 days 7 days 7 days Event data none 8 days 8 days 8 days Browser For accounts on our original product-based pricing, Browser data is stored depending on your subscription level: Component Lite Pro Metric data 24 hours 90 days Key metrics 24 hours forever Trace data 7 days 7 days Event data * 1 day 8 days SPA data Unavailable 8 days * Learn about how to extend the retention of event data. Infrastructure For accounts on our original product-based pricing, Infrastructure data retention policies depend on your Infrastructure subscription level and your New Relic Infrastructure compute units pricing model. Data retention rules apply the same whether that data is displayed in the UI or queried. Tip Infrastructure data retention is not governed by your Insights subscription. Infrastructure downsampling and data retention Types of data are stored depending on your subscription level: Component Essentials Pro Infrastructure data 3 months 13 months Host count Host count will stop reflecting a host whose agent is no longer reporting after three minutes. However, host data will be available, subject to other retention criteria. 3 minutes 3 minutes Inventory attributes removed Inventory attributes for a host are retained for 24 hours after the agent stops reporting. 24 hours 24 hours Integration data Not available with Essentials Limit of 2275 integration events per compute unit per month In addition, Infrastructure downsamples your data on the fly, as it's generated. All Infrastructure metric data types (including On-Host Integrations metrics) will display different granularity depending on the age of the data and the size of the time window. The following table illustrates when different downsampled buckets will be used, both in the Infrastructure UI and for queries: Bucket Size Used For Time Windows Covering... Data Retained For... Raw (5, 10 or 15 second) 0 to 59 minutes 7 days 1 minute 60 minutes to 6 hours 30 days 10 minutes 6 hours to 3 days Full account retention period 1 hour 3 days to 14 days Full account retention period 3 hours 14+ days Full account retention period Integration compute unit event limits The 2275 limit on integration events per compute unit per month is a limit on total Infrastructure integration events. It's not a limit of 2275 for each integration's events. Additional details and clarifications about this limit: This limit applies to all events from all integrations (cloud integrations and on-host integrations). The events are all handled the same. Default data received by the Infrastructure agent does not count against the 2275 event per compute unit limit. If you exceed your limit, we do not enforce this limit. If you exceed your limit, we'll review pricing options with you to ensure you get the most cost-effective pricing for your organization's integrations. Insights For accounts on our original product-based pricing, an Insights subscription extends your event data retention. An Insights Pro subscription allows you to customize the length of your event data retention. Logs For accounts on our original product-based pricing, log data can be retained for up to 30 days by New Relic. Shorter retention periods of 8 or 15 days are also available. Logs in context data retention New Relic Logs logs in context data retention policy is based on your current APM product subscription level. For more information, see APM data retention. Mobile For accounts on our original product-based pricing, Mobile data retention policies depend on your New Relic Mobile product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and event data. For information about your subscription-related data usage, see Mobile subscription usage. Mobile data retention policies Component Lite Enterprise Overview page data 24 hours 90 days Crash data and stack traces 24 hours 90 days HTTP requests (except errors) as metric data Unavailable 90 days HTTP request errors as metric data Unavailable 3 days Interaction traces Unavailable 90 days Custom events * Unavailable 1 day Mobile events * 1 day 8 days MobileBreadcrumb events * Unavailable 3 days MobileCrash events * 1 day 90 days MobileHandledException events * Unavailable 3 days MobileJSError events (React Native beta) * Unavailable 3 days MobileRequest events * Unavailable 3 days MobileRequestError events * Unavailable 3 days MobileSession events * 1 day 90 days * Learn how to extend retention of event data. Standard Mobile (legacy) data retention policies Unless otherwise noted, Insights event data is unavailable for Standard subscriptions. Component Standard Overview page data 7 days Crash data and stack traces 7 days HTTP requests (except errors) as metric data 7 days HTTP request errors as metric data 3 days Interaction traces Unavailable MobileCrash events 8 days MobileSession events 8 days Plugins The retention period for historical data depends on the product and subscription level. The following data retention periods exist for New Relic Plugins. Important Plugins is not supported with accounts that host data in the EU region data center. Plugins data retention Component Lite Essentials Pro Enterprise Metric data 24 hours 3 days 90 days 90 days Legacy Plugins data retention Component Standard Startup Small Business Metric data 7 days 14 days 30 days Synthetics For accounts on our original product-based pricing, Synthetics data retention policies depend on your Synthetics product subscription level. This includes data components such as metric data, aggregate metrics, key metrics, trace data, and Insights events. Tip Synthetics events do not count against an Insights Pro subscription. Your current subscription level appears in the right column of the Account summary page: Go to synthetics.newrelic.com > (account dropdown) > Account settings > Account > Summary. Synthetics data retention policies Component Lite Pro Synthetics monitor data 2 weeks 13 months Event data 2 weeks 13 months Also see the data retention details for APIs, including: Metric API All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Trace API See Trace API general requirements and limits. Data components For accounts on our original product-based pricing, the section below provides an explanation of some types of data components governed by the data retention rules of specific products: Event data: reported by most products See Event data retention for information on the event data type. Metric timeslice data: reported by APM, Browser, and Mobile Metric timeslice data is a specific type of data that is used for most metric charts and reports in New Relic APM, Mobile, and Browser. Important Note that metric timeslice data differs from other metric data types. All metric timeslice data is aggregated, but New Relic deals with fresh data and old data in different ways. Fresh data has specific policies applied to the data to keep granular views of performance as aggregate metrics. As data ages and becomes less useful in a granular state, we summarize that data and only keep key metrics. Aggregate metric timeslice data: reported by APM, Browser, and Mobile Aggregate metric timeslice data summarizes calls to specific methods in your application: how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on your subscription level. Subscription Level Aggregate retention Enterprise Aggregates (averages) to 1-hour periods after 8 days. After 90 days, the permanent metric data continues to be stored in 1-hour periods. This means you cannot obtain data granularity of less than 1 hour after 8 days, and only a subset of metrics are available after 90 days. Pro After 8 days Essentials After 3 days. Legacy Small Business, Startup, and Standard After 3 days. Lite After 2 hours. We retain your most recent data in one-minute increments. We also aggregate permanent metric data to day-size increments after 90 days. When looking at older data in small time windows, you may notice that charts show less detail. As data ages, it is aggregated into larger segments. Key metrics: reported by APM, Browser, and Mobile New Relic retains certain \"key\" metric timeslice data aggregations forever for Enterprise and Pro customers, for any number of applications. New Relic aggregates permanent key metric data to hour-size increments after 90 days. Product Key metrics APM Apdex, for app server Throughput and page views Response time, plus breakdown into tiers or categories on your app's main Overview chart Page load time, plus breakdown into segments Error rate CPU usage Memory usage Browser Apdex, for browser Browser page load time Throughput total. After 90 days, there is no breakout by browser type, and only the combined average value is available for the time range requested. Mobile Crash rate: For iOS and for Android Network throughput Network response time Network error rates Interaction traces Trace data: reported by APM, Browser, and Mobile Depending on the product, New Relic retains different types of trace data: Product Trace data APM Types of trace data: Transaction traces Distributed tracing Slow query samples Error details See APM data retention details. Browser Types of trace data: Session traces Browser traces JavaScript errors* See Browser data retention details. Mobile Types of trace data: App crash stack traces Interaction traces See Mobile data retention details. * JavaScript errors in the stack trace UI are saved as trace data. JS errors are also saved as events.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.91783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview of <em>data</em> <em>retention</em> (original pricing plan)",
        "sections": "Overview of <em>data</em> <em>retention</em> (original pricing plan)",
        "tags": "Original <em>data</em> <em>retention</em>",
        "body": " <em>retention</em> values. You <em>manage</em> these existing <em>retention</em> settings from the <em>Data</em> management hub in New Relic One. To <em>manage</em> your <em>retention</em> settings, in New Relic One, click your user name, select <em>Manage</em> your <em>data</em>, and then select <em>Data</em> <em>retention</em>. You&#x27;ll see your existing <em>retention</em> settings. Adjust"
      },
      "id": "6043f75364441f6967378ec6"
    },
    {
      "sections": [
        "Users, roles, permissions (original user model)",
        "Requirements",
        "Updates about our new account/user model",
        "View and manage users in UI",
        "Tip",
        "Add a new user",
        "Important",
        "Manage user type (basic vs full)",
        "Determine full user count",
        "Enable SAML SSO and/or SCIM",
        "View pending SAML SSO users",
        "Update account roles",
        "Delete a user",
        "Update the account Owner",
        "User types: basic user and full user",
        "Account roles",
        "Add-on roles",
        "View roles",
        "Assign a managed role",
        "Create a custom role",
        "Assign a custom role",
        "Edit or delete a custom role",
        "Account permissions",
        "Alert permissions",
        "APM permissions",
        "Browser permissions",
        "Infrastructure permissions",
        "Insights permissions",
        "Mobile permissions",
        "Synthetics permissions",
        "Workloads permissions"
      ],
      "title": "Users, roles, permissions (original user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original users and roles"
      ],
      "external_id": "95ae42f3474b43dec394245cfc3e23628449a1ed",
      "image": "https://docs.newrelic.com/static/49612c40721bfa27afa90fafcba0e95c/c1b63/login-multiple-accounts-found.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-users-roles/users-roles-original-user-model/",
      "published_at": "2021-06-26T13:07:15Z",
      "updated_at": "2021-06-20T08:38:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our original user model, an introduction to how the user model works, including user roles and permissions, and how to add and manage users. Requirements This doc and the surrounding section of docs shows you how to manage users who are on our original user model. If you were a New Relic customer before July 30 2020, you likely have users on our original user model (and not the New Relic One user model). One way to quickly check your users' user model: if you can see users in the Users and roles UI, those users are on our original user model. Want to learn more about user model changes? See Overview of user models. Updates about our new account/user model In July of 2020, we released a new account/user model called the New Relic One user model, which offers many benefits in terms of how you manage your organization and users. At first this was only available to new sign-ups but over time we've been migrating more and more pre-existing organizations to the new model. Some organizations with users on the original user model are able to migrate their users on their own. We'll continue working on migrating users to the new model until the original user model is fully deprecated. One impact of the new user model is that it's possible now for users to have multiple logins associated with the same email. For example, a user with access to multiple organizations (like a contractor) may have their user record updated to the new user model in one organization, resulting in them having their original login method and records and a New Relic One user model record. This may result in the user being logged in to New Relic and not being able to find an account they're looking for. For more on that, see Factors affecting access. If a user's email is associated with more than one login, they'll see a \"multiple accounts found\" note when logging in. View and manage users in UI If your New Relic account has users on our original user model, you can use the Users and roles UI. To access this UI: select the account dropdown, select Account settings, and select Users and roles. Some features in the UI are visible only to account Owners and Admins. Tip You can also use the New Relic REST API to obtain a list of everyone and their roles in your New Relic account. Here are some instructions and tips for adding and managing users via the UI: Add a new user Tip Owner or Admins To add a new user to your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. In the upper right corner, click New user. Enter the appropriate name and email address. Select their base role as either Admin, User, or Restricted. Select Add user. The new user will receive an email notification automatically from New Relic. Important New Relic recommends a maximum of 1,000 accounts per user. Additional accounts may result in limited access to some New Relic features. Manage user type (basic vs full) To update a user's type (basic user versus full user): Go to: account dropdown > Account settings > Users and roles > Users. Either select a user and edit their type or bulk update the type for multiple useres. When basic users attempt to upgrade to full users, an upgrade request is sent to all admins. For more about our user types, see User type. Determine full user count If you're on New Relic One pricing plan, your count of full users is a factor in your billing. To see your count of full users, click the account dropdown and then click View your usage. If you have a master/sub-account structure (including a customer partnership), your count of full users may not match what you see when you go to Account settings > Users and roles. To examine users on a master account's sub-accounts, go to a master account's Account settings UI page, click on a sub-account, and go to their Users and roles UI page. Enable SAML SSO and/or SCIM For an introduction to using SAML SSO and/or SCIM provisioning, see Get started with SAML SSO or SCIM. View pending SAML SSO users New Relic accounts with SAML Single Sign On (SSO) may have a list of Pending users. These are individuals who have been added to the SAML-enabled account but have not yet confirmed. Update account roles Tip Owner or Admins To update a person's role and capabilities: Go to: account dropdown > Account settings > Users and roles > Users. Select the person's name. Under Roles and capabilities, select their base role as Admin, User, or Restricted. The account Owner must update the Owner role. Delete a user Tip Owner or Admins To remove a user from your New Relic account: Go to: account dropdown > Account settings > Users and roles > Users. Click on the name of the person you would like to update. Click Delete User. Tip You can also add, update, or delete users in bulk via CSV file. Update the account Owner A New Relic account can have only one Owner role at any time. You must be the current account Owner to change your role to someone who currently has an Admin role for the account. If the current Owner is unavailable, contact your account representative at New Relic, or get support at support.newrelic.com. You cannot delete or remove your assigned Owner role. However, if the account has one or more Admin role, you can change an Owner to an Admin. Go to: account dropdown > Account settings > Account > Users and roles. Above the Active users list, select Change owner. If an account has no Admins, this button won't be available. Select someone who currently has an Admin role for the account. Refresh the page for changes to take effect. Your previous Owner role automatically changes to an Admin role. To find out who is the current assigned Owner: Go to: account dropdown > Account settings > Account > Users and roles. View the Base role column to locate your account Owner. The Change owner button is only visible to the current account Owner. If the current Owner is unable to change the role (for example, that person no longer is with your organization), contact your account representative at New Relic, or get support at support.newrelic.com. User types: basic user and full user Important This section is for users on our original user model. If you're on our New Relic One user model, see our New Relic One user docs. Starting March 2021, we ended the preview period for basic users on our original user model. The preview period gave these basic users the same permissions as full users. For more on this, see our Explorers Hub post on user type changes. The user type (basic user or full user) determines what features a user has access to. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. If you're on our original pricing plan, billing impacts do not apply. Basic user. Details: These users have access to basic features like setting up reporting of data, running queries of data, making custom charts and dashboards, and setting up alerts. They do not have access to Full-Stack Observability features (for more details on feature access, see Capabilities). Basic users can request to become full users in the UI. They cannot self-upgrade. Basic users will see prompts when attempting to access unavailable features. Requests to upgrade are sent to all admins on that account. No matter what custom group a basic user is assigned to, they always have the capabilities of a basic user: no more and no less. Full user. Details: Full users have access to our Full-Stack Observability features, which include our curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, and synthetic monitors. For details on what's available, see Capabilities. For organizations on New Relic One pricing: these users are billable. The Standard edition includes one free full user and up to five total. If a user in your organization is set as a basic user in one account and a full user in another, the user has full user access for all accounts. For how to edit user type, see Manage users. Account roles A New Relic account can have only one Owner. To share an account with other users in your organization, create Admins, Users, or Restricted Users. Account role Description Owner The person who initially creates the New Relic account and receives all billing queries. The Owner has complete access to all of the account information. Admin Can add, edit, and delete users, and can enable or set up features. User Can use (and optionally set up) New Relic features. In general, Admins take responsibility for setting up features, and Users and Restricted Users can use them. Restricted User One or more individuals who can view (but not set up or change) any New Relic features. The Restricted User role is useful, for example, for demos. You can change your New Relic session settings so that Restricted User logins do not time out, and then set the user interface to Kiosk mode. Add-on roles With add-on roles, you can grant variable levels of access to all users in your account, across the entire platform of New Relic products. This allows you to tailor your account permissions levels to suit the needs of Users and Restricted Users within your account. Giving a User or Restricted User add-on manager access to a product grants them the equivalent of Admin capabilities within the product. They will continue to have User or Restricted User capabilities for all other New Relic products. For example, you could make a software engineer in your company a User in most products, but assign Admin-level access to APM. For another example, you might assign the Nerdpack manager role to a user, and that gives them the ability to subscribe and unsubscribe New Relic One applications to an account. There are two types of add-on roles: Add-on Manager roles are available to grant permissions on a per-product basis. Giving a User or Restricted User managed add-on access to a product grants them the equivalent of Admin capabilities within the product. Custom add-on roles can grant feature-specific permissions across different New Relic products. For example, a group of Users could have the ability to acknowledge incidents and close violations in New Relic Alerts, but not have the ability to modify your existing alert preferences. Individuals on a master account that has sub-accounts automatically have the same level of access for all sub-accounts. Below are options for managing both managed add-on roles and custom add-on roles: View roles To view the list of individuals assigned to your account and their current roles: Go to account dropdown > Account settings > Users and roles. Assign a managed role Tip Owner and Admins Managed add-on roles are available by default for each New Relic product. Adding a managed role for a user grants them Admin-level permissions for the assigned product. They cannot be edited or deleted. To assign a managed add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles. From the list of users associated with your account, select their name. Under Add-on roles, select the type of manager role for the user. To understand which capabilities may be added, use the Capabilities preview chart. Features in the Capabilities preview chart may not exactly match what features are available for your subscription level. Tip You can also add, update, or delete users in bulk by using a CSV file. Create a custom role To create a custom add-on role for your account: Go to account dropdown > Account settings > Users and roles > Roles. Select New custom add-on role. Select the capabilities necessary for the new custom role, then Create role. Assign a custom role Tip Owners and Admins You must create a custom role before assigning it to a user. To assign a custom add-on role for a User or Restricted User in your account: Go to account dropdown > Account settings > Users and roles > Users. From the list of users associated with your account, select their name ]. Under Add-on roles, select a custom role for the user. Click Update user. Edit or delete a custom role Tip Owners and Admins You cannot edit or delete New Relic's default roles. However, you can edit or delete custom add-on roles for your account: Go to account dropdown > Account settings > Users and roles > Roles. From the Add-on roles list, select the custom add-on role, then select Edit role or Delete role as appropriate. Account permissions Here is a summary of basic user rights for your New Relic account. Individuals on a master account with sub-accounts automatically have the same level of access for all sub-accounts. However, they will not receive email notifications for alerts or weekly reports for sub-accounts unless they are explicitly granted permission on these sub-accounts. Function Owner Admin User Restricted Maintain billing information. Change the account Owner. Add, update, and delete account Admins, Users, and Restricted Users. When the account Owner and Admins add individuals to the account, New Relic automatically sends them an email message. Update users' job titles and roles from Account settings in the New Relic UI. Create, modify and delete sub-accounts from Account settings in the New Relic UI. Update your own account information (name, password change or password reset request, default account, email preferences, etc.) from User preferences in the New Relic UI. Change someone else's password. You cannot reset passwords for anyone else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) > Account settings > Account > Summary in the New Relic UI. Manage flexible data retention. Subscribe and unsubscribe applications to New Relic One Alert permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Alerts. To allow a User or Restricted User to execute any of these functions in New Relic Alerts, assign an Alerts add-on manager role. Admin and manager capabilities for Alerts include: Create or name alert policies. Specify incident preferences. Disable or define alert conditions. Provide runbook instructions. Select product targets. Alter alert condition thresholds. Create, modify, or delete notification channels. APM permissions Here is a summary of Admin and Add-on manager capabilities with New Relic APM. To allow a User or Restricted User to execute any of these functions in New Relic APM, assign an APM add-on manager role. Admin and manager capabilities for APM include: Remove applications from the New Relic UI. Delete app traces and error traces. Browser permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Browser. To allow a User or Restricted User to execute any of these functions in New Relic Browser, assign a Browser add-on manager role. Admin and manager capabilities for Browser include: Add, rename, or delete applications. Manage whitelists. Manage domain conditions. Infrastructure permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Infrastructure. To allow a User or Restricted User to execute any of these functions in New Relic Infrastructure, assign an Infrastructure manager role. Admin and manager capabilities for Infrastructure include: Create alert conditions in New Relic Infrastructure, including conditions for host not reporting. Add or modify integrations. Insights permissions Here is a summary of Admin and Add-on manager capabilities with New Relic Insights. To allow a User or Restricted User to execute any of these functions in New Relic Insights, assign an Insights manager role. These functions include: Create, view, modify, or delete Query API keys or Insert API keys. Tip New Relic Insights includes permission levels to share your Insights dashboards with others. Mobile permissions To give permission to delete a mobile app from New Relic, you can assign an Admin or Mobile manager role. Synthetics permissions Here's a summary of Admin and Add-on manager capabilities with New Relic Synthetics. To allow a User or Restricted User to execute any of these functions in New Relic Synthetics, assign a Synthetics add-on manager role. Admin and manager capabilities for Synthetics include: Create, edit, or delete monitors. Edit monitor scripts. Create, edit, or delete private locations. Create, edit, or delete monitor downtimes. Create, view, edit, or delete secure credentials. For more information, see User roles in Synthetics. Workloads permissions Here's a summary of Admin and Add-on manager capabilities with New Relic One workloads: Create, duplicate, modify, or delete workloads. Link dashboards to workloads and save filters. To allow a User or Restricted User to execute these functions, assign the workloads manager add-on role.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.26654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View and <em>manage</em> users in UI",
        "body": " else on the account, even if you are an Owner or Admin. Instead, follow standard procedures to request a password reset from New Relic. View the list of individuals on the account from (account dropdown) &gt; Account settings &gt; Account &gt; Summary in the New Relic UI. <em>Manage</em> flexible <em>data</em> <em>retention</em>"
      },
      "id": "603e88b2e7b9d2a3f12a07d5"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-your-data": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.42914,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.35712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a <em>data</em> dropping rule to remove attributes at <em>ingest</em> time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries"
      },
      "id": "603ea57b64441f44f34e887d"
    },
    {
      "sections": [
        "Metric API limits and restricted attributes",
        "Maximum limits",
        "Additional account conditions",
        "Rate limit violations",
        "Max data points per minute (DPM)",
        "Max unique timeseries per account per day",
        "Max unique timeseries per metric name per day",
        "Max payloads per minute",
        "Restricted attributes"
      ],
      "title": "Metric API limits and restricted attributes",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "1ea3583a3283c2edbbc3aacd021b9fb9f821948f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api-limits-restricted-attributes/",
      "published_at": "2021-06-26T13:10:44Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes data requirements for the Metric API, including: Maximum limits Restricted attributes Maximum limits The following default limits apply for all Metric data: Condition Limit Age range for timestamp values Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. Max data points per minute (DPM) See Additional account conditions. 1 million DPM Max unique timeseries (cardinality) per account per day See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Max unique timeseries (cardinality) per metric name per day 100k Max payloads per minute 100k Max attributes per metric 100 Max metric attribute name length 255 characters Max characters for an attribute key 255 characters Max metric attribute value length 4096 characters Allowed HTTP protocols HTTPS only Numerical long values falling outside minimum or maximum Java long values Numerical long values that fall outside of the minimum or maximum Java long value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Numerical double values falling outside minimum or maximum Java double values Numeric double values that fall outside of a the minimum or maximum Java double value will be rejected. If the number is in the common block, then the entire block will be dropped. If the number is in a metric data point, then the metric data point it resides in will be dropped. Payload size Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. Payload format The payload must encoded as UTF-8. Attribute naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). The following default limits apply only to data collected via the Prometheus Remote Write integration: Condition Limit Max unique Count and Summary timeseries (cardinality) per account per 5 minute interval See Additional account conditions. 1 million A timeseries is a single, unique combination of a metric name and any attributes. Timeseries received above this limit are dropped. This limit is enforced prior to and in addition to standard Metric limits. Additional account conditions Metric API limits apply at the individual account level. Trial and paid accounts receive a 1M DPM and 1M cardinality limit for trial purposes, but you can request up to 15M DPM and 15M cardinality for your account. To request changes to your metric rate limits, contact your New Relic account representative, or visit our Support portal. Rate limit violations This section describes how the Metric API behaves when you exceed the rate limits, and how to respond if limits are exceeded. Max data points per minute (DPM) Data points per minute refers to the per minute rate at which individual metric values are sent to the Metric API. When the maximum DPM limit is exceeded for an account, the New Relic Metric API returns a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Max unique timeseries per account per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-account, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max unique timeseries per metric name per day A timeseries is a single, unique combination of a metric name and any attributes assigned to that metric. For example, if a CPU utilization metric with a single attribute hostname is sent from ten different hosts, this equals ten distinct values for the hostname attribute and ten unique metric timeseries. If the per-metric name, per-day unique metric timeseries (cardinality) limit is exceeded during a 24 hour period, the endpoint will continue to receive and store raw metric data. However, New Relic will stop creating additional aggregate rollups (1 minute, 5 minutes, etc.) for the remainder of the 24 hour period. (These rollups are used used by default to query time windows longer than 60 minutes.) You can continue to query your data when such a violation occurs by specifying a 60 minute or shorter time window or specifying the RAW keyword as described in view and query your metrics. This can be helpful in identifying potential causes for the violation. Max payloads per minute If you make more than 100k POST requests to the Metric API endpoint within a minute, the endpoint will return a 429 response for the remainder of the minute. The response will include a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. In general, if you reach this limit, consider creating larger payloads. To do this, combine more data points into each request to reduce the number of POSTs that are necessary. If this is not an option, you can request a rate limit increase by contacting your New Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic platform. Any values submitted with these keys in the attributes section of a metric data point will cause the data point to be dropped, or the value to be omitted or overwritten: Attribute Description newrelic.source This resets to the value metricAPI. metricName This resets to the name value passed into each data point. This allows name to be an attribute key. endTimestamp timestamp and interval.ms will be converted to an endTimestamp for the data point. These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Attribute Description entity.guid Unique identifier assigned to an entity by New Relic. entity.name Human-readable name of an entity, often used to identify an entity in the UI. entity.type Used to differentiate between different types of entities, like hosts, applications, etc. Additional restrictions include: Restriction Comments Metric and attribute names You cannot pass the same value for metric name and attribute name. In the following example, the metric is invalid because the metric is named service.errors.all and there is an attribute service.errors.all. Example: Metric value used as an attribute (invalid) [ { \"metrics\": [ { \"name\": \"service.errors.all\" , \"type\": \"count\", \"value\": 15, \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"service.errors.all\" : \"test\", \"service.name\": \"foo\" } } ] } ] Copy Reserved words The Metric API inherits some reserved words from New Relic Insights, including accountID, appId, and eventType. Additionally, the syntax terms for NRQL are restricted unless you backtick (``) them. For a full list, see Reserved words: NRQL syntax terms. Keys within metric JSON All keys used within the metric JSON cannot be attribute keys. This includes interval.ms, timestamp, value, common, min, max, count, sum, and metrics. Exception: You can use name as an attribute key.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.35712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric API limits <em>and</em> restricted attributes",
        "sections": "Max <em>data</em> points per minute (DPM)",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " Relic account representative or visiting our Support portal. Restricted attributes These attributes are restricted by the New Relic <em>platform</em>. Any values submitted with these keys in the attributes section of a metric <em>data</em> point will cause the <em>data</em> point to be dropped, or the value to be omitted"
      },
      "id": "603ea95128ccbca08eeba7a6"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/query-limits": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.66797,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " on usage <em>data</em> describes how to set alerts to get notified if you&#x27;re nearing <em>data</em> <em>ingest</em> <em>limits</em> you don&#x27;t want to cross. For example, you might set an alert on logs, which can stack up quickly in an active <em>system</em>. Adjust your <em>data</em> <em>ingest</em> Drop <em>data</em> for lower retention costs and <em>data</em> compliance"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.66779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " family! Sign up to create your free account in only a few seconds. Then <em>ingest</em> up to 100GB of <em>data</em> for free each month. Forever. <em>Manage</em> all your <em>data</em> We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits",
        "For more information"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-06-25T19:54:40Z",
      "updated_at": "2021-05-15T10:05:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per sub-account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of records inspected (see query limits). When this limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which have these limit-related attributes: Attribute Description category 'RateLimit' or 'ApiLimit'. The 'RateLimit' category is used for limits based on a unit of time such as the number of requests ingested per minute. The 'ApiLimit' is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions. For more information See Troubleshoot Metric API with NRIntegrationError events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.82051,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>system</em> <em>limits</em>",
        "sections": "View <em>system</em> <em>limits</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", or how close you are to reaching a <em>limit</em>. For more on creating queries and alerts for <em>data</em> <em>ingest</em> and billing <em>metrics</em>, see Query billing&#x2F;usage <em>data</em>. one.newrelic.com &gt; account dropdown &gt; <em>Manage</em> your <em>data</em> &gt; <em>Limits</em>: An example of a chart on the <em>Limits</em> UI page displaying a cardinality violation <em>limit</em>"
      },
      "id": "60446a7c64441f48d7378f2b"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/view-system-limits": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.42865,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "7e0acfa00ae2dd25e23e41dbbf9d38c56ac485ae",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-06-25T16:19:47Z",
      "updated_at": "2021-06-09T02:27:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details To view details about the errors, run this NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When a NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCONT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.35709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Match errors to <em>ingested</em> payloads",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a <em>data</em> dropping rule to remove attributes at <em>ingest</em> time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries"
      },
      "id": "603ea57b64441f44f34e887d"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights": [
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "b6122126a390d40ee68c246abdb66fc2c0211a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-06-26T08:23:17Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    },
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-06-26T08:20:36Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.88148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring custom <em>events</em> and attributes",
        "sections": "Report browser monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " browser. After the 120-<em>event</em> limit is reached, additional <em>events</em> are not captured for that cycle. <em>Event</em>&#x2F;attribute naming, <em>data</em> type, size Ensure you follow general requirements around <em>event</em>&#x2F;attribute naming syntax, <em>data</em> types, and size. Create PageAction <em>events</em> To create a PageAction <em>event</em>: Ensure"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products": [
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "af971d2b95ff397b57bf125f6801f57007ea5e77",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-06-26T08:20:35Z",
      "updated_at": "2021-05-15T09:10:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "b6122126a390d40ee68c246abdb66fc2c0211a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-06-26T08:23:17Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.88148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring custom <em>events</em> and attributes",
        "sections": "Report browser monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " browser. After the 120-<em>event</em> limit is reached, additional <em>events</em> are not captured for that cycle. <em>Event</em>&#x2F;attribute naming, <em>data</em> type, size Ensure you follow general requirements around <em>event</em>&#x2F;attribute naming syntax, <em>data</em> types, and size. Create PageAction <em>events</em> To create a PageAction <em>event</em>: Ensure"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-apm": [
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-06-26T08:20:36Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 347.9718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "sections": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "tags": "Default <em>events</em>",
        "body": "New Relic products <em>report</em> different types of data. One type of data <em>reported</em> is <em>event</em> data. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the <em>events</em> <em>reported</em> by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Manage error data",
        "Error data types: events and trace details",
        "Events",
        "Trace details",
        "Caps on error reporting",
        "Charting error rates and counts",
        "Report custom errors",
        "Ignore errors",
        "Reduce noise with expected errors",
        "Disable error traces",
        "Delete error traces",
        "Caution"
      ],
      "title": "Manage error data",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Error analytics"
      ],
      "external_id": "29a2ebdc7b91029a1fada50791b90e9dc548f17e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/apm-ui-pages/error-analytics/manage-error-data/",
      "published_at": "2021-06-25T18:20:44Z",
      "updated_at": "2021-03-13T03:03:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM Errors page helps you identify, triage, and fix errors in your services. The Errors page uses data collected by the APM agent to display stack traces, transaction attributes such as HTTP header values, and any other custom attributes, so you can understand the context of the error and fix it. Error data types: events and trace details By default, our APM agents collect two type of error data: Events Trace details Events The error event data type includes default attributes, as well as any custom attributes instrumented in your service. It doesn't include a stack trace. Find your events data in the Errors UI as follows: The Errors column in the Error traces table. The Top 5 errors chart. When you’ve drilled into a grouping of errors, those errors not displaying a stack trace are based on this type of data. You can disable Show only errors with stack trace to show errors that have this type of data collected, but no associated trace details. Events are subject to sampling (see Caps on error reporting and Charting error rates and counts). For more on error event data, see Events reported by APM. Trace details The trace details error data type includes stack traces and attributes, and supplements events with more data. It's expected that more events will be reported than trace details--see Caps on error reporting. Find your trace details data in the Errors UI as follows: The “Stack traces” column of the Error traces table. When you’ve drilled into a grouping of errors, those errors with a stack trace use this type of data: Show only errors with stack trace is enabled by default, to constrain the errors shown to just those that have this type of data collected. This data is governed by specific retention rules for Error details. Caps on error reporting New Relic caps error reporting at: 100 events per minute per agent instance 20 trace details per minute per agent instance These caps prevent error reporting from negatively impacting application performance. Examples: App running across five EC2 instances, one JVM each. New Relic caps error reporting at: 100 events per minute x 5 instances = 500 events per minute 20 trace details per minute x 5 instances = 100 trace details per minute App running on one host with ten instances. New Relic caps error reporting at: 100 events per minute x 10 instances = 1000 events per minute 20 trace details per minute x 10 instances = 200 events per minute Charting error rates and counts The Error rate chart is driven by a query on metric timeslice data, which is an unsampled aggregate data type that is accurate but has very limited dimensionality. This data can't be faceted or filtered as flexibly as error event data. You can reproduce this chart in a dashboard, or explore the metric timeslice data further by clicking the ... menu on the Error rate chart, and then using the View query or Add to dashboard options. To chart faceted error counts using event data, as in the Top 5 errors chart, use an NRQL event query. Click the ... menu on the Top 5 errors chart and choose View query for a starting point in creating your chart. Since event data can be sampled (see Caps on error reporting), you can use the EXTRAPOLATE keyword to get an accurate error count, even if sampling is occurring. Report custom errors You can report errors not collected by default with our agents using our agent APIs. For more, see the documentation on the API. Ignore errors You can prevent certain errors that would normally be reported to New Relic from being collected using our agent APIs or the server-side configuration UI. For more details, see Manage errors in APM. Reduce noise with expected errors Sometimes you want to collect error data, but not have those errors wake you up through alerts. Using the agent API, you can mark such errors as “expected”. They’ll still be visible in the Errors page, but won’t affect your service’s error rate or Apdex metrics. Disable error traces To prevent certain errors from being reported to New Relic, disable them in your agent's configuration file. For most agents, you can ignore certain error codes or disable errors completely. For more information, see your specific agent's configuration documentation: C SDK Go (not applicable; the agent only reports errors when configured to do so) Java .NET Node.js PHP Python Ruby Delete error traces Caution You cannot recover error traces after you delete them. Deleting errors is currently only available in the legacy Errors Classic UI. If you want to... Do this... Delete all error traces for your app If you have permissions to delete all error traces for an app: Go to one.newrelic.com > APM > (select an app) > More views > Errors (classic). Select Delete all errors. Delete all error traces for your account To delete all error traces for your New Relic account, get support at support.newrelic.com. Delete individual error traces To delete individual error traces, use New Relic APM's Errors (classic) page. Drill into an error from the table of errors, then click Delete this error. In addition to deleting error traces, you may also want to delete transaction traces or database/slow SQL traces. This will remove potentially sensitive data while retaining your other application data (such as Apdex, deployment information, etc.).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.6415,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Error data types: <em>events</em> and trace details",
        "tags": "<em>APM</em>",
        "body": " that have this type of data collected, but no associated trace details. <em>Events</em> are subject to sampling (see Caps on error reporting and Charting error rates and counts). For more on error <em>event</em> data, see <em>Events</em> <em>reported</em> by <em>APM</em>. Trace details The trace details error data type includes stack traces"
      },
      "id": "6044077e28ccbcab752c60d1"
    },
    {
      "sections": [
        "Event limits and sampling for APM and mobile monitoring",
        "Difference between events and metrics",
        "Why sampling of events is necessary",
        "The impact of sampling",
        "Important",
        "Change how sampling occurs",
        "APM: Compensate for sampling"
      ],
      "title": "Event limits and sampling for APM and mobile monitoring",
      "type": "docs",
      "tags": [
        "APM",
        "New Relic APM",
        "Troubleshooting"
      ],
      "external_id": "27b04d675cbdea50185303ed1c6c9290990488d6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling/",
      "published_at": "2021-06-26T08:36:48Z",
      "updated_at": "2021-03-16T15:50:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our APM agents and mobile agents have limits on the number of events that can be reported. This document explains: Why event-reporting limits are necessary How sampling works How to work with and understand sampled data Difference between events and metrics This document is about limits on event data and how those limits lead to sampling. First, it may help you to understand the differences between these two types of data: Metrics: aggregated measurements over time. Examples: average response time over a one-minute time range, throughput over time, CPU utilization over time. Events: discrete events that happen at a specific moment in time. Examples: a log or error being reported, or a configuration change. Some events are aggregated over time to form metrics (for example: a count of errors over time). These two types of data have different uses: metrics are useful for recognizing patterns over time in your system, and events are useful for drilling down and getting detail about the causes of those patterns. Because metrics are aggregated over time, they’re useful for spotting trends and changes in system behavior. For metrics that represent an aggregated count of events (like an HTTP response time metric), the individual events give you granular detail about what happened, and let you facet by attributes that have high cardinality (like account or user ID). Why sampling of events is necessary Our APM agents and mobile agents have limits on how many events can be reported per harvest cycle. This is necessary because if there were no limit, a very large number of events being sent could have performance impacts on your application or on New Relic. When the limit is reached, the agents begin sampling events. Different agents have different limits, but the goal is to give a representative sample from across the harvest cycle. Also, agents may sample if they can't connect to New Relic. When an agent can’t connect to New Relic, it continues to store data locally. But it must restrict the size of the payload that is eventually sent. For this reason, it samples events during the disconnected period. The longer it is disconnected, the more it will sample. The impact of sampling One result of sampling is that there can be a discrepancy between unsampled metric data and sampled event data. Examples of this: An APM chart showing unsampled metric data may show you higher throughput than an equivalent NRQL query of sampled event data. For more about the difference between our metric timeslice data and event data, see Data types. A non-New Relic monitoring service may show different results from New Relic. Events that are capped and subject to sampling include: Transaction TransactionError Span (see Distributed tracing sampling) Custom events reported via agent API (example: the .NET agent's RecordCustomEvent) Mobile MobileRequest MobileCrash MobileHandledException Important For APM, you can compensate for sampling when querying data. Change how sampling occurs Before attempting to change how sampling occurs, please read these caveats and recommendations: Reporting more events will result in the agent using more memory. There will usually be a way for you to get the data you need without raising an agent's event-reporting limit. The payload size limit is 1MB (10^6 bytes) (compressed), so the number of events may still be affected by that limit. To determine if events are being dropped, see the agent log for a 413 HTTP status message. Here are some ways to impact sampling: Most agents have configuration options for changing the limit on sampled transactions (examples: Java agent’s max_samples_stored or the Android mobile agent’s setMaxEventPoolSize). If it’s important to you that a specific app activity not be sampled, you can use the Event API. You could deploy your application across a greater number of instances. Because the limits are per-agent, more agents will mean a larger event reservoir. APM: Compensate for sampling When querying APM-reported events, you can compensate for sampling by using EXTRAPOLATE. This will give you an approximation of what unsampled data looks like.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 117.42576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Event</em> limits and sampling for <em>APM</em> and mobile monitoring",
        "sections": "<em>Event</em> limits and sampling for <em>APM</em> and mobile monitoring",
        "tags": "<em>APM</em>",
        "body": "Our <em>APM</em> agents and mobile agents have limits on the number of <em>events</em> that can be <em>reported</em>. This document explains: Why <em>event</em>-reporting limits are necessary How sampling works How to work with and understand sampled data Difference between <em>events</em> and metrics This document is about limits on <em>event</em>"
      },
      "id": "603eb32564441f35734e886f"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-browser-monitoring": [
    {
      "sections": [
        "Not seeing specific page or endpoint names in Browser data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing specific page or endpoint names in Browser data",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Troubleshooting"
      ],
      "external_id": "e91e38e0160cd95da45e928f462c70fde1457031",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/troubleshooting/not-seeing-specific-page-or-endpoint-names-browser-data/",
      "published_at": "2021-06-25T17:37:36Z",
      "updated_at": "2021-06-14T22:19:10Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You're looking for performance breakdowns for specific pages or endpoints on the browser monitoring Page views UI page or AJAX UI page. The UI doesn't show the URL group you're looking for, or it only shows / and /*. This behavior also appears in SPA data in BrowserInteraction events and applies to browserInteractionName, targetGroupedUrl, and previousGroupedUrl attributes. Solution Browser monitoring automatically \"learns\" to group your page views when your application is first deployed, and it adds that information to an allow list for URLs. Sometimes this grouping may not match your current page view information. To solve this problem, manage your application's URL segment list settings by editing existing rules or by adding the domains and URL segments that make up your site's URLs. After you add the necessary rules, you should see a useful breakdown of your information in the UI. Here are some useful tips: Adding segments to your allow list Tip Use constant URL segments. Only add the URL segments that remain constant across many page views. Do not add unique segments such as IDs or highly-specific categories, because this can lead to metric grouping issues. Enter exact matches. Enter any URL segments as exact matches, including case. Use existing rules. If a rule already appears for a domain: Go to one.newrelic.com > Browser > (select an app) > Settings > Segment allow lists. Rather than creating a new rule, edit the existing rule, and add the domain to the UI's Allow listed segments field. Group sub-domains. Group similar sub-domains such as foo.domain.com and bar.domain.com under *.domain.com. This grouping must occur just before the top-level domain name. Set up single-page apps. If your site is a single-page application and you only see / under page views, then your grouping is working correctly. New Relic records subsequent requests as AJAX loads, and your AJAX page will contain more detailed information. If it doesn't, then follow the tips in this document. Remove rules when appropriate. If you need to remove a rule, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.28812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing specific page or endpoint names in <em>Browser</em> data",
        "sections": "Not seeing specific page or endpoint names in <em>Browser</em> data",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "Problem You&#x27;re looking for performance breakdowns for specific pages or endpoints on the <em>browser</em> <em>monitoring</em> Page views UI page or AJAX UI page. The UI doesn&#x27;t show the URL group you&#x27;re looking for, or it only shows &#x2F; and &#x2F;*. This behavior also appears in SPA data in <em>Browser</em>Interaction <em>events</em>"
      },
      "id": "603e8fff28ccbc8813eba7a1"
    },
    {
      "sections": [
        "Install the browser monitoring agent",
        "Tip",
        "Select a deployment option",
        "Important",
        "Enable an APM-monitored app",
        "Enable with copy/paste",
        "Instrument webpages using the APM agent",
        "Troubleshoot Browser agent installation"
      ],
      "title": "Install the browser monitoring agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Installation"
      ],
      "external_id": "bc45bbc86cd4d8b81367ad0904907ddc735717f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/browser-monitoring/installation/install-browser-monitoring-agent/",
      "published_at": "2021-06-25T17:43:53Z",
      "updated_at": "2021-06-14T21:26:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser uses a JavaScript snippet (or \"agent\") to instrument your app's webpages. The JavaScript collects data for browser monitoring. To install the browser agent, you can choose from a number of deployment options. Tip To use Browser and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Select a deployment option No matter which option you use to deploy browser monitoring, the end result is to inject the browser agent's JavaScript snippet into your pages for browser monitoring. The method you select depends on your preferences and business needs. To view the procedure to install and enable the browser agent, click the link for the option you want to use. You can also use the Browser Application settings page to update settings. Important The following configuration options refer only to the browser monitoring agent. These are not the same as the New Relic user roles and editions. Browser deployment option Description Use the APM agent to inject the JavaScript You can use an APM agent to automatically inject the browser monitoring JavaScript snippet for you. This is the easiest way to install the agent for an app that already is being monitored by APM. (APM-monitored apps are listed on your APM Applications index.) Paste the JavaScript snippet into a webpage This allows you to control the exact placement of the JavaScript into your app's webpage(s) by copying and pasting the browser agent's JavaScript snippet. This is useful for: Standalone apps, static sites, and cached pages delivered by CDN APM apps that are not as closely coupled to the browser app as with a standard server-side app (for example, when your client-side app talks to a REST API back end) Enable single-page app (SPA) monitoring Enabling SPA requires a Pro + SPA browser agent subscription, and you may need to re-deploy the browser JavaScript agent. Use the REST API The REST API lets you manage deployment outside the browser UI. This is useful for large organizations deploying multiple apps. Use an APM agent API to manually instrument the JavaScript snippet For apps that are monitored by APM, you can use the APM agent's API to inject the JavaScript manually instead of automatically. Enable an APM-monitored app Use this procedure to automatically deploy the browser agent on an app that is monitored by APM: Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Enable via New Relic APM. In the Choose your instrumentation section, select Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Select your application section, type or use the search window to find an app's name. Click Enable. Important Node.js: To finish enabling the browser agent for a Node.js app, follow the additional procedure to insert the JavaScript header into the beginning of your HTML page's head tag. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. Enable with copy/paste Use this procedure to insert browser's JavaScript snippet for browser monitoring into your app's webpages yourself. This option is useful for monitoring static sites (such as Jekyll) or cached pages delivered by CDN. Tip Near the bottom of the generated JavaScript is your browser license key and application ID. This is useful with the REST API and API Explorer. Go to one.newrelic.com, select Browser, and then select Add more data. In the Back-end, front-end, and mobile applications section, select the New Relic Browser tile. When prompted to select the account you want to add this instrumentation to, choose your account, and click Continue. From the Get started with New Relic Browser page, in the Choose a deployment method section, select Copy/Paste JavaScript Code. In the Choose your instrumentation section, select the type of agent: Lite, Pro, or Pro + SPA. In the Configure your instrumentation section, make the selections you want. In the Name your app section, name your app: If your app is monitored by APM, select Yes, then type or use the search window to find the app's name. If you have a standalone app for Browser (not monitored by APM), select No, then type the app's name. Click Enable. A new section, Instrument the agent, opens on the page with JavaScript code for your project. Copy the code snippet, then paste it inline into your pages as close to the top of the <head> element as possible, but after any position-sensitive <meta> tags (for example, X-UA-Compatible or charset information). For more information on the inline head placement, see JavaScript placement requirements. Generate some traffic for your app. Wait a few minutes for Browser to start collecting data, then select your app from the Browser applications index. If you use the copy/paste method, but don't finish the setup process, you can still view and copy the generated JavaScript snippet from your app's Browser Application settings page or by using the REST API (v2). Instrument webpages using the APM agent This information applies to apps that are also monitored by APM. New Relic's agents can instrument webpages with the required JavaScript for page load timing. If you use the APM agent to add the JavaScript snippet to your webpages, insert the instrumentation snippet as close to the top as possible. This allows you to take advantage of detailed information about browser's AJAX calls and JavaScript errors. For more information, see the instructions for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby Troubleshoot Browser agent installation When you enable browser Pro features for session traces, AJAX calls, or JavaScript errors, it may take approximately five minutes before information becomes available. If you have problems with your browser installation or if no data appears after five minutes, refer to the troubleshooting tips, and restart your agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.236176,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>browser</em> <em>monitoring</em> agent",
        "sections": "Install the <em>browser</em> <em>monitoring</em> agent",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "<em>Browser</em> uses a JavaScript snippet (or &quot;agent&quot;) to instrument your app&#x27;s webpages. The JavaScript collects data for <em>browser</em> <em>monitoring</em>. To install the <em>browser</em> agent, you can choose from a number of deployment options. Tip To use <em>Browser</em> and the rest of our observability platform, join the New Relic"
      },
      "id": "604429e628ccbcb80b2c60d0"
    },
    {
      "sections": [
        "addPageAction (Browser agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples",
        "Record link clicks (JavaScript)",
        "Record link clicks (jQuery)",
        "Capture form input"
      ],
      "title": "addPageAction (Browser agent API)",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Browser agent and SPA API"
      ],
      "external_id": "051774181e5be11026841b52aeb04a693ffad434",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/browser-agent-spa-api/add-page-action/",
      "published_at": "2021-06-26T11:57:57Z",
      "updated_at": "2021-06-14T23:24:03Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.addPageAction(string $name[, JSON object $attributes]) Copy Reports a Browser PageAction event to New Relic One along with a name and optional attributes. Requirements Agent version nr-593 or higher. Description This API call sends a Browser PageAction event with your user-defined name and optional attributes to dashboards, along with several default attributes. This is useful to track any event that is not already tracked automatically by the Browser agent, such as clicking a Subscribe button or accessing a tutorial. PageAction events are sent to New Relic One every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that harvest cycle. Parameters Parameter Description $name string Required. Name or category of the action. Reports to New Relic One as the actionName attribute. Avoid using reserved NRQL words when you name the attribute or value. $attributes JSON object Optional. JSON object with one or more key/value pairs. For example: {key:\"value\"}. The key will report to New Relic One as its own PageAction attribute with the specified values. Avoid using reserved NRQL words when you name the attribute/value. Examples Record link clicks (JavaScript) This example records a PageAction event whenever a user selects the Try Me link. The event is recorded with an actionName of clickedTryMe: < a href=\"/demo\" id=\"try-me\" >Try Me!< /a> <script> document.getElementById('try-me').addEventListener('click',function (e) { newrelic.addPageAction('clickedTryMe'); }) </script> Copy You can then query the number of times the Try Me button was clicked with the following NRQL query: SELECT count(*) FROM PageAction WHERE actionName='clickedTryMe' SINCE 1 hour ago Copy Record link clicks (jQuery) This example sends a PageAction event when a user clicks on an element with the class copy-text. The actionName is copy-text-button and the value is reported as another attribute called Result that corresponds to methods named success and error that handle the outcome. $('.copy-text').click(function (){ var clipboard = new Clipboard ('.copy-text'); clipboard.on('success', function(event) { // Do stuff // Report data to New Relic One if (typeof newrelic == 'object') { newrelic.addPageAction('copy-text-button', {result: 'success'}); } }); clipboard.on('error', function(event) { // Do stuff // Report data to New Relic One if (typeof newrelic == 'object') { newrelic.addPageAction('copy-text-button', {result: 'error'}); } }); }); Copy Then in the query builder, you can create a pie chart to see the breakdown of how many button clicks resulted in success versus error over the past 30 days: SELECT count(*) AS 'Clicks' FROM PageAction WHERE actionName = 'copy-text-button' FACET result SINCE 30 days ago Copy Or you can create a query to see what pages have the most copy button clicks in the last 30 days: SELECT count(*) AS 'Clicks' FROM PageAction WHERE actionName = 'copy-text-button' FACET currentUrl SINCE 30 days ago Copy Capture form input This example captures user input (email addresses) from a form called Signup. The event is recorded with an actionName of userSignup: <form action=\"/signup\" id=\"myform\"> <input id=\"email\" name=\"email\"> <input type=\"submit\" value=\"Signup\"> </form> <script type=\"text/javascript\"> document.getElementById('myform').addEventListener('submit', function (e) { var email = e.target.elements['email'].value; newrelic.addPageAction('userSignup', {email: email}); }) </script> Copy You can then see the emails that you gathered with the following NRQL query: SELECT uniques(email) FROM PageAction WHERE actionName='userSignup' SINCE 1 hour ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 97.28911,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "addPageAction (<em>Browser</em> agent API)",
        "sections": "addPageAction (<em>Browser</em> agent API)",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": " name and optional attributes to dashboards, along with several default attributes. This is useful to track any <em>event</em> that is not already tracked automatically by the <em>Browser</em> agent, such as clicking a Subscribe button or accessing a tutorial. PageAction <em>events</em> are sent to New Relic One every 30"
      },
      "id": "60440d4628ccbc14742c60cb"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-mobile-monitoring": [
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-06-26T14:38:25Z",
      "updated_at": "2021-06-26T14:38:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in Mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The Mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the Mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.22464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors page helps you to better understand HTTP errors and network failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/attribute-dictionary/",
      "sections": [
        "New Relic data dictionary",
        "AjaxRequest",
        "AwsLambdaInvocation",
        "AwsLambdaInvocationError",
        "BrowserInteraction",
        "BrowserTiming",
        "ContainerSample",
        "DistributedTraceSummary",
        "InfrastructureEvent",
        "JavaScriptError",
        "Metric",
        "Mobile",
        "MobileCrash",
        "MobileHandledException",
        "MobileRequest",
        "MobileRequestError",
        "MobileSession",
        "NetworkSample",
        "NrAuditEvent",
        "NrConsumption",
        "NrDailyUsage",
        "NrIntegrationError",
        "NrMTDConsumption",
        "NrUsage",
        "PageAction",
        "PageView",
        "PageViewTiming",
        "ProcessSample",
        "Span",
        "StorageSample",
        "SyntheticCheck",
        "SyntheticRequest",
        "SyntheticsPrivateLocationStatus",
        "SyntheticsPrivateMinion",
        "SystemSample",
        "Transaction",
        "TransactionError",
        "WorkloadStatus"
      ],
      "published_at": "2021-06-30T01:43:19Z",
      "title": "New Relic data dictionary",
      "updated_at": "2021-06-30T01:43:18Z",
      "type": "docs",
      "external_id": "cbca3a897621bcbb31159067d6d4ec27c5178fe4",
      "document_type": "views_page_content",
      "popularity": 1,
      "body": "Displaying 0 of 37 results Clear AjaxRequest Data source : Browser agent An AjaxRequest event is created automatically when an Ajax request occurs during a BrowserInteraction event. The event attributes track geographic and browser info. Attribute name Definition Events appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming groupedPageURL The grouped URL of the view that made the AJAX request. For example: myapp.com/acct/*/dash. AjaxRequest BrowserTiming groupedRequestUrl The grouped URL of the AJAX request. For example: myapp.com/acct/*/ajax. AjaxRequest Span hostname The fully qualified domain name (FQDN) of the request URL. AjaxRequest httpMethod enum The HTTP method of the AJAX request. Example: POST. AjaxRequest httpResponseCode enum The HTTP response code. Example: 200. AjaxRequest jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError port enum The request port. AjaxRequest Span priority Likelihood this event will be saved. AjaxRequest regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming requestBodySize bytes (B) The payload size of the request body, in bytes. AjaxRequest requestUrl The URL of the AJAX request. For example: myapp.com/acct/1/ajax. AjaxRequest responseBodySize bytes (B) The payload size of the response body, in bytes. AjaxRequest session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span timeSinceBrowserInteractionStart seconds (s) The time in seconds between the start of the BrowserInteraction and the start of the request. AjaxRequest BrowserTiming timeToLastCallbackEnd seconds (s) The duration, in seconds, from the start of the request (timestamp) to the end of the last callback. This is not just an additive function; the callback time can overlap with the wait time. AjaxRequest BrowserTiming timeToLoadEventStart seconds (s) The time, in seconds, from the start of the AJAX request to the start of its load event. This value represents the duration of the AJAX request with single page app (SPA) monitoring. For more information, see the Mozilla developer documentation about XMLHttpRequest load events. AjaxRequest timeToSettle seconds (s) The time, in seconds, from the start of the request to when all resulting callbacks (including callbacks of subsequent AJAX requests) are complete. AjaxRequest BrowserTiming timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span userAgentName The browser’s name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browser’s reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browser’s reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming AwsLambdaInvocation Data source : AWS Lambda This event is reported by New Relic monitoring for AWS Lambda. This event captures overall function timing and associated metadata. A single AwsLambdaInvocation event is generated for each invocation. Attribute name Definition Events aws.lambda.arn The Amazon Resource Name (ARN) of the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.coldStart A Boolean indicating if the AWS Lambda invocation is a cold start. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.eventSource.arn The Amazon Resource Name (ARN) of the entity that invoked the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.requestId ID AWS identifier of the invocation. AwsLambdaInvocation AwsLambdaInvocationError databaseCallCount count The number of database calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError databaseDuration seconds (s) The database response time in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError duration seconds (s) The total invocation time for the transaction, in seconds. (Data source: AWS Lambda) AwsLambdaInvocation AwsLambdaInvocationError externalCallCount count The number of external calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError externalDuration seconds (s) The total response time of all external (out-of-process) services, in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError newRelic.ingestPoint Where the data point entered the platform (such as browser.spans, or api.traces). AwsLambdaInvocation AwsLambdaInvocationError Span parent.account ID If a distributed tracing payload is received, this is the account identifier for the transaction's upstream caller. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.app ID If a distributed tracing payload is received, this is the application identifier. APM agents retrieve this value in the connect response under the key primary_application_id. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.transportType When a distributed tracing payload is received, the method of transport for the payload. Example values: Unknown, HTTP, HTTPS, Kafka, JMS, IronMQ, AMQP, Queue, or Other. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.type If a distributed trace payload was received, the parent's data source type. Example values: App, Browser, Mobile. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.accept The types as read from the HTTP Accept request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentLength bytes (B) Incoming request size in bytes as read from the Content-Length HTTP request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentType Incoming request content-type as read from the HTTP request header Content-Type. Example value: application/octet-stream. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.host The name from the HTTP host request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.referer The incoming request referer as read from the Referer request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.userAgent The contents of the User-Agent HTTP header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.method The HTTP request method used. Example values: POST, GET. AwsLambdaInvocation AwsLambdaInvocationError Span Transaction TransactionError response.headers.contentLength bytes (B) The outgoing response size in bytes as read from the Content-Length response header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.headers.contentType For an HTTP response, the data type of the returned response. Example values: text/html, application/json. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.status bytes (B) The response code for an HTTP request AwsLambdaInvocation totalTime seconds (s) The sum of all async components' duration, in seconds. An async component is a method or function where there is no instrumented encapsulating method or function. AwsLambdaInvocation Transaction traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span type The New Relic event type. Example values: Transaction, Span. AwsLambdaInvocation AwsLambdaInvocationError AwsLambdaInvocationError Data source : AWS Lambda This event is reported by New Relic monitoring for AWS Lambda. It's generated when an error occurs during a Lambda function invocation. Attribute name Definition Events aws.lambda.arn The Amazon Resource Name (ARN) of the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.coldStart A Boolean indicating if the AWS Lambda invocation is a cold start. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.eventSource.arn The Amazon Resource Name (ARN) of the entity that invoked the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.requestId ID AWS identifier of the invocation. AwsLambdaInvocation AwsLambdaInvocationError databaseCallCount count The number of database calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError databaseDuration seconds (s) The database response time in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError duration seconds (s) The total invocation time for the transaction, in seconds. (Data source: AWS Lambda) AwsLambdaInvocation AwsLambdaInvocationError error.class The class name or type for the error. This will be server and platform specific. AwsLambdaInvocationError TransactionError error.message The error message for the transaction. This will be server and platform specific. AwsLambdaInvocationError TransactionError externalCallCount count The number of external calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError externalDuration seconds (s) The total response time of all external (out-of-process) services, in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError newRelic.ingestPoint Where the data point entered the platform (such as browser.spans, or api.traces). AwsLambdaInvocation AwsLambdaInvocationError Span parent.account ID If a distributed tracing payload is received, this is the account identifier for the transaction's upstream caller. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.app ID If a distributed tracing payload is received, this is the application identifier. APM agents retrieve this value in the connect response under the key primary_application_id. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.transportType When a distributed tracing payload is received, the method of transport for the payload. Example values: Unknown, HTTP, HTTPS, Kafka, JMS, IronMQ, AMQP, Queue, or Other. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.type If a distributed trace payload was received, the parent's data source type. Example values: App, Browser, Mobile. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.accept The types as read from the HTTP Accept request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentLength bytes (B) Incoming request size in bytes as read from the Content-Length HTTP request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentType Incoming request content-type as read from the HTTP request header Content-Type. Example value: application/octet-stream. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.host The name from the HTTP host request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.referer The incoming request referer as read from the Referer request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.userAgent The contents of the User-Agent HTTP header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.method The HTTP request method used. Example values: POST, GET. AwsLambdaInvocation AwsLambdaInvocationError Span Transaction TransactionError response.headers.contentLength bytes (B) The outgoing response size in bytes as read from the Content-Length response header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.headers.contentType For an HTTP response, the data type of the returned response. Example values: text/html, application/json. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError stackTrace The error stack trace. The format will be different depending on the agent language. AwsLambdaInvocationError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span transactionName Name of the transaction in which the error occurred. Example value: Controller/customers/show. Value may be 'Unknown' if an error occurs outside of a transaction. AwsLambdaInvocationError TransactionError type The New Relic event type. Example values: Transaction, Span. AwsLambdaInvocation AwsLambdaInvocationError BrowserInteraction Data source : Browser agent A BrowserInteraction represents a unit of work in a browser session, triggered by a user interacting with the webpage. It captures information about the session, AJAX calls and custom JavaScript timing that occurred as a result of the interaction. Initial load and route changes are captured as special types of Browser interactions, and are used for SPA monitoring. Attribute name Definition Events actionText The text of the HTML element that was clicked when a browser interaction started. BrowserInteraction ajaxCount count A count of all XHRs included in the timing of a SPA interaction. BrowserInteraction appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming backendTransactionName The name of the backend transaction that served the initial page load. BrowserInteraction browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming category The type of interaction; either initial page load, route change, or custom. BrowserInteraction city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView domain The domain portion of the request URL. BrowserInteraction JavaScriptError PageView PageViewTiming duration seconds (s) The total time elapsed of the interaction event BrowserInteraction eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming firstContentfulPaint firstContentfulPaint is the point when the browser renders the first bit of content from the DOM, which may be text, an image, SVG, or a <canvas> element. Google's User-centric Performance Metrics contains detailed information about its Paint Timing API and firstContentfulPaint. See Compatibility and requirements for New Relic Browser for additional information about firstContentfulPaint browser compatibility. BrowserInteraction PageView firstPaint firstPaint marks the point when the browser renders anything that is visually different from what was on the screen prior to navigation. This includes non-default background paint and the enclosing box of an iframe. Google's User-centric Performance Metrics contains detailed information about its Paint Timing API and firstPaint. See Compatibility and requirements for New Relic Browser for additional information about firstPaint browser compatibility. BrowserInteraction PageView jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming monitorAccountId The Synthetics account from which you are running the monitor. BrowserInteraction JavaScriptError monitorId ID A unique number identifying a particular monitor. BrowserInteraction JavaScriptError SyntheticCheck monitorJobId ID The ID of a single Synthetics monitor run, which began at a specific time and originated from a specific location. BrowserInteraction JavaScriptError parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError previousGroupedUrl The grouped version of the URL in the browser at the start of the interaction. BrowserInteraction previousRouteName The route name of the page at the start of the interaction. This is the last value passed by setCurrentRouteName before the start of the interaction. BrowserInteraction previousURL The ungrouped URL in the browser at the start of the interaction. BrowserInteraction regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span targetGroupedUrl The grouped version of the URL in the browser at the end of the interaction. BrowserInteraction targetRouteName The route name for the page at the end of the interaction. The last value passed by setCurrentRouteName before the end of the interaction. BrowserInteraction targetUrl The ungrouped URL in the browser at the end of the interaction. BrowserInteraction timeToConnectEnd seconds (s) The time, in seconds, from the start of the interaction to the connectEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToConnectStart seconds (s) The time, in seconds, from the start of the interaction to the connectStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomComplete seconds (s) The time, in seconds, from the start of the interaction to the domComplete, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomContentLoadedEventEnd seconds (s) The time, in seconds, from the start of the interaction to the domContentLoadedEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomContentLoadedEventStart seconds (s) The time, in seconds, from the start of the interaction to the domContentLoadedEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomInteractive seconds (s) The time, in seconds, from the start of the interaction to the domInteractive, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomLoading seconds (s) The time, in seconds, from the start of the interaction to the domLoading, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomainLookupEnd seconds (s) The time, in seconds, from the start of the interaction to the domainLookupEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomainLookupStart seconds (s) The time, in seconds, from the start of the interaction to the domainLookupStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToFetchStart seconds (s) The time, in seconds, from the start of the interaction to the fetchStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToLoadEventEnd seconds (s) The time, in seconds, from the start of the interaction to the loadEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToLoadEventStart seconds (s) The time, in seconds, from the start of the interaction to the loadEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information, see our documentation about instrumentation for the Navigation Timing API. BrowserInteraction timeToRedirectEnd seconds (s) The time, in seconds, from the start of the interaction to the redirectEnd, as defined by the Navigation Timing API. This attribute exists only for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToRedirectStart seconds (s) The time, in seconds, from the start of the interaction to the redirectStart, as defined by the Navigation Timing API. This attribute exists only for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToRequestStart seconds (s) The time, in seconds, from the start of the interaction to the requestStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToResponseEnd seconds (s) The time, in seconds, from the start of the interaction to the responseEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToResponseStart seconds (s) The time, in seconds, from the start of the interaction to the responseStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToSecureConnectionStart seconds (s) The time, in seconds, from the start of the interaction to the secureConnectionStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToUnloadEventEnd seconds (s) The time, in seconds, from the start of the interaction to the unloadEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToUnloadEventStart seconds (s) The time, in seconds, from the start of the interaction to the unloadEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span trigger The cause of the route change or page load. The default values are click, submit, popstate, or initial page load. For a custom event created with the API, the default value for trigger will be api. This value can also be set via the API. BrowserInteraction userAgentName The browser’s name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browser’s reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browser’s reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming BrowserTiming Data source : Browser agent BrowserTiming is a custom event that captures SPA timing data for browser interactions started using the custom createTracer SPA API method. BrowserTiming contains many of the same attributes used by other events, especially AjaxRequest. Attribute name Definition Events appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming browserTimingName The name of the event. This is taken from the name argument of createTracer. BrowserTiming city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming groupedPageURL The grouped URL of the view that made the AJAX request. For example: myapp.com/acct/*/dash. AjaxRequest BrowserTiming jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span timeSinceBrowserInteractionStart seconds (s) The time in seconds between the start of the BrowserInteraction and the start of the request. AjaxRequest BrowserTiming timeToLastCallbackEnd seconds (s) The duration, in seconds, from the start of the request (timestamp) to the end of the last callback. This is not just an additive function; the callback time can overlap with the wait time. AjaxRequest BrowserTiming timeToSettle seconds (s) The time, in seconds, from the start of the request to when all resulting callbacks (including callbacks of subsequent AJAX requests) are complete. AjaxRequest BrowserTiming timeToTracedCallbackStart seconds (s) The time in seconds from the start of the custom tracer until the start of the traced callback. This attribute is unique to the BrowserTiming event. BrowserTiming timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span tracedCallbackDuration seconds (s) The duration in seconds of the traced callback. This attribute is unique to the BrowserTiming event. BrowserTiming userAgentName The browser’s name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browser’s reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browser’s reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming ContainerSample Data source : Infrastructure This event is reported by the New Relic Infrastructure agent. It collects data from all the Docker containers on the host (which may or may not be running). It includes the container's ID, name, image, image name, and metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into this event, which is then sent to New Relic. This data appears on the Containers UI page. Attribute name Definition Events StorageDataAvailableBytes bytes (B) Data space available in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataTotalBytes bytes (B) Total Data space in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataUsagePercent percentage (%) Percent of Data space used in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataUsedBytes bytes (B) Data space used by the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataAvailableBytes bytes (B) Metadata space available in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataTotalBytes bytes (B) Total Metadata space in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataUsagePercent percentage (%) Percent of Metadata space used in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataUsedBytes bytes (B) Metadata space used by the Storage Driver. Only Device Mapper driver is supported. ContainerSample commandLine The command line used in the container. ContainerSample containerId ID The unique Docker container ID. ContainerSample cpuKernelPercent percentage (%) CPU time percentage used in kernel space. ContainerSample cpuLimitCores count Number of cores available for the container. ContainerSample cpuPercent percentage (%) CPU usage percentage used. ContainerSample cpuShares count Number of CPU shares assigned to the container. ContainerSample cpuThrottlePeriods count Total number of periods throttled. ContainerSample cpuThrottleTimeMs milliseconds (ms) Total throttling time in milliseconds. ContainerSample cpuUsedCores percentage (%) CPU usage per core. ContainerSample cpuUsedCoresPercent percentage (%) CPU usage percentage per core. ContainerSample cpuUserPercent percentage (%) CPU time percentage used in user space. ContainerSample criticalViolationCount count The number of times that alert conditions violated critical thresholds, causing critical violations and opening incidents. If this attribute does not exist on the sample, it has zero violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample image ID The Docker image ID for the image the container is based on. ContainerSample imageName The Docker image name for the container. ContainerSample label_KEY Docker labels associated with this container (where KEY represents a custom label's key value). ContainerSample memoryCacheBytes count The amount of memory used by the container that can be associated precisely with a block on a block device. ContainerSample memoryKernelUsageBytes bytes (B) The amount of current kernel memory allocation. ContainerSample memoryResidentSizeBytes bytes (B) The amount of memory that doesn't correspond to anything on disk: stacks, heaps, and anonymous memory maps. ContainerSample memorySizeLimitBytes bytes (B) The total amount of memory the container is allowed to use. ContainerSample memorySoftLimitBytes bytes (B) The soft limit of memory usage equivalent to the memory reservation of the container. ContainerSample memorySwapLimitBytes bytes (B) The total amount of memory the container is using, including swap. ContainerSample memorySwapLimitUsagePercent percentage (%) This metric is calculated as the percentage of memorySwapUsageBytes over memorySwapLimitBytes, if the limit exists. ContainerSample memorySwapOnlyUsageBytes bytes (B) The amount of swap memory the container is using. This memory doesn't include non-swap memory. ContainerSample memorySwapUsageBytes bytes (B) The amount of memory swap the container is using, including swap. ContainerSample memoryUsageBytes bytes (B) This metric doesn't account for swap usage. ContainerSample memoryUsageLimitPercent percentage (%) This metric is calculated as the memoryUsageBytes percentage over memorySizeLimitBytes, if the limit exists. ContainerSample name The Docker container name. ContainerSample networkRxBytes bytes (B) Total number of received bytes. ContainerSample networkRxBytesPerSecond rate Number of received bytes per second. ContainerSample networkRxDropped count Total number of received packets dropped. ContainerSample networkRxDroppedPerSecond rate Number of received packets dropped per second. ContainerSample networkRxError count Total number of received packets with error. ContainerSample networkRxErrorsPerSecond rate Number of received packets with error per second. ContainerSample networkRxPackets count Total number of received packets. ContainerSample networkRxPacketsPerSecond rate Number of received packets with error per second. ContainerSample networkTxBytesPerSecond rate Number of transmitted bytes per second. ContainerSample networkTxDropped count Total number of transmitted packets dropped. ContainerSample networkTxDroppedPerSecond rate Number of transmitted packets dropped per second. ContainerSample networkTxErrors count Total number of transmitted packets with error. ContainerSample networkTxErrorsPerSecond rate Number of transmitted packets with error per second. ContainerSample networkTxPackets count Total number of transmitted packets. ContainerSample networkTxPacketsPerSecond rate Number of transmitted packets per second. ContainerSample networksTxBytes count Total number of bytes transmitted. ContainerSample restartCount count The number of times the container was restarted. ContainerSample state It can be: created, restarting, running, removing, paused, exited, or dead. ContainerSample status Holds the current container state. ContainerSample warningViolationCount count The number of times that alert conditions violated warning thresholds, causing warning violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample DistributedTraceSummary Data source : Distributed Tracing This event contains summary data about a distributed trace and provides an aggregated view of distributed tracing data. DistributedTraceSummary events are generated by New Relic and are triggered by distributed tracing data from agents or the Trace API. Attribute name Definition Events accountIds A comma delimited list of newrelic accountIds that took part in this trace. DistributedTraceSummary backend.duration.ms milliseconds (ms) The total elapsed time in milliseconds of all backend services in this trace. DistributedTraceSummary backend.timestamp milliseconds (ms) The timestamp of the first span in this trace from a backend entity. In distributed tracing, any events that are not from client-side applications contributed to the backend duration. DistributedTraceSummary duration.ms The duration of the entire distributed trace, including both backend and client-side entities. the earliest span to the latest. DistributedTraceSummary entityCount count The number of unique entities that took part in this trace. DistributedTraceSummary entityGuids A comma delimited list of entity GUIDs for entities that participated in this trace. These GUIDs are assigned by New Relic for the New Relic-monitored entity (host, application, etc.). Each GUID is stored as a Base64 encoded value. DistributedTraceSummary errorCount count The number of events in this distributed trace that were identified as errors. DistributedTraceSummary newRelic.traceFilter.type The name of the trace filter used by the Infinite Tracing trace observer to select this trace. DistributedTraceSummary Span root.entity.accountId The New Relic account ID that the root entity of this trace reports data to. DistributedTraceSummary root.entity.guid The entity GUID associated with the root entity of this trace. DistributedTraceSummary root.entity.name The name of the root entity of this trace. DistributedTraceSummary root.span.duration.ms milliseconds (ms) The elapsed time in milliseconds of the root span of this trace. The root of a distributed trace is the first span, and will have a null value for parent.id. DistributedTraceSummary root.span.id The unique identifier of the root span of this trace. The root of a distributed trace is the first span, and it has a null value for parent.id. DistributedTraceSummary root.span.name The name of the root span of this trace. DistributedTraceSummary root.span.timestamp milliseconds (ms) The timestamp of the root span of this trace. The root of a distributed trace is the first span, and will have a null value for parent.id. DistributedTraceSummary spanCount count The number of events in this distributed trace. Events in a distributed trace can have several event types, including Span, Transaction, and TransactionError. DistributedTraceSummary timestamp milliseconds (ms) The timestamp of the root span in this distributed trace. DistributedTraceSummary trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError InfrastructureEvent Data sources : InfrastructureCloudTrail InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, Infrastructure will produce an InfrastructureEvent that logs that activity. Attribute name Definition Events category A New Relic category used to organize events in the UI. For example: automation, notification, and service. InfrastructureEvent changeType A simple classification of the type of change made to the entity: added, modified, or removed. InfrastructureEvent changedPath The fully specified name of the item that changed. This is constructed by taking the source and adding one or more additional path elements that uniquely identify the item that changed. InfrastructureEvent deltaId Delta refers to a recorded change in the system. The deltaId is a number used by New Relic to organize incoming inventory change data. InfrastructureEvent eventId The unique ID of the event, generated by New Relic. InfrastructureEvent format The type of infrastructure event. Each format type includes attributes that may be used to render the event in the UI. InfrastructureEvent newStatus The new agent status: disconnected or connected. InfrastructureEvent newValue If a change is made to the entity, this attribute contains the new value of the inventory that was changed. This will have no value if no change has been made. The value will display approximately 4K bytes of data. InfrastructureEvent oldValue If a change is made to the entity, this attribute contains the old value of the inventory that was changed. This will be blank if no change has been made. InfrastructureEvent provider For integrations that use generic event types (like the DatastoreSample event), the provider value specifies the source of the data (the service, or a sub-category of data from that service). Some Insights events are generic and are used by several integrations. For example, the DatastoreSample event is used by several integrations, including the AWS DynamoDB integration and the AWS RDS integration. In these cases, the provider attribute value represents the source of that attribute. This will usually be the service that data comes from or, for integrations that use several provider values, a certain sub-category of data from that service. When a provider value is present for a generic event, that event will have additional integration-specific attributes attached to it. Here’s an example of an Insights NRQL query that returns the attributes present for a DatastoreSample event reported by the AWS RDS integration: SELECT * from DatastoreSample where provider = 'RdsDbCluster' InfrastructureEvent source The fully specified origin of this inventory item. This is typically in the form category/plugin, where plugin is the generic word used for the tool that gathered this data. InfrastructureEvent summary A summary of the change that happened. Uses a human-friendly string, such as Agent disconnected. InfrastructureEvent violationUpdateType The type of change to the violation: For example: open or closed. InfrastructureEvent JavaScriptError Data source : Browser agent As JavaScript errors are triggered, we capture details as events. The JavaScriptError event contains information to help you segment errors to understand how they impact performance. Attribute name Definition Events appId ID The identification number for the reporting browser agent. JavaScriptError appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserStackHash ID An unique identifier generated for a stack trace. The browserStackHash for a stack trace is different across different browsers. An identical stack trace will generate the same identifier. JavaScriptError city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView domain The domain portion of the request URL. BrowserInteraction JavaScriptError PageView PageViewTiming entityGuid The unique identifier of the monitor referenced in New Relic One. JavaScriptError SyntheticCheck SyntheticRequest errorClass The error type of the JavaScript Error object. Examples: ReferenceError, SyntaxError, and UncaughtException. JavaScriptError errorMessage The error message that was delivered. JavaScriptError firstErrorInSession A value to indicate whether or not this was the first JS error in the session. Example: true. JavaScriptError monitorAccountId The Synthetics account from which you are running the monitor. BrowserInteraction JavaScriptError monitorId ID A unique number identifying a particular monitor. BrowserInteraction JavaScriptError SyntheticCheck monitorJobId ID The ID of a single Synthetics monitor run, which began at a specific time and originated from a specific location. BrowserInteraction JavaScriptError pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming releaseIds ID The releases in which the app was updated. Example: {\\\"jQuery\\\":\\\"v3.1.1\\\",\\\"multiverse\\\":\\\"96e9ac7\\\"}. JavaScriptError requestUri The URI of the requested resource. JavaScriptError session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span stackHash ID A unique identifier generated by the Browser agent for a stack trace. The stackHash for a stack trace is the same across different browsers. An identical stack trace will generate the same identifier. JavaScriptError stackTrace A collection of the active stack frames when the error occurred. JavaScriptError stackTraceGzip A compressed version of the stackTrace attribute. JavaScriptError timestamp The time that the error occurred, in Unix time. JavaScriptError transactionName The full metric name of the transaction in which the error occurred, or Unknown if the error occurs outside of a transaction. JavaScriptError userAgentName The browser’s name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browser’s reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browser’s reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Metric Data source : Metrics Represents a metric data point (e.g., a measurement over a range of time, or a sample at a specific point in time) with multiple attributes attached, which allow for in-depth analysis and querying. This metric data comes from our Metric API, our Telemetry SDKs, and some of our open-source exporters/integrations. Attribute name Definition Events endTimestamp milliseconds (ms) The end of the time range associated with the metric, in Unix time, in milliseconds. This is calculated by adding the metric interval to the timestamp of the metric (timestamp + interval.ms). Metric interval.ms milliseconds (ms) The length of the time window. Metric metricName Name of the metric. Metric newrelic.source The source of this data. For example: metricAPI. Metric timestamp milliseconds (ms) The start time for the metric in Unix time, in milliseconds. Metric Mobile Data source : Mobile A Mobile event is created when a crash occurs, when an interaction ends or has run for 1 second, or if a session completes after the app is closed, backgrounded, or has run for 10 minutes. Mobile events were once the only event type and were generated for every event, but now there are several specialized event types. Recommendation: Upgrade to the most recent New Relic Mobile agent version to take full advantage of the new event types. Attribute name Definition Events category The type of data, either session or interaction. Mobile MobileSession interactionDuration For interaction category events only. This is the total time for the interaction to render on the device. In addition to render time, this usually includes all external calls associated with the interaction. Currently, this attribute is measured in seconds for Android devices and in milliseconds for iOS devices. Mobile name For interaction category events only. This is the label of the interaction associated with the event. It is by default assigned by New Relic. For example: ApplicationsListFragment or Display iOS_Example.MasterViewController. Mobile reportedTimestampMs For interaction category events only. The UTC based timestamp for when the event was sent to New Relic. This is different from the attribute ‘timestamp’, which is when the event began. Mobile MobileCrash Data source : Mobile The MobileCrash event is created when an app crashes. MobileCrash includes attributes such as crash line number, class, and crash message. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appToken The mobile application license token. MobileCrash appVersion The version number of the monitored app. For example: 2.2.9. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession architecture The processor architecture of the device. For example: armv7 or arm64. MobileCrash asnOwner The telecom owner of the ASN. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession bundleId ID The unique string used to identify the application. MobileCrash MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession crashException The exception associated with the crash, if one is present. For example: java.lang.NullPointerException. MobileCrash crashFingerprint ID The New Relic-generated fingerprint used to uniquely identify the crash and other crashes identical to this one. MobileCrash crashLocationFile The file in which the crash occurred. MobileCrash crashMessage The message associated with the crash, if one is present. MobileCrash deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceName The device's name. MobileCrash deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession diskAvailable bytes (B) Space available on the device, in bytes. MobileCrash interactionHistory The client interactions with the application that led to the crash. MobileCrash isFirstOccurrence A boolean value indicating whether or not this was the first occurrence of the crash. MobileCrash lastInteraction The last interaction before a crash or harvest event, if one is present. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession modelNumber The model of the device. This is the same as the session-level deviceModel attribute. MobileCrash networkStatus The type of network that the device was on at the time of crash, such as wifi or LTE. MobileCrash newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession occurrenceId ID The ID for this instance of the crash. MobileCrash orientation The orientation of the device, such as landscape or portrait. MobileCrash osBuild For Android only. The specific build of the Android OS. MobileCrash MobileHandledException osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession parentProcess The parent process that launched the crashing process. MobileCrash parentProcessId ID The parent identification number (PID) of the parent process. MobileCrash platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession processId ID The PID of the previously running process on the device. MobileCrash processName The name of the previously running process. MobileCrash processPath The path to the binary. MobileCrash reportedTimestampMs The UTC timestamp for when the event was received by New Relic. (This is different from timestamp, which is when the MobileSession event began that crashed.) MobileCrash runTime For Android only. The Android Runtime version where the exception/crash was generated. MobileCrash MobileHandledException sessionCrashed A boolean value indicating whether or not that session crashed. MobileCrash MobileSession sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession symbolicated A boolean value indicating whether or not the crash was properly symbolicated. MobileCrash timeSinceLastInteraction milliseconds (ms) The time, in milliseconds, since the interaction before a crash event. MobileCrash userImageUuids ID The array of build UUIDs for applications and libraries. MobileCrash uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession MobileHandledException Data source : Mobile MobileHandledException is sent when an exception is caught and is used for non-fatal exceptions reported to New Relic using the recordHandledException API for Android or iOS. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession exceptionAppBuildUuid ID The build uuid of the application binary in which the exception was caught. MobileHandledException exceptionCause The unsymbolicated, platform-specific cause of the exception. MobileHandledException exceptionLocation New Relic defined location of an exception. Contains a combination of exception file name, class, line number, and method. MobileHandledException exceptionLocationClass The class that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationFile The class that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationLibraryOffset For XCFramework agent only. The library offset of the library that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationLine Comes from the exception: The line number where the exception was generated. Only present if symbolication succeeded. MobileHandledException exceptionLocationMethod The method that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionMessage The unsymbolicated message from the exception. It can be user-generated or a generic system message. For Android, this is the Throwable message. MobileHandledException exceptionName The unsymbolicated exception type. MobileHandledException fingerprint ID The New Relic-generated identifier used to group like exceptions. MobileHandledException handledExceptionUuid ID The unique ID of the exception event. MobileHandledException lastInteraction The last interaction before a crash or harvest event, if one is present. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession libraryName For XCFramework agent only. The library name where the exception was generated. MobileHandledException libraryStartAddr For XCFramework agent only. The library start address where the exception was generated. MobileHandledException memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession occurrenceTimestamp Agent-reported epoch timestamp of the handled exception. MobileHandledException osBuild For Android only. The specific build of the Android OS. MobileCrash MobileHandledException osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession runTime For Android only. The Android Runtime version where the exception/crash was generated. MobileCrash MobileHandledException sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession timestamp Epoch timestamp of the handled exception. This exception timestamp represents the time New Relic created the event, if it's older than two days or some other unexpected time. MobileHandledException uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession MobileRequest Data source : Mobile A MobileRequest event is created when an HTTP request successfully completes, resulting in a response code below 400. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession bytesReceived bytes (B) Optional: If the application received a response from the requestUrl, the size of that response in bytes. MobileRequest MobileRequestError bytesSent bytes (B) Optional: If the application sent a request to the requestUrl, the size of that request in bytes. MobileRequest MobileRequestError carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession connectionType The type of connection which the device was using, such as 2G or 3G. MobileRequest MobileRequestError countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceSize The display size of the device: Small, normal, large, xlarge. MobileRequest MobileRequestError deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession duration seconds (s) Optional: The time to complete the request, measured in fractional seconds. MobileRequest MobileRequestError guid ID The unique identifier for the segment. This is equivalent to spanID in OpenTracing semantics. MobileRequest MobileRequestError Span lastInteraction The last interaction before a crash or harvest event, if one is present. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession requestDomain The domain that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestFingerprint ID The New Relic-generated identifier used to group like request events. MobileRequest requestMethod The REST method (GET, PUT, POST, etc.) that the application attempted when the event occurred. MobileRequest MobileRequestError requestPath The path that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUrl The URL that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUuid ID A unique identifer for the request event. MobileRequest MobileRequestError responseTime seconds (s) The time between the request and the response in fractional seconds. MobileRequest MobileRequestError sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession statusCode Optional: The HTTP status code for the HTTP event. MobileRequest MobileRequestError timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession MobileRequestError Data source : Mobile A MobileRequestError is used for HTTP errors or network failures. HTTP errors are HTTP requests that have a status code greater than 400. A network failure is a HTTP request that results in no response. The event is sent when the HTTP request completes. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession bytesReceived bytes (B) Optional: If the application received a response from the requestUrl, the size of that response in bytes. MobileRequest MobileRequestError bytesSent bytes (B) Optional: If the application sent a request to the requestUrl, the size of that request in bytes. MobileRequest MobileRequestError carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession connectionType The type of connection which the device was using, such as 2G or 3G. MobileRequest MobileRequestError countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceSize The display size of the device: Small, normal, large, xlarge. MobileRequest MobileRequestError deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession duration seconds (s) Optional: The time to complete the request, measured in fractional seconds. MobileRequest MobileRequestError errorType Either HTTPError or NetworkFailure, depending on whether the error is a result of a failed request to a host or a failure on the cellular network. MobileRequestError guid ID The unique identifier for the segment. This is equivalent to spanID in OpenTracing semantics. MobileRequest MobileRequestError Span lastInteraction The last interaction before a crash or harvest event, if one is present. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession networkError The error message associated with the iOS NSURL Error code. See networkErrorCode for more information. MobileRequestError networkErrorCode If the error is a network error, this is the iOS network error code. For Android applications, this is the mapped value. MobileRequestError newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession requestDomain The domain that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestErrorFingerprint ID The New Relic-generated identifier used to group like request error events. MobileRequestError requestMethod The REST method (GET, PUT, POST, etc.) that the application attempted when the event occurred. MobileRequest MobileRequestError requestPath The path that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUrl The URL that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUuid ID A unique identifer for the request event. MobileRequest MobileRequestError responseBody Optional: The response that is sent from the requestDomain for the HTTP error, up to 4096 bytes. MobileRequestError responseTime seconds (s) The time between the request and the response in fractional seconds. MobileRequest MobileRequestError sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession statusCode Optional: The HTTP status code for the HTTP event. MobileRequest MobileRequestError timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession MobileSession Data source : Mobile A MobileSession event is sent when an app is closed, backgrounded, or when 10 minutes of active use has elapsed. This is the source of the general session data used by the other New Relic Mobile events. MobileSession captures attributes such as device type, device OS, and geographical information. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession bundleId ID The unique string used to identify the application. MobileCrash MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession category The type of data, either session or interaction. Mobile MobileSession city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession install Indicates true only if the current session is the first session after app install. MobileSession lastInteraction The last interaction before a crash or harvest event, if one is present. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession newRelicAgent The New Relic agent running on the application. For example: the iOSAgent or the androidAgent. MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession sessionCrashed A boolean value indicating whether or not that session crashed. MobileCrash MobileSession sessionDuration seconds (s) The length of time for which the user used the application in seconds. If the session crashes, sessionDuration is not captured (although other events and attributes are still recorded). For sessions longer than 10 minutes, events in the Interaction and Custom event categories are sent to Insights while the session is ongoing, and therefore do not have sessionDuration attributes. Events recorded near the end of the session will include the duration, as will the Session event category. MobileSession sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession timeSinceLoad seconds (s) The time, in seconds, from the beginning of the mobile session to the time the event occurred. MobileSession timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession upgradeFrom Indictates previous version number only if this is the first launch after app upgrade. MobileSession uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileCrash MobileHandledException MobileRequest MobileRequestError MobileSession NetworkSample Data source : Infrastructure NetworkSample event captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. New Relic samples this data every 10 seconds for each attached network interface and packages it into a NetworkSample event, then sends the raw data to New Relic's collectors every 60 seconds. Attribute name Definition Events agentName The name of the agent (Infrastructure). NetworkSample ProcessSample StorageSample SystemSample agentVersion The version of the New Relic Infrastructure agent. NetworkSample ProcessSample StorageSample SystemSample criticalViolationCount count The number of times that alert conditions violated critical thresholds, causing critical violations and opening incidents. If this attribute does not exist on the sample, it has zero violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample entityID ID New Relic's unique ID number for the entity that is reporting data. This is used by New Relic to distinguish between customers and their entities. NetworkSample ProcessSample StorageSample SystemSample fullHostname The fully qualified (DNS) hostname. NetworkSample ProcessSample StorageSample SystemSample hardwareAddress The unique hardware address of the interface. NetworkSample hostname The short version of the entity's name. NetworkSample ProcessSample StorageSample SystemSample interfaceName The interface name as reported by the operating system. NetworkSample ipV4Address The IP version 4 address. NetworkSample ipV6Address The IP version 6 address. NetworkSample kernelVersion The Linux kernel version, in string format. This attribute is available only for systems on a Linux platform. NetworkSample ProcessSample StorageSample SystemSample linuxDistribution The name of the Linux distribution the server is using. This attribute is available only for systems on a Linux platform. NetworkSample ProcessSample StorageSample SystemSample operatingSystem The operating system on which the agent is installed. NetworkSample ProcessSample StorageSample SystemSample receiveBytesPerSecond bytes (B) The number of bytes per second received during the sampling period. NetworkSample receiveDroppedPerSecond count The number of received packets per second dropped during the sampling period. NetworkSample receiveErrorsPerSecond count The number of receive errors per second on the interface during the sampling period. NetworkSample receivePacketsPerSecond count The number of packets per second (as defined by OS) received during the sampling period. NetworkSample state The state of the entity: either up or down. NetworkSample timestamp The time (date, hour, minute, second) at which the interaction occurred. NetworkSample ProcessSample StorageSample SystemSample transmitBytesPerSecond bytes (B) The number of bytes sent per second during the sampling period. NetworkSample transmitDroppedPerSecond count The number of dropped send packets per second during the sampling period. NetworkSample transmitErrorsPerSecond count The number of send errors per second on the interface during the sampling period. NetworkSample transmitPacketsPerSecond count The number of packets per second as defined by OS) sent during this sampling period. NetworkSample warningViolationCount count The number of times that alert conditions violated warning thresholds, causing warning violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample windowsFamily The Windows family indicates w",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.10927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em>",
        "body": " for iOS devices. <em>Mobile</em> name For interaction category <em>events</em> only. This is the label of the interaction associated with the <em>event</em>. It is by default assigned by New Relic. For example: ApplicationsListFragment or Display iOS_Example.MasterViewController. <em>Mobile</em> <em>reported</em>TimestampMs For interaction"
      },
      "id": "603f53b164441f41894e8875"
    },
    {
      "sections": [
        "Carriers page",
        "Viewing the Carriers page",
        "For more help"
      ],
      "title": "Carriers page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "18de05b6ec2253f12b3e54f158c687eeb6ca87a1",
      "image": "https://docs.newrelic.com/static/d65def75dab0ea60d3a339ea8a3e96a5/c1b63/carriers.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/carriers-page/",
      "published_at": "2021-06-26T14:36:45Z",
      "updated_at": "2021-05-16T06:34:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Carriers page for Mobile monitoring includes charts that show your users' wireless carriers and their response time impact, error rate, and active sessions for the selected time period. Wifi is included as a carrier. From here you can sort and drill down into detailed information about specific carriers. Viewing the Carriers page one.newrelic.com > Mobile > (select an app) > Network > Carriers: Use this page to view, sort, or drill down into detailed information about your users' mobile carriers by response time impact, network failures, and active sessions. To view your users' mobile carriers: Go to one.newrelic.com > Mobile > (select an app) > Network > Carriers. To change the information that appears (including response time, active devices, or network errors), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To select the mobile app versions or time period, use the Versions menu and time picker below the New Relic menu bar. To view details for a specific carrier, select its name. Use any of our standard user interface functions and page functions to drill down into detailed information. For more help Additional documentation resources include: Errors for mobile apps (detailed charts and information about errors with mobile apps) Devices page (performance details about the top devices using your mobile application) Versions analysis (seven-day report with a color-coded chart for mobile app usage, plus a table that summarizes mobile versions, date created, and averages) Monthly uniques report (bar charts showing the number of devices running your mobile app over the past 12 months)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.66827,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "The Carriers page for <em>Mobile</em> <em>monitoring</em> includes charts that show your users&#x27; wireless carriers and their response time impact, error rate, and active sessions for the selected time period. Wifi is included as a carrier. From here you can sort and drill down into detailed information about specific"
      },
      "id": "603ea36ae7b9d267502a0811"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring": [
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "af971d2b95ff397b57bf125f6801f57007ea5e77",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-06-26T08:20:35Z",
      "updated_at": "2021-05-15T09:10:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-06-26T08:20:36Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 244.89282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute Browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-06-26T08:19:29Z",
      "updated_at": "2021-06-15T00:49:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the Browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Subscription level This feature requires a Browser Pro subscription. The instrumentation level setting for an application does not affect the availability of JavaScript API functions. Agent version Your New Relic Browser agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the Browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default Browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute Browser API call To add a custom attribute to the PageView event via the Browser agent, use the setCustomAttribute Browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual Browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.88142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring custom <em>events</em> and attributes",
        "sections": "Report browser monitoring custom <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " browser. After the 120-<em>event</em> limit is reached, additional <em>events</em> are not captured for that cycle. <em>Event</em>&#x2F;attribute naming, <em>data</em> type, size Ensure you follow general requirements around <em>event</em>&#x2F;attribute naming syntax, <em>data</em> types, and size. Create PageAction <em>events</em> To create a PageAction <em>event</em>: Ensure"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/nrauditevent-event-data-query-examples": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/query-account-audit-logs-nrauditevent/",
      "sections": [
        "Query account audit logs (NrAuditEvent)",
        "Account data security and retention",
        "Run NrAuditEvent query"
      ],
      "published_at": "2021-06-26T08:24:37Z",
      "title": "Query account audit logs (NrAuditEvent)",
      "updated_at": "2021-05-15T09:10:01Z",
      "type": "docs",
      "external_id": "0d7ba78f9aa862a1d90b29d09d0137b804a22d6f",
      "document_type": "page",
      "popularity": 1,
      "body": "As an additional security measure for managing your New Relic account, you can use the NrAuditEvent event to view audit logs that show changes to your New Relic account. This includes: Individuals added or deleted Role changes Account changes made via API Synthetic monitor changes Dashboard deletion Workload configuration changes You can also use alerts to be notified about changes to your New Relic account. Account data security and retention All New Relic accounts can query up to 13 months of account changes. To ensure account security, the audit logging NRQL query only tracks changes to your currently selected account. It does not show audit log events for any associated sub-accounts. To query changes to another account or sub-account, select the account and run a NRQL query there. Audit logging is different than configuring audit mode for your APM agent. APM audit mode records information about all data being transmitted from your app. Run NrAuditEvent query To track and view changes to your New Relic account: At any NRQL interface, run the following query, adjusting the time frame as needed up to thirteen months: SELECT * from NrAuditEvent SINCE 1 day ago Copy To customize your query, use any of the available NrAuditEvent attributes. To be notified about account changes, create NRQL conditions with New Relic Alerts. To query changes to another account or sub-account, select the account and run a separate NRQL query for that account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 326.11322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> account <em>audit</em> logs (<em>NrAuditEvent</em>)",
        "sections": "<em>Query</em> account <em>audit</em> logs (<em>NrAuditEvent</em>)",
        "body": " information about all <em>data</em> being transmitted from your app. Run <em>NrAuditEvent</em> <em>query</em> To track and view changes to your New Relic account: At any NRQL interface, run the following <em>query</em>, adjusting the time frame as needed up to thirteen months: SELECT * from <em>NrAuditEvent</em> SINCE 1 day ago Copy To customize"
      },
      "id": "60a8eb1fe7b9d202f1aeac03"
    },
    {
      "sections": [
        "Synthetic monitoring audit log: Track changes made by users",
        "Feature description",
        "Query details",
        "Example use case: Finding changes made by a user"
      ],
      "title": "Synthetic monitoring audit log: Track changes made by users",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "4673ae884e9d00a1c90e9577f2b8ff229b73b543",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you see a 13-month history of synthetic monitoring audit events. Feature description When you take specific actions in synthetic monitoring like creating or editing a monitor, an NrAuditEvent is generated. This event includes details about the action taken and which user took that action. This data is stored for 13 months. This historical data may be helpful if you'd like to investigate how a problem with your account was created and who made that change. Synthetic monitoring's changes tracked include: Monitors Creation Edits (including location change, mute/unmute, and enable/disable) Script creation, edits, validation (including secure credentials used) Deletion Monitor downtimes Creation Edits Deletion Secure credentials Creation Edits Views Deletion Private locations Creation Edits (including clearing queues) Deletion For details on how to query this data, see Query details. Query details To query changes, use the query builder to explore the NrAuditEvent and its associated attributes. For an introduction to using the NrAuditEvent event, see Query account audit logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create synthetics_monitor.update synthetics_monitor.create_script synthetics_monitor.update_script synthetics_monitor.validate_script synthetics_monitor.delete Monitor downtimes synthetics_monitor_downtime.create synthetics_monitor_downtime.update synthetics_monitor_downtime.delete Secure credentials synthetics_secure_credential.create synthetics_secure_credential.update synthetics_secure_credential.view synthetics_secure_credential.delete Private locations synthetics_private_location.create​ synthetics_private_location.update​ synthetics_private_location.delete How the change was made: The actorAPIKey attribute indicates if the change was made via the API or by a user via the UI. When this value is null, it's a user update; when not null, it's an API update. For examples of synthetic monitoring's audit log queries, see: The example use case. The synthetic monitoring specific examples in Audit query examples. Example use case: Finding changes made by a user Here's an example of using the synthetic monitoring audit log to solve a common problem: You are a manager at a company that uses synthetic monitoring. A new employee has been playing with your company's accounts to learn how synthetic monitoring works. Unfortunately, this employee was accidentally given full access to the production accounts, instead of the pre-production accounts. You want to determine what synthetic monitors this employee created, deleted, and updated, so that you will know which monitors need to be fixed. Instead of having to review every monitor in the account, you open the query builder and run the following NRQL query of the NrAuditEvent event: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' AND actorEmail = 'EMPLOYEE_EMAIL' FACET actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy The query will return all the synthetic monitors that the employee has updated, deleted, created, disable, or muted. One by one, you and the employee review the list and update the edited monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.52536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>audit</em> log: Track changes made by users",
        "sections": "Synthetic monitoring <em>audit</em> log: Track changes made by users",
        "body": " details. <em>Query</em> details To <em>query</em> changes, use the <em>query</em> builder to explore the <em>NrAuditEvent</em> and its associated attributes. For an introduction to using the <em>NrAuditEvent</em> <em>event</em>, see <em>Query</em> account <em>audit</em> logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create"
      },
      "id": "603eb96fe7b9d251b82a07cd"
    },
    {
      "sections": [
        "Add and manage users, groups, and roles",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "User management definitions",
        "Example user management tasks",
        "Add, edit, and delete users",
        "Assign users access to accounts (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes"
      ],
      "title": "Add and manage users, groups, and roles",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/b1c2da968a637f68569e890c8bd72a1c/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-06-25T16:49:32Z",
      "updated_at": "2021-06-25T16:49:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user information, and approve upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts To optimally use our more advanced user management features, it's important to first understand the concept of the \"access grant.\" An access grant gives a group of users access to a) a role and b) an account. For a New Relic organization that has many accounts, groups typically require more than one access grant because users in a group usually need access to multiple accounts and roles. The diagram below explains the elements that make up an access grant. Note that if your organization is on Standard edition and want to assign a user to a default group (Admin or User), you don't need to create an access grant: you would simply add a user to that group and you're done. But for Pro and Enterprise edition, if you're trying to grant users access to a custom group, a custom role, or to other accounts, you must create an access grant. A diagram explaining how you can grant user groups access to roles and accounts. Note that this applies to users on our New Relic One user model (and not our original user model). Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? For smaller, flatter organizations that are okay with full internal transparency, you may only need a couple groups. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). For examples of some common user management tasks, see Example tasks. User management definitions Here are some definitions of our user management terms and how they relate to each other: A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles. Example user management tasks In the Organization and access UI, you can create custom groups, roles, and grant access to user groups. Here are some example user management procedures: Add, edit, and delete users To add or edit users, use the User management UI. To add users: If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Assign users access to accounts (access grants) See our user management tutorial. Create new custom groups and roles See our user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager role. Important Users cannot have only organization-scoped roles assigned; they must also be in a group that has account-scoped roles (for example, the default Admin group). You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can assign those roles to a custom group. From the Organization and access UI: Select Access grants, and choose To this organization. Create an access grant that assigns the Authentication domain manager role to a custom group. From the User management UI, add users to that group. To see a tutorial on creating new groups and roles, see Tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 271.8699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add <em>and</em> manage users, groups, <em>and</em> roles",
        "sections": "<em>Example</em> user management tasks",
        "tags": "Accounts <em>and</em> billing",
        "body": " role to a custom group. From the User management UI, add users to that group. To see a tutorial on creating new groups and roles, see Tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an <em>audit</em> log of changes to your account, including user management actions, you can <em>query</em> the <em>NrAuditEvent</em>."
      },
      "id": "603e7bce28ccbc415beba74c"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/query-account-audit-logs-nrauditevent": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/nrauditevent-event-data-query-examples/",
      "sections": [
        "NrAuditEvent event data and query examples",
        "Available events and attributes",
        "Example queries",
        "General account changes",
        "What changes have been made to the New Relic account?",
        "What type of account change was made the most?",
        "What trends appear in account changes?",
        "What user management changes have been done?",
        "Synthetics: What changes have been made to a monitor?",
        "Workloads: What changes were made to any workload configuration?",
        "Changes made by specific users",
        "What account changes have been made by any user?",
        "What account changes have been made by a specific user?",
        "Who made the most changes to the account?",
        "Synthetics: What monitors were created by a specific user?",
        "Changes made using the API",
        "What account changes have been made using an API key?"
      ],
      "published_at": "2021-06-26T08:23:17Z",
      "title": "NrAuditEvent event data and query examples",
      "updated_at": "2021-05-15T09:10:01Z",
      "type": "docs",
      "external_id": "1cb581c67b8196fedfd66c9eb527bd88e6090a40",
      "document_type": "page",
      "popularity": 1,
      "body": "To view changes made in your New Relic account, you can query NrAuditEvent events. Available events and attributes The NrAuditEvent is created to record configuration changes made in our products. The data gathered for this event includes the type of account change, actor (user or API key) that made the change, a human-readable description of the action taken, and a timestamp for the change. To see all the attributes attached to this event, see NrAuditEvent. Example queries These examples show some of the ways you can run NRQL queries of the NrAuditEvent event. General account changes What changes have been made to the New Relic account? To view all changes to your New Relic account for a specific time frame, run this basic NRQL query: SELECT * from NrAuditEvent SINCE 1 day ago Copy What type of account change was made the most? To query what type of change to the account users was made the most frequently during a specific time frame, include the actionIdentifier attribute in your query. For example: SELECT count(*) AS Actions FROM NrAuditEvent FACET actionIdentifier SINCE 1 week ago Copy What trends appear in account changes? When you include TIMESERIES in a NRQL query, the results are shown as a line graph. For example: SELECT count(*) from NrAuditEvent TIMESERIES facet actionIdentifier since 1 week ago Copy What user management changes have been done? Note that your users' user model will impact these queries. If your users are on our original user model, you can only query per account. If your users are on the New Relic One user model, you should query the top-level account in your New Relic organization. To see all the changes made to users, you could use: SELECT * FROM NrAuditEvent WHERE targetType = 'user' SINCE this month Copy If you wanted to narrow that down to see changes to user type (full user vs basic user), you could use: SELECT * FROM NrAuditEvent WHERE targetType = 'user' AND actionIdentifier IN ('user.self_upgrade', 'user.change_type') SINCE this month Copy Synthetics: What changes have been made to a monitor? To query Synthetics monitor updates during a specific time frame, include the actionIdentifier attribute in your query. For example: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' FACET actionIdentifier, description, actorEmail SINCE 1 week ago LIMIT 1000 Copy For more information about this Synthetics feature, see Synthetics audit log. Workloads: What changes were made to any workload configuration? To query what configuration changes were made to any workload, use the query below. The targetId attribute contains the GUID of the workload that was modified, which you can use for searches. Since changes on workloads are often automated, you might want to include the actorType attribute to know if the change was done directly by a user through the UI or through the API. SELECT timestamp, actorEmail, actorType, description, targetId FROM NrAuditEvent WHERE targetType = 'workload' SINCE 1 week ago LIMIT MAX Copy Changes made by specific users What account changes have been made by any user? To see detailed information about any user who made changes to the account during a specific time frame, include actorType = 'user' in the query. For example: SELECT actionIdentifier, description, actorEmail, actorId, targetType, targetId FROM NrAuditEvent WHERE actorType = 'user' SINCE 1 week ago Copy What account changes have been made by a specific user? To query account activities made by a specific person during the selected time frame, you must know their actorId. For example: SELECT actionIdentifier FROM NrAuditEvent WHERE actorId = 829034 SINCE 1 week ago Copy Who made the most changes to the account? To identify who (actorType) has made the most changes to the account, include the actorEmail attribute in your query. For example: SELECT count(*) as Users FROM NrAuditEvent WHERE actorType = 'user' FACET actorEmail SINCE 1 week ago Copy Synthetics: What monitors were created by a specific user? To query Synthetics monitor updates made by a specific user, include the actionIdentifier and actorEmail attribute in your query. For example: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' FACET actorEmail, actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy Changes made using the API What account changes have been made using an API key? To see detailed information about changes to the account that were made using an API key during a specific time frame, include actorType = 'api_key' in the query. For example: SELECT actionIdentifier, description, targetType, targetId, actorAPIKey, actorId, actorEmail FROM NrAuditEvent WHERE actorType = 'api_key' SINCE 1 week ago Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 378.98578,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NrAuditEvent</em> <em>event</em> data and <em>query</em> examples",
        "sections": "<em>NrAuditEvent</em> <em>event</em> data and <em>query</em> examples",
        "body": "To view changes made in your New Relic <em>account</em>, you can <em>query</em> <em>NrAuditEvent</em> events. Available events and attributes The <em>NrAuditEvent</em> is created to record configuration changes made in our products. The data gathered for this <em>event</em> includes the type of <em>account</em> change, actor (user or API key"
      },
      "id": "60a8e35ce7b9d2b07caeabdd"
    },
    {
      "sections": [
        "Synthetic monitoring audit log: Track changes made by users",
        "Feature description",
        "Query details",
        "Example use case: Finding changes made by a user"
      ],
      "title": "Synthetic monitoring audit log: Track changes made by users",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "4673ae884e9d00a1c90e9577f2b8ff229b73b543",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users/",
      "published_at": "2021-06-26T00:43:43Z",
      "updated_at": "2021-03-16T18:11:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic lets you see a 13-month history of synthetic monitoring audit events. Feature description When you take specific actions in synthetic monitoring like creating or editing a monitor, an NrAuditEvent is generated. This event includes details about the action taken and which user took that action. This data is stored for 13 months. This historical data may be helpful if you'd like to investigate how a problem with your account was created and who made that change. Synthetic monitoring's changes tracked include: Monitors Creation Edits (including location change, mute/unmute, and enable/disable) Script creation, edits, validation (including secure credentials used) Deletion Monitor downtimes Creation Edits Deletion Secure credentials Creation Edits Views Deletion Private locations Creation Edits (including clearing queues) Deletion For details on how to query this data, see Query details. Query details To query changes, use the query builder to explore the NrAuditEvent and its associated attributes. For an introduction to using the NrAuditEvent event, see Query account audit logs. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create synthetics_monitor.update synthetics_monitor.create_script synthetics_monitor.update_script synthetics_monitor.validate_script synthetics_monitor.delete Monitor downtimes synthetics_monitor_downtime.create synthetics_monitor_downtime.update synthetics_monitor_downtime.delete Secure credentials synthetics_secure_credential.create synthetics_secure_credential.update synthetics_secure_credential.view synthetics_secure_credential.delete Private locations synthetics_private_location.create​ synthetics_private_location.update​ synthetics_private_location.delete How the change was made: The actorAPIKey attribute indicates if the change was made via the API or by a user via the UI. When this value is null, it's a user update; when not null, it's an API update. For examples of synthetic monitoring's audit log queries, see: The example use case. The synthetic monitoring specific examples in Audit query examples. Example use case: Finding changes made by a user Here's an example of using the synthetic monitoring audit log to solve a common problem: You are a manager at a company that uses synthetic monitoring. A new employee has been playing with your company's accounts to learn how synthetic monitoring works. Unfortunately, this employee was accidentally given full access to the production accounts, instead of the pre-production accounts. You want to determine what synthetic monitors this employee created, deleted, and updated, so that you will know which monitors need to be fixed. Instead of having to review every monitor in the account, you open the query builder and run the following NRQL query of the NrAuditEvent event: SELECT count(*) FROM NrAuditEvent WHERE actionIdentifier = 'synthetics_monitor.update_script' AND actorEmail = 'EMPLOYEE_EMAIL' FACET actionIdentifier, description SINCE 1 week ago LIMIT 1000 Copy The query will return all the synthetic monitors that the employee has updated, deleted, created, disable, or muted. One by one, you and the employee review the list and update the edited monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 348.73016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Synthetic monitoring <em>audit</em> <em>log</em>: Track changes made by users",
        "sections": "Synthetic monitoring <em>audit</em> <em>log</em>: Track changes made by users",
        "body": " details. <em>Query</em> details To <em>query</em> changes, use the <em>query</em> builder to explore the <em>NrAuditEvent</em> and its associated attributes. For an introduction to using the <em>NrAuditEvent</em> <em>event</em>, see <em>Query</em> <em>account</em> <em>audit</em> <em>logs</em>. Supported actionIdentifier events currently include: Monitors synthetics_monitor.create"
      },
      "id": "603eb96fe7b9d251b82a07cd"
    },
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "830536a1ec360e4923f48cad5f96a21f4bffaa5e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-06-26T08:35:43Z",
      "updated_at": "2021-03-13T03:22:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 329.29645,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> (<em>audit</em>) all data your New Relic agent transmits",
        "sections": "<em>Log</em> (<em>audit</em>) all data your New Relic agent transmits",
        "body": "_file values. Ruby Use <em>audit_log</em> values. For more information, see Ruby agent <em>audit</em> <em>log</em>. Infrastructure agent logging You can generate infrastructure monitoring <em>logs</em> for troubleshooting our infrastructure agent. New Relic <em>account</em>-related logging To <em>audit</em> changes to your New Relic <em>account</em>, run NRQL queries with <em>NrAuditEvent</em>. To customize your <em>query</em>, use any of the available <em>NrAuditEvent</em> attributes."
      },
      "id": "60444a7c28ccbc365e2c60da"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.2779,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " an overall <em>ingest</em> view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Tip",
        "Manage all your data",
        "Important",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/48e1c94f543871e00475b942b7b4fd0d/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-06-25T19:53:34Z",
      "updated_at": "2021-06-25T19:53:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. Tip To use NRDB and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Manage all your data We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. But we also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Data management hub: from the user profile drop down, select Manage your data. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data can be uncompressed, decorated with queryable attributes, and evaluated. Elements can be dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.27765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. Tip To use NRDB and the rest of our observability <em>platform</em>, join the New Relic"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "Introduction to querying data in New Relic",
        "Explore data",
        "Query data in the UI",
        "Tip",
        "Use NRQL or PromQL-style queries in the UI",
        "Query using simple UI interfaces",
        "Query data via API"
      ],
      "title": "Introduction to querying data in New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "f3f9efbd4d9565c83ad8224f1f1524f9a5957650",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/",
      "published_at": "2021-06-25T22:29:52Z",
      "updated_at": "2021-05-15T10:10:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your data in New Relic in several ways, including in the UI or via API. Explore data Before querying data, consider using our data explorer. The data explorer in the New Relic UI requires no querying knowledge. To better understand your data stored in New Relic, see Data types. Query data in the UI Reasons to query your data from the New Relic UI: To answer a specific question To create a custom chart or dashboard To access and navigate your data in a quick, visual way To query your data in the New Relic UI, you can use query languages, including our New Relic query language or our PromQL-style query language). You can also use simpler query interfaces that don't require knowledge of how to write a query. Tip Access your data easily in one.newrelic.com: Click the Browse data dropdown, then select the data type (metrics, events, logs, and traces) you want to explore. Use NRQL or PromQL-style queries in the UI There are two ways to write your own queries to retrieve data and build charts: Query builder in NRQL mode: query using New Relic query language (NRQL), the same language we use to build most of our UI experiences. Query builder in PromQL-style mode: write basic queries using a PromQL-style query. Query using simple UI interfaces New Relic One offers several experiences that don't require knowledge of NRQL: Data explorer: an intuitive data navigator to create visualizations for events and metrics. Query builder (basic mode): a simple, query-less, chart-building experience. Distributed tracing query: a specialized UI for querying traces. Logs query: a specialized UI for querying New Relic Logs data. Query data via API You can use APIs to retrieve and query your data in New Relic. For example, you can run NRQL (our query language) queries with NerdGraph (our GraphQL API). For more information, see the introduction to New Relic APIs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.72383,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to querying <em>data</em> in New Relic",
        "sections": "Introduction to querying <em>data</em> in New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can query your <em>data</em> in New Relic in several ways, including in the UI or via API. Explore <em>data</em> Before querying <em>data</em>, consider using our <em>data</em> explorer. The <em>data</em> explorer in the New Relic UI requires no querying knowledge. To better <em>understand</em> your <em>data</em> stored in New Relic, see <em>Data</em> types. Query"
      },
      "id": "609f9e1de7b9d2c96ac3eb08"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/metric-data/query-apm-metric-timeslice-data-nrql": [
    {
      "sections": [
        "Extract metric timeslice data",
        "Time based data",
        "Time range considerations",
        "Important",
        "Tip",
        "Controlling time period output",
        "Data retention",
        "Extracting non-existent metric timeslice data"
      ],
      "title": "Extract metric timeslice data",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Basic functions"
      ],
      "external_id": "2a144a4b775dd2332592a5d92c199a07c08f49fa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/basic-functions/extract-metric-timeslice-data/",
      "published_at": "2021-06-25T17:32:47Z",
      "updated_at": "2021-03-13T01:07:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One type of New Relic data is metric timeslice data. There are several ways to query metric timeslice data: You can query APM metric timeslice data via NRQL (and therefore via our NerdGraph API). You can query any metric timeslice data via the REST API This doc explains how to do this with the REST API. Note that the API is not intended for bulk data extraction of minute-by-minute data points. Time based data All time values returned by the REST API and the API Explorer are UTC (Universal Time Coordinated). Be sure to adjust the time values for data collection as necessary. Time range considerations Important The minimum time range for data requests is one minute (60 seconds). Requests for anything less will result in a 422 status code and no data will be returned. New Relic only collects data at one minute intervals. The API uses the same mechanism for requesting data as the UI: it depends on the time range for the data you request. The objective is to optimize the number of data points returned and provide an easily digestible graph and report. For example: If you request data from a time range of three hours or less, the API returns the one-minute data values originally collected. If you increase the time range to greater than three hours, the data values returned will be an average for two minutes. If you increase the time range to over six hours, the data values returned will be an average for five minutes, and so on. Tip If the initial time for a requested time range is older than eight days, ten evenly spaced data points will be returned for any time range less than four days in length. Here is a summary of the metric value retrieval for the time ranges available. Between this time range... and this time range Granularity of collected data data age ≤ 8 days data age > 8 days ≤ 3 hours 1 minute 10 evenly spaced data points > 3 hour ≤ 6 hours 2 minutes > 6 hours ≤ 14 hours 5 minutes > 14 hours ≤ 24 hours 10 minutes > 1 day (24 hrs) ≤ 4 days (96 hrs) 30 minutes > 4 days ≤ 7 days 1 hour 1 hour > 7 days ≤ 3 weeks 3 hours 3 hours > 3 weeks ≤ 6 weeks 6 hours 6 hours > 6 weeks ≤ 9 weeks 12 hours 12 hours > 63 days 3 days 3 days When the start time for a requested time range is older than eight days, data has been aggregated or averaged to one hour periods due to the data aggregation schedule. This means that for any one hour period, only a single data value is available. Obtaining data at less than an hourly period in the time range would cause oversampling, resulting in duplicate values being returned. Returning only ten values prevents oversampling and presents a smoother chart, which eliminates a possibly misleading \"plateau\" effect. Controlling time period output Sometimes the output data's granularity may be too fine, or the time period for the data returned may be too short. To control this, include the period= parameter in the query command as the number of seconds you want each time period to report. Make sure your specifications follow New Relic's data aggregation schedules. Example #1: Following New Relic's table summarizing granularity of collected data, the following API call would normally return data in 30-minute periods, since the request is for 4 days (from=2018-02-13 and to=2018-02-17). By adding period=3600, the data will be returned as 60-minute periods. curl -X GET 'https://api.newrelic.com/v2/applications/$APPID/metrics/data.xml' \\ -H 'Api-Key:$API_KEY' -i \\ -d'names[]=CPU/User+Time&from=2018-02-13T04:00:00+00:00&to=2018-02-17T04:00:00+00:00&period=3600' Copy You cannot specify a period smaller than the default for the time range you are requesting. For example: In the command example above, you can request 1-hour periods, since that is greater than the default (half hour) granularity for the time range. In the command example above, you cannot request 1-minute periods, since that is less than the default (half hour) granularity for the time range. Example #2: If you request a range > 7 days but ≤ 3 weeks, where the default period is 3 hours, you can specify periods such as 6, 12, or 24 hours. However, you cannot request 1-hour periods, because that is less than the default (3 hours). Data retention How long data is available depends on the data retention for specific types of data. Extracting non-existent metric timeslice data Situations may arise where non-existent metric names are requested. For example: The metric timeslice data has not been created for one application, but exists for another. When the same metric extraction query is used on both of these applications, it will not be located for one. The metric name was incorrectly specified. Important Metric values that have existed in the past, but are no longer collected, will return a zero value. A successful response will include a 200 status code and metadata about the request. The metadata will contain the names of the metrics requested and the status of the request for those names. Response Metadata Description Response Metric Data metrics_not_found Lists all metric names for which matching data was not found in the requested time period. Metric timeslice data will not be returned for these metrics metrics_found Lists all metric names for which matching data was found in the requested time period. Metric timeslice data will be returned for these metrics Here is an example of output for a valid metric name, HttpDispatcher. HTTP/1.1 200 OK etag: \"0dc87c63d8dff6b1a9714bdf7531ec09\" Content-Type: application/json cache-control: max-age=0, private, must-revalidate {   \"metric_data\": {     \"from\": \"2016-01-28T18:06:06+00:00\",     \"to\": \"2016-01-28T18:36:06+00:00\",     \"metrics_not_found\": [], <---<<< INDICATES NO INVALID METRIC NAMES REQUESTED     \"metrics_found\": [       \"HttpDispatcher\" <---<<< INDICATES THIS METRIC NAME WAS VALID     ],     \"metrics\": [ <---<<< DATA RETURNED       {         \"name\": \"HttpDispatcher\",         \"timeslices\": [           {             \"from\": \"2016-01-28T18:03:00+00:00\",             \"to\": \"2016-01-28T18:04:00+00:00\",             \"values\": {               \"average_response_time\": 364,               \"calls_per_minute\": 99800,               \"call_count\": 99770,               \"min_response_time\": 3.5,               \"max_response_time\": 85000,               \"average_exclusive_time\": 0,               \"average_value\": 0.364,               \"total_call_time_per_minute\": 36300,               \"requests_per_minute\": 99800,               \"standard_deviation\": 1900,               \"average_call_time\": 364 ... Copy Here is an example of output for a invalid metric name, Foo. HTTP/1.1 200 OK etag: \"e51782cf7c5a5596139a7f5340c3de23\" Content-Type: application/json cache-control: max-age=0, private, must-revalidate {   \"metric_data\": {     \"from\": \"2016-01-28T18:06:33+00:00\",     \"to\": \"2016-01-28T18:36:33+00:00\",     \"metrics_not_found\": [       \"Foo\" <---<<< INDICATES THIS METRIC NAME WAS INVALID     ],     \"metrics_found\": [], <---<<< INDICATES NO VALID METRIC NAMES FOUND     \"metrics\": [] <---<<< NO DATA RETURNED   } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1246.0284,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Extract <em>metric</em> <em>timeslice</em> <em>data</em>",
        "sections": "Extract <em>metric</em> <em>timeslice</em> <em>data</em>",
        "body": "One type of New Relic <em>data</em> is <em>metric</em> <em>timeslice</em> <em>data</em>. There are several ways to <em>query</em> <em>metric</em> <em>timeslice</em> <em>data</em>: You can <em>query</em> <em>APM</em> <em>metric</em> <em>timeslice</em> <em>data</em> via <em>NRQL</em> (and therefore via our NerdGraph API). You can <em>query</em> any <em>metric</em> <em>timeslice</em> <em>data</em> via the REST API This doc explains how to do this with the REST"
      },
      "id": "60440691e7b9d201b8579a00"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-06-25T19:53:35Z",
      "updated_at": "2021-06-25T19:53:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and account/user structure. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and LogExtendedRecord Metric group: LoggingBytes Log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes Namespaces that contain all tracing events, including tracing spans and excluding internal tracing. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest Important This feature is currently in limited availability. If you're interested in getting access, speak to your New Relic account representative. You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.70992,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>data</em> coming into New Relic",
        "sections": "Manage <em>data</em> coming into New Relic",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": ". The sources are described here. Billable <em>data</em> sources Description Timeslices (1-minute) and <em>Metric</em>:Raw Metrics are timeslices + <em>Metric</em>Raw <em>Metric</em> group: MetricsBytes <em>Metric</em> <em>timeslice</em> <em>data</em> averages to one-hour periods after eight days. After 90 days, the permanent <em>metric</em> <em>data</em> continues to be stored in one"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/images/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-06-26T08:49:37Z",
      "updated_at": "2021-06-20T18:19:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Simulate SQL JOIN functions Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and Browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a New Relic APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. For more on faceting on multiple attributes, with some real-world examples, see this New Relic blog post. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. See Set time range on dashboards and charts for detailed information and examples. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our tools that use that API, like our Telemetry SDKs and our open-source telemetry integrations (OpenTelemetry, Kamon, Micrometer, more). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more on understanding these data types, see Metric data types. Functions Here is a listing of the available functions in NRQL. The definitions below contain example NRQL queries. Aggregator functions Use aggregator functions to filter and aggregate data in a NRQL query. Some helpful information about using aggregator functions: See the New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. Data type \"coercion\" is not supported. Read about available type conversion functions. Cohort analysis functions appear on the New Relic Insights Cohort analysis page. The cohort functions aggregate transactions into time segments. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (i.e. 0-59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.0388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> <em>metric</em> <em>data</em>",
        "tags": "<em>Query</em> your <em>data</em>",
        "body": ", Micrometer, more). <em>Query</em> <em>metric</em> <em>timeslice</em> <em>data</em>, which is our original <em>metric</em> <em>data</em> type reported by our <em>APM</em>, mobile monitoring, and browser monitoring. For more on understanding these <em>data</em> types, see <em>Metric</em> <em>data</em> types. Functions Here is a listing of the available functions in <em>NRQL</em>. The definitions below"
      },
      "id": "604456c1196a678db8960f41"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/metric-data/query-metric-data-type": [
    {
      "sections": [
        "Transition to New Relic One from Insights",
        "Important",
        "Features",
        "Improved query abilities",
        "Improved visualizations",
        "Steps for a successful transition"
      ],
      "title": "Transition to New Relic One from Insights",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "4af99cd8030909a71d21a359a60af5ac93b93a66",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/transition-new-relic-one-insights/",
      "published_at": "2021-06-26T14:45:52Z",
      "updated_at": "2021-05-22T00:14:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we're upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. Released in 2014, New Relic Insights was our original way to create custom queries, charts, and dashboards. With New Relic One, we have modernized the experience for you to access, analyze, and visualize your data. New Relic One offers an improved charts and dashboards experience, and it provides a platform where we can more rapidly bring new innovations to you. This transition guide can help you understand: What are some of the new and improved features you get with New Relic One charts, dashboards, and queries Why it's easy to transition to New Relic One What to know and considerations when you make the switch How to get the most out of using New Relic One Features You can scroll down to the transition details, but first here are some features we've added that show how New Relic One dashboards are a clear improvement over Insights dashboards. Improved query abilities With New Relic One, you get: Ability to query many accounts from the same widget: New Relic One lets you query across all your associated accounts in one place. Better querying and charting experiences: Query access is available globally, no matter where you are in New Relic One. This includes a \"basic\" query mode that doesn't require knowledge of NRQL. Improved query experience: You can query both the Metric data type and metric timeslice data. Easy customization: Every visualization now has the query accessible. You can augment any curated chart just by changing the NRQL query. Improved visualizations Not only can you select a wide range of visualization options, you can also add more to your dashboards: Better display options: Make your data easier to understand by using visualizations other than dense, line-heavy charts. New Relic One also offers a better TV mode. Facet linking: You can filter your dashboards by faceted attributes, making your dashboards more interactive and easy to use. There's also support for cases. Learn more. More charts or widgets in an area: Insights restricted you to a 3-across limit. Now you can display up to 12 across your dashboard, providing increased data density along with improved tooltips and tracking across charts. Easier creation of multi-page dashboards: Insights referred to these as data apps. Your Insights data apps are preserved as multi-page dashboards in New Relic One. Chart consistency and flexibility: Dashboards include facet color consistency across widgets and faster loading times for more performant dashboards. Also, you can add any chart type to a dashboard in New Relic One! The New Relic Insights UI has served our users well for many years, but it's time to give you an even better experience. Join us and make the switch to New Relic One! Steps for a successful transition The transition to New Relic One has two parts: the UI and mobile app experience (April 12, 2021) and the Dashboard API (July 2021). Insights functionality Transition to New Relic One UI We have already taken care of your transition from Insights to New Relic One for you! As of April 12, 2021, your old Insights web URLs redirect automatically to New Relic One. We recommend that you familiarize yourself with the new UI features available to you, as described in this transition guide. If you need to view any Insights charts embedded in other websites, go to one.newrelic.com > More > Manage Data. (These older embedded charts will continue to function as expected.) Mobile apps Your Insights mobile app is deprecated as of April 11, 2021. Go to the Google Play Store 2 or Apple App store. Delete your old Insights mobile app, and download the New Relic One mobile app. tvOS apps and large displays New Relic's tvOS app is still available. No action is needed by you at this time. Some New Relic customers with the original pricing model may have set up dashboards on wall screens for restricted users with kiosk mode. No action is required for you to continue to view these dashboards. APIs In July of 2021, the Insights Dashboard API will be deprecated and replaced with NerdGraph functionality. For more on this change, and tips on how to migrate, see NerdGraph API for dashboards. Partnership accounts This applies only if your account is one of the few using our partnership account structure to deliver New Relic services to your direct customers. In this situation, the Insights EOL will not affect your customers’ pricing. This is simply an EOL for the UI, not an EOL for the account type. Questions If you have questions about the transition, please comment in our Explorers Hub post. Or, if you work with an account team, they will be happy to help you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 420.29242,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Improved <em>query</em> abilities",
        "body": " a &quot;basic&quot; <em>query</em> mode that doesn&#x27;t require knowledge of NRQL. Improved <em>query</em> experience: You can <em>query</em> both the <em>Metric</em> <em>data</em> <em>type</em> and <em>metric</em> timeslice <em>data</em>. Easy customization: Every visualization now has the <em>query</em> accessible. You can augment any curated chart just by changing the NRQL <em>query</em>"
      },
      "id": "6044171164441f454a378ee2"
    },
    {
      "sections": [
        "StatsD monitoring integration (version 2)",
        "Features",
        "Requirements",
        "Install",
        "Install for Kubernetes",
        "Kubernetes manifest examples",
        "Configure",
        "Tip",
        "Example of custom configuration",
        "Docker: overwrite default configuration",
        "Kubernetes: overwrite default configuration",
        "Metric format",
        "Metric types",
        "Counter",
        "Gauge",
        "Timer",
        "Add tags (attributes)",
        "Add default tags that apply to all metrics",
        "Add metric-level tags",
        "Create alerts",
        "Alert example",
        "Find and use data",
        "Check the source code"
      ],
      "title": "StatsD monitoring integration (version 2) ",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "85d86411ef83d98a2d2ab602f1259b71864e056d",
      "image": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/images/statsd-nrql-alert-condition-example.png",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/",
      "published_at": "2021-06-29T02:00:05Z",
      "updated_at": "2021-05-15T13:55:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The second version of our StatsD integration was released on May 25 2020. It's an improvement on our first StatsD integration. Improvements include: simpler configuration, and a simpler method for adding tags (key-value pairs). Features Our StatsD integration (version 2) lets you easily get StatsD-format data into New Relic. You can also add any arbitrary tags (key-value pairs) to your data. Once your metrics are in New Relic, you can query your data and create custom charts and dashboards. Requirements This integration uses our Metric API and our Event API to ingest data. To use these APIs, you'll need an Insert API key. The integration adheres to the Metric API requirements and data limits. The default rate limit is 100,000 data points per minute (DPM). If you think you're missing metrics or sending more than 100K DPM, see Request data changes. To see if your account is hitting the rate limit, run the following NRQL query: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' FACET category, message LIMIT 100 since 1 day ago Copy Install This section will explain how to do a standard install. If you want to run StatsD in Kubernetes, see Kubernetes install. To install the StatsD integration, run the following command and include your New Relic account ID and New Relic Insert API key. This generates a TOML configuration file used by gostatsd. docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=YOUR_INSERT_API_KEY \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy If your account is in the EU data center region, add this to the above command: -e NR_EU_REGION=true \\ Copy After installing, you can: Do optional additional configuration Define your metrics Add custom tags to your data Create alerts Install for Kubernetes Here are examples of Kubernetes manifests for deployment and service objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: apiVersion: apps/v1 kind: Deployment metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: selector: matchLabels: app: newrelic-statsd replicas: 2 revisionHistoryLimit: 2 template: metadata: labels: app: newrelic-statsd spec: containers: - name: newrelic-statsd image: newrelic/nri-statsd:2.0.0 env: - name: NR_ACCOUNT_ID value: \"NEW_RELIC_ACCOUNT_ID\" - name: NR_API_KEY value: \"NEW_RELIC_LICENSE_KEY\" Copy service.yml: apiVersion: v1 kind: Service metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: type: ClusterIP ports: - name: newrelic-statsd port: 80 targetPort: 8125 protocol: UDP selector: app: newrelic-statsd Copy For configuration details, see Kubernetes configuration. Configure In the install procedure, you run nri-statsd with environment variables, and this generates a TOML configuration file. Additionally, you can set these configuration options: Configuration options Description expiry-interval string If a metric is not updated for this amount of time, we stop reporting that metric. Default is 5m. If you want to send the metrics only if the value was updated between the flush intervals, configure this to 1ms. To never expire metrics, set it to 0. percent-threshold list of integers Specifies the percentiles used for metrics aggregation. Default: 90. metrics-addr string Indicates address on which to listen for metrics. Default: :8125. Tip To ensure FedRAMP compliance when using the StatsD integration you must define the following endpoints in the custom configuration: address = 'https://gov-insights-collector.newrelic.com/v1/accounts/ $NR_ACCOUNT_ID/events' Copy address-metrics = 'https://gov-infra-api.newrelic.com/metric/v1' Copy Here are some examples of customizing configuration by overwriting the default configuration: Example of custom configuration # Specify after how long do we expire metrics, default:5m expiry-interval = '1ms' # percent-threshold specify a list of percentiles for metrics aggregation, default:90 percent-threshold = [90, 99] backends='newrelic' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://insights-collector.newrelic.com/v1/accounts/$NR_ACCOUNT_ID/events' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_API_KEY' Copy Disable timer sub-metrics: By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. If you want to disable those metrics you can do it by adding a disabled-sub-metrics configuration section and set true for the ones you want disabled. Here's an example: # disabled-sub-metrics configuration section allows disabling timer sub-metrics [disabled-sub-metrics] # Regular metrics count=false count-per-second=false mean=false median=false lower=false upper=false stddev=false sum=false sum-squares=false # Percentile metrics count-pct=false mean-pct=false sum-pct=false sum-squares-pct=false lower-pct=false upper-pct=false Copy Docker: overwrite default configuration To overwrite the default nri-statsd configuration while running in a container, you can mount a configuration file inside the container. You can adopt the following template as needed for your situation. Example: backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_API_KEY' Copy To run the container with the file mounted in the appropriate path: docker run \\ ... -v ${PWD}/nri-statsd.toml:/etc/opt/newrelic/nri-statsd.toml \\ ... newrelic/nri-statsd:2.0.0 Copy Kubernetes: overwrite default configuration The best approach to configure nri-statsd running in Kubernetes is to use a configMap and mount the configMap into the container. (This is a similar process to mounting the configuration file in Docker.) Example: apiVersion: v1 kind: ConfigMap metadata: name: nri-statsd-config namespace: default data: nri-statsd.toml: | backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://metric-api.newrelic.com/metric/v1' api-key = '$NEW_RELIC_API_KEY' Copy To use the configMap, declare a volume on your deployment spec template and then declare a volumeMount on your container spec. Example: apiVersion: apps/v1 kind: Deployment spec: template: spec: containers: .... volumeMounts: - mountPath: /etc/opt/newrelic/ name: nri-statsd-config volumes: - name: nri-statsd-config configMap: name: nri-statsd-config Copy Metric format The integration receives metrics using the StatsD protocol. Optionally, the sample rate can be configured and tags can be added. Here's the metric data format we use: <metric name>:<value>|<type>|@<sample rate>|#<tags> Copy Here are explanations of these fields: Field name Description < metric name> string Required. Name of the metric. < value> string Required. The metric type: c = counter g = gauge ms = timer @ < sample rate> float Optional for simple counters or timer counters. When many metrics must be sent, you can use sampling to reduce network traffic. The downside is a reduction in the resolution of the data. An example of how this would work for sample rates below 1: If you set this to 0.1, the counter would send a measurement one out of every 10 times. # < tags> string Optional. Tags attached to your metrics are converted into attributes (key-value pairs). For more on tagging options, see Tags. Metric types Here are the types of metrics and how to format them: Counter A counter measures the number of occurrences of an event. Examples include cache hits per reporting interval and the number of threads created per reporting interval. A counter can be incremented or decremented during the same flush interval by adding a sign to the value. In the following example, the counter value will be 2: counter:4|c counter:-2|c Copy At each flush, the current count is sent and reset to 0. If the count is not updated, at the next flush it will send the value 0. You can opt to disable this behavior by setting expiry-interval to 1ms. Here’s an example of a counter that is being sampled 1 out of 10 times: counter:4|c@0.1 Copy Gauge A gauge represents a value that can increase or decrease with time. Examples of gauges include temperature, CPU usage, and memory. Here's an example: temperature:40|g Copy If the gauge is not updated, at the next flush it will send the previous value. You can opt to disable this behavior by setting expiry-interval to 1ms. Timer The timer metric type measures timing data. By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. These are sent as sub-metrics in the following format: <metric_base_name>.std_dev <metric_base_name>.median <metric_base_name>.summary <metric_base_name>.sum_squares <metric_base_name>.mean <metric_base_name>.per_second Copy The configured percentiles will generate the following metrics. The percentile threshold value will be attached as a tag. <metric_base_name>.sum_squares.percentiles <metric_base_name>.sum.percentiles <metric_base_name>.count.percentiles <metric_base_name>.upper.percentiles <metric_base_name>.mean.percentiles Copy The percentile threshold can be tweaked with the percent-threshold config option. These can be controlled through the disabled-sub-metrics configuration section. Add tags (attributes) You can add tags to your data, which we save as attributes (key-value pairs). There are two options for adding tags: Add default tags that apply to all metrics: These apply to all metrics. They are fixed and don't change over time. Add metric-level tags: These apply to specific metrics and allow the value to be changed between two submits. Add default tags that apply to all metrics Add tags to metrics and events by defining an environment variable in the startup command. Here's an example that would create two tags: -e TAGS=\"environment:production region:us\" Copy Here's that environment variable used in the startup command: docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=YOUR_INSERT_API_KEY \\ -e TAGS=\"environment:production region:us\" \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy Add metric-level tags When defining the metric format, you can add tags using this format: <bucket name>:<value>|<type>|#<tags> Copy In this example, <tags> is a comma-separated list of tags. Tags format is: simple or key:value. Here's an example NRQL query that includes a custom tag: SELECT count(*) FROM Metric WHERE environment = 'production' Copy Create alerts You can alert on StatsD data using NRQL alert conditions. Alert example This procedure walks you through sending some sample data and then creating an alert condition using that data. First, send this data to New Relic’s StatsD container: echo \"prod.test.num:32|g\" | nc -v -w 1 -u localhost 8125 Copy Next, create a NRQL alert condition using this query: SELECT latest(prod.test.num) FROM Metric WHERE metricName = 'prod.test.num' Copy Here's an image showing creating this NRQL alert condition. Notice that the sample data sent in is represented by the blue dot on the upper right of the chart. Now we can create the alert condition with these settings: Remember to set the Condition name. If a metric with a value above 50 is sent, then an incident is created and notified. The incident is closed automatically after 24 hours. To test that the alert is working, run this command: echo \"prod.test.num:60|g\" | nc -v -w 1 -u localhost 8125 Copy Find and use data To query your data, you'd use any New Relic query option. For example, you might run a NRQL query like: SELECT count(*) FROM Metric WHERE metricName = 'myMetric' and environment = 'production' Copy For more on how to query the Metric data type, see Query metric data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 410.89102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Metric</em> <em>types</em>",
        "body": "&gt;:&lt;value&gt;|&lt;<em>type</em>&gt;|#&lt;tags&gt; Copy In this example, &lt;tags&gt; is a comma-separated list of tags. Tags format is: simple or key:value. Here&#x27;s an example NRQL <em>query</em> that includes a custom tag: SELECT count(*) FROM <em>Metric</em> WHERE environment = &#x27;production&#x27; Copy Create alerts You can alert on StatsD <em>data</em> using NRQL"
      },
      "id": "6043a32364441fa554378eee"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-06-25T16:18:05Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze and monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Why create <em>metrics</em> from other <em>data</em> <em>types</em>?",
        "tags": "Convert <em>data</em> to <em>metrics</em>",
        "body": " retention is 13 months. <em>Query</em> capabilities You can <em>query</em> using the <em>Metric</em> <em>data</em> <em>type</em>. When you create metrics, this does not delete your events or other types of <em>data</em>. However, metrics are better for longer-range querying and charting. To get started converting your <em>data</em> to metrics, create a rule"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    }
  ]
}