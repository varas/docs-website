{
  "/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Tip",
        "Prerequisites",
        "Enable SPA monitoring",
        "Disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-06-20T11:12:40Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic UI, you can enable single-page app (SPA) monitoring. Tip To use SPA and browser monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Prerequisites In order to deploy SPA monitoring, you must: Make sure your app and Browser agent version meet New Relic's compatibility and requirements. Agree to the Terms of Service, which automatically appears during the setup process for the first app you select for your account. By agreeing to the Terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for your account. Enable SPA monitoring To deploy SPA monitoring for your app, you must already have a Pro subscription. Then, you must enable Pro + SPA monitoring, and deploy a new JavaScript snippet that includes SPA monitoring. Tip The bottom of the generated JavaScript snippet includes your Browser license key and application ID. This is useful, for example, when using the New Relic REST API (v2) or API Explorer. To enable SPA monitoring: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings, then select Pro + SPA. Agree to the Terms of Service. Select Save application settings. Deploy the new JavaScript snippet using the same method you used when you originally deployed Browser for your app: If you deploy Browser with the copy/paste method: Copy the entire JavaScript code snippet. Paste it as close to the top of the HEAD of your webpage as possible, but after any position-sensitive META tags (for example, X-UA-Compatible or charset information). If you deploy using an APM agent: If possible, restart your app and clear the server-side cache to ensure the APM agent picks up the change and deploys the new JavaScript snippet. Generate some traffic, then wait a few minutes for Browser to start receiving SPA monitoring data. To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. If SPA data does not start to appear in the Page views page after a few minutes, see Browser's troubleshooting procedures. Disable SPA monitoring To opt out of our SPA monitoring feature: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings. Select a different agent version/loader option. Select Save application settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.08046,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In the New Relic UI, you can enable <em>single</em>-<em>page</em> <em>app</em> (SPA) <em>monitoring</em>. Tip To use SPA and <em>browser</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features",
        "For more help"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-06-20T15:19:12Z",
      "updated_at": "2021-03-11T07:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page applications (SPAs) are web applications that load a single HTML page. The app dynamically updates without requiring a full page reload, in response to user interactions with the app, such as clicking a button or submitting a request. Browser's SPA monitoring provides deeper visibility and actionable insights into real users' experiences with single-page apps. SPA monitoring is also valuable for any app that uses AJAX requests to pull content dynamically and create a fluid user experience. In addition to monitoring route changes automatically, you can use Browser monitoring's SPA API to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring Before installing SPA monitoring, read SPA compatibility and requirements. Then, see Add apps to Single Page App monitoring. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use Browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by Browser monitoring can include: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in Browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in Browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing Browser account's data usage, see SPA and Browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes. For more help Additional documentation resources include: SPA compatibility and requirements (see technical requirements for getting single-page app monitoring from New Relic) View SPA data in Browser monitoring (understand how Browser displays your data in the UI) Understand SPA data collection (learn how we collect and save your SPA data)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.80801,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage of these features Robust views in <em>Browser</em>&#x27;s UI When a user initiates a <em>page</em> load or route change, New Relic begins to <em>monitor</em> all subsequent JavaScript, and ends the timing once all AJAX events are complete"
      },
      "id": "604408d328ccbcf69e2c6064"
    },
    {
      "sections": [
        "Missing route changes with SPA agent",
        "Problem",
        "Solution",
        "Short term solutions",
        "Support",
        "Cause"
      ],
      "title": "Missing route changes with SPA agent",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Troubleshooting"
      ],
      "external_id": "9ca088a0459684464512ee51dfb7ffca22e26c14",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent/",
      "published_at": "2021-06-20T14:25:33Z",
      "updated_at": "2021-03-16T06:51:00Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using the Browser Pro + SPA agent, but you are not seeing all of the route change browser interactions you expect. We are aware that this can be frustrating. Our goal in summer 2020 is to reevaluate the SPA feature functionality, making it simpler and more reliable, starting with the methods we use to detect and capture route changes. Additionally, we plan to add new frameworks and use cases to our testing suite based on your feedback and examples. Likely this work will include new APIs as well as framework-specific plug-ins. Check our release notes for the latest updates. Solution Short term solutions To make sure all route changes are captured, you can use our SPA interaction() API. Using the interaction API will categorize the BrowserInteraction event (in the category attribute) as custom rather than a route change if no route change is in fact detected. If your framework is exposing events that represent router activity, you can use custom instrumentation in these events. Here is an example using our API with the Angular router: router.events.subscribe( (event: Event) => { if (event instanceof NavigationStart) { let i = newrelic.interaction() i.setName(event.url) i.save() } }); Copy In this example, the router object is an instance of the Angular router (from the @angular/router module). The setName call sets the name attribute of the BrowserInteraction event to the new URL, and the save call ensures that the interaction is captured. You will need to adapt this for the needs of your own application’s framework. If your framework does not provide routing events, then you can add this code in the event handler of the original interaction event such as click): myButton.addEventListener('click', function () { let i = newrelic.interaction() i.setName(‘new URL') i.save() }); Copy Recommendation: If you do not have access to router events nor the interaction event handler, implement this as soon as possible in code that you know is the result of a user interaction. An alternative to using the SPA API is to capture routes as PageAction events. PageAction events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in BrowserInteraction events. Both of these solutions can ensure these events are captured, either as a BrowserInteraction event or as a PageAction event. However, they will not address recording the correct duration and related AJAX calls. Support If this solution does not resolve your issue, please file a support ticket, and have the following information available: For situations where you are seeing most route changes, but none for a particular route change you expect, attempt to evaluate the difference in the implementation of the code for that particular route. Is there something non-standard or unique about that route that you could provide to our support team? Document the frameworks and any libraries that might be of interest. If this is a new problem, has anything changed in your environment that has led to these interactions suddenly not being tracked? Note the Browser agent version you are using. If you are more than a few releases behind, we will recommend that you update to the latest release, as we may have already resolved a similar issue. Be aware that due to the complexity of diagnosing these issues, the team will likely need access to an environment and code that demonstrates the problem for testing and research. Cause The Browser product attempts to be framework agnostic, as well as support coding best practices. However, there are often edge cases that will be missed that lead to you not collecting the route changes you expect. The implementation is based on instrumenting most common asynchronous browser APIs. There are cases when a web application uses some asynchronous API or uses custom or third-party code that we do not instrument, and this can result in inaccurate or missed route changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.20633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": ". <em>Page</em>Action events can be used to capture any custom data. We recommend this option as a fallback in case using the SPA interaction API does not work as expected, or to completely separate the custom instrumentation from built-in <em>Browser</em>Interaction events. Both of these solutions can ensure these events"
      },
      "id": "603e937628ccbcd4efeba750"
    }
  ],
  "/docs/browser/single-page-app-monitoring/troubleshooting/missing-route-changes-spa-agent": [
    {
      "sections": [
        "Install Single Page App monitoring",
        "Tip",
        "Prerequisites",
        "Enable SPA monitoring",
        "Disable SPA monitoring"
      ],
      "title": "Install Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "04501b8d90b2c9b3bf3fa29f1662596a1379e2b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/install-single-page-app-monitoring/",
      "published_at": "2021-06-20T11:12:40Z",
      "updated_at": "2021-03-13T02:45:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic UI, you can enable single-page app (SPA) monitoring. Tip To use SPA and browser monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Prerequisites In order to deploy SPA monitoring, you must: Make sure your app and Browser agent version meet New Relic's compatibility and requirements. Agree to the Terms of Service, which automatically appears during the setup process for the first app you select for your account. By agreeing to the Terms, you authorize New Relic to collect hash fragments from URLs. You only need to select the checkbox option once for your account. Enable SPA monitoring To deploy SPA monitoring for your app, you must already have a Pro subscription. Then, you must enable Pro + SPA monitoring, and deploy a new JavaScript snippet that includes SPA monitoring. Tip The bottom of the generated JavaScript snippet includes your Browser license key and application ID. This is useful, for example, when using the New Relic REST API (v2) or API Explorer. To enable SPA monitoring: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings, then select Pro + SPA. Agree to the Terms of Service. Select Save application settings. Deploy the new JavaScript snippet using the same method you used when you originally deployed Browser for your app: If you deploy Browser with the copy/paste method: Copy the entire JavaScript code snippet. Paste it as close to the top of the HEAD of your webpage as possible, but after any position-sensitive META tags (for example, X-UA-Compatible or charset information). If you deploy using an APM agent: If possible, restart your app and clear the server-side cache to ensure the APM agent picks up the change and deploys the new JavaScript snippet. Generate some traffic, then wait a few minutes for Browser to start receiving SPA monitoring data. To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. If SPA data does not start to appear in the Page views page after a few minutes, see Browser's troubleshooting procedures. Disable SPA monitoring To opt out of our SPA monitoring feature: Go to one.newrelic.com > Browser > (select an app) > Settings > Application settings. Select a different agent version/loader option. Select Save application settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.88469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Install <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In the New Relic UI, you can enable <em>single</em>-<em>page</em> <em>app</em> (SPA) <em>monitoring</em>. Tip To use SPA and <em>browser</em> <em>monitoring</em>, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month"
      },
      "id": "6043f16664441f56fa378eec"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-20T12:36:07Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.23013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Browser</em> agent version",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (SPA) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these SPA <em>monitoring</em> requirements. <em>Browser</em> agent version SPA <em>monitoring</em> requires an SPA-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    },
    {
      "sections": [
        "Introduction to Single Page App monitoring",
        "Enable SPA monitoring",
        "Analyze throughput and performance data",
        "Browser SPA features",
        "For more help"
      ],
      "title": "Introduction to Single Page App monitoring",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "6dedda52851e1ca1f180c8d88bdcb7038c4d1b5d",
      "image": "https://docs.newrelic.com/static/98d434a02c314f2bd2ce9828aa7b755d/c1b63/browser_SPA.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/introduction-single-page-app-monitoring/",
      "published_at": "2021-06-20T15:19:12Z",
      "updated_at": "2021-03-11T07:33:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Single page applications (SPAs) are web applications that load a single HTML page. The app dynamically updates without requiring a full page reload, in response to user interactions with the app, such as clicking a button or submitting a request. Browser's SPA monitoring provides deeper visibility and actionable insights into real users' experiences with single-page apps. SPA monitoring is also valuable for any app that uses AJAX requests to pull content dynamically and create a fluid user experience. In addition to monitoring route changes automatically, you can use Browser monitoring's SPA API to monitor virtually anything that executes inside the browser. This allows developers and their team to: Create faster, more responsive, highly interactive apps. Monitor the throughput and performance that real users are experiencing. Troubleshoot and resolve problems within the context of the page load. Query your data to assist with business decisions. Bring better apps to the marketplace more quickly. Enable SPA monitoring Before installing SPA monitoring, read SPA compatibility and requirements. Then, see Add apps to Single Page App monitoring. Analyze throughput and performance data Improving on traditional industry standards for measuring page load timing, we give you a complete picture of the activity, both synchronous and asynchronous, associated with page loads and route changes. one.newrelic.com > Browser > (select an app) > Page views: Use Browser monitoring's SPA monitoring to examine the throughput and performance of your SPA-architecture app. SPA data monitored by Browser monitoring can include: Performance data and throughput for page loads and route changes AJAX request data JavaScript activity, both synchronous and asynchronous Dynamic page updates, monitored using the SPA API With this data, you will gain a clear understanding of how your users experience your app's page loads and route changes, and be able to solve bottlenecks and troubleshoot errors. For more about how New Relic handles SPA data, see Understand SPA data collection. Browser SPA features Here is a summary of SPA monitoring features: Single-page app monitoring Take advantage of these features Robust views in Browser's UI When a user initiates a page load or route change, New Relic begins to monitor all subsequent JavaScript, and ends the timing once all AJAX events are complete. This provides a more accurate view of when a page is actually ready for a user compared to the traditional method of ending the timing when the window load event is fired. When SPA monitoring is enabled, the Page views page in Browser shows event-driven data about application usage levels (throughput) and user experience (performance), including: Charts with drill-down details about initial page load performance, route changes, and historical performance Sort, search, and filter options, including custom attributes Additional AJAX breakdown data for all initial page loads and route changes For an explanation of how SPA monitoring will impact your existing Browser account's data usage, see SPA and Browser data usage. Data analysis with data explorer The data explorer supports three SPA-specific event types: BrowserInteraction, AjaxRequest, and BrowserTiming. You can query these events in the query builder to analyze your app's performance and make business decisions. Customized data from API Use SPA API to obtain the specific data you need, such as custom naming, custom timing, finishline API, or other custom attributes. For more help Additional documentation resources include: SPA compatibility and requirements (see technical requirements for getting single-page app monitoring from New Relic) View SPA data in Browser monitoring (understand how Browser displays your data in the UI) Understand SPA data collection (learn how we collect and save your SPA data)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.621,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Single</em> <em>Page</em> <em>App</em> <em>monitoring</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": " features Here is a summary of SPA <em>monitoring</em> features: <em>Single</em>-<em>page</em> <em>app</em> <em>monitoring</em> Take advantage of these features Robust views in <em>Browser</em>&#x27;s UI When a user initiates a <em>page</em> load or route change, New Relic begins to <em>monitor</em> all subsequent JavaScript, and ends the timing once all AJAX events are complete"
      },
      "id": "604408d328ccbcf69e2c6064"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection": [
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-06-20T10:42:50Z",
      "updated_at": "2021-03-13T02:42:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the Browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the Browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by Browser Interaction Name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line represents when the window load event is fired. This corresponds to the traditional page load timing measured by New Relic Browser without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical Performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical Performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.59842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-06-20T10:42:49Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.27763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-20T12:36:07Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.23013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-06-20T18:08:55Z",
      "updated_at": "2021-03-11T04:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how Browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the Browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the Browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, Browser initiates monitoring but then discards them. If these interactions do lead to a route change, Browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the Browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for Browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.89886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>Browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>Browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "View SPA data in Browser UI",
        "Single-page app (SPA) data",
        "Filter SPA views",
        "Group SPA views",
        "SPA view details",
        "Initial page load performance details",
        "Route change performance details"
      ],
      "title": "View SPA data in Browser UI",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "0ab30db71f34da6376ff5e71734292b247754ca4",
      "image": "https://docs.newrelic.com/static/04bcea9186a93fc786a6db3469765824/c1b63/spa_overview.png",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/",
      "published_at": "2021-06-20T10:42:50Z",
      "updated_at": "2021-03-13T02:42:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have opted in to SPA (single-page app) monitoring, the Browser Page views page will include data on SPA route changes and initial page loads. one.newrelic.com > Browser > (select an app) > Page views: When you opt in to SPA monitoring, the Browser Page views page will display SPA data like route changes and associated asynchronous browser activity. Single-page app (SPA) data To view SPA data: Go to one.newrelic.com > Browser > (select an app) > Page views. Initial page loads and route changes are automatically grouped by Browser Interaction Name. You can adjust this with your allow list settings for segments. If you set custom route names with the SPA API, the custom route names will be displayed. You can change how the page loads and route changes are grouped by using the Group page by dropdown. By default, the list of page loads and route changes displays the most time consuming views at the top of the list. You can also sort by average response time, median response time, and throughput per minute by using the Sort by dropdown. To search for specific views by grouped URL, type in the search bar below the Sort by dropdown. For example, to find URLs that represent your checkout page, search for checkout. The charts on the initial Page view page display: The five views with the slowest average response times The five views with the highest throughput To change the range of time being examined, use the time picker near the top of the page. (If you choose a time range more than eight days in the past, some filtering and grouping functionality won't be available.) Filter SPA views one.newrelic.com > Browser > (select an app) > Page views > Filter: Use the Filter to filter for route changes, initial page loads, and other attributes like location and browser type. To view only initial page loads or only route changes, use the Filter dropdown. For example, to view only route changes, select Filter > Route change. The filter also gives you the ability to filter by other attributes of page loads and route changes, such as app name, geographical location of the browser, and browser type. For example, to see only page loads and route changes that occurred on browsers in the city of Portland, Oregon, select Filter > City > Portland. Group SPA views You can use the Group page by dropdown to group the list of page views by any attribute. For example, if you want to compare the average response times by browser type, select Group page by > userAgent. The combination of filtering and grouping lets you quickly find very specific data. For example, to compare how a specific URL is loading on different browsers: From the Filter dropdown, select targetURL, then select the URL you want to study. From the Group page by dropdown, select userAgent. SPA view details one.newrelic.com > Browser > (select an app) > Page views > (select a view): Select a view from the list to see assorted details and breakdowns. Select an individual page load or route change to see details. Selecting either will provide a breakdown of where time was spent for a browser interaction, and display that data over a time series matching the window selected in the time picker. Every route change view can theoretically also be an initial page load. (For example, when a route change URL is sent to someone else and they load it, that will now be considered an initial page load to New Relic.) This is why the SPA view details page has charts for both initial page loads and route changes. This allows you to compare how a view performs as an initial page load to how its performance as a route change. There are three chart display options, selectable with the icons to the right of the Avg initial page load time chart title. The default display is the color-coded stacked area chart. You can also switch to a Histogram display or a percentile line graph. Also on the details page is a Throughput chart that combines initial page loads and route changes. The chart displays the 5 pages with the highest throughput, which are listed beneath the chart, and consolidates all other pages into Other. Here are details on the specific performance data displayed for both page loads and route changes: Initial page load performance details For initial page loads, the performance details include the average back end time, front end time, and the window onload event: Back end time includes network, web app time, and request queuing. Front end time includes DOM processing, page rendering, and the time to complete all XHRs. A horizontal red line represents when the window load event is fired. This corresponds to the traditional page load timing measured by New Relic Browser without SPA monitoring enabled. With SPA monitoring it is common to have a window load event before the front end time is complete. (For more about how SPA page load timing differs from traditional page load timing, see Understand SPA data collection.) Route change performance details For route changes, the performance chart displays JS duration and waiting time. JS Duration is the sum of all JavaScript execution time during the interaction, which is synchronous by definition. The remaining time is called Waiting time and is derived by subtracting JS duration from the total duration. The Historical Performance and Breakdown details are similar for both page loads and route changes: Detail tab Comments Historical data The Historical Performance tab displays throughput (views per minute) and response time charted against the same time period yesterday and last week. Breakdowns The Breakdowns tab lists the various components individually timed as part of an interaction. By default, all XHRs are captured and timed. You can also use the SPA API to include additional elements for a route change or page load.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.59842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>SPA</em> <em>data</em> in <em>Browser</em> UI",
        "sections": "<em>Single</em>-<em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "If you have opted in to <em>SPA</em> (<em>single</em>-<em>page</em> <em>app</em>) <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will include <em>data</em> on <em>SPA</em> route changes and initial <em>page</em> loads. one.newrelic.com &gt; <em>Browser</em> &gt; (select an <em>app</em>) &gt; <em>Page</em> views: When you opt in to <em>SPA</em> <em>monitoring</em>, the <em>Browser</em> <em>Page</em> views <em>page</em> will display <em>SPA</em> <em>data</em> like"
      },
      "id": "60440de328ccbc26592c60be"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-20T12:36:07Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.23013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui": [
    {
      "sections": [
        "SPA data collection",
        "Browser interactions",
        "Types of SPA data reporting",
        "Initial page loads",
        "Route changes",
        "Custom monitoring",
        "Difference from traditional page load timing",
        "Tip",
        "Timers",
        "Events and attributes"
      ],
      "title": "SPA data collection",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "d42d239aca2ea13a37fd926dca3672fcf83d73dd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/spa-data-collection/",
      "published_at": "2021-06-20T18:08:55Z",
      "updated_at": "2021-03-11T04:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains how Browser collects and stores your asynchronous single page app (SPA) data. This will give you a better understanding of the SPA data you see in the Browser UI. This will also help you more easily add custom monitoring with the SPA API. Browser interactions At the heart of SPA monitoring is the concept of the browser interaction. New Relic defines a browser interaction as anything that occurs in the app user's browser; for example: A user interaction that leads to a page load or route change A scheduled, dynamic update to an app's widget A browser interaction includes not just the initial triggering event, but also the activity caused by that event, such as AJAX requests and both synchronous and asynchronous JavaScript. By tracking not just the cause but also the effects of a browser interaction, we help you understand how users experience your application's views and route changes. All apps are different and have different monitoring needs. That's why we include default monitoring as well as the ability to set up custom monitoring for any browser interactions you choose. Types of SPA data reporting Three major categories of single page app data can be reported to New Relic: Initial page loads Route changes Custom browser interactions created via the SPA API Each of these creates a BrowserInteraction event. If one or more AJAX requests are part of an interaction, then associated AjaxRequest events are also created. These events and their attributes can be queried in the query builder. Initial page loads An initial page load is a traditional URL change, stemming from a complete load or reload of a URL. This is indicated in the browser when a page load event fires (the window.onload event). Initial page loads appear along with route changes in the Browser UI. Route changes SPA users experience dynamic route changes in a similar way to page loads. Visitors to a site or app generally do not care how a new view was delivered; they simply know that when they perform an action, a new view appears. For this reason, we treat route changes in a similar way to page loads in the UI. In order to optimally monitor single page applications, we start monitoring many browser interactions that could theoretically lead to route changes. If these interactions do not lead to route changes, Browser initiates monitoring but then discards them. If these interactions do lead to a route change, Browser saves the interaction sequence as a BrowserInteraction event, including information about both synchronous and asynchronous activity. An interaction is considered a route change and saved as a BrowserInteraction event when one of the following occurs: The URL hash changes (usually using window.location.hash). A popstate event fires during a callback associated with an interaction. A pushState or replaceState API is called. Route changes appear along with initial page loads in the Browser UI. We receive and save hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. For more information about data collection and reporting, see Security for Browser. Custom monitoring You can use the SPA API to set up custom monitoring of browser interactions that are not monitored by default. You can also use the API to disable default monitoring. Custom events are saved as BrowserInteraction events and have the following attributes: The category attribute will have the value Custom. The trigger attribute will have the value api. (This is the default value but can be changed with the API.) Difference from traditional page load timing To provide optimized data for single page app monitoring, we measure page load timing in a new way: by wrapping low level browser functions, both synchronous and asynchronous. This gives a fuller depiction of how long it takes to complete the changes required for a new view. This is different from the traditional method for page load timing. Traditional page load timing uses the firing of the window.onload event to determine when a page is loaded. This is not an optimal way to measure view change timing because web apps often have asynchronous code that runs for a significant amount of time after the window.onload event occurs. Tip Browser's standard, non-SPA Page views page displays different page load times than when SPA monitoring is enabled. Because SPA monitoring is measuring all asynchronous activity, the SPA load times will generally be longer than standard page load times. The traditional window.onload page load timing still appears on the SPA Page views page. When you select a specific page load event, Window onload appears as a red line in the page load time chart. You can also select Switch to standard page views to return to traditional load timing displays. Timers The agent monitors all asynchronous calls, including timers. Timers with durations shorter than one second are wrapped. Timers longer than one second are not wrapped because usually they are meant for non-web transactions, such as background work or polling that is unrelated to a user interaction. Events and attributes We save browser interactions that lead to route changes and page loads as BrowserInteraction events, and AJAX requests as AjaxRequest events. You can query these events in the query builder.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 221.89886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> <em>data</em> collection",
        "sections": "<em>SPA</em> <em>data</em> collection",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "This document explains how <em>Browser</em> collects and stores your asynchronous <em>single</em> <em>page</em> <em>app</em> (<em>SPA</em>) <em>data</em>. This will give you a better understanding of the <em>SPA</em> <em>data</em> you see in the <em>Browser</em> UI. This will also help you more easily add custom <em>monitoring</em> with the <em>SPA</em> API. <em>Browser</em> interactions At the heart"
      },
      "id": "60440d9b196a672eb1960f6d"
    },
    {
      "sections": [
        "Use SPA API"
      ],
      "title": "Use SPA API",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Use SPA data"
      ],
      "external_id": "85ba9b61e8ba08112a3a276d186fbe7af894251d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/use-spa-data/use-spa-api/",
      "published_at": "2021-06-20T10:42:49Z",
      "updated_at": "2021-03-11T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser's single-page application (SPA) monitoring includes an API to add custom monitoring of specific browser interactions. This is useful for monitoring interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget. The SPA API also allows you to turn off default monitoring for interactions that you do not consider important enough to monitor. For more information about the SPA API, including specific API calls, see the Browser agent and SPA API.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.27763,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Use</em> <em>SPA</em> API",
        "sections": "<em>Use</em> <em>SPA</em> API",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "<em>Browser</em>&#x27;s <em>single</em>-<em>page</em> application (<em>SPA</em>) <em>monitoring</em> includes an API to add custom <em>monitoring</em> of specific <em>browser</em> interactions. This is useful for <em>monitoring</em> interactions that New Relic does not record automatically because they do not result in route changes, such as a dynamically-updated widget"
      },
      "id": "60440de328ccbc04a23025de"
    },
    {
      "sections": [
        "SPA compatibility and requirements",
        "Browser agent version",
        "Browser types",
        "Framework requirements",
        "Security when collecting hash fragments",
        "For more help"
      ],
      "title": "SPA compatibility and requirements",
      "type": "docs",
      "tags": [
        "Browser",
        "Single page app monitoring",
        "Get started"
      ],
      "external_id": "17d916a952f7b86a1da190a9d7236072eff12361",
      "image": "",
      "url": "https://docs.newrelic.com/docs/browser/single-page-app-monitoring/get-started/spa-compatibility-requirements/",
      "published_at": "2021-06-20T12:36:07Z",
      "updated_at": "2021-05-05T17:26:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In order to set up Single Page Application (SPA) monitoring for Browser monitoring, make sure your app meets these SPA monitoring requirements. Browser agent version SPA monitoring requires an SPA-specific version of the Browser snippet, available for Browser agent version 885 or higher. To activate this snippet version for your application, enable your application for SPA monitoring. To check your version and integrate the updated snippet, follow the appropriate upgrade instructions. Browser types SPA monitoring requires the addEventListener Browser API and the Navigation Timing API. Both APIs are available in all modern browsers, including Google Chrome, Mozilla Firefox, Apple Safari, and Microsoft Internet Explorer (IE) versions 9 or higher. Framework requirements Because SPA instrumentation works by wrapping low-level browser APIs, it is framework-agnostic. SPA instrumentation is compatible with most SPA frameworks, such as Angular, Backbone, Ember, and React. It can also instrument requests made using JSONP. Below are known compatibility issues: If your application uses AngularJS and you want to use Browser's SPA monitoring capabilities, Zone.js versions 0.6.18-0.6.24 are not compatible with the SPA agent. The html2pdf.js library is not compatible with the SPA agent. Security when collecting hash fragments New Relic collects and saves hash fragments from route change URLs. If you use hashes to pass private or sensitive data, that data may be visible to your New Relic account users. Follow Browser's guidelines for security with data collection and reporting. For more help Additional documentation resources include: Browser settings (additional options to enable Browser features) Security for Browser monitoring (additional security considerations for Browser)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.23013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>SPA</em> compatibility and requirements",
        "sections": "<em>SPA</em> compatibility and requirements",
        "tags": "<em>Single</em> <em>page</em> <em>app</em> <em>monitoring</em>",
        "body": "In order to set up <em>Single</em> <em>Page</em> Application (<em>SPA</em>) <em>monitoring</em> for <em>Browser</em> <em>monitoring</em>, make sure your <em>app</em> meets these <em>SPA</em> <em>monitoring</em> requirements. <em>Browser</em> agent version <em>SPA</em> <em>monitoring</em> requires an <em>SPA</em>-specific version of the <em>Browser</em> snippet, available for <em>Browser</em> agent version 885 or higher"
      },
      "id": "6044095ee7b9d20d555799f3"
    }
  ],
  "/docs/cloud-instance-optimizer-find-underused-virtual-machines": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-20T12:41:26Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.43985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Find</em> and use data",
        "body": " <em>Machines</em> integration: Polling interval: 5 minutes Resolution: 1 data point per minute <em>Find</em> and use data To <em>find</em> your integration data, go to one.newrelic.com &gt; Infrastructure &gt; Azure and look for the integration. You can query and explore your data using the Azure<em>Virtual</em>MachineSample event type"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Google Compute Engine monitoring integration",
        "Activate integration",
        "Important",
        "Polling frequency",
        "Find and use data",
        "Metric data",
        "GcpVirtualMachineSample",
        "GcpVirtualMachineDiskSample",
        "Inventory data",
        "gcp/compute/virtual-machine",
        "gcp/compute/virtual-machine/disk",
        "Learn more"
      ],
      "title": "Google Compute Engine monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Google Cloud Platform integrations",
        "GCP integrations list"
      ],
      "external_id": "749ce2f670e38c332eb8b591fb0fbf0098ba157f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-compute-engine-monitoring-integration/",
      "published_at": "2021-06-20T23:04:49Z",
      "updated_at": "2021-05-15T19:35:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "All New Relic Infrastructure accounts, regardless of subscription level, can use New Relic's Compute Engine integration to get a comprehensive, real-time view of their host's performance and status. New Relic Infrastructure's integration with Google Compute Engine reports metadata about instances (virtual machines) hosted on Google's infrastructure. You can monitor and alert on your GCP instances data from New Relic Infrastructure, and you can create custom queries and chart dashboards in New Relic Insights. Activate integration To enable the integration follow standard procedures to connect your GCP service to New Relic Infrastructure. Important You must install the Infrastructure agent on each GCE host to see metrics from that host. Connecting your Google Cloud projects allows Infrastructure to access GCE metadata, such as region, type, and tags. Polling frequency New Relic Infrastructure integrations query your GCP services according to a polling interval, which varies depending on the integration. The polling interval for the Google Compute Engine integration is 5 minutes. Find and use data After activating the integration and waiting a few minutes (based on the polling frequency), data will appear in the New Relic UI. To find and use your data, including links to your dashboards and alert settings, go to one.newrelic.com > Infrastructure > GCP > (select an integration). Metric data Metric data that New Relic receives from your GCP Compute Engine integration include: GcpVirtualMachineSample Name Description firewall.DroppedBytes Delta count of incoming bytes dropped by the firewall. firewall.DroppedPackets Delta count of incoming packets dropped by the firewall. instance.cpu.ReservedCores Total number of cores reserved on the host of the instance. GcpVirtualMachineDiskSample Name Description instance.disk.ThrottledReadBytes Delta count of bytes in throttled read operations. instance.disk.ThrottledReadOps Delta count of throttled read operations. instance.disk.ThrottledWriteBytes Delta count of bytes in throttled write operations. instance.disk.ThrottledWriteOps Delta count of throttled write operations. Inventory data Inventory data is information about the status or configuration of a service or host. You can examine inventory data in New Relic Infrastructure and in New Relic Insights. The Google Compute Engine integration reports configuration information and labels for virtual machines and disks through the properties listed below. Virtual machine tags are treated as labels that take the value true. gcp/compute/virtual-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description instanceId isPreemptible label.* machineType metadataFingerprint name networkInterfaces onHostMaintenance project status networkTags zone gcp/compute/virtual-machine/disk creationTimestamp description diskId encrypted instanceId instanceName label.* lastAttachTimestamp lastDetachTimestamp licenses name project replicaZones sizeGb sourceImage sourceImageId sourceSnapshot sourceSnapshotId status type users zone Learn more",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.64276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "gcp&#x2F;compute&#x2F;<em>virtual</em>-<em>machine</em>",
        "tags": "Google <em>Cloud</em> Platform integrations",
        "body": " information and labels for <em>virtual</em> <em>machines</em> and disks through the properties listed below. <em>Virtual</em> machine tags are treated as labels that take the value true. gcp&#x2F;compute&#x2F;<em>virtual</em>-machine automaticRestart canIpForward cpuPlatform creationTimestamp deletionProtection description <em>instance</em>Id isPreemptible"
      },
      "id": "603e7d1f28ccbc483ceba771"
    },
    {
      "sections": [
        "Oracle Database monitoring integration",
        "Compatibility and requirements",
        "Oracle Database users and privileges",
        "Tip",
        "Install and activate",
        "Configure the integration",
        "Important",
        "Commands",
        "Arguments",
        "Labels",
        "Example configuration",
        "Example custom query configuration",
        "Find and use data",
        "Metric data",
        "Database metrics",
        "Tablespace metrics",
        "Inventory data",
        "Parameters",
        "Troubleshooting",
        "The Oracle library cannot be loaded",
        "ORACLE_HOME is not set correctly",
        "I get an ORA error",
        "Check the source code"
      ],
      "title": "Oracle Database monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "ec5ba9d06736a0cb168402e7af8a935068d748c9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/oracle-database-monitoring-integration/",
      "published_at": "2021-06-20T19:42:51Z",
      "updated_at": "2021-06-03T16:45:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Oracle Database integration collects key performance metrics on databases, tablespaces, and memory by default. You can customize your configuration to collect even more metrics, giving you detailed characterization of database performance. Read on to install the integration, and to see what data we collect. Compatibility and requirements Our integration is compatible with Oracle Database versions 11.2 and higher. Before installing the integration, make sure that you meet the following requirements: Linux distro compatible with infrastructure, except for RHEL/CentOS/OEL versions lower than 7. Install the infrastructure agent. Oracle Instant Client on the agent box. Oracle database with ORACLE_HOME configured to the correct directory for the root user. Oracle database user with both CONNECT and SELECT privileges on the required global views. Oracle database with a listener.ora file configured to monitor from a remote connection. By default, Oracle Database only listens to localhost. Oracle Database users and privileges In the Oracle database, execute the following statements to create a new user and assign user privileges. USERNAME and similar user-specific values must be replaced. If you use Oracle DB 12c or higher, use ALTER SESSION to access the database and manage users and user properties. Do not run this query if your Oracle DB version is lower than 12c. ALTER SESSION set \"_Oracle_SCRIPT\"=true; Copy Use CREATE USER to add a new user to the database. Replace USER_PASSWORD with the new user's password. CREATE USER USERNAME IDENTIFIED BY \"USER_PASSWORD\"; Copy Tip For assistance with user maintenance questions, consult the Oracle documentation or contact your system or database administrator. Grant CONNECT privileges to the user. GRANT CONNECT TO USERNAME; Copy Grant SELECT privileges to the user on the following global views: cdb_data_files cdb_pdbs cdb_users gv_$sysmetric gv_$pgastat gv_$instance gv_$filestat gv_$parameter sys.dba_data_files gv_$session gv_$sesstat gv_$statname gv_$rowcache gv_$sga gv_$sysstat v_$database gv_$librarycache gv_$sqlarea gv_$system_event dba_tablespaces gv_$session_wait gv_$rollstat v_$instance You can execute the following SQL statements together in one script or individually. GRANT SELECT ON cdb_data_files TO USERNAME; GRANT SELECT ON cdb_pdbs TO USERNAME; GRANT SELECT ON cdb_users TO USERNAME; GRANT SELECT ON gv_$sysmetric TO USERNAME; GRANT SELECT ON gv_$pgastat TO USERNAME; GRANT SELECT ON gv_$instance TO USERNAME; GRANT SELECT ON gv_$filestat TO USERNAME; GRANT SELECT ON gv_$parameter TO USERNAME; GRANT SELECT ON sys.dba_data_files TO USERNAME; GRANT SELECT ON DBA_TABLESPACES TO USERNAME; GRANT SELECT ON DBA_TABLESPACE_USAGE_METRICS TO USERNAME; GRANT SELECT ON gv_$session TO USERNAME; GRANT SELECT ON gv_$sesstat TO USERNAME; GRANT SELECT ON gv_$statname TO USERNAME; GRANT SELECT ON gv_$rowcache TO USERNAME; GRANT SELECT ON gv_$sga TO USERNAME; GRANT SELECT ON gv_$sysstat TO USERNAME; GRANT SELECT ON v_$database TO USERNAME; GRANT SELECT ON gv_$librarycache TO USERNAME; GRANT SELECT ON gv_$sqlarea TO USERNAME; GRANT SELECT ON gv_$system_event TO USERNAME; GRANT SELECT ON dba_tablespaces TO USERNAME; GRANT SELECT ON gv_$session_wait TO USERNAME; GRANT SELECT ON gv_$rollstat TO USERNAME; GRANT SELECT ON v_$instance TO USERNAME; Copy Install and activate To install the Oracle Database integration: Follow the instructions for installing an integration, using the file name nri-oracledb. Change directory to the integrations folder: cd /etc/newrelic-infra/integrations.d Copy Copy the sample configuration file: sudo cp oracledb-config.yml.sample oracledb-config.yml Copy Edit the oracledb-config.yml file as described in the configuration settings. Restart the infrastructure agent. Additional notes: Advanced: It's also possible to install the integration from a tarball file. This gives you full control over the installation and configuration process. On-host integrations do not automatically update. For best results, regularly update the integration package and the infrastructure agent. Configure the integration An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. For an example configuration, see the example config file. Important With secrets management, you can configure on-host integrations with New Relic infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. Commands The oracledb-config.yml file accepts the following commands: all_data: collects both inventory and metric data. Arguments The all_data command accepts the following arguments: service_name: Oracle Database service name of the instance (or cluster of instances) to monitor. This field is required. username: username of a user created with the required permissions. This field is required. password: password of a user created with the required permissions. This field is required. is_sys_dba: boolean value that indicates whether the authenticating user has SysDBA permissions. Default: false. oracle_home: path to where ORACLE_HOME is. This field is required. is_sys_oper: boolean value that indicates whether the authenticating user has SysOper permissions. Default: false. tablespaces: A JSON array of tablespaces to collect. If omitted, collects all tablespaces. Default: none (all tablespaces). Due to performance reasons, the integration will refuse to collect tablespace data for more than 200 tablespaces. If your database has more than 200 of tablespaces, you must restrict collection to a smaller number by using the tablespaces parameter. hostname: hostname of the instance to monitor. Default: 127.0.0.1. port: port number on which Oracle Database is running. Default: 1521. connection_string: a full connection string such as those found in tnsnames.ora. If this is specified, it takes priority over host, port, and service_name. extended_metrics: boolean value that indicates whether to collect extended metrics. Default: false. custom_metrics_query: a custom SQL query to run against the configured instance. Each row of the query is added as a new metric set on OracleCustomSample. Each non-null column in the row is added as an attribute on that metric set. custom_metrics_config: a path to a YAML file that contains a list of queries, along with custom sample names and metric type overrides. See example below for details. Labels The labels field controls the environment attribute. Default: production. Example configuration Example oracledb-config.yml file configuration: Example configuration integration_name: com.newrelic.oracledb instances: - name: oracledb command: all_data arguments: username: oracle_user password: oracle_password hostname: oracle-host.localnet oracle_home: <path to ORACLE_HOME> is_sys_dba: true service_name: ORCL custom_metrics_config: <path to custom queries yaml> # custom_metrics_query: >- # SELECT # 'physical_reads' AS \"metric_name\", # 'gauge' AS \"metric_type\", # SUM(PHYRDS) AS \"metric_value\", # INST_ID AS \"instanceID\" # FROM gv$filestat # GROUP BY INST_ID; labels: env: staging Copy Example custom query configuration --- queries: # Metric names are set to the column names in the query results - query: >- SELECT SUM(stat.gets) AS \"gets\", SUM(stat.waits) AS \"waits\", SUM(stat.waits)/SUM(stat.gets) AS \"ratio\", inst.inst_id FROM GV$ROLLSTAT stat, GV$INSTANCE inst WHERE stat.inst_id=inst.inst_id GROUP BY inst.inst_id # If not set explicitly here, metric type will default to # 'gauge' for numbers and 'attribute' for strings metric_types: gets: gauge # If unset, sample_name defaults to OracleCustomSample sample_name: MyCustomSample Copy For more about the general structure of on-host integration configuration, see Configuration. Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > Third-party services and select one of the Oracle Database integration links. Oracle Database data is attached to the following event types: OracleDatabaseSample OracleTablespaceSample For more on how to find and use your data, see Understand integration data. Metric data The Oracle Database integration collects the following metric data attributes. Each metric name is prefixed with a category indicator and a period, such as disk. or memory.. Database metrics These attributes can be found by querying the OracleDatabaseSample event type. Metric Description db.activeParallelSessions Active parallel sessions. db.activeSerialSessions Active serial sessions. db.averageActiveSessions Average active sessions. Extended: yes. db.backgroundCheckpointsPerSecond Checkpoints per second. db.backgroundCpuUsagePerSecond Background CPU usage per second. db.backgroundTimePerSecond Background time per second. db.blockChangesPerSecond DB block changes per second. db.blockChangesPerTransaction DB block changes per transaction. db.blockChangesPerUserCall DB block changes per user call. db.blockGetsPerSecond DB block gets per second. db.blockGetsPerTransaction DB block gets per transaction. db.blockGetsPerUserCall DB block gets per user call. db.branchNodeSplitsPerSecond Branch node splits per second. db.branchNodeSplitsPerTransaction Branch node splits per transaction. db.consistentReadChangesPerSecond Consistent read changes per second. db.consistentReadChangesPerTransaction Consistent read changes per transaction. db.consistentReadGetsPerSecond Consistent read gets per second. db.consistentReadGetsPerTransaction Consistent read gets per transaction. db.cpuTimeRatio Database CPU time ratio. db.cpuUsagePerSecond CPU usage per second. Extended: yes. db.cpuUsagePerTransaction CPU usage per transaction. db.crBlocksCreatedPerSecond CR blocks created per second. db.crBlocksCreatedPerTransaction CR blocks created per transaction. db.crUndoRecordsAppliedPerSecond CR undo records applied per second. db.crUndoRecordsAppliedPerTransaction CR undo records applied per transaction. db.currentLogons Current logons count. db.currentOpenCursors Current open cursors count. db.cursorCacheHitsPerAttempts Cursor cache hit ratio. db.databaseCpuTimePerSecond Database time per second. db.dbwrCheckpointsPerSecond DBWR checkpoints per second. db.enqueueDeadlocksPerSecond Enqueue deadlocks per second. db.enqueueDeadlocksPerTransaction Enqueue deadlocks per transaction db.enqueueRequestsPerSecond Enqueue requests per second db.enqueueRequestsPerTransaction Enqueue requests per transaction. db.enqueueTimeoutsPerSecond Enqueue timeouts per second. db.enqueueTimeoutsPerTransaction Enqueue timeouts per transaction. db.enqueueWaitsPerSecond Enqueue waits per second. db.enqueueWaitsPerTransaction Enqueue waits per transaction. db.executionsPerSecond Executions per second. db.executionsPerTransaction Executions per transaction. Extended: yes. db.executionsPerUserCall Executions per user call. db.fullIndexScansPerSecond Full index scans per second. db.fullIndexScansPerTransaction Full index scans per transaction. db.GcCrBlockRecievedPerSecond GC CR block received per second. db.GcCrBlockRecievedPerTransaction GC CR block received per transaction. db.GcCurrentBlockReceivedPerSecond GC current block received per second. db.GcCurrentBlockReceivedPerTransactino GC current block received per transaction. db.globalCacheAverageCrGetTime Global cache average CR get time. db.globalCacheAverageCurrentGetTime Global cache average current get time. db.hardParseCountPerSecond Hard parse count per second. db.hardParseCountPerTransaction Hard parse count per transaction. db.hostCpuUsagePerSecond Host CPU usage per second. db.hostCpuUtilization Host CPU utilization (percentage). Extended: yes. db.leafNodeSplitsPerSecond Leaf node splits per second. db.leafNodeSplitsPerTransaction Leaf node splits per transaction. db.libraryCacheHitRatio Library cache hit ratio. db.libraryCacheMissRatio Library cache miss ratio. db.logicalReadsPerSecond Logical reads per second. db.logicalReadsPerTransaction Logical reads per transaction. db.logonsPerSecond Logons per second. db.logonsPerTransaction Logons per transaction. db.longTableScansPerSecond Long table scans per second. db.longTableScansPerTransaction Long table scans per transaction. db.openCursorsPerSecond Open cursors per second. db.openCursorsPerTransaction Open cursors per transaction. db.osLoad Current OS load. db.parseFailureCountPerSecond Parse failure count per second. db.parseFailureCountPerTransaction Parse failure count per transaction. db.pgaCacheHitPercentage PGA cache hit percentage. db.processLimitPercentage Process limit percentage. db.recursiveCallsPerSecond Recursive calls per second. db.recursiveCallsPerTransaction Recursive calls per transaction. db.redoWritesPerSecond Redo writes per second. db.redoWritesPerTransaction Redo writes per transaction. db.responseTimePerTransaction Response time per transaction. db.rowCacheHitRatio Row cache hit ratio. db.rowCacheMissRatio Row cache miss ratio. db.rowsPerSort Rows per sort. db.sessionCount Session count. Extended: yes. db.sessionLimitPercentage Session limit percentage. db.sharedPoolFreePercentage Shared pool free percentage. db.softParseRatio Soft parse ratio. db.sortsPerUserCall Total sorts per user call. db.sqlServiceResponseTime SQL service response time. db.streamsPoolUsagePercentage Streams pool usage percentage. db.tableScansPerUserCall Total table scans per user call. db.totalIndexScansPerSecond Total index scans per second. Extended: yes. db.totalIndexScansPerTransaction Total index scans per transaction. db.totalParseCountPerSecond Total parse count per second. db.totalParseCountPerTransaction Total parse count per transaction. db.totalTableScansPerSecond Total table scans per second. Extended: yes. db.totalTableScansPerTransaction Total table scans per transaction. db.TransactionsPerLogon Transactions per logon. db.userCallsPerSecond User calls per second. db.userCallsPerTransaction User calls per transaction. db.userCallsRatio User calls ratio. db.userCommitsPercentage User commits percentage. db.userCommitsPerSecond User commits per second. db.userLimitPercentage User limit percentage. db.userRollbacksPercentage User rollbacks per transaction. db.userRollbacksPerSecond User rollbacks per second. db.userRollbackUndoRecordsAppliedPerSecond User rollback undo records applied per second. db.userRollbackUndoRecordsAppliedPerTransaction User rollback undo records applied per transaction. db.waitTimeRatio Database wait time ratio. disk.blocksRead Number of block reads. Extended: yes. disk.blocksWritten Number of block writes. Extended: yes. disk.logicalReadsPerUserCall Logical reads per user call. disk.physicalLobsReadsPerSecond Physical reads direct lobs per second. disk.physicalLobsWritesPerSecond Physical writes direct lobs per second. disk.physicalReadBytesPerSecond Physical read total bytes per second. Extended: yes. disk.physicalReadIoRequestsPerSecond Physical read total I/O requests per second. Extended: yes. disk.physicalReadsPerSecond Physical reads direct per second. Extended: yes. disk.physicalWriteBytesPerSecond Physical write total bytes per second. disk.physicalWriteIoRequestsPerSecond Physical write I/O requests per second. disk.physicalWritesPerSecond Physical writes direct per second. Extended: yes. disk.physicalWriteTotalIoRequestsPerSecond Physical write total I/O requests per second. Extended: yes. disk.reads Total number of physical reads. Extended: yes. disk.readTime Amount of file read time. Extended: yes. disk.sortPerSecond Disk sort per second. disk.sortPerTransaction Disk sort per transaction. disk.tempSpaceUsed Temp space used. disk.writes Total number of physical writes. Extended: yes. disk.writeTime Amount of file write time. Extended: yes. lockedAccounts Number of accounts whose account_status is not OPEN. longRunningQueries Number of long running (> 60s) queries. memory.bufferCacheHitRatio Buffer cache hit ratio. Extended: yes. memory.globalCacheBlocksCorrupted Global cache blocks corrupted. memory.globalCacheBlocksLost Global cache blocks lost. memory.pgaAllocated Current amount of PGA memory allocated by the instance. memory.pgaFreeable Number of bytes of PGA memory in all processes that could be freed back to the operating system. memory.pgaInUse Indicates how much PGA memory is currently consumed by work areas. This number can be used to determine how much memory is consumed by other consumers of the PGA memory (for example, PL/SQL or Java). memory.pgaMaxSize Maximum size of a work area executed in automatic mode. Extended: yes. memory.redoAllocationHitRatio Redo allocation hit ratio. memory.redoGeneratedBytesPerSecond Redo generated bytes per second. memory.redoGeneratedBytesPerTransaction Redo generated bytes per transaction. memory.sortsRatio Memory sorts ratio. network.ioMegabytesPerSecond I/O megabytes per second. network.ioRequestsPerSecond I/O requests per second. Extended: yes. network.trafficBytePerSecond Network traffic volume per second. Extended: yes. query.physicalLobsReadsPerTransaction Physical reads direct lobs per transaction. query.physicalLobsWritesPerTransaction Physical writes direct lobs per transaction. query.physicalReadsPerTransaction Physical reads per transaction. query.physicalReadsPerTransaction Physical reads direct per transaction. query.physicalWritesPerTransaction Physical writes per transaction. query.physicalWritesPerTransaction Physical writes direct per transaction. query.transactionsPerSecond User transaction per second. Extended: yes. redoLog.logFileSwitch Number of redo log file switch events. redoLog.logFileSwitchArchivingNeeded Number of redo log file switch events that need archiving. redoLog.logFileSwitchCheckpointIncomplete Number of redo log file switch event checkpoints that are incomplete. redoLog.waits Number of redo log waits. rollbackSegments.gets Number of rollback segments gets. rollbackSegments.ratioWait Ratio of waits for rollback segments. rollbackSegments.waits Number of rollback segments waits. sga.bufferBusyWaits Number of SGA buffer busy waits. sga.fixedSizeInBytes SGA fixed size. sga.freeBufferWaits Number of SGA free buffer waits. sga.freeBufferInspected Number of SGA free buffer inspected. sga.hitRatio Hit ratio for the SGA. sga.logBufferAllocationRetriesRatio Retry ratio of allocations for the SGA log buffer. sga.logBufferRedoAllocationRetries Redo allocation ratio for the SGA log buffer. sga.logBufferRedoEntries Number of Redo entries in the SGA log buffer. sga.logBufferSpaceWaits Buffer space waits for the SGA log buffer. sga.redoBuffersInBytes SGA Redo buffers, in bytes. sga.sharedPoolDictCacheMissRatio Miss ratio for the SGA shared pool dictionary (dict) cache. sga.sharedPoolLibraryCacheHitRatio Hit ratio for the SGA shared pool library cache. sga.sharedPoolLibraryCacheReloadRatio Reload ratio for the SGA shared pool library cache. sga.sharedPoolLibraryCacheShareableMemoryPerStatementInBytes SGA cacheable memory per statement, in bytes. sga.sharedPoolLibraryCacheShareableMemoryPerUserInBytes SGA cacheable memory per user, in bytes. sga.ugaTotalMemoryInBytes Total memory in the User Global Area (UGA). sorts.diskInBytes Sorts disk usage, in bytes. sorts.memoryInBytes Sorts memory usage, in bytes. Tablespace metrics The Oracle Database integration collects the following tablespace metrics. These attributes can be found by querying the OracleTablespaceSample event type. Metric Description tablespace.isOffline Boolean for tablespace offline status. Extended: yes. tablespace.offlinePDBDatafiles The number of PDB datafiles that are offline. tablespace.offlineCDBDatafiles The number of CDB datafiles that are offline. tablespace.pdbDatafilesNonWrite The number of PDB datafiles in a non-writable state. tablespace.spaceConsumedInBytes Consumed amount of tablespace in bytes. tablespace.spaceReservedInBytes Total reserved tablespace in bytes. tablespace.spaceUsedPercentage Ratio of used to total tablespace. Extended: yes. Inventory data The Oracle Database integration captures the configuration parameters of the Oracle database. The data is available on the Inventory page, under the config/oracledb source. For more about inventory data, see Understand integration data. The integration captures data for the following Oracle Database configuration parameters: Parameters Metric Description DBFIPS_140 Enable use of crypographic libraries in FIPS mode, public. O7_DICTIONARY_ACCESSIBILITY Version 7 dictionary accessibility support. active_instance_count Number of active instances in the cluster database. adg_account_info_tracking ADG user account info tracked in standby (LOCAL) or in primary (GLOBAL). allow_global_dblinks LDAP lookup for DBLINKS. allow_group_access_to_sga Allow read access for SGA to users of Oracle owner group. approx_for_aggregation Replace exact_aggregation with approximate_aggregation. approx_for_count_distinct Replace count_distinct with approx_count_distinct. approx_for_percentile Replace percentile_* with approx_percentile. aq_tm_processes Number of AQ time managers to start. archive_lag_target Maximum number of seconds of redos the standby could lose. asm_diskstring Disk set locations for discovery. asm_preferred_read_failure_groups Preferred read failure groups. audit_file_dest Directory in which auditing files are to reside. audit_sys_operations Enable sys auditing. audit_syslog_level Syslog facility and level. audit_trail Enable system auditing. autotask_max_active_pdbs Setting for autotask maximum maintenance PDBs. awr_pdb_autoflush_enabled Enable/Disable AWR automatic PDB flushing. awr_pdb_max_parallel_slaves Maximum concurrent AWR PDB MMON slaves per instance. awr_snapshot_time_offset Setting for AWR snapshot time offset. background_core_dump Core size for background processes. background_dump_dest Detached process dump directory. backup_tape_io_slaves Backup tape I/O slaves. bitmap_merge_area_size Maximum memory allow for bitmap merge. blank_trimming Blank trimming semantics parameter. buffer_pool_keep Number of database blocks/latches in keep buffer pool. buffer_pool_recycle Number of database blocks/latches in recycle buffer pool. cdb_cluster If TRUE startup in CDB cluster mode. cdb_cluster_name CDB cluster name. cell_offload_compaction Cell packet compaction strategy. cell_offload_decryption Enable SQL processing offload of encrypted data to cells. cell_offload_parameters Additional cell offload parameters. cell_offload_plan_display Cell offload explain plan display. cell_offload_processing Enable SQL processing offload to cells. cell_offloadgroup_name Set the offload group name. circuits Max number of circuits. client_result_cache_lag Client result cache maximum lag in milliseconds. client_result_cache_size Client result cache max size in bytes. clonedb Clone database. clonedb_dir CloneDB Directory. cluster_database If TRUE startup in cluster database mode. cluster_database_instances Number of instances to use for sizing cluster DB SGA structures. cluster_interconnects Interconnects for RAC use. commit_logging Transaction commit log write behaviour. commit_point_strength Bias this node has toward not preparing in a two-phase commit. commit_wait Transaction commit log wait behaviour. commit_write Transaction commit log write behaviour. common_user_prefix Enforce restriction on a prefix of a common user, role, or profile . compatible Database will be completely compatible with this software version. connection_brokers Connection brokers specification. containers_parallel_degree Parallel degree for a CONTAINERS() query. control_file_record_keep_time Control file record keep time in days. control_files Control file names list. control_management_pack_access Declares which manageability packs are enabled. core_dump_dest Core dump directory. cpu_count Number of CPUs for this instance. create_bitmap_area_size Size of create bitmap buffer for bitmap index. create_stored_outlines Create stored outlines for DML statements. cursor_bind_capture_destination Allowed destination for captured bind variables. cursor_invalidation Default for DDL cursor invalidation semantics. cursor_sharing Cursor sharing mode. cursor_space_for_time Use more memory in order to get faster execution. data_guard_sync_latency Data guard sync latency. data_transfer_cache_size Size of data transfer cache. db_16k_cache_size Size of cache for 16K buffers. db_2k_cache_size Size of cache for 2K buffers. db_32k_cache_size Size of cache for 32K buffers. db_4k_cache_size Size of cache for 4K buffers. db_8k_cache_size Size of cache for 8K buffers. db_big_table_cache_percent_target Big table cache target size in percentage. db_block_buffers Number of database blocks cached in memory. db_block_checking Header checking and data and index block checking. db_block_checksum Store checksum in DB blocks and check during reads. db_block_size Size of database block in bytes. db_cache_advice Buffer cache sizing advisory. db_cache_size Size of default buffer pool for standard block size buffers. db_create_file_dest Default database location. db_create_online_log_dest_1 Online log/controlfile destination #1. db_create_online_log_dest_2 Online log/controlfile destination #2. db_create_online_log_dest_3 Online log/controlfile destination #3. db_create_online_log_dest_4 Online log/controlfile destination #4. db_create_online_log_dest_5 Online log/controlfile destination #5. db_domain Directory part of global database name stored with CREATE DATABASE. db_file_multiblock_read_count DB block to be read each I/O. db_file_name_convert Datafile name convert patterns and strings for standby/clone db. db_files Max allowable number of db files. db_flash_cache_file Flash cache file for default block size. db_flash_cache_size Flash cache size for db_flash_cache_file. db_flashback_retention_target Maximum flashback database log retention time in minutes.. db_index_compression_inheritance Options for table or tablespace level compression inheritance. db_keep_cache_size Size of KEEP buffer pool for standard block size buffers. db_lost_write_protect Enable lost write detection. db_name Database name specified in CREATE DATABASE. db_performance_profile Database performance category. db_recovery_file_dest Default database recovery file location. db_recovery_file_dest_size Database recovery files size limit. db_recycle_cache_size Size of RECYCLE buffer pool for standard block size buffers. db_securefile Permit securefile storage during lob creation. db_ultra_safe Sets defaults for other parameters that control protection levels. db_unique_name Database unique name. db_unrecoverable_scn_tracking Track nologging SCN in controlfile. db_writer_processes Number of background database writer processes to start. dbwr_io_slaves DBWR I/O slaves. ddl_lock_timeout Timeout to restrict the time that DDLS wait for DML lock. default_sharing Default sharing clause. deferred_segment_creation Defer segment creation to first insert. dg_broker_config_file1 Data guard broker configuration file #1. dg_broker_config_file2 Data guard broker configuration file #2. dg_broker_start Start data guard broker (DMON process). diagnostic_dest Diagnostic base directory. disable_pdb_feature Disable features. disk_asynch_io Use asynch I/O for random access devices. dispatchers Specifications of dispatchers. distributed_lock_timeout Number of seconds a distributed transaction waits for a lock. dml_locks DML locks - one for each table modified in a transaction. dnfs_batch_size Max number of dNFS asynch I/O requests queued per session. dst_upgrade_insert_conv Enables/Disables internal conversions during DST upgrade. enable_automatic_maintenance_pdb Enable/Disable automated maintenance for non-root PDB. enable_ddl_logging Enable ddl logging. enable_dnfs_dispatcher Enable DNFS dispatcher. enable_goldengate_replication Goldengate replication enabled. enable_pluggable_database Enable pluggable database. enabled_PDBs_on_standby List of enabled PDB patterns. encrypt_new_tablespaces Whether to encrypt newly created tablespaces. event Debug event control - default null string. exafusion_enabled Enable exafusion. external_keystore_credential_location External keystore credential location. fal_client FAL client. fal_server FAL server list. fast_start_io_target Upper bound on recovery reads. fast_start_mttr_target MTTR target in seconds. fast_start_parallel_rollback Max number of parallel recovery slaves that may be used. file_mapping Enable file mapping. fileio_network_adapters Network adapters for File I/O. filesystemio_options IO operations on filesystem files. fixed_date Fixed SYSDATE value. forward_listener Forward listener. gcs_server_processes Number of background gcs server processes to start. global_names Enforce that database links have same name as remote database. global_txn_processes Number of background global transaction processes to start. hash_area_size Size of in-memory hash work area. heat_map ILM Heatmap Tracking. hi_shared_memory_address SGA starting address (high order 32-bits on 64-bit platforms). hs_autoregister Enable automatic server DD updates in HS agent self-registration. ifile Include file in init.Ora. inmemory_adg_enabled Enable IMC support on ADG. inmemory_automatic_level Enable Automatic In-Memory management. inmemory_clause_default Default in-memory clause for new tables. inmemory_expressions_usage Controls which In-Memory Expressions are populated in-memory. inmemory_force Force tables to be in-memory or not. inmemory_max_populate_servers Maximum inmemory populate servers. inmemory_optimized_arithmetic Controls whether or not DSBs are stored in-memory. inmemory_prefer_xmem_memcompress Prefer to store tables with given memcompress levels in xmem. inmemory_prefer_xmem_priority Prefer to store tables with given priority levels in xmem. inmemory_query Specifies whether in-memory queries are allowed. inmemory_size Size in bytes of in-memory area. inmemory_trickle_repopulate_servers_percent Inmemory trickle repopulate servers percent. inmemory_virtual_columns Controls which user-defined virtual columns are stored in-memory. inmemory_xmem_size Size in bytes of in-memory xmem area. instance_abort_delay_time Time to delay an internal initiated abort (in seconds). instance_groups List of instance group names. instance_mode Indicates whether the instance read-only or read-write or read-mostly. instance_name Instance name supported by the instance. instance_number Instance number. instance_type Type of instance to be executed. instant_restore Instant repopulation of datafiles. java_jit_enabled Java VM JIT enabled. java_max_sessionspace_size Max allowed size in bytes of a Java sessionspace. java_pool_size Size in bytes of java pool. java_restrict Restrict Java VM Access. java_soft_sessionspace_limit Warning limit on size in bytes of a Java sessionspace. job_queue_processes Maximum number of job queue slave processes. large_pool_size Size in bytes of large pool. ldap_directory_access RDBMS's LDAP access option. ldap_directory_sysauth OID usage parameter. license_max_sessions Maximum number of non-system user sessions allowed. license_max_users Maximum number of named users that can be created in the database. license_sessions_warning Warning level for number of non-system user sessions. listener_networks Listener registration networks. local_listener Local listener. lock_name_space Lock name space used for generating lock names for standby/clone database. lock_sga Lock entire SGA in physical memory. log_archive_config Log archive config. log_archive_dest Archival destination text string. log_archive_dest_1 Archival destination #1 text string. log_archive_dest_10 Archival destination #10 text string. log_archive_dest_11 Archival destination #11 text string. log_archive_dest_12 Archival destination #12 text string. log_archive_dest_13 Archival destination #13 text string. log_archive_dest_14 Archival destination #14 text string. log_archive_dest_15 Archival destination #15 text string. log_archive_dest_16 Archival destination #16 text string. log_archive_dest_17 Archival destination #17 text string. log_archive_dest_18 Archival destination #18 text string. log_archive_dest_19 Archival destination #19 text string. log_archive_dest_2 Archival destination #2 text string. log_archive_dest_20 Archival destination #20 text string. log_archive_dest_21 Archival destination #21 text string. log_archive_dest_22 Archival destination #22 text string. log_archive_dest_23 Archival destination #23 text string. log_archive_dest_24 Archival destination #24 text string. log_archive_dest_25 Archival destination #25 text string. log_archive_dest_26 Archival destination #26 text string. log_archive_dest_27 Archival destination #27 text string. log_archive_dest_28 Archival destination #28 text string. log_archive_dest_29 Archival destination #29 text string. log_archive_dest_3 Archival destination #3 text string. log_archive_dest_30 Archival destination #30 text string. log_archive_dest_31 Archival destination #31 text string. log_archive_dest_4 Archival destination #4 text string. log_archive_dest_5 Archival destination #5 text string. log_archive_dest_6 Archival destination #6 text string. log_archive_dest_7 Archival destination #7 text string. log_archive_dest_8 Archival destination #8 text string. log_archive_dest_9 Archival destination #9 text string. log_archive_dest_state_1 Archival destination #1 state text string. log_archive_dest_state_10 Archival destination #10 state text string. log_archive_dest_state_11 Archival destination #11 state text string. log_archive_dest_state_12 Archival destination #12 state text string. log_archive_dest_state_13 Archival destination #13 state text string. log_archive_dest_state_14 Archival destination #14 state text string. log_archive_dest_state_15 Archival destination #15 state text string. log_archive_dest_state_16 Archival destination #16 state text string. log_archive_dest_state_17 Archival destination #17 state text string. log_archive_dest_state_18 Archival destination #18 state text string. log_archive_dest_state_19 Archival destination #19 state text string. log_archive_dest_state_2 Archival destination #2 state text string. log_archive_dest_state_20 Archival destination #20 state text string. log_archive_dest_state_21 Archival destination #21 state text string. log_archive_dest_state_22 Archival destination #22 state text string. log_archive_dest_state_23 Archival destination #23 state text string. log_archive_dest_state_24 Archival destination #24 state text string. log_archive_dest_state_25 Archival destination #25 state text string. log_archive_dest_state_26 Archival destination #26 state text string. log_archive_dest_state_27 Archival destination #27 state text string. log_archive_dest_state_28 Archival destination #28 state text string. log_archive_dest_state_29 Archival destination #29 state text string. log_archive_dest_state_3 Archival destination #3 state text string. log_archive_dest_state_30 Archival destination #30 state text string. log_archive_dest_state_31 Archival destination #31 state text string. log_archive_dest_state_4 Archival destination #4 state text string. log_archive_dest_state_5 Archival destination #5 state text string. log_archive_dest_state_6 Archival destination #6 state text string. log_archive_dest_state_7 Archival destination #7 state text string. log_archive_dest_state_8 Archival destination #8 state text string. log_archive_dest_state_9 Archival destination #9 state text string. log_archive_duplex_dest duplex Archival destination text string. log_archive_format Archival destination format. log_archive_max_processes Maximum number of active ARCH processes. log_archive_min_succeed_dest Minimum number of archive destinations that must succeed. log_archive_start Start archival process on SGA initialization. log_archive_trace Establish archive operation tracing level. log_buffer Redo circular buffer size. log_checkpoint_interval Number of redo blocks checkpoint threshold. log_checkpoint_timeout Maximum time interval between checkpoints in seconds. log_checkpoints_to_alert Log checkpoint begin/end to alert file. log_file_name_convert Logfile name convert patterns and strings for standby/clone db. long_module_action Use longer module and action. max_datapump_jobs_per_pdb Maximum number of concurrent data pump jobs per PDB. max_dispatchers Max number of dispatchers. max_dump_file_size Maximum size (in bytes) of dump file. max_idle_time Maximum session idle time in minutes. max_iops MAX I/O per second. max_mbps MAX MB per second. max_pdbs Max number of pdbs allowed in CDB or Application ROOT. max_shared_servers Max number of shared servers. max_string_size Controls maximum size of VARCHAR2, NVARCHAR2, and RAW types in SQL. memoptimize_pool_size Size of cache for imoltp buffers. memory_max_target Max size for Memory Target. memory_target Target size of Oracle SGA and PGA memory. multishard_query_data_consistency Consistency setting for multishard queries. multishard_query_partial_results Enable partial results for multishard queries. nls_calendar NLS calendar system name. nls_comp NLS comparison. nls_currency NLS local currency symbol. nls_date_format NLS Oracle date format. nls_date_language NLS date language name. nls_dual_currency Dual currency symbol. nls_iso_currency NLS ISO currency territory name. nls_language NLS language name. nls_length_semantics Create columns using byte or char semantics by default. nls_nchar_conv_excp NLS raise an exception instead of allowing implicit conversion. nls_numeric_characters NLS numeric characters. nls_sort NLS linguistic definition name. nls_territory NLS territory name. nls_time_format Time format. nls_time_tz_format Time with timezone format. nls_timestamp_format Time stamp format. nls_timestamp_tz_format Timestamp with timezone format. noncdb_compatible Non-CDB Compatible. object_cache_max_size_percent Percentage of maximum size over optimal of the user session's object cache. object_cache_optimal_size Optimal size of the user session's object cache in bytes. ofs_threads Number of OFS threads. olap_page_pool_size Size of the olap page pool in bytes. one_step_plugin_for_pdb_with_tde Facilitate one-step plugin for PDB with TDE encrypted data. open_cursors Max number of cursors per session. open_links Max number of open links per session. open_links_per_instance Max number of open links per instance. optimizer_adaptive_plans Controls all types of adaptive plans. optimizer_adaptive_reporting_only Use reporting-only mode for adaptive optimizations. optimizer_adaptive_statistics Controls all types of adaptive statistics. optimizer_capture_sql_plan_baselines Automatic capture of SQL plan baselines for repeatable statements. optimizer_dynamic_sampling Optimizer dynamic sampling. optimizer_features_enable Optimizer plan compatibility parameter. optimizer_ignore_hints Enables the embedded hints to be ignored. optimizer_ignore_parallel_hints Enables embedded parallel hints to be ignored. optimizer_index_caching Optimizer percent index caching. optimizer_index_cost_adj Optimizer index cost adjustment. optimizer_inmemory_aware Optimizer in-memory columnar awareness. optimizer_mode Optimizer mode. optimizer_secure_view_merging Optimizer secure view merging and predicate pushdown/movearound. optimizer_use_invisible_indexes Usage of invisible indexes (TRUE or FALSE). optimizer_use_pending_statistics Control whether to use optimizer pending statistics. optimizer_use_sql_plan_baselines Use of SQL plan baselines for captured sql statements. os_authent_prefix Prefix for auto-logon accounts. os_roles Retrieve roles from the operating system. outbound_dblink_protocols Outbound DBLINK Protocols allowed. parallel_adaptive_multi_user Enable adaptive setting of degree for multiple user streams. parallel_degree_limit Limit placed on degree of parallelism. parallel_degree_policy Policy used to compute the degree of parallelism (MANUAL, LIMITED, AUTO, or ADAPTIVE). parallel_execution_message_size Message buffer size for parallel execution. parallel_force_local Force single instance execution. parallel_instance_group Instance group to use for all parallel operations. parallel_max_servers Maximum parallel query servers per instance. parallel_min_degree Controls the minimum DOP computed by auto DOP. parallel_min_percent Minimum percent of threads required for parallel query. parallel_min_servers Minimum parallel query servers per instance. parallel_min_time_threshold Threshold above which a plan is a candidate for parallelization (in seconds). parallel_servers_target Instance target in terms of number of parallel servers. parallel_threads_per_cpu Number of parallel execution threads per CPU. pdb_file_name_convert PDB file name convert patterns and strings for create cdb/pdb. pdb_lockdown Pluggable database lockdown profile. pdb_os_credential Pluggable database OS credential to bind. pdb_template PDB template. permit_92_wrap_format Allow 9.2 or older wrap format in PL/SQL. pga_aggregate_limit Limit of aggregate PGA memory for the instance or PDB. pga_aggregate_target Target size for the aggregate PGA memory consumed by the instance. plscope_settings Plscope_settings controls the compile time collection, cross reference, and storage of PL/SQL source code identifier and SQL statement data. plsql_ccflags PL/SQL ccflags. plsql_code_type PL/SQL code-type. plsql_debug PL/SQL debug. plsql_optimize_level PL/SQL optimize level. plsql_v2_compatibility PL/SQL version 2.X compatibility flag. plsql_warnings PL/SQL compiler warnings settings. pre_page_sga Pre-page sga for process. private_temp_table_prefix Private temporary table prefix. processes User processes. processor_group_name Name of the processor group that this instance should run in. query_rewrite_enabled Allow rewrite of queries using materialized views if enabled. query_rewrite_integrity Perform rewrite using materialized views with desired integrity. rdbms_server_dn RDBMS's distinguished name. read_only_open_delayed If TRUE delay opening of read only files until first access. recovery_parallelism Number of server processes to use for parallel recovery. recyclebin Recyclebin processing. redo_transport_user Data guard transport user when using password file. remote_dependencies_mode Remote-procedure-call dependencies mode parameter. remote_listener Remote listener. remote_login_passwordfile Password file usage parameter. remote_os_authent Allow non-secure remote clients to use auto-logon accounts. remote_os_roles Allow non-secure remote clients to use os roles. remote_recovery_file_dest Default remote database recovery file location for refresh/relocate. replication_dependency_tracking Tracking dependency for replication parallel propagation. resource_limit Master switch for resource limit. resource_manage_goldengate Goldengate resource manager enabled. resource_manager_cpu_allocation Resource Manager CPU allocation. resource_manager_plan Resource mgr top plan. result_cache_max_result Maximum result size as percent of cache size. result_cache_max_size Maximum amount of memory to be used by the cache. result_cache_mode Result cache operator usage mode. result_cache_remote_expiration Maximum life time (min) for any result using a remote object. resumable_timeout Set resumable timeout. rollback_segments Undo segment list. sec_case_sensitive_logon Case sensitive password enabled for logon. sec_max_failed_login_attempts Maximum number of failed login attempts on a connection. sec_protocol_error_further_action TTC protocol error continue action. sec_protocol_error_trace_action TTC protocol error action. sec_return_server_release_banner Whether the server returns the complete version information. serial_reuse Reuse the frame segments. service_names Service names supported by the instance. session_cached_cursors Number of cursors to cache in a session. session_max_open_files Maximum number of open files allowed per session. sessions User and system sessions. sga_max_size Max total SGA size. sga_min_size Minimum, guaranteed size of PDB's SGA. sga_target Target size of SGA. shadow_core_dump Core size for shadow processes. shared_memory_address SGA starting address (low order 32-bits on 64-bit platforms). shared_pool_reserved_size Size in bytes of reserved area of shared pool. shared_pool_size Size in bytes of shared pool. shared_server_sessions Max number of shared server sessions. shared_servers Number of shared servers to start up. shrd_dupl_table_refresh_rate Duplicated table refresh rate (in seconds). skip_unusable_indexes Skip unusable indexes if set to TRUE. smtp_out_server Utl_smtp server and port configuration parameter. sort_area_retained_size Size of in-memory sort work area retained between fetch calls. sort_area_size Size of in-memory sort work area. spatial_vector_acceleration Enable spatial vector acceleration. spfile Server parameter file. sql92_security Require select privilege for searched update/delete. sql_trace Enable SQL trace. sqltune_category Category qualifier for applying hintsets. standby_db_preserve_states Preserve state cross standby role transition. standby_file_management If auto, files are created/dropped automatically on standby. standby_pdb_source_file_dblink Database link to standby source files. standby_pdb_source_file_directory Standby source file directory location. star_transformation_enabled Enable the use of star transformation. statistics_level Statistics level. streams_pool_size Size in bytes of the streams pool. tape_asynch_io Use asynch I/O requests for tape devices. target_pdbs Parameter is a hint to adjust certain attributes of the CDB. tde_configuration Per-PDB configuration for transparent tata encryption. temp_undo_enabled Is temporary undo enabled. thread Redo thread to mount. threaded_execution Threaded Execution Mode. timed_os_statistics Internal os statistic gathering interval in seconds. timed_statistics Maintain internal timing statistics. trace_enabled Enable in memory tracing. tracefile_identifier Trace file custom identifier. transactions Max. Number of concurrent active transactions. transactions_per_rollback_segment Number of active transactions per rollback segment. undo_management Instance runs in SMU mode if TRUE, else in RBU mode. undo_retention Undo retention in seconds. undo_tablespace Use/switch undo tablespace. unified_audit_sga_queue_size Size of unified audit SGA queue. unified_audit_systemlog Syslog facility and level for unified audit. uniform_log_timestamp_format Use uniform timestamp formats vs pre-12.2 formats. use_dedicated_broker Use dedicated connection broker. use_large_pages Use large pages if available (TRUE, FALSE, or ONLY). user_dump_dest User process dump directory. version Oracle Database version. xwallet_root Wallet root instance initialization parameter. workarea_size_policy Policy used to size SQL working areas (MANUAL``AUTO). Troubleshooting Troubleshooting tips: The Oracle library cannot be loaded If monitoring remotely, install the Oracle Instant Client and follow the instructions on how to add libclntsh.so to the shared library search path. If monitoring from the box with Oracle Database installed, install the Oracle Instant Client and add the path ORACLE_HOME/lib to the ldconfig search path. ORACLE_HOME is not set correctly This error will appear in the logs as [ERR] ORA-01284: Error while trying to retrieve text for error. To avoid this error make sure ORACLE_HOME is set correctly for the agent process. The agent runs as root, so its environment is not the same as the oracle user. To verify this setting, execute cat /proc/$(pgrep newrelic-infra)/environ to print out the environment variables for the infrastructure process, the output should include ORACLE_HOME if configured correctly. I get an ORA error To resolve errors of the type ORA, refer to Oracle's error list. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.61844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Find</em> and use data",
        "body": " one-step plugin for PDB with TDE encrypted data. open_cursors Max number of cursors per session. open_links Max number of open links per session. open_links_per_<em>instance</em> Max number of open links per <em>instance</em>. <em>optimizer</em>_adaptive_plans Controls all types of adaptive plans"
      },
      "id": "6044571428ccbc04a23101f8"
    }
  ],
  "/docs/correlate-load-balancer-application-metrics-workloads": [
    {
      "image": "https://docs.newrelic.com/static/775fe6d355fc6f5fd1793f286aa52c54/ae694/Dashboard.png",
      "url": "https://docs.newrelic.com/whats-new/2021/03/aws-cloudwatch/",
      "sections": [
        "Amazon CloudWatch Metric Streams",
        "More metrics, more often - fill gaps in your observability with Amazon CloudWatch Metric Streams and New Relic One"
      ],
      "published_at": "2021-06-20T18:14:24Z",
      "title": "Amazon CloudWatch Metric Streams",
      "updated_at": "2021-04-04T20:34:06Z",
      "type": "docs",
      "external_id": "004ba80238187bccbaa649145cc6dd58d7a90a42",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "More metrics, more often - fill gaps in your observability with Amazon CloudWatch Metric Streams and New Relic One More metrics more often means that you’ll receive Amazon CloudWatch data from all the AWS services you use as soon as they are available. Keep your applications running in the AWS Cloud humming. Less delay equals faster decisions. Correlate, analyze, visualize, and alert on the Amazon CloudWatch metrics for all of the AWS services your AWS cloud-based applications use. Two integration modes are available when you create a new AWS integration. Once you’ve completed setup, you can bring the data from AWS into dashboards right alongside the other New Relic One data available to you. The example below shows metrics from New Relic One’s Synthetic and Infrastructure Monitoring right next to the AWS Application Load Balancer and RDS database Metric Streams data. The Metric Streams data is stored in New Relic One’s Telemetry Data Platform as dimensional metrics of the summary type and can be queried using NRQL and used in Navigator and Lookout. This is the Navigator view grouped by AWS namespaces. Below is the Amazon CloudWatch Metric Streams status dashboard from Infrastructure -> AWS -> Account status dashboard Check out this short video walking through Amazon CloudWatch Metric Streams benefits. To get started: Navigate to Infrastructure Click AWS to set up your AWS integration today",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.74037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon CloudWatch <em>Metric</em> Streams",
        "sections": "More <em>metrics</em>, more often - fill gaps in your observability <em>with</em> Amazon CloudWatch <em>Metric</em> Streams <em>and</em> New Relic One",
        "body": " bring the data from AWS into dashboards right alongside the other New Relic One data available to you. The example below shows <em>metrics</em> from New Relic One’s Synthetic and Infrastructure Monitoring right next to the AWS <em>Application</em> <em>Load</em> <em>Balancer</em> and RDS database <em>Metric</em> Streams data. The <em>Metric</em> Streams"
      },
      "id": "606a22be196a6752ec47e824"
    },
    {
      "sections": [
        "AWS ELB (Classic) monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Inventory data",
        "Child inventory data",
        "Tip"
      ],
      "title": "AWS ELB (Classic) monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "a2b3ad999c8ed420e698e813618feb7ca30ec75d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-elb-classic-monitoring-integration/",
      "published_at": "2021-06-20T22:47:37Z",
      "updated_at": "2021-03-11T10:45:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an Amazon Elastic Classic Load Balancing (ELB) integration for reporting Classic ELB data to New Relic. This document explains the integration's features, how to activate it, and what data can be reported. Features New Relic's integration for Amazon Elastic Classic Load Balancing (ELB) reports ELB data, including HTTP code message counts, healthy and unhealthy host counts, latency times, and ELB configuration states. AWS integration data is also available for querying and chart creation in New Relic One. Amazon offers three types of load balancers: Classic Load Balancer, Application Load Balancer (ALB), and Network Load Balancer (NLB). New Relic also offers an ALB/NLB integration to monitor the last two types of load balancers. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS ELB integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use this integration's data, go to one.newrelic.com > Infrastructure > AWS and select one of the ELB integration links. You can query and explore your data using the LoadBalancerSample event type, with a provider value of Elb. Metric data The integration collects the following metrics. For additional details about these metrics, see Amazon's ELB Classic Load Balancer metrics documentation. Name Description backendConnectionErrors.Sum Rate of the number of connections per second that were not successfully established between the load balancer and the registered instances. The load balancer retries the connection when there are errors, so this count may exceed the request rate. This count also includes any connection errors related to health checks. healthyHostCount unHealthyHostCount The number of healthy or unhealthy instances registered with your load balancer. A newly registered instance is considered healthy after it passes the first health check. If cross-zone load balancing is enabled, the number of healthy instances for the LoadBalancerName dimension is calculated across all availability zones. Otherwise, it is calculated per availability zone. httpCodeBackend2XX httpCodeBackend3XX httpCodeBackend4XX httpCodeBackend5XX [ HTTP listener] The number of HTTP response codes generated per second by registered instances. This count does not include any response codes generated by the load balancer. httpCodeElb4XX [ HTTP listener] The number of HTTP 4XX client error codes generated by the load balancer per minute. Client errors are generated when a request is malformed or incomplete. httpCodeElb5XX [ HTTP listener] The number of HTTP 5XX server error codes generated by the load balancer per minute. This count does not include any response codes generated by the registered instances. The metric is reported if there are no healthy instances registered to the load balancer, or if the request rate exceeds the capacity of the instances (spillover) or the load balancer. latency.Average latency.Maximum [ HTTP listener] The total time elapsed, in seconds, from the time the load balancer sent the request to a registered instance until the instance started to send the response headers. [ TCP listener] The total time elapsed, in seconds, for the load balancer to successfully establish a connection to a registered instance. Available statistics: aws.elb.latency.p90 aws.elb.latency.p95 aws.elb.latency.p99 requestCount The number of requests completed or connections made per second during the specified interval (1 or 5 minutes). spilloverCount The total number of requests that were rejected per second, due to the surge queue being full. surgeQueueLength.Average, Maximum, Minimum The total number of requests that are pending routing. The load balancer queues a request if it is unable to establish a connection with a healthy instance in order to route the request. The maximum size of the queue is 1,024. Additional requests are rejected when the queue is full. For more information, see SpilloverCount. estimatedAlbActiveConnectionCount.Average, Maximum, Minimum The estimated number of concurrent TCP connections active from clients to the load balancer and from the load balancer to targets. estimatedAlbConsumedLcus.Average, Maximum, Minimum The estimated number of load balancer capacity units (LCU) used by an application load balancer. estimatedAlbNewConnectionCount.Average, Maximum, Minimum The estimated number of new TCP connections established from clients to the load balancer and from the load balancer to targets. estimatedProcessedBytes.Average, Maximum, Minimum The estimated number of bytes processed by an application load balancer. Inventory data The following configuration options are available with the New Relic Amazon ELB integration. Name Description availabilityZone Lists one or more availability zones from the same region as the load balancer. awsRegion The AWS region that the load balancer runs in. canonicalHostedZoneNameId The ID of the Amazon Route 53 hosted zone name associated with the load balancer. canonicalHostedZoneName The name of the Amazon Route 53 hosted zone that is associated with the load balancer. If you specify internal for the Elastic Load Balancing scheme, use DNSNameinstead. For an internal scheme, the load balancer doesn't have a CanonicalHostedZoneName value. createdTime Timestamp with the date and time the load balancer was created. dnsName The public DNS name of the load balancer. instances A JSON string representing the list of IDs of EC2 instances associated with the load balancer. listeners A JSON string representing the list of Listeners associated with the load balancer. loadBalancerName The name of the load balancer. scheme For load balancers attached to an Amazon VPC, this parameter can be used to specify the type of load balancer to use. For more information, see the AWS ElasticLoadBalancing documentation about LoadBalancer properties. securityGroups A JSON string representing the list of security groups assigned to your load balancer within your virtual private cloud (VPC). sourceSecurityGroup The security group that you can use as part of your inbound rules for your load balancer's back-end Amazon EC2 application instances. subnets A JSON string representing the list of subnet IDs in your virtual private cloud (VPC) to attach to your load balancer. Do not specify multiple subnets that are in the same Availability Zone. You can specify the AvailabilityZones or Subnets property, but not both. vpcId The ID of the VPC that the load balancer has been configured in. Child inventory data Tip Data indicated with an asterisk * is only fetched if extended inventory collection is on. Name Description accessLog/enabled * A boolean. If true, access logs are enabled for this load balancer. connectionDraining/enabled * A boolean. Use connection draining to ensure that a Classic Load Balancer does not send requests to unhealthy instances. For more information, see the AWS documentation to configure connection draining for your Classic Load Balancer. connectionDraining/timeout * The number of seconds the load balancer waits before forcibly closing connections to the de-registering instance. Valid values are 1 to 3600. connectionSettings/idleTimeout * For more information, see the AWS documentation to configure the idle connection timeout for your Classic Load Balancer. crossZoneLoadBalancing/enabled * A boolean. For more information, see the AWS documentation to configure cross-zone load balancing for your Classic Load Balancer. healthCheck/healthyThreshold The number of consecutive successful health checks that must occur before declaring an EC2 instance healthy. Valid values: 2 to 10. healthCheck/interval The amount of time in seconds between health checks of an individual instance. Valid values: 5 to 300. healthCheck/target Combination of three properties: The protocol to use to connect with the instance. Valid values: TCP, HTTP, HTTPS, and SSL. The port to use to connect with the instance, as a protocol:port pair. If the load balancer fails to connect with the instance at the specified port within the configured response timeout period, the instance is considered unhealthy. The destination for the HTTP or HTTPS request. healthCheck/timeout The amount of time in seconds to wait when receiving a response from the health check. Valid values: 2 to 60. healthCheck/unhealthyThreshold The number of consecutive failed health checks that must occur before declaring an EC2 instance unhealthy. Valid values: 2 to 10. policies/otherPolicies JSON string representing security policies associated with this load balancer.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.14895,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Metric</em> data",
        "body": "&#x27;s data, go to one.newrelic.com &gt; Infrastructure &gt; AWS and select one of the ELB integration links. You can query and explore your data using the <em>LoadBalancer</em>Sample event type, with a provider value of Elb. <em>Metric</em> data The integration collects the following <em>metrics</em>. For additional details about"
      },
      "id": "6044aa46e7b9d218d85799d0"
    },
    {
      "sections": [
        "AWS ALB/NLB monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "ALB metrics",
        "ALB target group metrics",
        "NLB metrics",
        "NLB target group metrics",
        "Inventory data",
        "aws/alb/load-balancer",
        "aws/alb/target-group",
        "aws/alb/listener",
        "aws/alb/rule",
        "aws/nlb/load-balancer",
        "aws/nlb/target-group",
        "aws/nlb/listener",
        "aws/nlb/rule"
      ],
      "title": "AWS ALB/NLB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "26ea84faf0df7ee758479ff441ff761af7d1261d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-albnlb-monitoring-integration/",
      "published_at": "2021-06-20T20:53:44Z",
      "updated_at": "2021-03-11T10:43:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Application Load Balancing (ALB) distributes incoming application traffic across multiple targets, such as EC2 instances, in multiple availability zones. Amazon Network Load Balancer (NLB) distributes incoming traffic across multiple targets, such as Amazon EC2 instances. New Relic infrastructure integrations include an integration for reporting your AWS ALB/NLB data to New Relic products. This document explains how to activate this integration and describes the data that can be captured. New Relic also offers an integration for Amazon's Elastic Load Balancing (ELB) service. Activate integration To enable this integration, follow standard procedures to connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the AWS ALB/NLB integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute View and use data To view and use your integration data, go to one.newrelic.com > Infrastructure > AWS and select one of the AWS ALB integration links. You can query and explore your data using the LoadBalancerSample event type within four categories of data: ALB: Appears in New Relic with provider value Alb. NLB: Appears in New Relic with provider value Nlb. ALB target group: Appears in New Relic with provider value AlbTargetGroup. NLB target group: Appears in New Relic with provider valueNlbTargetGroup. Metric data There are two ALB integration categories of data: ALB and ALB target group. ALB metrics New Relic Infrastructure Amazon integrations collect the following Amazon ALB data to the provider Alb. Metric Description activeConnectionCount The total number of concurrent TCP connections active from clients to the load balancer and from the load balancer to targets. newConnectionCount The total number of new TCP connections established from clients to the load balancer and from the load balancer to targets. rejectedConnectionCount The number of connections that were rejected because the load balancer had reached its maximum number of connections. processedBytes The total number of bytes processed by the load balancer over IPv4 and IPv6. requestCount The number of requests received by the load balancer. This includes requests over IPv4 and IPv6. rulesEvaluated The number of rules processed by the load balancer given a request rate averaged over an hour. clientTlsNegotiationErrorCount The number of TLS connections initiated by the client that did not establish a session with the load balancer. Possible causes include a mismatch of ciphers or protocols. httpCodeElb5XXCount The number of HTTP 5XX server error codes that originate from the load balancer. This count does not include any response codes generated by the targets. httpCodeElb4XXCount The number of HTTP 4XX client error codes that originate from the load balancer. Client errors are generated when requests are malformed or incomplete. These requests have not been received by the target. IpV6ProcessedBytes The total number of bytes processed by the load balancer over IPv6. IpV6RequestCount The number of IPv6 requests received by the load balancer. lambdaTargetProcessedBytes The total number of bytes processed by the load balancer for requests to and responses from a Lambda function. ALB target group metrics Target group data is stored in New Relic in the provider AlbTargetGroup. For example, you can use this data to facet error metrics by target group. Metric Description requestCount The number of requests received by the load balancer. This includes requests over IPv4 and IPv6. healthyHostCount The number of targets that are considered healthy. unHealthyHostCount The number of targets that are considered unhealthy. targetResponseTime The time elapsed, in seconds, after the request leaves the load balancer until a response from the target is received. Available statistics: aws.applicationelb.target_response_time.p90 aws.applicationelb.target_response_time.p95 aws.applicationelb.target_response_time.p99 httpCodeTarget2XXCount The number of HTTP 2XX response codes generated by the targets. This does not include any response codes generated by the load balancer. httpCodeTarget3XXCount The number of HTTP 3XX response codes generated by the targets. This does not include any response codes generated by the load balancer. httpCodeTarget4XXCount The number of HTTP 4XX response codes generated by the targets. This does not include any response codes generated by the load balancer. httpCodeTarget5XXCount The number of HTTP 5XX response codes generated by the targets. This does not include any response codes generated by the load balancer. lambdaInternalError The number of requests to a Lambda function that failed because of an issue internal to the load balancer or AWS Lambda. lambdaUserError The number of requests to a Lambda function that failed because of an issue with the Lambda function. There are two NLB integration categories of data: NLB and NLB target group. NLB metrics New Relic Infrastructure Amazon integrations collect the following Amazon NLB data to the provider Nlb. Metric Description activeFlowCount The total number of concurrent flows (or connections) from clients to targets. This metric includes connections in the SYN_SENT and ESTABLISHED states. TCP connections are not terminated at the load balancer, so a client opening a TCP connection to a target counts as a single flow. activeFlowCountTls The total number of concurrent TLS flows (or connections) from clients to targets. This metric includes only connections in the ESTABLISHED states. clientTlsNegotiationErrorCount The total number of TLS handshakes that failed during negotiation between a client and a TLS listener. consumedLcus The number of load balancer capacity units (LCU) used by your load balancer. You pay for the number of LCUs that you use per hour. newFlowCount The total number of new flows (or connections) established from clients to targets in the time period. newFlowCountTls The total number of new TLS flows (or connections) established from clients to targets in the time period. processedBytes The total number of bytes processed by the load balancer, including TCP/IP headers. processedBytesTls The total number of bytes processed by TLS listeners. targetTlsNegotiationErrorCount The total number of TLS handshakes that failed during negotiation between a TLS listener and a target. tcpClientResetCount The total number of reset (RST) packets sent from a client to a target. These resets are generated by the client and forwarded by the load balancer. tcpElbResetCount The total number of reset (RST) packets generated by the load balancer. tcpTargetResetCount The total number of reset (RST) packets sent from a target to a client. These resets are generated by the target and forwarded by the load balancer. NLB target group metrics Target group data is stored in New Relic in the provider NlbTargetGroup. For example, you can use this data to facet error metrics by target group. Metric Description healthyHostCount The number of targets that are considered healthy. unHealthyHostCount The number of targets that are considered unhealthy. Inventory data Inventory data provides information about the service's state and configuration. ALB/NLB configuration options are reported as inventory data. aws/alb/load-balancer Name Description arn The Amazon Resource Name (ARN) of the load balancer. dnsName The public DNS name of the load balancer. canonicalHostedZoneId The ID of the Amazon Route 53 hosted zone associated with the load balancer. createdTime Timestamp with the date and time the load balancer was created. loadBalancerName The name of the load balancer. scheme The nodes of an Internet-facing load balancer have public IP addresses. The DNS name of an Internet-facing load balancer resolves publicly to the public IP addresses of the nodes. Therefore, Internet-facing load balancers can route requests from clients over the Internet. The nodes of an internal load balancer have only private IP addresses. The DNS name of an internal load balancer is resolves publicly to the private IP addresses of the nodes. Therefore, internal load balancers can only route requests from clients with access to the VPC for the load balancer. vpcId The ID of the VPC for the load balancer. state The state code. The initial state of the load balancer is provisioning. After the load balancer is fully set up and ready to route traffic, its state is active. If the load balancer could not be set up, its state is failed. availabilityZones Can be a list or a structure. As list: the availability zones for the load balancer. As structure: information about an availability zone. securityGroups List of the security group IDs for the load balancer. ipAddressType The type of IP addresses used by the subnets for your load balancer: ipv4 (for IPv4 addresses) dualstack (for IPv4 and IPv6 addresses) type The type of load balancer. accessLogsS3Enabled Indicates whether access logs are enabled. The value is true or false. The default is false . accessLogsS3Prefix The prefix for the location in the S3 bucket for the access logs. accessLogsS3Bucket The name of the S3 bucket for the access logs. This attribute is required if access logs are enabled. deletionProtectionEnabled Indicates whether deletion protection is enabled. The value is true or false . The default is false . idleTimeout The idle timeout value, in seconds. The valid range is 1-4000 seconds. The default is 60 seconds. routingHttp2Enabled Indicates whether HTTP/2 is enabled. The value is true or false. The default is true . aws/alb/target-group Name Description arn The Amazon Resource Name (ARN) of the target group targetGroupName The name of the target group protocol The protocol to use for routing traffic to the targets port The port on which the targets are listening vpcId The ID of the VPC for the targets healthCheckProtocol The protocol to use to connect with the target healthCheckTimeoutSeconds The amount of time, in seconds, during which no response means a failed health check healthyThresholdCount The number of consecutive health checks successes required before considering an unhealthy target healthy unhealthyThresholdCount The number of consecutive health check failures required before considering the target unhealthy healthCheckPath The destination for the health check request matcher Structure showing the HTTP codes to use when checking for a successful response from a target loadBalancerArn The Amazon Resource Names (ARN) of the load balancer that routes traffic to this target group stickinessEnabled Indicates whether sticky sessions are enabled. This is fetched only if extended inventory collection is enabled. sticknessType The type of stickiness. This is fetched only if extended inventory collection is enabled. deregistrationDelayTimeout The deregistration delay timeout. This is fetched only if extended inventory collection is enabled. slowStartDurationSeconds The time period, in seconds, during which a newly registered target receives a linearly increasing share of the traffic to the target group. After this time period ends, the target receives its full share of traffic. This is fetched only if extended inventory collection is enabled. stickinessLbCookieDurationSeconds The time period, in seconds, during which requests from a client should be routed to the same target. After this time period expires, the load balancer-generated cookie is considered stale. This is fetched only if extended inventory collection is enabled. aws/alb/listener Listener state will be only fetched if extended inventory collection is enabled. Name Description arn The Amazon Resource Name (ARN) of the listener. protocol The protocol for connections from clients to the load balancer. port The port on which the load balancer is listening. loadBalancerArn The Amazon Resource Name (ARN) of the load balancer. aws/alb/rule Rule state will be only fetched if extended inventory collection is enabled. Name Description arn The Amazon Resource Name (ARN) of the rule priority The priority isDefault Indicates whether this is the default rule conditions The conditions actions The actions aws/nlb/load-balancer Name Description arn The Amazon Resource Name (ARN) of the load balancer. dnsName The public DNS name of the load balancer. canonicalHostedZoneId The ID of the Amazon Route 53 hosted zone associated with the load balancer. createdTime Timestamp with the date and time the load balancer was created. loadBalancerName The name of the load balancer. scheme The nodes of an Internet-facing load balancer have public IP addresses. The DNS name of an Internet-facing load balancer publicly resolves to the public IP addresses of the nodes. Therefore, Internet-facing load balancers can route requests from clients over the Internet. The nodes of an internal load balancer only have private IP addresses. The DNS name of an internal load balancer is publicly resolves to the private IP addresses of the nodes. Therefore, internal load balancers can only route requests from clients with access to the VPC for the load balancer. vpcId The ID of the VPC for the load balancer. state The state code. The initial state of the load balancer is provisioning. After the load balancer is fully set up and ready to route traffic, its state is active. If the load balancer could not be set up, its state is failed. availabilityZones Can be a list or a structure. As list: the availability zones for the load balancer. As structure: information about an availability zone. ipAddressType The type of IP addresses used by the subnets for your load balancer: ipv4 (for IPv4 addresses) dualstack (for IPv4 and IPv6 addresses) type The type of load balancer. accessLogsS3Enabled Indicates whether access logs are enabled. The value is true or false. The default is false . accessLogsS3Prefix The prefix for the location in the S3 bucket for the access logs. accessLogsS3Bucket The name of the S3 bucket for the access logs. This attribute is required if access logs are enabled. deletionProtectionEnabled Indicates whether deletion protection is enabled. The value is true or false . The default is false . crossZoneEnabled Indicates whether cross-zone load balancing is enabled. The value is true or false . The default is false . aws/nlb/target-group Name Description arn The Amazon Resource Name (ARN) of the target group. targetGroupName The name of the target group. protocol The protocol to use for routing traffic to the targets. port The port on which the targets are listening. vpcId The ID of the VPC for the targets. healthCheckProtocol The protocol to use to connect with the target. healthCheckTimeoutSeconds The amount of time, in seconds, during which no response means a failed health check. healthyThresholdCount The number of consecutive health checks successes required before considering an unhealthy target healthy. unhealthyThresholdCount The number of consecutive health check failures required before considering the target unhealthy. healthCheckPath The destination for the health check request. loadBalancerArn The Amazon Resource Names (ARN) of the load balancer that routes traffic to this target group deregistrationDelayTimeout The deregistration delay timeout. This is fetched only if extended inventory collection is enabled. matcher Structure showing the HTTP codes to use when checking for a successful response from a target proxyProtocolV2Enabled Indicates whether Proxy Protocol version 2 is enabled. The value is true or false . The default is false . This is fetched only if extended inventory collection is enabled. aws/nlb/listener Listener state will be only fetched if extended inventory collection is enabled. Name Description arn The Amazon Resource Name (ARN) of the listener. protocol The protocol for connections from clients to the load balancer. port The port on which the load balancer is listening. loadBalancerArn The Amazon Resource Name (ARN) of the load balancer. aws/nlb/rule Rule state will be only fetched if extended inventory collection is enabled. Name Description arn The Amazon Resource Name (ARN) of the rule. priority The priority. isDefault Indicates whether this is the default rule. conditions The conditions. actions The actions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 112.819214,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "aws&#x2F;alb&#x2F;<em>load</em>-<em>balancer</em>",
        "body": " integration categories of data: ALB and ALB target group. ALB <em>metrics</em> New Relic Infrastructure Amazon integrations collect the following Amazon ALB data to the provider Alb. <em>Metric</em> Description activeConnectionCount The total number of concurrent TCP connections active from clients to the <em>load</em> <em>balancer</em>"
      },
      "id": "6043eedee7b9d2ef825799ef"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0662f6c3fbc151a0c836b54c104e81756b34827f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:39Z",
      "updated_at": "2021-03-16T07:28:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "603eb55be7b9d2dcb72a07e8"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "068b7f6bc27cf0a360699121c3cf8c46c9398d6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-06-20T20:33:13Z",
      "updated_at": "2021-03-13T01:25:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.20107,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "6044091d28ccbcc5b22c6097"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-20T20:43:49Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.30855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools": [
    {
      "sections": [
        "Introduction to Infrastructure Integrations SDK",
        "Important",
        "What is the Integrations SDK?",
        "What data can you report with an on-host integration?",
        "Create a custom integration"
      ],
      "title": "Introduction to Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "0662f6c3fbc151a0c836b54c104e81756b34827f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:39Z",
      "updated_at": "2021-03-16T07:28:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are several ways New Relic lets you create your own integration: General telemetry (metrics, traces) solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. If you have New Relic Infrastructure, you can use our lightweight Flex integration tool (recommended) or use our Integrations SDK to build a complete Infrastructure on-host integration. Important New Relic is transitioning to rely on open source standards like Prometheus for future on-host integrations. Though the infrastructure SDK is the foundation of that transition, some of the tutorials and tools around this SDK might not be up-to-date with the latest developments. What is the Integrations SDK? Our Infrastructure Integrations SDK lets you build an on-host integration that reports custom data from your hosts or services. That data can then be found in New Relic Infrastructure and can be used to create custom queries and charts. What data can you report with an on-host integration? When you build an integration using the Integrations SDK, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning something that reports data to New Relic (for example: a local host, a load balancer, or a database). A single integration can report data from multiple entities, which gives you the ability to report data from more than one service or host instance. There are three types of data an entity can generate: Metrics: Metric data is used for numerical measurement data. Examples: how many requests are in a queue, or the number of hits on a database per minute. Metric data from a custom integration can be queried and used to create dashboards. Inventory: Live system state and configuration information. This data will show up on the Infrastructure Inventory UI page. Events: Events are used to record important activities on a system. Examples: a service starting or a new table being created. Event data will be shown in the Infrastructure Events UI page. Create a custom integration To create an integration using the Integrations SDK, use these resources: See the Go language build tools and tutorial. The tutorial walks you through creating a Redis integration in Go. (Note: Go is not required; it's just the language for which we provide additional build tools. For more information, see Integrations SDK requirements.) See the integration file structure documentation, which describes the files required to create an integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.68076,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Introduction to <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": " Relic <em>Infrastructure</em> and can be used to <em>create</em> custom queries and charts. What data can you report with an on-host integration? When you build an integration using the <em>Integrations</em> <em>SDK</em>, you assign the entities that report data. In New Relic terms, entity is a purposefully ambiguous term meaning"
      },
      "id": "603eb55be7b9d2dcb72a07e8"
    },
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.20767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-20T20:43:49Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.30855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/get-started/introduction-infrastructure-integrations-sdk": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.20767,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "Go language integration tutorial and build tools",
        "Integrations tutorial",
        "Important",
        "Tip",
        "Go language integration building package"
      ],
      "title": "Go language integration tutorial and build tools",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "068b7f6bc27cf0a360699121c3cf8c46c9398d6a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/go-language-integration-tutorial-build-tools/",
      "published_at": "2021-06-20T20:33:13Z",
      "updated_at": "2021-03-13T01:25:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. Integrations tutorial Important The following tutorial is based on integrations using the SDK integration protocol v3. Find more information about the integration protocol v4 in the Github repository. The Go language integration-building tutorial on GitHub gives step-by-step procedures for building a Go language integration that reports Redis data. The tutorial shows how to build an integration using the Linux command line, but you can use the same techniques for a Windows integration with a standard Go install and PowerShell. The make command will not work with PowerShell, but you can use the Go commands inside it as a guide for building your integration. Tip You can create an on-host integration in any language, but Go is the language New Relic uses for its own integrations and build tools. To create an integration in another language, adhere to the integration file structures and JSON output requirements. Go language integration building package The tutorial relies on a New Relic Go language integration-building library package, which provides a set of useful Go functions and data structures. The package gives you tools that: Generate a \"scaffold\" integration structure with all the required fields. Read values from command-line arguments or environment variables. Generate and print JSON data to stdout. For information about file formats and JSON output specifications, see File requirements.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.20105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Go language <em>integration</em> tutorial and build tools",
        "sections": "<em>Integrations</em> tutorial",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you build a custom on-host integration. This document explains the build tools and resources available for building an on-host integration with our Go language tools. <em>Integrations</em> tutorial Important The following tutorial is based on <em>integrations</em>"
      },
      "id": "6044091d28ccbcc5b22c6097"
    },
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-20T20:43:49Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.30855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-configuration-overview": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.92049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-executable-file-json-specifications": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.92049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.92049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.92049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Newer configuration format",
        "Configuration structure",
        "Tip",
        "Important",
        "List of configuration properties",
        "Select an integration to run",
        "name",
        "exec",
        "cli_args",
        "when",
        "Pass configuration to the integration executable",
        "env",
        "config",
        "config_template_path",
        "Configure how the agent executes your integrations",
        "integration_user",
        "interval",
        "inventory_source",
        "labels",
        "timeout",
        "working_dir",
        "Update older integration configuration"
      ],
      "title": "On-host integrations: Newer configuration format ",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bc5bee12812cff6fabc728961e1b342b83f3e471",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. In December 2019, Infrastructure agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other improvements. This document will explain how this newer format works. The older standard configuration format is supported by current Infrastructure agents. For an introduction to configuration, see Config overview. Configuration structure An on-host integration's configuration YAML must have an integrations top-level section containing a YAML array, where each entry represents an integration and its configuration. For each integration entry, only the name property is mandatory. The other properties are optional. Here's an example configuration featuring two integrations: our built-in Docker integration, which requires no configuration, and our MySQL integration: integrations: # New Relic integration that does not require any configuration - name: nri-docker # New Relic integration that gets its configuration from the environment - name: nri-mysql env: PORT: 3306 USERNAME: newrelic PASSWORD: 123456789 # to hide this field, read the secrets management documentation # Any free-form integration executed via a user-provided command - name: my-own-integration exec: python /opt/integrations/my-script.py --host=127.0.0.1 Copy You can have as many configuration YAML files as you want and can group your integration instances. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Each configuration YAML file can also contain discovery and variables top-level sections. Important This configuration format does not require an agent restart. When saved, changes are detected and implemented immediately. This means that saving intermediate configuration changes may cause the integration to stop working. List of configuration properties This is a list of the general properties used to configure an integration. For more details about using these properties, including example values, see the documentation following the table. Config Description name Name of the integration. This is the only mandatory configuration property across all on-host integrations. If the exec field is not set it will also be the name of the integration executable. cli_args Optional list of command line arguments when name is used to provide the integration executable. Available since agent version 1.13.0. exec Full path to the integration executable, plus arguments. It may be a single-line string or a string array. If left unspecified, the exec field defaults to the name field. env YAML map containing the environment variables to be passed to the integration, where key is the environment variable name, and value is the variable value. config Configuration that is written as an external file and the path that is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. config_template_path Any external file whose path is passed to the integration with the CONFIG_PATH environment variable or the ${config.path} variable placeholder. Its usage allows applying discovery and secrets binding to any external configuration. integration_user Name of the user who runs the integration. interval Time between consecutive executions of the integration. It must be a number followed by a time unit (s, m or h), without spaces. inventory_source Allows overriding the category and term of the inventory source. labels Map with labels that decorate the data (metrics, events, inventory) reported by the integration. timeout A number followed by a time unit (ms, s, m or h). An integration that hasn't responded in this time period is killed and restarted. working_dir Working directory for the integration binary. when Integration is only executed if the clause evaluates to true. Conditions are defined below. The remainder of this document describes config properties grouped by their functionality: Select an integration to run Pass configuration to the integration command Configure how the agent executes integrations Select an integration to run There are two properties to select which integration will run: name and exec. The only mandatory property across all on-host integrations is name. The remaining properties specified in this document are optional. Example: integrations: - name: nri-docker - name: my-integration exec: /usr/local/bin/my-integration --metrics --inventory Copy name The mandatory name property can work in two ways: If the exec property is set: The name property only provides an identifier for the integration instance. This identifier is used in log messages and to provide a default inventory category/source in the form integration/<name> (for example, integration/nri-redis). This inventory path can be overridden with the inventory_source configuration option. If the exec property is not set: The agent looks for (and executes) an executable with the name value in any of the following folders: Linux: /var/db/newrelic-infra/newrelic-integrations/bin /var/db/newrelic-infra/newrelic-integrations /var/db/newrelic-infra/custom-integrations/bin /var/db/newrelic-infra/custom-integrations Windows C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations\\bin C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations If there is no executable with this name in the above folders the agent logs an error and the integration is not executed. Important In Windows, do not append the .exe extension to the name. The agent does this for you (for example, name: nri-mysql would look for nri-mysql.exe in the above folders). exec The exec optional property specifies the path, command, and command-line arguments of the integration to execute. When none of the path folders or arguments have spaces, it can be written in a single-line string: - name: my-integration exec: /usr/bin/python /opt/integrations/my-script.py --host=127.0.0.1 Copy If any of the path/arguments have spaces that are part of a single element, you can use a YAML array notation: - name: my-integration exec: - C:\\Program Files\\My Integration\\integration.exe - --host - 127.0.0.1 - --port - 8080 Copy The default working directory is the root directory of the agent configuration. It can be overridden with the working_dir property. cli_args The cli_args optional property specifies command line arguments that should be passed to the integration. It is useful when using name as it only provides the integration name identifier (not compatible with exec). - name: my-integration cli_args: [ -interval 10s ] Copy Usual YAML multi-line list format can be used as well: - name: my-integration cli_args: - -interval - 10s Copy when The when property allows to execute the integration only when all the evaluated conditions are successful. Available conditions are: env_exists: Environment variables exist and match value. file_exists: Given file path exists. feature: Provided feature-flag is enabled. Example: integrations: - name: ssh-integration when: file_exists: /var/run/sshd.pid Copy Pass configuration to the integration executable Often integration executables need to receive a configuration to work properly (for example, hostname and port of the monitored system, user credentials, etc.). The Infrastructure agent allows you to configure the integration commands in three ways (which you can combine): Command-line arguments, passed in the exec property. Environment variables, using the env property. Configuration files, whose path needs to be passed through environment variables or command-line arguments (see the config) property. Example: integrations: - name: my-integration exec: /opt/path/bin/script --host 127.0.0.1 --port 8081 - name: nri-mysql env: STATUS_URL: http://10.0.0.3/server-status?auto REMOTE_MONITORING: true Copy env The env property allows you to set environment variables that are passed to the executable. It is a key-value map with the required variables. Example: integrations: - name: nri-postgresql env: DATABASE: postgres PORT: 6432 COLLECTION_LIST: '[\"postgres\"]' COLLECT_DB_LOCK_METRICS: false VERBOSE: 1 Copy If you expect your integration to receive the configuration from the host's environment rather than specifying it explicitly in the configuration file, you need to set the required variables in the Infrastructure agent passthrough_environment global configuration property config This section describes various ways to pass configuration information to an integration. Pass configuration file directly Some integration commands may get their configuration from an external file. If your integration requires a configuration file, nothing prevents you from directly passing its path directly as a command-line argument or an environment variable. Here's an example using configuration of our Flex integration: integrations: - name: nri-flex env: CONFIG_FILE: /etc/nri-flex/configs/http-service.yaml - name: other-integration exec: /opt/integration/integration -f /opt/integration/config.properties Copy The above example assumes that the http-service.yaml and config.properties files exist. We can see that the nri-flex integration is expecting the http-service.yaml complete path via the CONFIG_FILE environment variable and the other-integration expects the complete config.properties path after the -f command-line flag. In the above example, it's necessary for the integration installer/configurator that the configuration files exist in the provided path and that the agent and integrations have read permissions on them. Pass configuration through config section If you prefer to keep your configuration file with the rest of the integration configuration, you can use the config section in the integration entry, which can contain a valid YAML object or just a multi-line string: integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv - name: other-integration exec: /opt/integration/integration -f ${config.path} config: | example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostname=localhost example.cfg.port=9025 Copy In the above examples, every time the nri-flex integration is executed, the agent creates a temporary file with the following contents: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy The above YAML is only a configuration example for the nri-flex integration. The agent ignores its contents; instead, it creates a temporary file and replaces the ${config.path} variable placeholder with its path. When the integration completes execution the temporary file is removed. Also, the agent creates another temporary file before executing the other-integration integration: example.cfg.verbose=true example.cfg.logger=/var/logs/integration.log example.cfg.hostid=localhost example.cfg.port=9025 Copy It replaces the -f ${config.path} command-line placeholder with the temporary path of the written file. By convention, if you do not place the ${config.path} variable in any command-line argument or environment variable value, the agent passes the path of the configuration file via the CONFIG_PATH environment variable: # assuming that nri-example command is prepared to receive the configuration # file via the CONFIG_PATH environment variable integrations: - name: nri-example config: name: csvFileExample apis: - name: csvFile file: /Users/hello/test.csv Copy Pass secrets and discovery through config section The main benefit for using a config section instead of hardcoding the full path of an external file is that you can insert ${variable} placeholders to apply our auto-discovery feature and secrets management. Here's an example followed by some explanations: variables: my_credentials: vault: http: url: http://my.vault.host/v1/newengine/data/secret headers: X-Vault-Token: my-vault-token discovery: docker: match: label.service: foo integrations: - name: foo-monitor exec: /opt/foo/bin/monitor --config=${config.path} config: | foo.host=${discovery.ip} foo.port=${discovery.port} foo.user=${my_credentials.user} foo.password=${my_credentials.password} Copy Tip (For more details about the variables and discovery sections, please visit the discovery and secrets management documentation). The above example relies on the following premises: There is a Vault service that allows retrieving a JSON object formed by the user and password fields. There may be a variable number of Docker containers labeled with service=foo, which are accessible from the agent host via a discoverable public IP and Port. The user has configured the foo-monitor integration to monitor all the service=foo labeled containers, which share a common user and password. Each instance of the foo-monitor integration requires executing the /opt/foo/bin/monitor executable, passing the text configuration inside the config section via the --config=<path> command-line argument. As example of workflow, imagine that the Vault invocation returns the following JSON: {\"user\":\"monitorer\",\"password\":\"5up3r53cr3t!\"} Copy At the moment of executing the foo-monitor integration, there are three running containers labeled with service=foo: ip: 10.0.0.3, port: 8080 ip: 10.0.0.3, port: 8081 ip: 10.0.0.3, port: 8082 The agent then creates the following three temporary files, using the contents of the config property as a template, but replacing the ${placeholders} by the acquired variables and discovered items (files' path is invented for the sake of simplicity): First match (/tmp/123_discovered): foo.host=10.0.0.3 foo.port=8080 foo.user=monitorer foo.password=5up3r53cr3t! Copy Second match (/tmp/456_discovered): foo.host=10.0.0.3 foo.port=8081 foo.user=monitorer foo.password=5up3r53cr3t! Copy Third match (/tmp/789_discovered) foo.host=10.0.0.3 foo.port=8082 foo.user=monitorer foo.password=5up3r53cr3t! Copy After the config variable placeholders have been replaced and the temporary files have been created, the /opt/foo/bin/monitor executable is executed three times (one per matched container), replacing the ${config.path} command-line placeholder with the temporary file corresponding to each discovered configuration: First match: /opt/foo/bin/monitor --config=/tmp/123_discovered Second match: /opt/foo/bin/monitor --config=/tmp/456_discovered Third match: /opt/foo/bin/monitor --config=/tmp/789_discovered To ensure security and to minimize the chance of leaking secrets to disk, the agent: Creates the files owned by the agent user, for example, root or nri-agent, depending on the user you have configured to run the agent. Sets read permissions only for the owner. Removes the created files when the integration instance finishes its execution. config_template_path If you want to use the secrets management and discovery in the configuration files that you're passing to the integration executable, but you prefer to keep them as an individual file, you can use the config_template_path: <path> option. It works exactly as in the config section: The agent applies secrets management and discovery to the file contents. The agent creates different temporary files that are passed to the integration via the ${config.path} placeholder (or the CONFIG_PATH environment variable). Example: discovery: docker: match: name: /^redis/ integrations: - name: nri-flex env: CONFIG_FILE: ${config.path} config_template_path: /etc/flex-configs/redis.yml Copy In the above example, the redis.yml external file can contain container discovery variable placeholders, like ${discovery.ip} or ${discovery.port}. Configure how the agent executes your integrations The properties of this section modify the way the Infrastructure agent executes and interacts with the integrations, or the way the agent decorates the integrations' data. integration_user The integration commands run as the same user as the agent (usually root or nri-agent). If due to permission restrictions an integration needs to run as another user, its name must be specified in the integration_user property. Example: integrations: - name: dbus-inventory exec: python my-dbus-script.py integration_user: dbus Copy interval The interval option sets the time between consecutive executions of an integration. The accepted format is an integer immediately followed by a time unit (s for seconds, m for minutes, h for hours). The default is 30s, and the minimum accepted value is 15s. Any value lower than 15s is automatically set to 15s. Example: integrations: - name: nri-nginx env: STATUS_URL: http://127.0.0.1/status STATUS_MODULE: discover interval: 20s Copy inventory_source Any inventory item must be catalogued under a category/source taxonomy. By default, each integration inventory is stored as integration/ + name value (for example, integration/nri-apache, integration/nri-mysql). The inventory_source property allows you to override the default taxonomy of inventory data. Example: integrations: - name: nri-nginx - name: nri-apache exec: - /var/db/newrelic-infra/newrelic-integrations/bin/nri-apache - --inventory inventory_source: config/apache Copy In the above example, the nri-nginx inventory, if any, would be visible in the New Relic UI under the integration/nri-nginx source. The nri-apache inventory would be visible under config/apache. labels labels is a key-value map that allows extra metadata to be provided for the integration. The agent uses those labels to decorate the metrics, events, and inventory that it receives from a given integration instance. Example: integrations: - name: nri-apache inventory_source: config/apache labels: env: production role: load_balancer Copy In the above example, the agent decorates all the metrics and events from the nri-apache instance with the following fields: label.env: production label.role: load_balancer Also, the following entries are added to the integration inventory: config/apache/labels/env: production config/apache/labels/role: load_balancer timeout If an integration has not returned any metric (or a heartbeat message as described below) before the time specified in the timeout value, the agent kills the integration process and restarts it after the corresponding interval. The accepted format is an integer number immediately followed (without spaces) by a time unit (ms for milliseconds, s for seconds, m for minutes, h for hours). If a zero (or negative) timeout value is provided, the integration can run forever without being killed by a timeout expiration. For long-running integrations (integrations that keep running, periodically returning metrics/events/inventory), each time the integration submits a metrics/events/inventory payload, the timeout deadline is restarted. That means that long-running integrations must return a valid JSON payload in an interval that is lower than timeout. Returning an empty JSON ({}) is interpreted as a heart-beat message that restarts the timeout, preventing the long-running integration from being killed, even if they don't have information to report. The default is 120s, and the minimum accepted value is 100ms. Any value lower than 100ms is automatically set to 100ms. Example: integrations: - name: nri-jmx arguments: JMX_HOST: jmx-host.localnet JMX_PORT: 7096 COLLECTION_FILES: \"/etc/newrelic-infra/integrations.d/jvm-metrics.yml\" timeout: 30s Copy working_dir working_dir sets the working directory of the command. If empty or unspecified, the agent runs the command in the Infrastructure agent's current directory. The default is the Infrastructure agent root directory. Example: integrations: - name: my-integration exec: /opt/integration/bin/integration working_dir: /opt/integration/scratch-zone Copy Update older integration configuration In December 2019, the Infrastructure agent version 1.8.0 began using a different configuration format. For details, see Config format differences. The main difference between these formats is that the older configuration format uses two separate configuration files (a INTEGRATION_NAME-definition.yml file and a INTEGRATION_NAME-config.yml file) and the newer version uses a single configuration file. Here are some of the features added by the newer configuration functionality: Flexible configuration via command-line arguments, environment variables, or external files. Ability to group different integrations in the same file. Hot reload: adding a new integration or changing its configuration does not require restarting the agent. Timeouts: if an integration doesn't respond before a user-specified time, the integration process is killed and restarted. Not all on-host integrations come with the newer configuration format, but you can update the configuration to the new format for all on-host integrations to take advantage of the new features. The following YAML shows an example Apache integration configuration using the older configuration format. Note that this configuration will still work with newer agents, but we recommend updating your integrations to take full advantage of features. integration_name: com.newrelic.apache instances: - name: apache-server-metrics command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy To update an older integration configuration to the new format, you must perform two steps: Rename the instances top-level section to integrations. Remove the integration_name top-level section and add it to each integration entry. You are no longer required to keep a separate file for each integration type and you can group your legacy integration entries in the same file as other integrations. The new version of the Apache integration config: integrations: - name: apache-server-metrics integration_name: com.newrelic.apache command: metrics arguments: status_url: http://127.0.0.1/server-status?auto remote_monitoring: true labels: env: production role: load_balancer - name: apache-server-inventory integration_name: com.newrelic.apache command: inventory arguments: remote_monitoring: true labels: env: production role: load_balancer Copy Please note that because the older configuration format doesn't support hot reloading. You will need to restart the Infrastructure agent to remove the old integrations configuration (otherwise the old instances will coexist with the new ones).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Newer configuration format ",
        "sections": "On-host <em>integrations</em>: Newer configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. In December 2019, <em>Infrastructure</em> agent version 1.8.0 began supporting a newer configuration format that makes use of a single configuration file (instead of two separate files), and provides other"
      },
      "id": "603e923928ccbcb8dfeba751"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations": [
    {
      "sections": [
        "Compatibility and requirements for Infrastructure Integrations SDK",
        "Infrastructure version",
        "Operating systems",
        "Data and file specifications",
        "SDK version changes"
      ],
      "title": "Compatibility and requirements for Infrastructure Integrations SDK",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Get started"
      ],
      "external_id": "ea949057459c7c9648a9215928c1fd54c9d6a703",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/get-started/compatibility-requirements-infrastructure-integrations-sdk/",
      "published_at": "2021-06-20T10:43:40Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before using the New Relic Infrastructure integrations SDK to create a custom on-host integration, make sure your system meets these requirements. Infrastructure version To use the infrastructure Integrations SDK v4, you must have the Infrastructure agent version 1.13.0 or higher. To use SDK v3, you must have agent version 1.0.888 or higher. For Infrastructure agent version information and options for installation and updates, see the Infrastructure release notes. For notes on SDK versions and changes, see the change log. Operating systems Integrations built with the SDK can be compiled for either Linux or Windows operating systems. Data and file specifications Infrastructure on-host integrations can be created with any programming language, as long as they adhere to the data and file specifications. SDK version changes Infrastructure agent version Details 1.13.0 or higher Changes to integration protocol (v4), including support to dynamically register entities in NR1 and send dimensional metrics. New metric types. See SDK v4 release notes. 1.0.888 or higher Changes to JSON format, including support for multiple entities. The new JSON format is referred to as protocol 2 (described in JSON output documentation and also used in the definition file). Uses newer set of Go language build tools (referenced as GoSDK v3). 1.0.726 (for Linux); 1.0.775 (for Windows) Uses JSON protocol 1 (described in JSON output documentation and also used in the definition file). Uses older set of Go language build tools (referenced as GoSDK v2). If you've built an integration using the older Go language build tools and wish to update, see Upgrade from GoSDK v2 to v3 and Upgrade from v3 to v4. For updating the Infrastructure agent, see Update the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 199.63551,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "sections": "Compatibility and requirements for <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Before using the New Relic <em>Infrastructure</em> <em>integrations</em> <em>SDK</em> to <em>create</em> a custom on-host integration, make sure your system meets these requirements. <em>Infrastructure</em> version To use the <em>infrastructure</em> <em>Integrations</em> <em>SDK</em> v4, you must have the <em>Infrastructure</em> agent version 1.13.0 or higher. To use <em>SDK</em> v3"
      },
      "id": "60440de564441fa14f378ecc"
    },
    {
      "sections": [
        "On-host integration files",
        "Integration files"
      ],
      "title": "On-host integration files",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "bad9028bde5eb2b92ad7971e0ca42517530f3796",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integration-files/",
      "published_at": "2021-06-20T20:35:26Z",
      "updated_at": "2021-03-16T08:29:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Infrastructure Integrations SDK lets you create an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before you build an on-host integration, verify you meet the compatibility and requirements. An integration requires at least these files: An executable file, written in any language, that export JSON data in a format expected by the Infrastructure agent One or more configuration files For Go language build tools and a tutorial for creating these files, see Build resources.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.92049,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integration</em> files",
        "sections": "On-host <em>integration</em> files",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "The New Relic <em>Infrastructure</em> <em>Integrations</em> <em>SDK</em> lets you <em>create</em> an on-host integration for reporting custom host and service data. This document explains what files an on-host integration requires. New Relic also provides Go language integration building tools and a tutorial. Integration files Before"
      },
      "id": "603ed7e264441ff57a4e883b"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 191.91362,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes": [
    {
      "sections": [
        "Not seeing Infrastructure integration data",
        "Problem",
        "Solution",
        "Troubleshoot integration requirements",
        "Check the integration log file for error messages",
        "Check that the integration is loading correctly"
      ],
      "title": "Not seeing Infrastructure integration data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "6b918ff0c14a1df232f58fb6cba063d6ab85114e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data/",
      "published_at": "2021-06-20T20:44:29Z",
      "updated_at": "2021-03-13T02:49:24Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You created a custom New Relic Infrastructure on-host integration using the Integrations SDK, but you're not seeing data in the Infrastructure UI. Solution To troubleshoot and resolve the problem: Verify that your integration meets New Relic Infrastructure's integration requirements. After ruling out common problems with integration requirements, follow the more in-depth troubleshooting procedures for error logs and integration loading. Troubleshoot integration requirements If you are not receiving data from your custom integration, verify that your integration follows these requirements. Integration requirements Comments Environment Make sure your environment meets the Integrations SDK requirements. Configuration file Use a validator such as yamllint to verify that the configuration file is a valid YAML file. Verify that the file is in the correct location. Definition file Use a validator such as yamllint to verify that the definition file is a valid YAML file. Verify that the header fields have the required format. Verify that the prefix for inventory set in the definition file is no more than two levels deep. Verify that the file is in the correct location. Metric sets Verify that the integration: Does not generate metric sets with more than 120 key-value pairs. Does not generate more than 1000 metric sets. JSON payload Verify that the integration does not generate a single JSON payload of more than 5 MB. Check the integration log file for error messages After ruling out common problems with integration requirements, follow these more in-depth troubleshooting procedures. Recommendation: Configure a log file in the Infrastructure agent configuration. This helps separate the types of errors so you can spot integration errors more easily. When there is an error loading or running your integration, the Infrastructure agent adds an error message to the log file. Errors are logged even if verbose mode is disabled. Check the log file for lines that include \"level=error\". If there are no error messages, check whether the Infrastructure agent is loading the integration correctly. Check that the integration is loading correctly To verify whether the Infrastructure agent is loading the integration correctly: Enable verbose mode in the Infrastructure agent configuration. Restart the Infrastructure agent. Verify that the first lines of the log file contain two messages: \"loaded plugin\" plugin=<your_integration_name> \"found plugin config file\" plugin-path=\"<your_integration_config_path>\" Copy Check for errors just before or after these lines that indicate a problem with loading. The agent schedules data to be sent based on the schedule set in the definition file. Look in the log file for the integration's JSON. JSON payload example nginx-server-metrics: {\\\"name\\\":\\\"com.newrelic.nginx\\\",\\\"protocol_version\\\":\\\"1\\\",\\\"integration_version\\\":\\\"0.5.0\\\",\\\"metrics\\\": [{\\\"event_type\\\":\\\"NginxSample\\\",\\\"net.connectionsAcceptedPerSecond\\\":0.10344827586206896,\\\"net.connectionsActive\\\":1, \\\"net.connectionsDroppedPerSecond\\\":0,\\\"net.connectionsReading\\\":0,\\\"net.connectionsWaiting\\\":0,\\\"net.connectionsWriting\\\":1, \\\"net.requestsPerSecond\\\":0.10344827586206896,\\\"software.edition\\\":\\\"open source\\\",\\\"software.version\\\":\\\"1.4.6 (Ubuntu)\\\"}],\\\"inventory\\\":{},\\\"events\\\":[]} Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.88428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "sections": "Not seeing <em>Infrastructure</em> <em>integration</em> data",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem You created a custom New Relic <em>Infrastructure</em> on-host integration using the <em>Integrations</em> <em>SDK</em>, but you&#x27;re not seeing data in the <em>Infrastructure</em> UI. Solution To <em>troubleshoot</em> and resolve the problem: Verify that your integration meets New Relic <em>Infrastructure</em>&#x27;s integration requirements. After"
      },
      "id": "6043efdf28ccbc6d182c6081"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices",
        "For more help"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "5cd5cc6af7ef854ed9f5aabb3c8c6ddbc3e123fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-06-20T20:35:27Z",
      "updated_at": "2021-03-13T02:51:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package. For more help For logging for all New Relic agents, see New Relic agent logs and troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.2285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "6043f02664441fcb4e378efc"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.48315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-infrastructure-integration-data": [
    {
      "sections": [
        "Not seeing attributes data",
        "Problem",
        "Solution"
      ],
      "title": "Not seeing attributes data",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Troubleshooting"
      ],
      "external_id": "25a763fd32bebfa1cb33b77caf260df9a4d9fe53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/troubleshooting/not-seeing-attributes/",
      "published_at": "2021-06-20T20:43:49Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided integrations send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.7473,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "Problem Your integration is reporting data, but a few inventory attributes are missing. Solution The following inventory key names are used internally by our platform. If customer-provided <em>integrations</em> send inventory items with the same key name, they will remain invisible to the user: pid installed_epoch epoch time size boot_id product_uuid installed_time"
      },
      "id": "60506c9564441f0e645321ab"
    },
    {
      "sections": [
        "Integration logging recommendations",
        "Logging requirements",
        "Recommendations and best practices",
        "For more help"
      ],
      "title": "Integration logging recommendations",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "5cd5cc6af7ef854ed9f5aabb3c8c6ddbc3e123fc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/integration-logging-recommendations/",
      "published_at": "2021-06-20T20:35:27Z",
      "updated_at": "2021-03-13T02:51:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure provides an SDK for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It's up to the integration creator to decide what kind of log messages to create, and what kind of information will be useful for debugging issues. There is only one requirement for how an integration must generate logs: The integration executable must write logs to standard error (stderr). The Infrastructure agent will capture lines written to standard error and merge them into the logging stream written by the Infrastructure agent itself. To avoid depending on third-party logging solutions, the Go integration building library provides a simple log package with the common log-levels. Recommendations and best practices Here are the recommended practices for generating integration logs: By default, an integration should be \"quiet.\" Aside from the data emitted to standard output, there should be very few logging or diagnostic messages generated. It's recommended you include a verbose logging mode similar to the verbose setting in the Infrastructure agent. Include a command line switch to enable and disable verbose logging (for example, -verbose). To debug your integration while the integration is running, include the verbose switch in the definition file as part of the command line to be run. This will send the verbose logs to the Infrastructure agent's own log file. For general debugging purposes, New Relic recommends you use a flag that writes the standard out JSON data in human-readable \"pretty-printed\" form (for example, --pretty). Note that output written in a \"pretty-printed\" form is only for your debugging purposes and is not compatible with the Infrastructure agent. Your integration should be created so that it can run on its own. If in doubt whether the integration is communicating with the Infrastructure agent, you can run the integration from the command line and see if it's producing the correct output or log messages you expect. For information about the Go language logging package, see Logging package. For more help For logging for all New Relic agents, see New Relic agent logs and troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.2285,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Integration</em> logging recommendations",
        "sections": "<em>Integration</em> logging recommendations",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> provides an <em>SDK</em> for creating an on-host integration. This document explains requirements and best practices for generating integration logs. Logging requirements It&#x27;s up to the integration creator to decide what kind of log messages to <em>create</em>, and what kind of information"
      },
      "id": "6043f02664441fcb4e378efc"
    },
    {
      "sections": [
        "On-host integrations: Standard configuration format",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Standard configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "3b4c5ab77b2b8025ca8de375403f24bc75b3dca7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/",
      "published_at": "2021-06-20T20:36:20Z",
      "updated_at": "2021-03-16T07:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host integrations and is supported by newer Infrastructure agents (which also support a newer, improved configuration format). For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.48315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host <em>integrations</em>: Standard configuration format",
        "sections": "On-host <em>integrations</em>: Standard configuration format",
        "tags": "<em>Infrastructure</em> <em>Integrations</em> <em>SDK</em>",
        "body": "New Relic <em>Infrastructure</em> on-host <em>integrations</em> can use one of two types of configuration formats. This document explains the older, standard configuration format. This format is used by most on-host <em>integrations</em> and is supported by newer <em>Infrastructure</em> agents (which also support a newer, improved"
      },
      "id": "603e923a196a67581ca83db3"
    }
  ],
  "/docs/csp-v2-error-inline-javascript-not-allowed": [
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-20T06:42:21Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.69147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "tags": "REST API <em>v2</em>",
        "body": "&quot;: &quot;string&quot;, &quot;loader_<em>script</em>&quot;: &quot;string&quot; } Copy API (<em>v2</em>) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app&#x27;s name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/csp-v2-host-install-browser-agent/",
      "sections": [
        "CSP v2: Host and install the Browser agent",
        "Contents",
        "Requirements",
        "1. Whitelist New Relic Browser domains",
        "2. Copy Browser app's JS snippet",
        "3. Create .js file for page"
      ],
      "published_at": "2021-06-20T04:43:40Z",
      "title": "CSP v2: Host and install the Browser agent",
      "updated_at": "2021-05-16T11:10:54Z",
      "type": "docs",
      "external_id": "75530e0b53071dd92148ca07d572bc3a032e9c4e",
      "document_type": "page",
      "popularity": 1,
      "body": "If your organization has strict requirements about Content Security Policy (CSP) v2, you may need to host the New Relic Browser agent in order to properly install and run it. For example, if the New Relic domain hosting the Browser agent is being blocked by your website, you may see an error similar to this: Browser agent.js is unable to run because it violates the following Content Security Protocol directive: script-src = *.google.com other URLs Copy In this situation, you must copy and paste the agent's JavaScript code and self-host it as a .js file. This allows the page to reference the .js file during page load. Contents Requirements In order to host the Browser agent with your app, make sure you follow these requirements: CSP and Browser agent Requirements Application or platform Your app or platform where your site is hosted must meet New Relic Browser's standard compatibility requirements. Exception: CSP restrictions prevent you from linking an APM app for Browser monitoring. Subscription You must have a Pro+SPA Browser subscription for your app. Host location for domains The .js file for New Relic Browser must be hosted on a highly available or replicated location, such as a CDN or distributed network. This helps ensure performance is not affected. If you see error messages, add New Relic Browser domains to your CSP whitelist. If you want New Relic Browser to monitor Salesforce Lightning pages, follow the Salesforce procedures to add New Relic Browser domains to your CSP whitelist. By hosting the agent, you are responsible for any performance impact on the location where the agent is hosted. Browser agent version Your selected app must use the latest Browser agent version. 1. Whitelist New Relic Browser domains Follow your organization's standard procedures to request a CSP exception. Then add both of these New Relic Browser domains to your CSP whitelist: https://js-agent.newrelic.com: This is where the New Relic Browser agent is hosted. The Browser agent download requires three files to run. Two are downloaded after the initial agent is run to continue capturing performance data. https://bam.nr-data.net: This is the endpoint where the New Relic Browser agent receives data from your site. Here is example HTML to add to the head of your site: Content-Security-Policy: default-src 'self' https://js-agent.newrelic.com https://bam.nr-data.net Copy 2. Copy Browser app's JS snippet To create and host a .js file, you must first copy the Browser agent's JavaScript snippet from the hosting app. Go to one.newrelic.com and click Browser. From the list of Browser apps, select the app for which you want to self-host the Browser agent. Select Settings > Application settings > Copy/paste JavaScript code. Copy the Browser agent's JavaScript snippet. Save and exit the Browser app's Application settings page. Continue with the procedures to create a .js file for your page. 3. Create .js file for page After you copy the Browser agent's JavaScript snippet from the selected Browser app: Open a text editor and paste the Browser agent's JavaScript snippet. Delete the first line (<script type=\"text/javascript\">) and the last line of the JavaScript snippet (</script>). Save the text file as nr-spa-VERSION_NUMBER.min.js, where VERSION_NUMBER is the latest Browser agent version. Reference the .js file in the <head> of your webpage. After you install the Browser agent's JavaScript snippet, you can use the New Relic Browser UI to monitor website performance.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.15483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CSP</em> <em>v2</em>: Host and install the Browser agent",
        "sections": "<em>CSP</em> <em>v2</em>: Host and install the Browser agent",
        "body": "If your organization has strict requirements about Content Security Policy (<em>CSP</em>) <em>v2</em>, you may need to host the New Relic Browser agent in order to properly install and run it. For example, if the New Relic domain hosting the Browser agent is being blocked by your website, you may see an <em>error</em>"
      },
      "id": "6043d37364441f42cf378ee8"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/python-release-notes/python-agent-60401158/",
      "sections": [
        "Python agent v6.4.1.158",
        "Notes",
        "New Features",
        "Improvements",
        "Bug Fixes"
      ],
      "published_at": "2021-06-20T16:17:28Z",
      "title": "Python agent v6.4.1.158",
      "updated_at": "2021-06-09T12:48:41Z",
      "type": "docs",
      "external_id": "e80e9b29d88819e6d2375727e58f985ad9f6c5e3",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes This release of the Python agent adds support for Flask v2, improves logging for HTTP exceptions, and includes a bug fix. The agent can be installed using easy_install/pip/distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add support for Flask v2 The agent will automatically instrument error handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes Non-PID specific memory metric being reported In agent version v6.2.0.156, memory metrics were modified to add the PID to each metric name. This release reintroduces non-PID specific memory metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.73538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python agent <em>v6.4.1.158</em>",
        "sections": "Python agent <em>v6.4.1.158</em>",
        "body": " support for Flask <em>v2</em> The agent will automatically instrument <em>error</em> handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes"
      },
      "id": "60c0b8aa196a67bcdad09e47"
    }
  ],
  "/docs/csp-v2-host-install-browser-agent": [
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-20T06:42:21Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 428.3521,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list <em>Browser</em> apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list <em>Browser</em> apps <em>via</em> API (<em>v2</em>)",
        "tags": "<em>Browser</em> examples (<em>v2</em>)",
        "body": " multiple apps, or for integration partners who facilitate New Relic account creation and <em>browser</em> monitoring deployments. Important When you add a <em>browser</em> app via API (<em>v2</em>), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use <em>Browser</em> SPA <em>agent</em>. To add"
      },
      "id": "603ed6a928ccbc422beba77b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/csp-v2-monitor-salesforce/",
      "sections": [
        "CSP v2: Monitor Salesforce",
        "Contents",
        "Requirements",
        "1. Whitelist New Relic Browser domains",
        "2. Copy Browser app's JS snippet",
        "3. Create .js file for page",
        "4. Keep Browser agent up to date"
      ],
      "published_at": "2021-06-20T02:04:52Z",
      "title": "CSP v2: Monitor Salesforce",
      "updated_at": "2021-05-16T15:27:49Z",
      "type": "docs",
      "external_id": "c1086099119c1b6a2972d0b3380cd11439f48c48",
      "document_type": "page",
      "popularity": 1,
      "body": "Salesforce has strict requirements about Content Security Policy (CSP) v2. In this situation, you must copy and paste the New Relic Browser agent's JavaScript code and self-host it as a .js file. This allows the page to reference the .js file during page load. Contents Requirements In order to use New Relic Browser to monitor Salesforce Lightning pages, make sure you follow these requirements: CSP and Salesforce Lightning Browser agent requirements Application or platform Your app or platform where your site is hosted must meet New Relic Browser's standard compatibility requirements. Exception: CSP restrictions prevent you from linking an APM app for Browser monitoring. Subscription You must have a Pro+SPA Browser subscription for your app. Host location for domains The .js file for New Relic Browser must be hosted on a highly available or replicated location, such as a CDN or distributed network. This helps ensure performance is not affected. Follow the Salesforce procedures to add New Relic Browser URLs to your CSP whitelist. Browser agent version Your selected app must use the latest Browser agent version. You must manually update the .js file whenever the New Relic Browser agent version is updated. New Relic Browser cannot make this change automatically for Salesforce Lightning apps. 1. Whitelist New Relic Browser domains Follow the Salesforce procedures to add New Relic Browser URLs to your CSP whitelist. Add both of these New Relic Browser domains to your CSP whitelist: https://js-agent.newrelic.com: This is where the New Relic Browser agent is hosted. The Browser agent download requires three files to run. Two are downloaded after the initial agent is run to continue capturing performance data. https://bam.nr-data.net: This is the endpoint where the New Relic Browser agent receives data from your site. 2. Copy Browser app's JS snippet To create and host a .js file, you must first copy the Browser agent's JavaScript snippet from the hosting app. Go to one.newrelic.com and click Browser.. From the list of Browser apps, select the app for which you want to self-host the Browser agent. Select Settings > Application settings > Copy/paste JavaScript code. Copy the Browser agent's JavaScript snippet. Save and exit the Browser app's Application settings page. Continue with the procedures to create a .js file for your page. 3. Create .js file for page After you copy the Browser agent's JavaScript snippet from the selected Browser app: Open a text editor and paste the Browser agent's JavaScript snippet. Delete the first line (<script type=\"text/javascript\">) and the last line of the JavaScript snippet (</script>). Save the text file as nr-spa-AGENT_VERSION.min.js, where AGENT_VERSION is the latest Browser agent version. Upload the .js file to your Salesforce external JavaScript libs directory, and reference the .js file in the <head> of your webpage. After you install the Browser agent's JavaScript snippet, you can use the New Relic Browser UI to monitor website performance. 4. Keep Browser agent up to date You must manually update the .js file whenever New Relic updates the Browser agent version. New Relic Browser cannot make this change automatically for Salesforce Lightning apps.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 316.7941,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>CSP</em> <em>v2</em>: Monitor Salesforce",
        "sections": "<em>CSP</em> <em>v2</em>: Monitor Salesforce",
        "body": "Salesforce has strict requirements about Content Security Policy (<em>CSP</em>) <em>v2</em>. In this situation, you must copy and paste the New Relic <em>Browser</em> <em>agent</em>&#x27;s JavaScript code and self-<em>host</em> it as a .js file. This allows the page to reference the .js file during page load. Contents Requirements In order to use"
      },
      "id": "6043b986e7b9d2d0025799c0"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/python-release-notes/python-agent-60401158/",
      "sections": [
        "Python agent v6.4.1.158",
        "Notes",
        "New Features",
        "Improvements",
        "Bug Fixes"
      ],
      "published_at": "2021-06-20T16:17:28Z",
      "title": "Python agent v6.4.1.158",
      "updated_at": "2021-06-09T12:48:41Z",
      "type": "docs",
      "external_id": "e80e9b29d88819e6d2375727e58f985ad9f6c5e3",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes This release of the Python agent adds support for Flask v2, improves logging for HTTP exceptions, and includes a bug fix. The agent can be installed using easy_install/pip/distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add support for Flask v2 The agent will automatically instrument error handlers, nested blueprints, and async views. Improvements Improved logging for 410 status codes The agent now logs the content of a data collector response which specifies the reason for a disconnect for 410 status codes. Bug Fixes Non-PID specific memory metric being reported In agent version v6.2.0.156, memory metrics were modified to add the PID to each metric name. This release reintroduces non-PID specific memory metrics.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.72964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Python <em>agent</em> <em>v6.4.1.158</em>",
        "sections": "Python <em>agent</em> <em>v6.4.1.158</em>",
        "body": "Notes This release of the Python <em>agent</em> adds support for Flask <em>v2</em>, improves logging for HTTP exceptions, and includes a bug fix. The <em>agent</em> can be installed using easy_<em>install</em>&#x2F;pip&#x2F;distribute via the Python Package Index or can be downloaded directly from the New Relic download site. New Features Add"
      },
      "id": "60c0b8aa196a67bcdad09e47"
    }
  ],
  "/docs/csp-v2-monitor-salesforce": [
    {
      "sections": [
        "Introduction to New Relic's REST API Explorer",
        "Features",
        "Differences from API version 1",
        "Tip",
        "For more help"
      ],
      "title": "Introduction to New Relic's REST API Explorer",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "457d31007ab690d5e6f3679e150814c280b49441",
      "image": "https://docs.newrelic.com/static/c506cb08149178347d12b6cbb236c855/23592/API_explorer_main_page.png",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/introduction-new-relics-rest-api-explorer/",
      "published_at": "2021-06-20T20:42:50Z",
      "updated_at": "2021-06-20T20:42:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers several APIs, including the New Relic REST API. This document introduces you to the REST API Explorer, which allows admin users and those with the API Key to: Browse the available REST API endpoints. Interact with the REST API within a user interface (the API Explorer). View a live source of documentation. Obtain curl commands for API actions. Share configured API calls with colleagues by copy and pasting API Explorer's URLs. This helps you to quickly search for solutions and test your API calls before adding them to your own software components. Features New Relic's API Explorer includes an interactive user interface for your selected account. The API Explorer UI lists the types of API calls (Applications, Users, etc.) and their available functions, such as GET metric data, PUT (update) applications, DELETE applications, etc. As you type values for Parameters, they automatically appear in the Request so that you can test and verify your syntax before sending the request. The UI indicates required fields, field descriptions, their type (integer, float, Boolean, etc.), and their location (path, query, etc.). For information on API key requirements, see REST API keys. rpm.newrelic.com/api/explore: The New Relic API Explorer makes it easy to test and send requests for any API endpoint. After you select your account and your choice of functions for the type of API call (applications, browsers, users, etc.), the UI provides an interactive form to view requirements and test your parameter values. Differences from API version 1 This API Explorer applies only to the New Relic REST API version 2, which focuses on data in and data out of New Relic. Version 2 replaces New Relic's deprecated REST API version 1. Be aware there are some differences between version 2 and 1: Names for data may be different. Some cURL commands for v2 are different than v1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 430.33392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Differences from API <em>version</em> 1",
        "tags": "REST API <em>v2</em>",
        "body": " and 1: Names for data may be different. Some cURL commands for <em>v2</em> are different than <em>v</em>1. Tip The New Relic agents use different APIs and are not accessible via the API Explorer. For more help"
      },
      "id": "6043ff97196a67c2f2960f65"
    },
    {
      "sections": [
        "Use the API Explorer",
        "API key requirements",
        "Important",
        "Access the API Explorer"
      ],
      "title": "Use the API Explorer",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "API Explorer v2"
      ],
      "external_id": "0af25c5683418b6c806b4ec2addad065fe569e07",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/api-explorer-v2/use-api-explorer/",
      "published_at": "2021-06-20T03:51:59Z",
      "updated_at": "2021-06-20T03:51:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's REST API Explorer (v2) makes it easy to test and send requests for any available API endpoint. After you select your choice of functions for the type of API call (applications, browsers, etc.), the user interface provides an interactive form to view requirements and test your parameter values. It also provides a live source of documentation about the API values. API key requirements Before you can use the API Explorer, API access must be activated and an API key must be generated for your account. Important We recommend using the user key, not the REST API key, because the user key has fewer restrictions. Tips: If you're signed in to New Relic, when you use the API Explorer you can choose your API key at the top of the UI and that key will appear automatically in the Request and Parameters sections of the Explorer. If you're not signed in to New Relic, you can paste your API key into the API Explorer's Parameters. Access the API Explorer To use the New Relic API Explorer: Go to rpm.newrelic.com/api/explore. From the API Explorer's menu bar, select the account name for your app from the dropdown list. From the sidebar, select a product (Applications, Browsers, etc.) and an available API function: GET, PUT, DELETE. Type the other Parameters values for your API call. (Refer to the UI for descriptions and requirements for v2.) Select the format for your request: JSON or XML. Select Send Request.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 416.48267,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "REST API <em>v2</em>",
        "body": "New Relic&#x27;s REST API Explorer (<em>v2</em>) makes it easy to test and send requests for any available API endpoint. After you select your choice of functions for the type of API call (applications, browsers, etc.), the user interface provides an interactive form to view requirements and test your parameter"
      },
      "id": "6043ffe528ccbcf8ca2c6069"
    },
    {
      "sections": [
        "Add or list Browser apps via API (v2)",
        "Important",
        "Add browser apps",
        "List all browser apps",
        "View specific browser apps"
      ],
      "title": "Add or list Browser apps via API (v2)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v2",
        "Browser examples (v2)"
      ],
      "external_id": "53568984e3b360bac9255a33adad7e6b43fadf5d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v2/browser-examples-v2/add-or-list-browser-apps-api-v2/",
      "published_at": "2021-06-20T06:42:21Z",
      "updated_at": "2021-06-14T23:01:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are examples of how to use the New Relic REST API (v2) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying multiple apps, or for integration partners who facilitate New Relic account creation and browser monitoring deployments. Important When you add a browser app via API (v2), you can only instrument basic page load timing. To use instrumentation supporting all SPA features, see Use Browser SPA agent. To add a fully instrumented app, go to one.newrelic.com, and click the Add more data button on the top right hand-side. Then, use the guided install to start monitoring your app. Add browser apps To add an app to New Relic One, replace ${APIKEY} with your New Relic API key, and replace ${STRING} with the app's name in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > POST Create. Use the following command: curl -X POST 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i -H 'Content-Type: application/json' \\ -d \\ '{ \"browser_application\": { \"name\": ${STRING} } }' Copy The API returns an array of data where the element is a Browser application and the data associated with it: { \"browser_application\": { \"id\": \"integer\", \"name\": \"string\", \"browser_monitoring_key\": \"string\", \"loader_script\": \"string\" } Copy API (v2) output Description Browser app id (integer) This is the unique identification code for each app in New Relic One. App name (string) This is the app's name as it appears in the New Relic One. The browser_monitoring_key (string) This a unique key that is linked to (but is not the same as) the account license key. It is used to indicate the account in New Relic One where data will be reported. It cannot be used to determine your New Relic account's license key. Browser monitoring loader_script (string) The returned loader script is a JSON-encoded JavaScript snippet that is configured with the New Relic license key and application ID. The rest of the script is static and is approximately 10k in size. The loader script must be inserted into the user’s HTML pages correctly: It must appear in the page's <head> tag before the first script tag. If there are no script tags, put the JavaScript immediately before the </head> (end of head) tag. The entire loader script must be inserted in-line, not as a link to the .js file. List all browser apps To view a list of your apps in New Relic Browser, replace ${APIKEY} with your New Relic API key in the following command. To accomplish the same task from the API Explorer, use your API key and go to rpm.newrelic.com/api/explore > Browser Applications > GET List. Use the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i Copy You can use the results to verify the account or name, and to get a copy of the loader script for the app, if needed. View specific browser apps View by name: To view a specific Browser app if you know its name, replace ${APIKEY} with your New Relic API key, and replace ${NAME} with your app's name in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d \"filter[name]=${NAME}\" Copy View by Browser application ID: To view a specific Browser app if you know its ID, replace ${APIKEY} with your New Relic API key, and replace ${ID} with your Browser application ID in the following command: curl -X GET 'https://api.newrelic.com/v2/browser_applications.json' \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'filter[ids]=${ID}' Copy View multiple browser apps: To get information for multiple apps, separate the name or ID values with a comma in these commands; for example: -d 'filter[ids]=12345,23456' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 350.8557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "sections": "Add or list Browser apps <em>via</em> API (<em>v2</em>)",
        "tags": "REST API <em>v2</em>",
        "body": "Here are examples of how to use the New Relic REST API (<em>v2</em>) to add apps to browser monitoring or to get a list of your browser apps for a specific API key. This helps you manage deployment outside of New Relic One. These API calls are useful, for example, with larger organizations deploying"
      },
      "id": "603ed6a928ccbc422beba77b"
    }
  ],
  "/docs/distributed-tracing/concepts/distributed-tracing-planning-guide": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.25232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and Mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-06-20T06:57:36Z",
      "updated_at": "2021-05-16T15:32:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and Mobile trace reporting Browser monitoring distributed tracing and Mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.33575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.18463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 307.2522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick <em>start</em>. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-20T20:56:23Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.6211,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "): This shows the transaction <em>trace</em> UI before <em>distributed</em> <em>tracing</em> is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.1846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/concepts/introduction-distributed-tracing": [
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-20T20:56:23Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.6211,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "): This shows the transaction <em>trace</em> UI before <em>distributed</em> <em>tracing</em> is enabled, with a link to the associated transaction. With <em>distributed</em> <em>tracing</em> enabled, it will display the service&#x27;s URL. If you wanted to <em>get</em> more detail about <em>trace</em> activity, you would go to the <em>Distributed</em> <em>tracing</em> UI page and examine"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "How New Relic distributed tracing works",
        "Tip",
        "Trace sampling",
        "Head-based sampling (standard distributed tracing)",
        "Language agents: adaptive sampling",
        "Language agents: limits and sampling",
        "Trace rate limiting",
        "Lambda trace sampling",
        "Tail-based sampling (Infinite Tracing)",
        "Architecture",
        "Tail-based sampling algorithms",
        "No sampling",
        "Browser and Mobile trace reporting",
        "Trace API",
        "How trace data is structured",
        "How trace data is stored",
        "How trace context is passed between applications",
        "Important",
        "Scenario 1: Trace touching three agent types",
        "Scenario 2: Trace with W3C New Relic and middleware",
        "Scenario 3: Trace with any W3C-compliant agent and a New Relic agent."
      ],
      "title": "How New Relic distributed tracing works",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "4dbe0119017f78ad4db2a2b8a9ca2d287222753a",
      "image": "https://docs.newrelic.com/static/406c9f3af4012dab16df681c8feab256/c1b63/new-relic-distributed-tracing-trace-structure.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/",
      "published_at": "2021-06-20T06:57:36Z",
      "updated_at": "2021-05-16T15:32:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some technical details about how New Relic distributed tracing works: How trace sampling works How we structure trace data How we store trace data How trace context is passed between applications Tip For instructions about setting up distributed tracing, see Overview: Enable distributed tracing. Trace sampling How your traces are sampled will depend on your setup and the New Relic tracing tool you're using. For example, you may be using a third-party telemetry service (like OpenTelemetry) to implement sampling of traces before your data gets to us or, if you're using Infinite Tracing, you'd probably send us all your trace data and use our sampling. We have a few sampling strategies available: Head-based sampling (standard distributed tracing) Tail-based sampling (Infinite Tracing) No sampling Head-based sampling (standard distributed tracing) With the exception of our Infinite Tracing feature, most of our tracing tools use a head-based sampling approach. This applies filters to individual spans before all spans in a trace arrive, which means decisions about whether to accept spans is made at the beginning (the \"head\") of the filtering process. We use this sampling strategy to capture a representative sample of activity while avoiding storage and performance issues. Here are some details about how head-based sampling is implemented in our standard distributed tracing tools: Language agents: adaptive sampling Our APM language agents use adaptive sampling to capture a representative sample of system activity. The following is an explanation of how adaptive sampling works. For the first service in a distributed trace, 10 requests are chosen to be sampled. The throughput to that service is used to adjust how frequently requests are sampled. This is explained in more detail below. The first service we monitor in a distributed trace is called the trace origin. The trace origin chooses requests at random to be traced. That decision propagates to the downstream services touched by that request. When the request has completed, all of the spans touched by that request that we've detected are made available in the UI as a complete trace (though agent limits may result in fragmented traces). APM agents have a limit on the number of transactions collected per minute (this can vary, depending on agent) and a limit on the number of spans collected per minute (1000 per agent instance). To adhere to these limits, the default number of traces at the trace origin is 10 traces per minute. An APM agent spreads out the collection of these 10 traces over a minute in order to get a representative sample over time. The exact sampling rate depends on the number of transactions in the previous minute. The rate responds to changes in transaction throughput, going up or down. For example, if the previous minute had 100 transactions, the agent would anticipate a similar number of transactions and select 1 out of every 10 transactions to be traced. Language agents: limits and sampling An APM language agent instance using head-based sampling has a limit of 1000 spans per minute. The agent attempts to keep all spans that are marked to be sampled as part of a distributed trace. In many distributed systems, the average microservice may generate 10 to 20 spans per request. In those cases, the agent span limit can accommodate all spans chosen, and that service will have full detail in a trace. However, some requests to services will generate many spans, and the agent span limit will be reached. As a result, some traces will not have full detail for that service. One solution to this would be to custom instrument an agent to report less activity and therefore report fewer spans. To read about how browser monitoring of trace data may vary from our language agents, see Browser traces. Trace rate limiting If the above sampling methods still result in too much trace data, we may limit incoming data by sampling traces after they're received. By making this decision at the trace level, it avoids fragmenting traces (accepting only part of a trace). This process works similarly to adaptive sampling. The total spans received in a minute are totaled. If too many spans are received, fewer spans may be accepted in the following minute, in order to achieve a floating-average throughput rate. Lambda trace sampling Our AWS Lambda monitoring uses its own sampling process. Tail-based sampling (Infinite Tracing) Our Infinite Tracing feature uses a tail-based sampling approach. \"Tail-based sampling\" means that trace-retention decisions are done at the tail end of processing after all the spans in a trace have arrived. With Infinite Tracing, you can send us 100% of your trace data from your application or third-party telemetry service, and Infinite Tracing will figure out which trace data is most important. And you can configure the sampling to ensure the traces important to you are retained. Architecture For Infinite Tracing, agents or integrations send 100% of all instrumented spans to a trace observer. The trace observer is a distributed tracing service residing in a cluster of services on AWS called New Relic Edge. Tip Only your spans go to the trace observer—all other data such as metrics, custom events, and transaction traces are sent the normal route to New Relic and are subject to local sampling. You configure a unique trace observer endpoint for the AWS region you want to send data to. You can request multiple endpoints, one per AWS region. The endpoint represents a trace observer for a particular workload. For example, all spans from a single trace (request) must go to that endpoint. Here are two architectural diagrams: one showing how data flows if you use APM agents and another if you use New Relic integrations like OpenTelemetry exporters: The trace observer holds traces open while spans for that trace arrive. Once the first span in a trace arrives, a session is kept open for 10 seconds. Each time a new span for that trace arrives, the expiration time is reset to 10 seconds. Traces that haven't seen a span arrive within the last 10 seconds will automatically expire. Tail-based sampling algorithms By default, each trace observer offers traces to three samplers: one looking for duration outliers, one looking for traces with errors, and one trying to randomly sample across all trace types. Each sampler keeps a target percentage of traces that match their criteria. Here are details about each sampler: Sampler Matching criteria Target percent Duration Traces with an outlier duration, using two algorithms: Gaussian (Assumes a normal distribution and a threshold at the 99th percentile) Eccentricity (Assumes no distribution and a threshold based on cluster) 100% Error Traces having at least one span with an error 100% Random All traces 1% (This is configurable. See Infinite Tracing: Random trace filter) If the matching criteria matches the trace, each sampler looks at the trace’s shape. A trace’s shape is the unique combination of the root span’s entity name and span name. This is a simple way to separate traces using the entry point of the request. Once the shape is determined, the sampler makes a decision to keep or reject the trace based on its target sampling percent. If it’s 100%, the trace is automatically kept. If it’s anything less, the probability the sampler keeps a given trace is determined by the target percent. For example, the default target percent is 1 for random traces, so 1% of those traces are kept. If you prefer, you can change the random filter percentage. Because the trace observer uses percentages of throughput, the number of traces selected will vary with that throughput. No sampling Some of our tools don't use sampling. Sampling details for these tools: Browser and Mobile trace reporting Browser monitoring distributed tracing and Mobile monitoring report all spans. Our APM language agents are often used in conjunction with browser and mobile monitoring, and our language agents use sampling. This means that there will likely be many more browser and mobile spans than back-end spans, which can result in browser and mobile app spans disconnected from back-end spans. For tips on querying for traces that contain front and back-end spans, see Find browser span data. Trace API If you don't have Infinite Tracing enabled, our Trace API does no sampling (unless the default data limits are exceeded). It's expected that you set up the Trace API to send us the traces you think are important. How trace data is structured Understanding the structure of a distributed trace can help you: Understand how traces are displayed in our UI Help you query trace data A distributed trace has a tree-like structure, with \"child\" spans that refer to one \"parent\" span. This diagram shows some important span relationships in a trace: This diagram shows how spans in a distributed trace relate to each other. This diagram shows several important concepts: Trace root. The first service or process in a trace is referred to as the root service or process. Process boundaries. A process represents the execution of a logical piece of code. Examples of a process include a backend service or Lambda function. Spans within a process are categorized as one of the following: Entry span: the first span in a process. Exit span: a span is a considered an exit span if it a) is the parent of an entry span, or b) has http. or db. attributes and therefore represents an external call. In-process span: a span that represents an internal method call or function and that is not an exit or entry span. Client spans. A client span represents a call to another entity or external dependency. Currently, there are two client span types: Datastore. If a client span has any attributes prefixed with db. (like db.statement), it's categorized as a datastore span. External. If a client span has any attributes prefixed with http. (like http.url) or has a child span in another process, it's categorized as an external span. This is a general category for any external calls that are not datastore queries. Trace duration. A trace's total duration is determined by the length of time from the start of the earliest span to the completion of the last span. You can query span relationship data with the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. How trace data is stored Understanding how we store trace data can help you query your trace data. We save trace data as: Span: A span represents operations that are part of a distributed trace. The operations that a span can represent include browser-side interactions, datastore queries, calls to other services, method-level timing, and Lambda functions. One example: in an HTTP service, a span is created at the start of an HTTP request and completed when the HTTP server returns a response. Span attributes contain important information about that operation (such as duration, host data, etc.), including trace-relationship details (such as traceId, guid). For span-related data, see span attributes. Transaction: If an entity in a trace is monitored by an agent, a request to that entity generates a single Transaction event. Transactions allow trace data to be tied to other New Relic features. For transaction-related data, see transaction attributes. Contextual metadata. We store metadata that shows calculations about a trace and the relationships between its spans. To query this data, use the NerdGraph GraphiQL explorer. How trace context is passed between applications We support the W3C Trace Context standard, which makes it easier to trace transactions across networks and services. When you enable distributed tracing, New Relic agents add HTTP headers to a service's outbound requests. HTTP headers act like passports on an international trip: They identify your software traces and carry important information as they travel through various networks, processes, and security systems. The headers also contain information that helps us link the spans together later: metadata like the trace ID, span ID, the New Relic account ID, and sampling information. This header information is passed along each span of a trace, unless the progress is stopped by something like middleware or agents that don't recognize the header format (see Figure 1). Figure 1 To address the problem of header propagation, we support the W3C Trace Context specification that requires two standardized headers. Our latest W3C New Relic agents send and receive these two required headers, and by default, they also send and receive the header of the prior New Relic agent: W3C (traceparent): The primary header that identifies the entire trace (trace ID) and the calling service (span id). W3C (tracestate): A required header that carries vendor-specific information and tracks where a trace has been. New Relic (newrelic): The original, proprietary header that is still sent to maintain backward compatibility with prior New Relic agents. This combination of three headers allows traces to be propagated across services instrumented with these types of agents: W3C New Relic agents Non-W3C New Relic agents W3C Trace Context-compatible agents Important If your requests only touch W3C Trace Context-compatible agents, you can opt to turn off the New Relic header. See the agent configuration documentation for details about turning off the newrelic header. The scenarios below show various types of successful header propagation. Scenario 1: Trace touching three agent types This shows the flow of headers when a request touches three different agent types: Scenario 2: Trace with W3C New Relic and middleware This shows the combination of headers sent by a W3C New Relic agent to some middleware. Scenario 3: Trace with any W3C-compliant agent and a New Relic agent. This shows the two required W3C headers from another vendor accepted by a W3C New Relic agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.33575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "sections": "How New Relic <em>distributed</em> <em>tracing</em> works",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Here are some technical details about how New Relic <em>distributed</em> <em>tracing</em> works: How <em>trace</em> sampling works How we structure <em>trace</em> data How we store <em>trace</em> data How <em>trace</em> context is passed between applications Tip For instructions about setting up <em>distributed</em> <em>tracing</em>, see Overview: Enable <em>distributed</em>"
      },
      "id": "6072a66664441f14089d856c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 170.1846,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> API general requirements and limits ",
        "sections": "<em>Trace</em> API general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you <em>get</em> a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    }
  ],
  "/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.03516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you&#x27;re done, return here with your <em>trace</em> observer information and continue with the next step to <em>configure</em> the agent. Step 3: <em>Configure</em> the agent for Infinite <em>Tracing</em> Infinite <em>Tracing</em> configuration settings include the standard <em>distributed</em> <em>tracing</em> plus information about the <em>trace</em> observer. Find"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " and why the high latency is occurring and which team should address the issue. Instrumentation: The key to <em>distributed</em> <em>tracing</em> <em>Distributed</em> <em>tracing</em> starts with the instrumentation of your services to <em>enable</em> data collection and correlation across the entire <em>distributed</em> system. Instrumention means"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.8915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " and why the high latency is occurring and which team should address the issue. Instrumentation: The key to <em>distributed</em> <em>tracing</em> <em>Distributed</em> <em>tracing</em> starts with the instrumentation of your services to <em>enable</em> data collection and correlation across the entire <em>distributed</em> system. Instrumention means"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.49965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    },
    {
      "sections": [
        "Overview: Set up distributed tracing",
        "New Relic integrations",
        "New Relic integrations for third-party telemetry tools",
        "Set up your own solution with our Trace API",
        "Tip"
      ],
      "title": "Overview: Set up distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "cd81f363a9ee07640029b514cafe1f84ac04ef99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-04-11T07:33:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer a variety of ways to capture distributed tracing data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic Trace API New Relic integrations We offer a range of agents to capture trace data from your applications: Product Description Language agents See telemetry data from applications instrumented with our language-specific agents: C, Go, Java, .NET, Node.js, PHP, Python, and Ruby. Monitoring for AWS Lambda See Lambda function activity, and examine the functions in your traces. Browser See users' browser-side traces. Mobile See users' mobile traces. New Relic integrations for third-party telemetry tools If you are collecting data with these telemetry tools, you can send your data to New Relic: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray Set up your own solution with our Trace API Send data from your telemetry tool directly to New Relic without using an integration that exports the data. Tip Note that this may require more manual configuration than using an integration. Data format Description Trace API: New Relic format Convert your trace data to the New Relic format and send it to New Relic for viewing. Trace API: Data in Zipkin format Send your Zipkin trace data to New Relic for viewing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.8915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "sections": "Overview: Set up <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "We offer a variety of ways to capture <em>distributed</em> <em>tracing</em> data, including: New Relic integrations (including APM, AWS Lambda, browser, and mobile monitoring) New Relic integrations for third-party telemetry tools New Relic <em>Trace</em> API New Relic integrations We offer a range of agents to capture <em>trace</em>"
      },
      "id": "6072a666196a67a2bf64a758"
    }
  ],
  "/docs/distributed-tracing/enable-configure/overview-enable-distributed-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.03516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents <em>and</em> <em>distributed</em> <em>tracing</em>",
        "sections": "<em>Configure</em> standard <em>distributed</em> <em>tracing</em> for your older agents",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you&#x27;re done, return here with your <em>trace</em> observer information and continue with the next step to <em>configure</em> the agent. Step 3: <em>Configure</em> the agent for Infinite <em>Tracing</em> Infinite <em>Tracing</em> configuration settings include the standard <em>distributed</em> <em>tracing</em> plus information about the <em>trace</em> observer. Find"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " and why the high latency is occurring and which team should address the issue. Instrumentation: The key to <em>distributed</em> <em>tracing</em> <em>Distributed</em> <em>tracing</em> starts with the instrumentation of your services to <em>enable</em> data collection and correlation across the entire <em>distributed</em> system. Instrumention means"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Enable distributed tracing for our telemetry tool integrations",
        "Sampling considerations",
        "Set up integrations"
      ],
      "title": "Enable distributed tracing for our telemetry tool integrations",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "ca05c9c79d80af7bc4f16230459e9811a23a94b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/integrations-enable-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-04-15T22:20:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the telemetry tools Istio, Kamon, OpenCensus, OpenTelemetry, or AWS X-Ray, you can get that data into New Relic with our telemetry integrations. Sampling considerations Because distributed systems can generate a lot of trace data, telemetry tools rely on data sampling (filtering). When you install a telemetry integration that reports trace data, you'll have an option to enable Infinite Tracing. Choosing Infinite Tracing has implications for how you configure sampling in your telemetry tool: Standard installation without Infinite Tracing: A standard installation assumes you want your telemetry tool to sample trace data before it's sent to us. (If your trace data exceeds our Trace API limits, we may also do additional sampling.) Install with Infinite Tracing: If you choose Infinite Tracing (read requirements), we assume your telemetry tool's sampling is set to 100%, so that all of that tool's trace data is sent to us. The trace observer selects the most important and actionable traces using tail-based sampling, and then that data is ingested via our Trace API. Set up integrations To set up your telemetry tool for sending distributed traces to New Relic, follow the instructions for your tool: OpenTelemetry Istio Kamon OpenCensus AWS X-Ray",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 224.49965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "sections": "<em>Enable</em> <em>distributed</em> <em>tracing</em> for our telemetry tool integrations",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " you install a telemetry integration that reports <em>trace</em> data, you&#x27;ll have an option to <em>enable</em> Infinite <em>Tracing</em>. Choosing Infinite <em>Tracing</em> has implications for how you <em>configure</em> sampling in your telemetry tool: Standard installation without Infinite <em>Tracing</em>: A standard installation assumes you want"
      },
      "id": "6072a66664441f271c9d8557"
    }
  ],
  "/docs/distributed-tracing/enable-configure/quick-start": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 415.93073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Get <em>started</em>",
        "body": " API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our <em>Quick</em> <em>start</em>. To learn more about what&#x27;s happening under the hood, see How distributed tracing works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://developer.newrelic.com/static/c1fd6182602c7dbc74bf14b13dc1a4c0/0086b/dev-terms-and-conditions.png",
      "url": "https://developer.newrelic.com/build-apps/ab-test/install-nr1/",
      "sections": [
        "Install and configure the New Relic One CLI",
        "Course",
        "Install and configure the CLI",
        "Tip"
      ],
      "published_at": "2021-06-23T01:48:24Z",
      "title": "Install and configure the New Relic One CLI",
      "updated_at": "2021-05-21T01:46:56Z",
      "type": "developer",
      "external_id": "a09ffc1a2296796669ad9d026d6c16937b23a3d4",
      "document_type": "page",
      "popularity": 1,
      "info": "Install and configure the New Relic One CLI",
      "body": "Course This lesson is part of a course that teaches you how to build a New Relic One application from the ground up. If you haven't already, check out the course introduction. Each lesson in the course builds upon the last, so make sure you've completed the last lesson, Spin up your demo services, before starting this one. One of the primary elements of the New Relic One SDK is the command line interface (CLI). To create a Nerdpack , you'll need to install the SDK, configure the CLI to work with your New Relic account, and then utilize its create command. Install and configure the CLI Step 1 of 5 Go to the Build on New Relic quick start. Step 2 of 5 Get your API key: Once you install the CLI, you'll use this key to create a user profile that's associated with your account. The CLI uses this profile to manage entities within your account. Step 3 of 5 Read and accept the New Relic developer terms and conditions: Even if you install the CLI, you won't be able to use it without first accepting these terms and conditions. Step 4 of 5 Choose your operating system and click Download installer: Once you've installed the SDK, you'll have access to the nr1 CLI. Verify this by checking your SDK version: bash Copy $ nr1 --version If you already had the CLI, update it: bash Copy $ nr1 update Tip It’s important to distinguish between the newrelic CLI and the nr1 CLI. newrelic is for managing entities in your New Relic account. nr1 is for managing New Relic One applications. Step 5 of 5 Copy the command to save your credentials: This command has a profile name, your region, and your API key baked in. Run the command in your terminal: bash Copy $ nr1 profiles:add --name <profile name> --api-key <User key> --region <region> Profiles let you select which New Relic account you want to run commands against. If you have multiple accounts, you can view them with profiles:list: bash Copy $ nr1 profiles:list Notice that one profile is your default profile. This is the account your commands will run against, unless you specify another. To specify a profile for a particular command, use the --profile option: bash Copy $ nr1 create --profile <your profile> If this is your first time using the CLI, then the profile you just added is your default profile. If you have other profiles, you need to set your default to the one you'd like to use for this course: bash Copy $ nr1 profiles:default Tip If you forget these commands, you can look them up in the profiles help menu: bash Copy $ nr1 profiles --help Now, you can exit the Build on New Relic quick start. You’re ready to build an application with the New Relic One CLI! Course This lesson is part of a course that teaches you how to build a New Relic One application from the ground up. Continue on to the next lesson: Create a Nerdpack.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 361.5559,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " of 5 Go to the Build on New Relic <em>quick</em> <em>start</em>. Step 2 of 5 Get your API key: Once you install the CLI, you&#x27;ll use this key to create a user profile that&#x27;s associated with your account. The CLI uses this profile to manage entities within your account. Step 3 of 5 Read and accept the New Relic"
      },
      "id": "6091faf1196a6714b4d52a39"
    },
    {
      "sections": [
        "Set up your development environment",
        "Before you begin",
        "A note on support",
        "Tip",
        "Prepare to build or modify apps",
        "Start building",
        "Contribute to developer.newrelic.com"
      ],
      "title": "Set up your development environment",
      "type": "developer",
      "tags": [
        "developer account",
        "API key",
        "New Relic One CLI"
      ],
      "external_id": "c45638a9cd548d1ffffc9f1c7708f115a92ae04a",
      "image": "",
      "url": "https://developer.newrelic.com/build-apps/set-up-dev-env/",
      "published_at": "2021-06-23T01:42:14Z",
      "updated_at": "2021-05-05T01:51:53Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Prepare to build apps and contribute to this site",
      "body": "If you've decided to build a custom app or modify one of our open source apps, you need a few essential tools: The New Relic One command line interface (CLI) An API key, which you get when you download the CLI Depending on what you want to do with your app, you might have some additional setup and configuration. This guide covers: Downloading the New Relic One CLI to build or modify apps Contribute content to this website Before you begin Before you begin, we recommend first reading about permissions. To start building, you must have: A github account account - While not strictly necessary for building apps, a GitHub account enables you to download and customize our open source apps, and contribute an open source project. A New Relic developer account - if you don't already have one, you can get a free trial account for developing New Relic applications. npm - If you've installed Node.js, then you already have npm, which is used to share, reuse, and update JavaScript code, and is necessary for working with React components that are the framework for New Relic apps and this website. A note on support Building a New Relic One application is the same as building any JavaScript/React application. We offer support to help with our building tools (our CLI and SDK library). However, we don't offer support for basic JavaScript or React coding questions or issues. For common questions and answers about building, see the Explorers Hub page on building on New Relic One. Tip Use the New Relic One VSCode extension or the New Relic VSCode extension pack to build your apps. Prepare to build or modify apps Step 1 of 1 Download the CLI and API key. On the Build New Relic One applications page, complete the Quick start steps. These six Quick start steps get you an API key for use with developing apps, and the New Relic One CLI, for building and deploying apps. At the end of the Quick start, you have a project consisting of the following: A Nerdpack - The package containing all the files required by your application. It contains two types of files that you customize to build your app: Nerdlets, and the launcher. One or more Nerdlet files - A specific UI view or window. A Nerdlet is a React JavaScript package that includes an index.js file, a stylesheet, and a JSON-format config file. It can contain any JS functionality (charts, interactive fields, tooltips, etc.). A launcher file: This is the basis for the launcher, which is used to open your application from New Relic One after you publish your app. Start building Step 1 of 1 If you're ready to code, cd to your Nerdpack and get started. If you want to learn more about building applications, try these step-by-step guides: Build a \"Hello, World!\" application shows how to create a little application, publish it to New Relic One, and share it with others by subscribing accounts to it. Map pageviews by region takes you through the steps to create one of our popular open source apps. You learn to add a custom query to an app and view it in a table, then add that data to a map. Contribute to developer.newrelic.com This site is open source, and we want your input. Create a pull request if you see a mistake you know how to fix. Drop us a GitHub issue if you see some content gaps you want us to work on. Or write up a whole new guide if you have one you'd like to share. Read on to learn how. Step 1 of 3 Fork the developer-website GithHub repo. Forking the repo enables you to work on your own copy of the developer.newrelic.com files, and build the site locally. It also enables us to more easily manage incomimg pull requests. On the developer-website page in GitHub, select the Fork button on the top right of the page, choose the account you want to fork to, and wait a few seconds while the fork is created. Sync regularly to keep your fork up to date with changes and additions to the main branch upstream. Step 2 of 3 Make a feature or documentation request. On any page, select the GitHub button at the top of the page, and then select the kind of change you want, and fill out the GitHub form. Step 3 of 3 Contribute a new guide. Check out our contributors guidelines, which will walk you through the process.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 358.5307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> building",
        "body": " Relic One VSCode extension or the New Relic VSCode extension pack to build your apps. Prepare to build or modify apps Step 1 of 1 Download the CLI and API key. On the Build New Relic One applications page, complete the <em>Quick</em> <em>start</em> steps. These six <em>Quick</em> <em>start</em> steps get you an API key for use"
      },
      "id": "6091fa3ae7b9d2e0595068b1"
    }
  ],
  "/docs/distributed-tracing/index": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Logs",
        "Metrics explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-20T10:17:06Z",
      "updated_at": "2021-06-20T10:17:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about. If you need help understanding the data, see the explanations which follow. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once you’re in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in your application's response time. To get a list of transactions: From the Transaction Summary page, select the transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals capture calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On the Errors page, you can see total errors as well as charts showing error count and error rate. Logs The Logs page displays logs from your application. For more information about how to associate log data to your application in New Relic, see our OpenTelemetry and logging documentation. Metrics explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 871.4573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Distributed</em> <em>tracing</em>",
        "body": " need to dig deeper. <em>Distributed</em> <em>tracing</em> When you access <em>distributed</em> <em>tracing</em> through the explorer, you are looking at traces that include that service. Once you’re in that service, you can filter spans to find the ones you want. For example, to query service.name or <em>trace</em>.id, you can use the following"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Distributed</em> <em>tracing</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "image": "https://docs.newrelic.com/static/f487e8c287d614c494f56bd35fd38bb5/c1b63/arrow-step-diagram-trans.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/quick-start/",
      "sections": [
        "Quick start"
      ],
      "published_at": "2021-06-20T21:26:38Z",
      "title": "Quick start",
      "updated_at": "2021-04-11T07:32:21Z",
      "type": "docs",
      "external_id": "f9f4aa287602eee82a0eb7d15775d033ada26d63",
      "document_type": "page",
      "popularity": 1,
      "body": "To set up distributed tracing, you'll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you'll need this information in the next step). If you have an environment diagram like the following, you could use it to create a list of services handling requests: Instrument services: Instrument each service you identify so it can send your trace data. Some tools, such as New Relic APM agents, instrument services automatically, while other tools require you to insert some code in the services. Click the icon below for instrumentation steps: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby New Relic Browser New Relic Mobile AWS Lambda Functions Istio Kamon OpenTelemetry X-Ray Zipkin format: custom integration New Relic format: custom integration View traces: After you instrument the services, generate some traffic in your application, and then go to the New Relic UI to see your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "To set up <em>distributed</em> <em>tracing</em>, you&#x27;ll complete these three general steps: Identify services: Identify and write down the endpoints, services, languages, and systems that are used to complete this request (you&#x27;ll need this information in the next step). If you have an environment diagram like"
      },
      "id": "6072a60564441f2f6f9d8541"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-proxy-support": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-random-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-span-attribute-trace-filter": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/infinite-tracing-configure-trace-observer-monitoring": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42587,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/infinite-tracing/set-trace-observer": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/other-requirements/infinite-tracing-configuring-ssl-java-7-8": [
    {
      "sections": [
        "Language agents and distributed tracing",
        "Tip",
        "Quick start for standard distributed tracing (recommended):",
        "Step 1. Identify services",
        "Step 2. Instrument each service with an APM agent",
        "Step 3. View traces",
        "View traces that include a specific service",
        "View traces across accounts",
        "Set up Infinite Tracing (advanced option)",
        "Step 1. Complete the instrumentation for standard distributed tracing in the quick start above",
        "Step 2. Set up the trace observer",
        "Step 3: Configure the agent for Infinite Tracing",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Step 4. (Optional) Customize Infinite Tracing",
        "Options for older APM agents",
        "Compatibility guide",
        "Important",
        "Configure standard distributed tracing for your older agents",
        "Manual instrumentation (If automatic instrumentation doesn't work)",
        "Instrument the calling service",
        "Instrument the called service"
      ],
      "title": "Language agents and distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Enable and configure"
      ],
      "external_id": "b87eacf981bfae09990c95604ba3b7fc19741a40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/enable-configure/language-agents-enable-distributed-tracing/",
      "published_at": "2021-06-20T21:25:56Z",
      "updated_at": "2021-04-22T06:39:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic has APM language agents for C, Go, Java, Node.js, .NET, PHP, Python, and Ruby. Each of these offers several ways to leverage the power of distributed tracing: Quick start for standard distributed tracing (recommended): A fast way to get started Infinite Tracing: An advanced alternative to standard distributed tracing Older APM agents: Tracing options if you have older APM agents Manual instrumentation: Tips if automatic instrumentation doesn't work Tip If you want to get more background before getting started, check out these topics: How span sampling works explains distributed tracing options. Impacts to APM tells you what to expect if you are a current APM user but haven't set up distributed tracing. Quick start for standard distributed tracing (recommended): This is the best approach to set up standard distributed tracing if you haven't installed any New Relic APM agents for your services yet, or if you want to instrument additional services. Tip You'll need a New Relic account to set up distributed tracing. If you don't already have one, you can quickly create a free account. Step 1. Identify services Figure out which services you want to instrument so they each send trace data to New Relic. Step 2. Instrument each service with an APM agent We have installation assistants for a variety of languages to help you instrument each service. You should run the installation assistant for each service you want to instrument to ensure that each installation has a unique application name. To start the assistant, click the link for your language: New Relic APM: C New Relic APM: Golang New Relic APM: Java New Relic APM: .NET New Relic APM: Node.js New Relic APM: PHP New Relic APM: Python New Relic APM: Ruby Tip This quick-start approach with the installation assistant automatically enables distributed tracing for each service you run it on, but if you already have a New Relic APM agent that you want to participate in distributed tracing, you'll need to manually enable distributed tracing. See Options for older APM agents. Step 3. View traces After you instrument each of your services with APM agents, generate some traffic in your application so we can capture some traces. Here are two ways to view your traces in the UI: View traces that include a specific service Here's one way you can see traces for a particular service: Go to one.newrelic.com. Click APM in the top menu bar. Click your service. In the left navigation's Monitor section, click Distributed tracing. If you don't see the traces you want, you can filter by the trace.id. View traces across accounts This option allows you to search all traces across all New Relic accounts in your organization that you have access to. Go to one.newrelic.com. Click Browse data in the top menu bar, and then click Traces. Select your entity in the left pane. If you don't see the traces you want, you can filter by the trace.id. For more help finding your traces in the UI: Understand and use the distributed tracing UI Query distributed trace data Set up Infinite Tracing (advanced option) Standard distributed tracing for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up Infinite Tracing. This alternative to standard distributed tracing is available for all APM language agents except C SDK. Tip To learn more about this feature, see Infinite Tracing. Before beginning, first ensure you meet the requirements. Step 1. Complete the instrumentation for standard distributed tracing in the quick start above The Infinite Tracing setup builds on the instrumentation step from the Quick start for standard distributed tracing. Step 2. Set up the trace observer The trace observer is a New Relic AWS-based service that collects and analyzes all your traces. Follow the instructions in Set up trace observer. When you're done, return here with your trace observer information and continue with the next step to configure the agent. Step 3: Configure the agent for Infinite Tracing Infinite Tracing configuration settings include the standard distributed tracing plus information about the trace observer. Find the settings for your language agent below: C SDK Infinite tracing is not available for C SDK. Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Infinite Tracing Configuration options: newrelic.Config structure: app, err := newrelic.NewApplication( newrelic.ConfigAppName(YOUR_APP_NAME), newrelic.ConfigLicense(YOUR_LICENSE_KEY), func(cfg *newrelic.Config) { cfg.DistributedTracer.Enabled = true cfg.InfiniteTracing.TraceObserver.Host = YOUR_TRACE_OBSERVER_HOST }, ) Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=YOUR_TRACE_OBSERVER_HOST Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } infinite_tracing: { trace_observer: { host: 'YOUR_TRACE_OBSERVER_HOST' } } Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true newrelic.span_events_enabled = true newrelic.infinite_tracing.trace_observer.host= \"YOUR_TRACE_OBSERVER_HOST\" Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Infinite Tracing Pull down the libraries with this installation command, and then set up the configuration file or environment variables: pip install newrelic[infinite-tracing] Copy Configuration options: Configuration file (newrelic.ini): distributed_tracing.enabled = true infinite_tracing.trace_observer_host= YOUR_TRACE_OBSERVER_HOST Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Infinite Tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: 'YOUR_TRACE_OBSERVER_HOST' Copy Environment variables: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy Step 4. (Optional) Customize Infinite Tracing After you add the agent configuration settings, you should start seeing data in the New Relic UI. After you spend some time analyzing your data, you may want to adjust some of the features of Infinite Tracing: Configure trace observer monitoring Configure span attribute trace filter Configure random trace filter Options for older APM agents If you have older APM agents, use this section to figure out if the distributed tracing features you want are supported. Following the compatibility information is a section showing the basic configuration settings to turn on standard distributed tracing. If your older agent supports Infinite Tracing and you want to set it up, see the steps above. Compatibility guide Find your language agents below to confirm if you can use your existing agents with distributed tracing: C SDK Install (compile) or update to the required C SDK version. For best results, update to the latest C SDK version. Option C SDK version Standard distributed tracing 1.1.0 or higher (W3C Trace Context not available) Infinite Tracing Not available Go Install or update to the required Go agent version. For best results, update to the latest Go agent version. Option Go agent version Standard distributed tracing 2.1.0 or higher With W3C Trace Context: 3.1.0 or higher Infinite Tracing v3.5.0 (includes W3C Trace Context) Supported environments: Go 1.9 or higher Java Install or update to the required Java agent version. For best results, update to the latest Java agent version. Important Your JVM's networkaddress.cache.ttl security setting must not be set to forever (i.e. -1). For more information about this networking property, please visit the Oracle Network Properties docs. Type Java agent version Standard distributed tracing 4.3.0 or higher With W3C Trace Context: 5.10 or higher Infinite Tracing 5.12.1 or higher (includes W3C Trace Context) Supported environments: Java 8: Update 252 or higher All versions of Java 9 or higher Tip For special considerations, see Infinite Tracing: Configuring SSL for Java 7 and 8. .NET Install or update to the required .NET agent version. For best results, update to the latest .NET agent version. Option .NET agent version Standard distributed tracing 8.6.45.0 or higher With W3C Trace Context: 8.27.139.0 or higher Infinite Tracing 8.30.0 (includes W3C Trace Context) Supported environments: .NET Framework 4.5 or higher .NET Core 2.0 or higher Node.js Install or update to the required Node.js agent version. For best results, update to the latest Node.js agent version. Option Node.js agent version Standard distributed tracing 4.7.0 or higher With W3C Trace Context: 6.4 or higher Infinite Tracing 7.3.0 (includes W3C Trace Context) Supported environments: Node version 10.10.0 or higher PHP Install or update to the required PHP agent version. For best results, update to the latest PHP agent version. Option PHP agent version Standard distributed tracing 8.4 or higher With W3C Trace Context: 9.8 or higher Infinite Tracing 9.12.0.268 or higher Python Install or update to the required Python agent version. For best results, update to the latest Python agent version. Option Python agent version Standard distributed tracing 4.2.0.100 or higher With W3C Trace Context: 5.6 or higher Infinite Tracing 5.12.0.140 (includes W3C Trace Context) Supported environments: CPython only (pypy is unsupported) Ruby Install or update to the required Ruby agent version. For best results, update to the latest Ruby agent version. Also install the additional Ruby agent gem for Infinite Tracing. Option Ruby agent version Standard distributed tracing newrelic_rpm 5.3.0.346 or higher With W3C Trace Context: newrelic_rpm 6.9 or higher Infinite Tracing newrelic_rpm 6.11.0.365 or higher (includes W3C Trace Context) newrelic-infinite_tracing 6.11.0.375 or higher Configure standard distributed tracing for your older agents Distributed tracing is enabled through configuration settings. Review the following agent-specific sections. For general help with agent configurations, see Configure the agent. Important Server-side configuration is not available for Infinite Tracing. C SDK Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your C applications. Type Required configuration Standard distributed tracing Configuration options: newrelic_app_config_t structure: newrelic_app_config_t* config; config = newrelic_create_app_config(app_name, license_key); config->distributed_tracing.enabled = true; Copy Go Here's an overview of the settings. For more help with configuration, see Enable distributed tracing for your Go applications. Type Required configuration Standard distributed tracing Configuration options: ConfigOption structure: newrelic.NewApplication( newrelic.ConfigAppName(\"Example App\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), newrelic.ConfigDistributedTracerEnabled(true), ) Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Java Here's an overview of the settings. For more help with configuration, see Java agent configuration: Config file. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Infinite Tracing Configuration options: Configuration file (newrelic.yml) (indented 2 spaces under the common stanza): distributed_tracing: enabled: true infinite_tracing: trace_observer: host: \"YOUR_TRACE_OBSERVER_HOST\" Copy Java system property: -Dnewrelic.config.distributed_tracing.enabled=true -Dnewrelic.config.infinite_tracing.trace_observer.host=\"YOUR_TRACE_OBSERVER_HOST\" Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST=\"YOUR_TRACE_OBSERVER_HOST\" Copy .NET Here's an overview of the settings. For more help with configuration, see .NET agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.config): <configuration . . . > <distributedTracing enabled=\"true\" /> </configuration> Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Node.js Here's an overview of the settings. For more help with configuration, see Node.js agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.js): distributed_tracing: { enabled: true } Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy PHP Here's an overview of the settings. For more help with configuration, see Distributed tracing for the PHP agent Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.ini): newrelic.distributed_tracing_enabled = true Copy Python Here's an overview of the settings. For more help with configuration, see Python agent configuration Type Required configuration Standard distributed tracing Configuration file (newrelic.ini): distributed_tracing.enabled = true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Ruby Here's an overview of the settings. For more help with configuration, see Ruby agent configuration. Type Required configuration Standard distributed tracing Configuration options: Configuration file (newrelic.yml): distributed_tracing: enabled: true Copy Environment variable: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy Tip If you need help with proxy configuration, see Proxy support. Manual instrumentation (If automatic instrumentation doesn't work) Recommendation: Before performing any custom instrumentation, read: How distributed tracing works Troubleshoot missing data If a service is not passing the trace header to other services, you can use the distributed tracing payload APIs to instrument the calling service and the called service. The calling service uses an API call to generate a payload, which is accepted by the called service. Instrument the calling service To instrument the calling service: Ensure the version of the APM agent that monitors the calling service supports distributed tracing. Invoke the agent API call for generating a distributed trace payload: C SDK | Go | Java | .NET | Node.js | PHP | Python | Ruby. Important To maintain proper ordering of spans in a trace, ensure you generate the payload in the context of the span that sends it. Add that payload to the call made to the destination service (for example, in a header). (Optional) Identify the call as an external call: C SDK Go Java .NET: n/a Node.js PHP: n/a Python Ruby Instrument the called service To instrument the called service: Ensure the version of the APM agent that monitors the called service supports distributed tracing. If the New Relic agent on the called service does not identify a New Relic transaction, use the agent API to declare a transaction: C SDK One way to tell that a transaction is not in progress: when newrelic_create_distributed_trace_payload() is called, a NULL pointer is returned. To solve this problem, follow the procedures to create a transaction with the C SDK. Go One way to tell that a transaction is not in progress: when Transaction.InsertDistributedTraceHeaders(h http.Header) is called, no headers are inserted. To create a transaction, see Instrument Go transactions. Java One way to tell that a transaction is not in progress: when Transaction.insertDistributedTraceHeaders(Headers) is called, no headers are inserted (this API requires agent 6.4.0+). To create a transaction, see Java agent transaction-related APIs. .NET One way to tell that a transaction is not in progress: CreateDistributedTracePayload() returns an empty payload. To create a transaction, see Introduction to .NET custom instrumentation. Node.js One way to tell that a transaction is not in progress: the Node.js agent logs will report an error similar to this: No transaction found when calling Transaction.acceptDistributedTracePayload. Copy Use startWebTransaction to create a web transaction or startBackgroundTransaction to capture a non-web transaction. PHP One way to tell that a transaction is not in progress: newrelic_insert_distributed_trace_headers() returns false. To create a transaction, see newrelic_start_transaction. Python To tell that a transaction is not in progress: when transaction = current_transaction() is run, transaction is None. Or, if result = accept_distributed_trace_payload(payload) is run, then the result is False. Use background_task to report a non-web transaction. For more on Python instrumentation, see Monitor transactions and segments. Ruby If you are using a Rack-based web framework and have enabled New Relic's Rack instrumentation, the Ruby agent will handle starting a transaction for you. For other use cases, see the add_transaction_tracer API method. Extract the payload from the call that you received (for example, in a header). Invoke the call for accepting the payload: C SDK | Go | Java | .NET | PHP | Node.js | Python | Ruby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.17386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Language agents and <em>distributed</em> <em>tracing</em>",
        "sections": "Language agents and <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>tracing</em> UI Query <em>distributed</em> <em>trace</em> data Set up <em>Infinite</em> <em>Tracing</em> (advanced option) Standard <em>distributed</em> <em>tracing</em> for APM agents (above) captures up to 10% of your traces, but if you want us to analyze all your data and find the most relevant traces, you can set up <em>Infinite</em> <em>Tracing</em>. This alternative"
      },
      "id": "6072a66564441fb28e9d8595"
    },
    {
      "sections": [
        "Infinite Tracing: trace configuration conflicts",
        "Problem"
      ],
      "title": "Infinite Tracing: trace configuration conflicts",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "b5f9f72d5adf410a972ef089484d53ffa355aa65",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts/",
      "published_at": "2021-06-20T21:02:58Z",
      "updated_at": "2021-04-11T07:38:14Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Traces with configuration conflicts are caused when you've enabled Infinite Tracing for one or more services in a trace, but other services in that trace have our standard (non-Infinite Tracing) distributed tracing solutions enabled. You can solve this problem by enabling Infinite Tracing for all services in a trace. A tracing configuration conflict can cause issues like: Fragmented traces and orphaned spans. Incomplete Infinite Tracing metrics due to not taking standard trace sampling into account. Discrepancies for metrics like span count, service count, durations, and error count. Confusing search results. For example, for standard tracing spans that send headers to Infinite Tracing-instrumented services, those spans may show in the trace list but not in the trace waterfall view. Missing traces for monitored browser apps and mobile apps. Because Infinite Tracing isn’t yet available for browser or mobile monitoring, spans from these services won’t show up in the trace waterfall when they make requests to Infinite Tracing-enabled services. For traces with a configuration conflict, we’ll display only the Infinite Tracing data in the UI because that data is of higher quality. (All tracing data is queryable via NRQL.)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.34807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "sections": "<em>Infinite</em> <em>Tracing</em>: <em>trace</em> configuration conflicts",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem Traces with configuration conflicts are caused when you&#x27;ve enabled <em>Infinite</em> <em>Tracing</em> for one or more services in a <em>trace</em>, but other services in that <em>trace</em> have our standard (non-<em>Infinite</em> <em>Tracing</em>) <em>distributed</em> <em>tracing</em> solutions enabled. You can solve this problem by enabling <em>Infinite</em> <em>Tracing</em>"
      },
      "id": "6072a76664441fe9c09d859a"
    },
    {
      "sections": [
        "Introduction to Infinite Tracing",
        "Tip",
        "What is Infinite Tracing?",
        "Requirements",
        "Enable Infinite Tracing",
        "Configure Infinite Tracing"
      ],
      "title": "Introduction to Infinite Tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Infinite Tracing"
      ],
      "external_id": "836125c2bb783114009b0b4748837b36fefb7a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/",
      "published_at": "2021-06-20T07:00:19Z",
      "updated_at": "2021-05-05T19:20:12Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some of our tracing solutions support our Infinite Tracing feature. Infinite Tracing is a fully managed cloud-based solution that can analyze 100% of your trace data and choose the most actionable data, letting you investigate and solve issues quickly. This document only applies to our Infinite Tracing feature. For an overview of all distributed tracing options, see Enable distributed tracing. Tip To use Infinite Tracing and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is Infinite Tracing? Infinite Tracing allows you to send all your trace data to our cloud-based service and rely on Infinite Tracing to make sampling decisions. You can configure Infinite Tracing in various ways to ensure it's keeping the trace data you need to see. Unlike our standard distributed tracing options, Infinite Tracing can process more trace data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard tracing feature uses. Resources for learning more about Infinite Tracing: Infinite Tracing product page Technical details about sampling and architecture Requirements Requirements differ depending on your pricing plan: New Relic One pricing: requires Pro or Enterprise edition. Original pricing: requires New Relic help to enable it for your organization. For questions, contact your New Relic account representative. Enable Infinite Tracing When enabling Infinite Tracing, you should ideally enable it for all associated services. If you have a mix of Infinite Tracing and our standard tracing solutions enabled, traces will have configuration conflict issues. To start setting up Infinite Tracing, and to see specific requirements, see the docs for these tools: Our language agents Our integrations for third-party telemetry tools Our Trace API Configure Infinite Tracing After enabling Infinite Tracing, there are various ways you can configure it to ensure it's keeping the data you want. See Configure.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 246.29597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "sections": "Introduction to <em>Infinite</em> <em>Tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " standard <em>distributed</em> <em>tracing</em> options, <em>Infinite</em> <em>Tracing</em> can process more <em>trace</em> data. It uses superior tail-based sampling (sampling after data is collected), as opposed to the head-based sampling that our standard <em>tracing</em> feature uses. Resources for learning more about <em>Infinite</em> <em>Tracing</em>: <em>Infinite</em>"
      },
      "id": "6072a6a4196a67faa964a788"
    }
  ],
  "/docs/distributed-tracing/trace-api/introduction-trace-api": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>API</em> explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.75665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-20T21:02:00Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.69536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-new-relic-format-traces-trace-api": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>API</em> explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.75665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-20T21:01:38Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.96552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>API</em> explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.75665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-20T21:01:38Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.96552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-decorate-spans-attributes": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>API</em> explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Trace API general requirements and limits",
        "Endpoints",
        "Data formats",
        "Data limits",
        "Restricted attributes",
        "Request metadata (headers and query parameters)",
        "Important",
        "Response validation",
        "See HTTP status codes",
        "Exceeding span limits"
      ],
      "title": "Trace API general requirements and limits ",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "f77504082dae8374e0c7009a31abebbd4c0123f3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits/",
      "published_at": "2021-06-20T21:02:59Z",
      "updated_at": "2021-06-09T00:57:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Information about Trace API data requirements, including: Data specifications and max limits Required metadata (headers, query parameters) Response validation details This document applies to the Trace API overall. For rules regarding specific data formats, see: New Relic-format trace data Zipkin-format trace data Endpoints All trace data is sent via a POST to a Trace API endpoint. We have a few endpoints, depending on your setup: Default Trace API endpoint: https://trace-api.newrelic.com/trace/v1 EU data centers: https://trace-api.eu.newrelic.com/trace/v1 (see other EU endpoints). Infinite Tracing: when you complete the Trace observer setup, you get a custom YOUR_TRACE_OBSERVER_URL value to use as an endpoint. If you're using an integration that uses the Trace API (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust the sampling of your tracing service to send us 100% of spans. For FedRAMP, see FedRAMP endpoints. Data formats Currently, the Trace API accepts two types of data formats: zipkin: For reporting Zipkin trace data. Zipkin data must be Zipkin JSON v2. newrelic: For reporting all other trace data. Data limits Data limits and rules: Condition Limit Max age of span timestamp values 20 minutes. timestamp must be within 20 minutes of current time at ingest, or within 20 minutes from the time the last span with the same trace.id was received by New Relic. Max payload size 1MB (10^6 bytes) (gzip compression supported) Max requests per minute 100K Max spans per minute per account family Dependent on agreement. Max limit: 2M. Max spans per trace 50K Max attributes per span 200 Max span attribute value length 4000 characters Allowed HTTP protocols HTTPS only Cross-account visibility of span details Potential data obfuscation To see an example of how span limits are enforced, see Exceeding limits. Restricted attributes The attributes in the table below are restricted in the newrelic-format JSON (in the attributes block) and in the zipkin-format JSON (in the tags block). Any values with these keys will be omitted: Restricted attribute Description entityGuid string Unique identifier for the entity that created this span. Generated from service.name, if available. guid string Used for backwards compatibility with data from APM agents. The attributes in the table below are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis: Restricted attribute description entity.guid string Unique identifier for the entity associated with this span. entity.name string Human-readable name of an entity, often used to identify an entity in the UI. entity.type string Used to differentiate between different types of entities, like hosts, applications, etc. Request metadata (headers and query parameters) The following table shows the required request metadata for all trace data formats. This metadata can be sent as HTTP headers on an ingest request or, in some cases, provided as query parameters, which may be required for tracing frameworks that don't allow header modification. Important Security note: We suggest using headers because query parameters are present in the URL and may be logged before being encrypted and received by New Relic. All data sent as query parameters must be URL-safe. Header Query param? Details Content-Type No Required. Must be application/json. Content-Length No Required. The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes (case-sensitive) Required. The Trace API requires the Insights insert key. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if compressed payload. The value must be gzip. Data-Format Yes Required for zipkin. Optional for newrelic. If present, Data-Format-Version must also be present. Data-Format-Version Yes Required for zipkin. If present, Data-Format must also be present. There are only two possible pairings for these values: If Data-Format is zipkin, Data-Format-Version must be 2. If Data-Format is newrelic, Data-Format-Version must be 1. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. Response validation A response for successfully sending trace data will include a requestId. For example: {\"requestId\":\"c1bb62fc-001a-b000-0000-016bb152e1bb\"} Copy There are two ways success/errors are signaled: HTTP status code (synchronous). Authentication and request errors will be signaled via HTTP status code. See HTTP status codes Code Meaning 202 Data accepted. This means that you've passed preliminary checks, but is not a guarantee that the data has been successfully parsed and indexed as part of a distributed trace. 400 The structure of the request was invalid. Errors with query parameters, etc. 403 Authentication error. May occur with an invalid license key or if you lack necessary entitlement to use the Trace API. 404 The request path is incorrect. 405 For any request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry). NrIntegrationError events (asynchronous). Errors with the JSON payload or other semantic errors are asynchronously signaled via NrIntegrationError events that are stored in the account whose license key is associated with the request. For all errors of this type, the attribute newRelicFeature will be Distributed Tracing and requestId will be the requestId from the endpoint response. If you receive a 202 response and don't see an NrIntegrationError event, your data should be visible in New Relic One's global distributed tracing UI in about a minute. You should be able to find the trace using a standard trace search like: traceId = TRACE_ID_SENT Copy Exceeding span limits When you exceed your span rate limit, an NrIntegrationError event is generated. You can query rate limit messages with this NRQL: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Distributed Tracing' AND category = 'RateLimit' AND rateLimitType = 'SpansPerMinute' Copy To get a notification when you exceed the limit, you can set up a NRQL alert. We calculate a rolling 10-minute average based on your span rate limit. This allows for temporary rate bursts, and lets us prioritize keeping and dropping complete traces instead of indiscriminately dropping spans on a per minute limit basis. In the example below of exceeding the rate, the rate limit is the default 100,000 spans per minute. New Relic allows a burst above 100K for a couple of minutes without downsampling, because the remaining minutes in the 10-minute window averaged under 100K spans/minute. For the previous 10 minutes (8:50 - 9:00) the service received 60,000 spans/minute. Minute Spans sent to API Total for past 10 minutes 8:59 60,000 600,000 9:00 40,000 580,000 9:01 50,000 570,000 9:02 250,000 760,000 9:03 220,000 920,000 9:04 125,000 985,000 9:05 70,000 995,000 9:06 50,000 985,000 9:07 40,000 965,000 9:08 40,000 945,000 9:09 40,000 925,000",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 232.75662,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Trace</em> <em>API</em> general requirements and limits ",
        "sections": "<em>Trace</em> <em>API</em> general requirements and limits",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>Tracing</em>: when you complete the <em>Trace</em> observer setup, you get a custom YOUR_<em>TRACE</em>_OBSERVER_URL value to use as an endpoint. If you&#x27;re using an integration that uses the <em>Trace</em> <em>API</em> (for example, these integrations), you must configure that integration with that endpoint. You will also want to adjust"
      },
      "id": "6071cf7628ccbcf8b851c158"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-20T21:01:38Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.96552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    }
  ],
  "/docs/distributed-tracing/trace-api/trace-api-general-requirements-limits": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.42549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " <em>API</em> explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what&#x27;s happening under the hood, see How <em>distributed</em> <em>tracing</em> works."
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Introduction to the Trace API",
        "Tip",
        "What is the Trace API?",
        "Requirements",
        "Sampling considerations",
        "Start reporting data",
        "Find data",
        "Next steps"
      ],
      "title": "Introduction to the Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "119447fbb33c4469c81877ffaa273bd7b1956e9f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/introduction-trace-api/",
      "published_at": "2021-06-20T21:01:38Z",
      "updated_at": "2021-04-10T16:16:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Trace API is used to send distributed tracing data to New Relic: either in our own generic format or the Zipkin data format. This API is also how trace data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go to Start reporting data. Tip To use APIs and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. What is the Trace API? The Trace API is one way that New Relic collects distributed tracing data. We have some tracing tools that report data via this API (Infinite Tracing, our open source integrations, and our Telemetry SDKs), or you can use the API directly to create your own tracing implementation. Reasons to use the Trace API: You have your own custom distributed tracing tool and want to see that data in New Relic without changing your instrumentation. You have a tool that emits tracing data but that requires a backend for trace storage. You want to report distributed tracing data to New Relic without the use of our installed solutions. You use Zipkin and want to see that trace data in New Relic without changing your instrumentation. Want to understand how trace data relates to other New Relic data? Read about our data types. Requirements For details about what data you can send and how it is handled, see Rules and limits. Sampling considerations When using the Trace API, you have the option to enable Infinite Tracing. Whether you use Infinite Tracing has implications for how you configure sampling: Use your own sampling (no Infinite Tracing): If you don't use Infinite Tracing, it's assumed you want to use your own sampling implementation to sample traces before they're sent to us. (If your trace data exceeds our data limits, we do enact sampling.) Use Infinite Tracing: If you want to use Infinite Tracing, a typical approach is to send us 100% of your trace data and rely on Infinite Tracing sampling. (When you go through the Start reporting data instructions, below, you'll have an option for enabling Infinite Tracing.) Start reporting data The Trace API accepts trace data in these two JSON formats: zipkin: the Zipkin JSON v2 trace data format (learn what Zipkin is). Get started sending Zipkin data. newrelic: our general format. If you don't have Zipkin-format data, use this. Get started sending New Relic-format data. Having problems getting data to report? See Troubleshooting. Find data You can find data sent via the Trace API, or from integrations that use this API, in these locations: In our distributed tracing UI. By querying: For details about how to query and create custom charts, see Query distributed tracing data. Next steps Here are some additional steps to consider: Learn more about how distributed tracing works and the data structure. Decorate span data with custom attributes. Use our GraphQL-based NerdGraph API to programmatically query your trace data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.96552,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Trace</em> <em>API</em>",
        "sections": "Introduction to the <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Our <em>Trace</em> <em>API</em> is used to send <em>distributed</em> <em>tracing</em> data to New Relic: either in our own generic format or the Zipkin data format. This <em>API</em> is also how <em>trace</em> data from some of our integrations and exporters is reported to New Relic. To skip some introductory content and get started quickly, go"
      },
      "id": "6071cf7728ccbcf4bc51c16a"
    },
    {
      "sections": [
        "Report Zipkin-format traces via Trace API",
        "Zipkin version requirements",
        "Overview of using the Trace API",
        "Send sample Zipkin trace payload",
        "Send Zipkin-format payload",
        "Send data from existing Zipkin instrumentation",
        "Transformation of Zipkin data",
        "Add other tags/attributes"
      ],
      "title": "Report Zipkin-format traces via Trace API",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Trace API"
      ],
      "external_id": "dba8334d1f068236c741ff04c13ecc2be2c184fc",
      "image": "https://docs.newrelic.com/static/96e69137f0dd86b313ec72d5f0c1ad83/119c7/Screen-Shot-2020-08-13-at-1.26.17-PM.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/trace-api/report-zipkin-format-traces-trace-api/",
      "published_at": "2021-06-20T21:02:00Z",
      "updated_at": "2021-04-10T16:18:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you want to create your own tracing implementation, you can use our Trace API. This doc explains how to send Zipkin-format trace data to our Trace API. (For our general data format, see New Relic format.) Zipkin version requirements The Trace API supports data from Zipkin JSON v2 (or higher) without any modification. For details on this version, see Zipkin v2 release details and the Zipkin v2 schema. Overview of using the Trace API Using our Trace API is as simple as: Sending trace data in the expected format (in this case, zipkin format). Sending that data to the appropriate endpoint Our send-data instructions have options for enabling Infinite Tracing. To learn more about this, see Intro to Infinite Tracing and Sampling considerations. To get started using the Trace API, choose an option: Send a sample trace: This shows a curl example of sending a trace to New Relic. This is useful for understanding how the Trace API works, and to verify you're seeing data in New Relic. Report data from existing Zipkin instrumentation: if you have an existing Zipkin implementation, you can simply change the endpoint of where your data gets sent. Send sample Zipkin trace payload This section describes how to send a simple Zipkin-format trace to our Trace API via curl request. You might choose to do this in order to learn how our API works and to verify that data is showing up in New Relic before doing in-depth instrumentation. To get started sending a sample payload: (Optional, to enable Infinite Tracing) First, you must set up a trace observer. That procedure includes instructions for sending a sample trace using our general new-relic format. When you get to that step, return here to instead learn how to send a Zipkin-format trace. Send a Zipkin-format payload following the instructions below. Send Zipkin-format payload To send a sample Zipkin-format trace: Get an Insights insert key: Go to the API keys UI and select Insights insert keys. If you don't already have a key, create a new one by selecting Insert keys +. You'll be executing a curl request, below. Notes on this: Replace the insert key placeholder with your insert key. If you're using Infinite Tracing, use the YOUR_TRACE_OBSERVER_URL value in place of the standard endpoint. If you want to send more than one post, change the trace ID to a different value. Sending the same payload or span id multiple times for the same traceId may result in fragmented traces in the UI. curl -i -H 'Content-Type: application/json' \\ -H 'Api-Key: $NEW_RELIC_INSERT_KEY' \\ -H 'Data-Format: zipkin' \\ -H 'Data-Format-Version: 2' \\ -X POST \\ -d '[ { \"traceId\": \"test-zipkin-trace-id-1\", \"id\": \"3e0f5885710776cd\", \"kind\": \"CLIENT\", \"name\": \"post\", \"duration\": 508068, \"localEndpoint\": { \"serviceName\": \"service-1\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { } }, { \"traceId\": \"test-zipkin-trace-id-1\", \"parentId\": \"3e0f5885710776cd\", \"id\": \"asdf9asdn123lkasdf\", \"kind\": \"CLIENT\", \"name\": \"service 2 span\", \"duration\": 2019, \"localEndpoint\": { \"serviceName\": \"service-2\", \"ipv4\": \"127.0.0.1\", \"port\": 8080 }, \"tags\": { \"error.message\": \"Invalid credentials\" } } ]' 'https://trace-api.newrelic.com/trace/v1' Copy Within a minute, the trace should be available in the our distributed tracing UI. To find it, run a query for the trace.id. In this example, it was test-zipkin-trace-id-1. Note that you search by the transformed attribute of trace.id (not traceId). To learn more: Learn where Trace API data shows up in the UI. Send data from an existing Zipkin instrumentation. Learn how to decorate spans by adding tags. This helps you customize how traces are displayed in our UI for a richer, more helpful experience. Learn about general endpoint information (data limits, required metadata, and response validation). Learn about how Zipkin data is transformed and stored in our format. If you don't see your trace data, see Troubleshooting. Send data from existing Zipkin instrumentation Preliminary notes: If you want to enable Infinite Tracing, you first must set up a trace observer. It can be helpful to first send a sample payload to verify things are working properly. To report data from an existing Zipkin instrumentation, you'll point the Zipkin tracer at the appropriate Trace API endpoint with some required request metadata. You can send the required metadata as headers or query parameters (some Zipkin tracer versions don't allow specifying HTTP headers). Here's an example of what it might look like to create a Zipkin OkHttpSender in Java configured for the Trace API: OkHttpSender.create(\"https://trace-api.newrelic.com/trace/v1?Api-Key=NEW_RELIC_INSERT_API_KEY&Data-Format=zipkin&Data-Format-Version=2\"); Copy Note that if you were using Infinite Tracing, or had an EU-region New Relic account, the endpoint would be different. For an explanation of Api-Key and the other metadata, see Request metadata. Transformation of Zipkin data To create a consistent search/query experience, some Zipkin data will be transformed to match New Relic attribute naming. For more on how we store and structure trace data, see How distributed tracing works. Zipkin tag Stored in New Relic as... Details traceId trace.id Unique identifier for a trace. id id Unique identifier for a span. parentId parent.id Identifier of the upstream span that called the service. kind kind Either Client or Server. name name Name of span. duration duration.ms Zipkin v2 spans must have durations specified in microseconds, and will be converted to milliseconds. localEndpoint: serviceName service.name We use the Zipkin v2 service name to identify the entity that created this span. localEndpoint: port localEndpoint.port All values in the localEndpoint object will be flattened to a span attribute called localEndpoint.key tags reported as attributes Key:value pairs in the tags object in Zipkin v2 will be written as span attributes. annotations not supported We do not currently support annotations in the Trace API. Spans will not be rejected if they contain annotations, but the annotations data will not be written. Add other tags/attributes You can add any tags you want to the tags block, with the exception of the restricted tags. For example, you might want to add attributes like customer.id or user.id to help you analyze your trace data. Tags will be converted to New Relic attributes. To learn how to control how spans appear in New Relic (for example, adding errors or setting a span as a datastore span), see Decorate spans.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.69536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "sections": "Report Zipkin-format <em>traces</em> via <em>Trace</em> <em>API</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": ", &quot;localEndpoint&quot;: { &quot;serviceName&quot;: &quot;service-2&quot;, &quot;ipv4&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: 8080 }, &quot;tags&quot;: { &quot;error.message&quot;: &quot;Invalid credentials&quot; } } ]&#x27; &#x27;https:&#x2F;&#x2F;<em>trace</em>-<em>api</em>.newrelic.com&#x2F;<em>trace</em>&#x2F;v1&#x27; Copy Within a minute, the <em>trace</em> should be available in the our <em>distributed</em> <em>tracing</em> UI. To find it, run a query"
      },
      "id": "6071cfc864441fa88f9d8530"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/infinite-tracing-trace-configuration-conflicts": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-20T20:56:23Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.03316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to <em>distributed</em> <em>tracing</em> for other features"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Missing trace data",
        "Problem",
        "Solution",
        "Important",
        "Problems with enabling or instrumenting",
        "Missing spans due to service not having distributed tracing enabled",
        "Missing apps/services may require manual instrumentation",
        "Problems with spans",
        "Infinite Tracing: missing spans",
        "Missing span not getting exported",
        "Missing spans due to sampling process",
        "Missing spans due to span limits maxed out",
        "Missing spans due to spans being sent late",
        "Problems with trace details",
        "Middleware doesn't recognize proprietary New Relic header",
        "An intermediary is missing or isn't passing trace context",
        "Tip",
        "Stitching together spans from mixed sources",
        "Trace details are obfuscated",
        "Trace list information and trace details don't match",
        "Long traces with short backend times",
        "Problems with browser applications",
        "Missing spans and transactions after enabling for a browser application",
        "Not seeing browser app end-user spans",
        "Browser spans are not connected to other spans",
        "Other problems",
        "Search by entity.name not finding associated app names",
        "Supporting OpenTelemetry"
      ],
      "title": "Missing trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Troubleshooting"
      ],
      "external_id": "2997172d74563c4fa31d5a9fc05c562d62c1c790",
      "image": "https://docs.newrelic.com/static/ef51359ad9a7999f7fdaf812fab535bc/d7542/missing-exporter.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/troubleshooting/missing-trace-data/",
      "published_at": "2021-06-20T21:03:40Z",
      "updated_at": "2021-04-11T07:38:15Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have enabled distributed tracing but data you expected to see does not appear in New Relic's distributed tracing UI. Solution Important Before performing troubleshooting, we recommend reading How distributed tracing works. Here are some causes and solutions when you have problems finding expected data in the distributed tracing UI: Problems with enabling or instrumenting Missing spans due to service not having distributed tracing enabled In order for distributed tracing to report details for all nodes in a trace, each application must be monitored by a New Relic agent that has had distributed tracing enabled. If an application's New Relic account has not had distributed tracing enabled, it will have these issues: Its distributed tracing UI page won't have data. It won't report data to other accounts' distributed traces. Missing apps/services may require manual instrumentation When you enable distributed tracing for applications and services that New Relic automatically instruments, you'll usually see complete and detailed data for those nodes in the distributed tracing UI. However, you may notice that some services or applications are missing from traces, or that there are some internal spans you expect to see that are missing. If that's the case, you may want to implement custom instrumentation of applications or specific transactions to see more detail in traces. Some examples of when you may need to do this: Transactions not automatically instrumented. To ensure your application is automatically instrumented, read the compatibility and requirements documentation for the New Relic agent you're using. If an application isn't automatically instrumented, or if you'd like to add instrumentation of specific activity, see Custom instrumentation. All Go applications. The Go agent, unlike other agents, requires manual instrumentation of your code. For instructions, see Instrument a Go application. A service doesn't use HTTP. If a service doesn't communicate via HTTP, the New Relic agent won't send distributed tracing headers. This may be the case for some non-web applications or message queues. To remedy this, use the distributed tracing APIs to instrument either the calling or called application. Problems with spans Infinite Tracing: missing spans If your APM agent can’t write data fast enough to the trace observer, queue_size is an additional APM agent configuration to limit the number of spans the agent will hold. See the following examples for your agent: .NET configuration method Example Configuration file <configuration . . . > <infiniteTracing> <trace_observer> <span_events queue_size=\"100000\" /> </trace_observer> </infiniteTracing> </configuration> Copy Environment variable NEW_RELIC_INFINITE_TRACING_SPAN_EVENTS_QUEUE_SIZE=100000 Copy Python configuration method Example Configuration file infinite_tracing.span_queue_size = 100000 Environment Variable NEW_RELIC_INFINITE_TRACING_SPAN_QUEUE_SIZE = 100000 Missing span not getting exported Sometimes header propagation is successful, but the span information isn't getting sent to New Relic. For example, if OpenTelemetry is not instrumented with a New Relic exporter, the span details never make it to New Relic. In this diagram, notice that the header propagation is successful, but no exporter is set up in Service 2 to send the span to New Relic: The following diagram also shows successful header propagation, but it includes an exporter in Service 2 that sends the span details to New Relic (see Trace API): Missing spans due to sampling process Standard distributed tracing for APM uses adaptive sampling. This means that a percentage of calls to a service will be reported as part of a distributed trace. Specific calls to your service might not have been selected to be sampled. Missing spans due to span limits maxed out There are limits on the number of spans that can be collected and displayed. If an application generates a very large number of spans for a single call, it might exceed the APM agent's span-collection limit for that harvest cycle. This could result in missing spans and significantly limit the number of traces the agent can completely sample and report. We currently only show 10,000 spans at a time. Missing spans due to spans being sent late Spans must be sent within the last twenty minutes to be captured in a trace index. If you send any spans older than twenty minutes but newer than a day, the span data will still be written. However, it won't be rolled into the trace index, which controls the trace list in the distributed tracing UI. If a span has a timestamp older than a day, it will be dropped. This often occurs when there is clock skew (timing differences) between systems or long running background jobs. Problems with trace details Middleware doesn't recognize proprietary New Relic header If your transactions are only sending the proprietary New Relic header, some middleware might not recognize the format and then drop the information as shown in this diagram: One solution is to upgrade your New Relic agent to a version that supports W3C trace context. In the diagram below, the W3C-compliant New Relic agent passes the prior header along with two standardized headers: An intermediary is missing or isn't passing trace context Some potential problems with proxies and other intermediaries: Incomplete trace. Some intermediaries won't automatically propagate the distributed tracing header. In that case, you must configure that component to allow the header to be passed from source to destination. For instructions, consult the documentation for that intermediary component. Missing intermediary in trace. If the intermediary is New Relic-monitored, ensure that it propagates the newrelic header that is generated or updated by the New Relic agent running on that intermediary. This may manifest when an intermediary was previously visible in traces, but disappeared after distributed tracing was enabled for an upstream entity (for example, a Browser-monitored application). Tip If some entities report trace data to another tracing system, you can use the trace ID from the New Relic UI to search other tracing systems for missing spans. Stitching together spans from mixed sources If each agent in a chain supports W3C Trace Context, then we can stitch the spans together into a complete trace. If part of the chain is from an agent, such as Zipkin, which doesn't support W3C Trace Context, then spans coming from that agent may not be included in the trace. Trace details are obfuscated If a trace contains data from applications monitored by multiple New Relic accounts, and your user permissions don't allow you to access those accounts, some of the span and service details will be obfuscated in the UI. For example, you may see a series of asterisks ( * * * * * ) instead of the service name in your distributed tracing list if you don't have access to the account linked with the service. Trace list information and trace details don't match The trace list is generated by trace indexes, which are captured in a twenty minute window from when the first spans are received. Usually, this is due to late spans. Long traces with short backend times If you're seeing unusually short backend times for long traces, this is likely an issue with the timestamps being sent. For example, the root span might be reposting microseconds as milliseconds. This can also happen if the root span is a browser application. When using an external client like a web browser, you may experience clock skew (timing differences) more often. Problems with browser applications Missing spans and transactions after enabling for a browser application Older versions of some APM agents are incompatible with distributed tracing for browser applications. If the browser application makes an AJAX request to an APM application running an incompatible agent, then the APM agent may not record transaction and span data for that request. If distributed tracing is enabled for a browser application and you are not seeing transaction or span data for downstream APM requests, review the Browser data in distributed tracing requirements, and confirm that all applications are running supported versions of the APM agent. Not seeing browser app end-user spans If traces seem to be missing end-user spans, be sure you've read and understand the Browser distributed tracing requirements and enable procedures. On the New Relic Browser AJAX UI page, there are links to the distributed tracing UI regardless of whether there are end-user spans present in that trace. For details about what data generates spans, see Requirements. Browser spans are not connected to other spans Older versions of some APM agents are incompatible with distributed tracing for browser applications. If APM spans are missing consistently from traces that include browser applications, please refer to the Browser data in distributed tracing requirements and confirm that all applications are running supported versions of the APM agent. For other causes of orphaned browser spans, see Browser span reporting. Other problems Search by entity.name not finding associated app names Potential cause: For applications that have multiple app names, the entity.name attribute will be associated only with the primary app name. To search by other app names, search using the appName attribute. Supporting OpenTelemetry Questions about integrating with OpenTelemetry should be taken to the Explorers Hub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 173.50807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Missing <em>trace</em> data",
        "sections": "Missing spans due to service not having <em>distributed</em> <em>tracing</em> enabled",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "Problem You have enabled <em>distributed</em> <em>tracing</em> but data you expected to see does not appear in New Relic&#x27;s <em>distributed</em> <em>tracing</em> UI. Solution Important Before performing <em>troubleshooting</em>, we recommend reading How <em>distributed</em> <em>tracing</em> works. Here are some causes and solutions when you have problems"
      },
      "id": "6072a76764441f109b9d857b"
    }
  ],
  "/docs/distributed-tracing/troubleshooting/missing-trace-data": [
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 241.18884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> data, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect data as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Distributed tracing: Planning guide",
        "Impact to APM features",
        "External services page has less detail",
        "Transaction trace UI displays service URLs, not transaction links",
        "Cross-application tracing will be disabled",
        "Impacts related to mobile monitoring",
        "Plan your rollout",
        "Enable distributed tracing"
      ],
      "title": "Distributed tracing: Planning guide",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "10263f2b6ec929f082153e28cbce07fe3a1f106a",
      "image": "https://docs.newrelic.com/static/7072dfa9e494767baabba420d78e7094/c1b63/distributed-trace-txn-trace-affects.png",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/distributed-tracing-planning-guide/",
      "published_at": "2021-06-20T20:56:23Z",
      "updated_at": "2021-05-28T11:44:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are new to New Relic distributed tracing, we recommend you read the following before you enable distributed tracing. Impact to APM features Our distributed tracing improves on APM's previous cross application tracing feature. Here are some key benefits: See more cross-service activity details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete trace even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to distributed tracing for other features. Enabling distributed tracing may affect some APM features you currently use. These changes affect only applications monitored by agents that have distributed tracing enabled—they don't apply on an account-level. We may provide backward compatibility with some or all of the affected features in future releases. For now, you should understand the following changes before enabling distributed tracing: External services page has less detail When distributed tracing is enabled for an application, external calls do not have internal transaction details at one.newrelic.com > APM > (select an app) > Monitor > External services > (select external service). To find that information, you would instead go to the Distributed tracing UI page, find the external call URLs, and see what their child spans are. Transaction trace UI displays service URLs, not transaction links When distributed tracing is enabled for an application, the transaction trace UI will no longer have the transaction name and link for the called service (see screenshot below). This will be replaced with the called service's URL. one.newrelic.com > APM > (select an app) > Monitor > Transactions > (select a transaction trace): This shows the transaction trace UI before distributed tracing is enabled, with a link to the associated transaction. With distributed tracing enabled, it will display the service's URL. If you wanted to get more detail about trace activity, you would go to the Distributed tracing UI page and examine that trace. Cross-application tracing will be disabled Enabling distributed tracing will disable the cross application tracing feature. Distributed tracing is an improved version of cross-application tracing and only one can be enabled at a time. Impacts related to mobile monitoring APM-related impacts include: When distributed tracing is enabled for an APM-monitored entity, legacy service maps will not show applications monitored by mobile. The App server drill-down feature of the legacy Mobile HTTP requests UI page is not available. Plan your rollout If you're enabling distributed tracing for a large, distributed system, here are some tips: If you are a current APM user, see Impact to APM features. Determine the requests that are the most important for your business, or the most likely to require analysis and troubleshooting, and enable distributed tracing for those services. Enable tracing for services at roughly the same time so you can more easily gauge how complete your end-to-end traces are. When you look at traces in the distributed tracing UI, you'll see spans in the trace for external calls to other services. Then, you can enable distributed tracing for any of those services you want. If a service is fairly standalone and not often used in context with other services, you may not want to enable distributed tracing for it. Here's a visual representation of such a phased roll-out: If you are using APM for a large, monolithic service, there may be many sub-process spans per trace and APM limits may result in fewer traces than expected. You can solve this by using APM agent instrumentation to disable the reporting of unimportant data. Distributed tracing works by propagating header information from service to service in a request path. Some services may communicate through a proxy or other intermediary service that does not automatically propagate the header. In that case, you will need to configure that proxy so that it allows the newrelic header value to be propagated from source to destination. Enable distributed tracing If you are aware of the impact to APM features and have thought about your rollout, you are ready to set up distributed tracing. See Overview: Enable distributed tracing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.03316,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "sections": "<em>Distributed</em> <em>tracing</em>: Planning guide",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " details and more complete end-to-end traces. Filter and query traces, as well as make custom charts. See the complete <em>trace</em> even when calls cross account boundaries (for accounts with the same master account or in the same customer partnership). See Introduction to <em>distributed</em> <em>tracing</em> for other features"
      },
      "id": "6072a60564441f3a629d8535"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-20T21:05:00Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 172.57298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "sections": "<em>Understand</em> and use the <em>distributed</em> <em>tracing</em> UI",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> helps you monitor and analyze the behavior of your <em>distributed</em> system. After you enable <em>distributed</em> <em>tracing</em>, you can use our UI tools to search for traces and analyze them. For example, let&#x27;s say you are an engineer <em>troubleshooting</em> errors in a complex transaction spanning many"
      },
      "id": "6072a70028ccbc265a51c13d"
    }
  ],
  "/docs/distributed-tracing/ui-data/query-distributed-trace-data": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-20T21:03:59Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.55804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-20T21:05:00Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.53815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.99445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> <em>data</em>, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect <em>data</em> as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    }
  ],
  "/docs/distributed-tracing/ui-data/span-attributes": [
    {
      "sections": [
        "Understand and use the distributed tracing UI",
        "Open the distributed tracing UI",
        "View traces for a specific service",
        "View traces across all accounts",
        "Tip",
        "Find traces that are useful",
        "Filter using the query bar",
        "Find traces that touch two services",
        "Find error spans using the like operator",
        "Trace groups",
        "Filter using the scatter plot",
        "Filters",
        "Trace histograms",
        "Important",
        "Trace details UI page",
        "Span details pane",
        "View related logs",
        "Additional UI details",
        "How to understand span errors",
        "Anomalous spans",
        "Client span duration: time differences between client and server spans",
        "Fragmented traces",
        "Trace details obfuscated based on account access",
        "Span limits and sampling",
        "Incomplete span names in waterfall view",
        "Missing spans and span/service count discrepancies"
      ],
      "title": "Understand and use the distributed tracing UI",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "f5b66e03583e42613810f1390b4e5adab4ed2caa",
      "image": "https://docs.newrelic.com/static/ec08996f31e6586bb257c6f89b3c8f99/e5166/new-relic-distributed-tracing-client-span-time.jpg",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/",
      "published_at": "2021-06-20T21:05:00Z",
      "updated_at": "2021-06-02T17:03:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them. For example, let's say you are an engineer troubleshooting errors in a complex transaction spanning many services. Here's what you can do in our UI: Open the distributed tracing UI page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the trace details page, you review the span along the request route that originated the error. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate. Read on to explore the options in the distributed tracing UI. Open the distributed tracing UI Here's how you can access the distributed tracing UI, depending on the type of search you want to do: View traces for a specific service The New Relic Explorer and APM are two menu options that help you navigate to a specific service so you can see traces that include that service. Go to one.newrelic.com. Click Explorer or APM in the top menu bar. Filter to the service you enabled for distributed tracing by typing the service name, and then press Enter. In the left navigation's Monitor section, click Distributed tracing. View traces across all accounts If you want to view traces from across all accounts you have access to, go to one.newrelic.com, click Browse data, and then Traces. Tip If you don't have access to accounts for some services in a trace, we'll obfuscate some details for those services. Find traces that are useful We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces, and you can quickly refine this list using these tools: Query bar Trace groups Scatter plot chart Filters Interactive histograms Tip In addition to these tools, you can also use other options mentioned in Query distributed trace data. Filter using the query bar The Find traces query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query. Query returns are based on span attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans. If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values. Queries for traces are similar to NRQL (our query language). Here are the main exceptions: String values don't require quote marks (for example, you can use either appName = MyApp or appName = 'MyApp') The like operator doesn’t require % (for example, you can use either appName like product or appName like %product%). Tip Some queries that return a large number of results may return false positives. The trace list limits these incorrect results to 10% of the returned results. False positives may also result in histogram chart results that are not displayed in the trace list. Here are two query bar examples: Find traces that touch two services The query in the image below finds traces that: Pass through both WebPortal and Inventory Service applications Have an Inventory Service datastore call that takes longer than 500 ms Contains an error in any span. Go to one.newrelic.com > Apps > Distributed tracing Find error spans using the like operator The query in the image below finds traces that: Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application Contain spans where the customer_user_email attribute contains a value ending with hotmail.com anywhere in the trace. Go to one.newrelic.com > Apps > Distributed tracing Trace groups The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle Group similar traces to turn this on and off. With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected. Filter using the scatter plot The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the Group similar traces toggle at the top of the page. In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details: Here's how you can control what's displayed in the scatter plot: In the View by dropdown, select the duration type: Back-end duration Root span duration Trace duration In Group traces by, select one of these options: Errors: Group by whether or not traces contain errors. Root service: Group by the name of the first service in traces. In a trace where Service A calls Service B and Service B calls Service C, the root service would be Service A. Root entry span: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: \"Service A - GET /user/%\". Service entry span: Group by the span name of the service currently being viewed in APM. For example, for a trace where Service A calls Service B and Service B calls Service C, if you're viewing Service B in APM and select this grouping, the traces will be represented by their Service B span names. If a service has multiple spans in a trace, this grouping option will use that service's first entry point. Filters In the left pane, you can filter traces by multi-span traces, specific entities, or error types. Once you select a filter, only traces associated with that specific type are displayed. This makes it much easier to view the traces you're most interested in so you can find and fix issues faster. Trace histograms The histogram charts give you a quick understanding of trace distribution for important values, such as duration. Click Show filters at the bottom of the left pane to display the histograms. When you move the histogram sliders, they change the data displayed in the scatterplot or the trace group charts. For example, you can drag the Trace duration chart slider to show only traces over 500 ms, as shown in the histogram example below. Important Some queries that produce many results may result in false positives in histograms. This could manifest as histograms showing trace results that are not in the trace list. Trace details UI page When you select a trace from the trace list, you see that trace's timeline and spans: one.newrelic.com > APM > (select an application) > Monitor > Distributed tracing > (select a trace) > (select a span): See the spans in a trace. Examine individual span details and see notifications for spans with anomalous behavior. The UI indicates some span properties with icons: Span property Indicator Description Service This icon represents a span that's a service's entry point. In-process This icon represents an in-process span, which is a span that takes place within a process (as opposed to a cross-process span). Examples: middleware instrumentation, user-created spans. Datastore This icon represents a span call to a datastore. External This icon represents category representing a call to an external service made via HTTP. Browser app This icon represents a browser application span. Lambda This icon represents a span from a Lambda function. Some spans will have additional indicators: Span property Indicator Description Type of connection Solid lines indicate a direct parent-child relationship; in other words, one process or function directly calling another. A dotted line indicates a non-direct relationship. For more on relationships between spans, see Trace structure. Errors A span with an error. See How to understand span errors. Anomalous This icon represents the detection of an anomalous span. Orphaned spans Some spans may be \"orphaned,\" or separated, from the trace. These spans will appear at the bottom of the trace. For more details, see Fragmented traces. Multiple app names When beside a span name, this represents an entity that has had multiple app names set. Select this to see all app names it reports to. To search trace data by alternate app names, use the appName attribute. Client/server time difference If a span's duration indicator is not completely colored in (like in this example), it means that there is a time discrepancy between the server-side duration and the client-side duration for that activity. For details on this, see Client/server time difference. For more on the trace structure and how span properties are determined, see Trace structure. Span details pane When you select a span, a pane opens up with span details. These details can be helpful for troubleshooting performance issues. Details include: Performance charts Span attributes The span's data source Anomalous span details The span's full name What a span displays is based on its span type. For example, a datastore span's name attribute will contain the datastore query. View related logs If you are using our logs in context feature together with our log management, you can see any logs that are linked to your traces: Go to the trace details page by clicking on a trace. Click See logs in the upper-right corner. For details related to an individual log message, click directly on the message. Additional UI details Here are some additional distributed tracing UI details, rules, and limits: How to understand span errors Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an exception is shown with an error in the UI and contributes to the total error count for that trace. Here are some general tips about understanding span errors: Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the Error Details pane for each span. All spans that exit with errors are counted in the span error count. When multiple errors occur on the same span, only one is written to the span in this order of precedence: A noticeError The most recent span exception This table describes how different span errors are handled: Error type Description Spans ending in exceptions An exception that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the exception is caught or exits the transaction. You can see if an exception is caught in an ancestor span. Notice errors Errors noticed by calls to the agent noticeError API or by the automatic agent instrumentation are attached to the currently executing span. Response code errors Response code errors are attached to the associated span, such as: Client span: External transactions prefixed with http or db. Entry span: In the case of a transaction ending in a response code error. The response code for these spans is captured as an attribute httpResponseCode and attached to that span. Anomalous spans If a span is displayed as anomalous in the UI, it means that the following are both true: The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours. The span's duration is more than 10% of the trace's duration. Client span duration: time differences between client and server spans When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The client span (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to: Clock skew, due to system clock time differences Differences in duration, due to things like network latency or DNS resolution delay The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span. It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them: When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response. When a client span starts after a server span, this is most likely clock skew. Fragmented traces Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as \"orphaned.\" Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. Types of orphaned span properties indicated in the UI: No root span. Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root. Orphaned span. A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span. Orphaned trace fragment. A group of connected spans where the first span in the group is an orphan span. This can happen for a number of reasons, including: Collection limits. Some high-throughput applications may exceed collection limits (for example, APM agent collection limits, or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached. Incorrect instrumentation. If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details. Spans still arriving. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported. UI display limits. Orphaned spans may result if a trace exceeds the 10K span display limit. Trace details obfuscated based on account access If you don’t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include: Span name concealed by asterisks Service name replaced with New Relic account ID and app ID The two main factors affecting this obfuscation: Account permissions. Master/sub-account relationships will impact access. If you have access to only a sub-account, you’ll be able to see details for only that sub-account. If you have access to a master account, you’ll be able to see details for that account’s sub-accounts. Authentication. You’ll be able to see span details only for New Relic accounts you can access based on your current login. This means that, for example, even the admin of a master account may not be able to see all details if the trace crosses the boundaries of different authentication mechanisms. Span limits and sampling See Sampling. Incomplete span names in waterfall view When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the Full span name. Knowing the complete name can be valuable for querying that data with NRQL. Missing spans and span/service count discrepancies A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the trace list and the count displayed on the trace details page. Reasons for missing spans and count discrepancies include: An APM agent may have hit its 1K span collection limit. A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue. The UI may have hit its 10K span display limit. All spans collected, including those not displayed, can be queried with NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.53815,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "sections": "<em>Understand</em> <em>and</em> use the <em>distributed</em> <em>tracing</em> <em>UI</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": " services. Here&#x27;s what you can do in our <em>UI</em>: Open the <em>distributed</em> <em>tracing</em> <em>UI</em> page. Sort through your traces using a filter to find that specific request and show only traces containing errors. On the <em>trace</em> details page, you review the span along the request route that originated the error. Noting"
      },
      "id": "6072a70028ccbc265a51c13d"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.99445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> <em>data</em>, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect <em>data</em> as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-06-20T21:03:59Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.07272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    }
  ],
  "/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui": [
    {
      "sections": [
        "Span attributes"
      ],
      "title": "Span attributes",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "725c10cb22b5d8f3b2a825c2dbf38b8640f93b13",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/span-attributes/",
      "published_at": "2021-06-20T21:03:59Z",
      "updated_at": "2021-06-02T17:14:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing creates Span data that can be queried in New Relic. Here are ways to learn more about Span data: To explore your span data, you can use the query builder. To see the default attributes attached to span data, use the data dictionary. For help with NRQL queries using these attributes, see these example queries.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.55804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> creates Span <em>data</em> that can be queried in New Relic. Here are ways to learn more about Span <em>data</em>: To explore your span <em>data</em>, you can use the query builder. To see the default attributes attached to span <em>data</em>, use the <em>data</em> dictionary. For help with NRQL queries using these attributes, see these example queries."
      },
      "id": "6072a767196a673e9964a7c3"
    },
    {
      "sections": [
        "Introduction to distributed tracing",
        "Why it matters",
        "Instrumentation: The key to distributed tracing",
        "What you can see in the New Relic UI",
        "Next steps"
      ],
      "title": "Introduction to distributed tracing",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "Get started"
      ],
      "external_id": "ac173988a6503674b4411c9c2efe6713912c37f2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/concepts/introduction-distributed-tracing/",
      "published_at": "2021-06-20T06:58:34Z",
      "updated_at": "2021-06-20T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Distributed tracing tracks and observes service requests as they flow through distributed systems. With distributed tracing data, you can quickly pinpoint failures or performance issues and fix them. Distributed tracing systems collect data as the requests go from one service to another, recording each segment of the journey as a span. These spans contain important details about each segment of the request and are combined into one trace. The completed trace gives you a picture of the entire request. Here is an example a web transaction where agents measure the time spent in each service. Agents then send that timing information to New Relic as spans where they are combined into one distributed trace. Why it matters A request might pass through various microservices to reach completion. The microservices or functions could be located in multiple containers, serverless environments, virtual machines, different cloud providers, on-premises, or any combination of these. For example, let's say that you're in a situation where a slow-running request affects the experience of a set of customers: The request is distributed across multiple microservices and serverless functions. Several different teams own and monitor the various services that are involved in the request. None of the teams have reported any performance issues with their microservices. Without a way to view the performance of the entire request across the different services, it’s nearly impossible to pinpoint where and why the high latency is occurring and which team should address the issue. Instrumentation: The key to distributed tracing Distributed tracing starts with the instrumentation of your services to enable data collection and correlation across the entire distributed system. Instrumention means either manually adding code to services or installing agents that automatically track trace data. Many of our New Relic solutions automatically instrument your services for a large number of programming languages and frameworks. You can also use open source tools and open instrumentation standards to instrument your environment. OpenTelemetry, part of the Cloud Native Computing Foundation (CNCF), is becoming the one standard for open source instrumentation and telemetry collection. What you can see in the New Relic UI After the data is collected, you can visualize it to see service dependencies, performance, and any anomalous events such as errors or unusual latency. Here are some examples of what you can do with your data: What you can do Description Detect anomalous spans Spans that are slow in comparison to typical behavior are marked as anomalous, with charts comparing them to typical performance. See your errors and logs Frontend and backend errors appear right in the context of your traces. Everything you need to troubleshoot is in one place. Filter results You can filter charts using many data points, so you can analyze trace data in different ways. Customize queries and dashboards You can create custom queries of your trace data and create custom data dashboards. See data across accounts See a global view of traces from across all your accounts and applications in New Relic One. Query traces programmatically Query distributed trace data by using GraphQL in our NerdGraph API explorer. Next steps Here are some tasks to consider: To instrument your services, check out our Quick start. To learn more about what's happening under the hood, see How distributed tracing works.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 257.99445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>distributed</em> <em>tracing</em>",
        "sections": "Introduction to <em>distributed</em> <em>tracing</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "<em>Distributed</em> <em>tracing</em> tracks and observes service requests as they flow through <em>distributed</em> systems. With <em>distributed</em> <em>tracing</em> <em>data</em>, you can quickly pinpoint failures or performance issues and fix them. <em>Distributed</em> <em>tracing</em> systems collect <em>data</em> as the requests go from one service to another, recording"
      },
      "id": "6072a767e7b9d231f1a5c64c"
    },
    {
      "sections": [
        "Query distributed trace data",
        "Example NRQL queries",
        "Tip",
        "Datastore time percentile for an app",
        "Datastore query time for an app, faceted by host",
        "Average duration for a method of a service, faceted by host",
        "Histogram of external services called by a service, faceted by external URI",
        "Average duration for external calls across all applications",
        "Example NerdGraph queries",
        "Can't find data?"
      ],
      "title": "Query distributed trace data",
      "type": "docs",
      "tags": [
        "Understand dependencies",
        "Distributed tracing",
        "UI and data"
      ],
      "external_id": "7ad60264aa5c46ef3859a886fc5c97471ccfb02f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/distributed-tracing/ui-data/query-distributed-trace-data/",
      "published_at": "2021-06-20T21:03:59Z",
      "updated_at": "2021-04-11T07:36:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can query your distributed tracing data in several ways: The search bar at top of the distributed tracing UI NRQL query NerdGraph GraphiQL explorer To learn about trace structure, see How distributed tracing works. Example NRQL queries Tip You can also construct complex queries in the search bar at the top of the distributed tracing UI. Some example NRQL queries: Datastore time percentile for an app SELECT percentile(duration, 50, 95) FROM Span WHERE category = 'datastore' and appName = 'YOUR_APP_NAME' SINCE 4 hours ago TIMESERIES 1 minute Copy Datastore query time for an app, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and category = 'datastore' FACET host TIMESERIES 1 minute Copy Average duration for a method of a service, faceted by host SELECT average(duration) FROM Span WHERE appName = 'YOUR_APP_NAME' and name = 'FUNCTION_NAME' FACET host TIMESERIES 1 minute Copy Histogram of external services called by a service, faceted by external URI SELECT histogram(duration, 10, 60) FROM Span WHERE category = 'http' and appName = 'YOUR_APP_NAME' FACET `http.url` SINCE 4 hours ago Copy Average duration for external calls across all applications SELECT average(duration) FROM Span WHERE category = 'http' SINCE 4 hours ago FACET `http.url` TIMESERIES 1 minute Copy Example NerdGraph queries You can also use NerdGraph to query your trace data using the API. For more information, see the NerdGraph distributed tracing data query examples. Can't find data? Having trouble finding data when querying? See Troubleshooting: missing data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.07272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "sections": "Query <em>distributed</em> <em>trace</em> <em>data</em>",
        "tags": "<em>Understand</em> <em>dependencies</em>",
        "body": "You can query your <em>distributed</em> <em>tracing</em> <em>data</em> in several ways: The search bar at top of the <em>distributed</em> <em>tracing</em> <em>UI</em> NRQL query NerdGraph GraphiQL explorer To learn about <em>trace</em> structure, see How <em>distributed</em> <em>tracing</em> works. Example NRQL queries Tip You can also construct complex queries in the search"
      },
      "id": "6072a6ff196a67ddaf64a75a"
    }
  ],
  "/docs/fedramp-endpoint-logs-metrics": [
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile agents",
        "Infrastructure monitoring",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-06-20T22:24:52Z",
      "updated_at": "2021-06-20T22:24:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. Currently Infinite Tracing is not FedRAMP compliant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 641.9353,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>FedRAMP</em>-compliant <em>endpoints</em>",
        "sections": "<em>FedRAMP</em>-compliant <em>endpoints</em>",
        "tags": "Security <em>and</em> Privacy",
        "body": " script. Data-ingest APIs Below are details about the <em>FedRAMP</em> <em>endpoint</em> for our ingest APIs: <em>Metric</em> API, the Event API, the <em>Log</em> API, and the Trace API. <em>Metric</em> API To ensure <em>FedRAMP</em> compliance when using the <em>Metric</em> API, instead of sending <em>metric</em> data to the default <em>Metric</em> API <em>endpoint</em> of https:&#x2F;&#x2F;<em>metric</em>"
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/whats-new/2021/03/fedramp-logs-metrics/",
      "sections": [
        "FedRAMP: Logs and Metrics now certified",
        "Accelerate government IT modernization"
      ],
      "published_at": "2021-06-20T18:12:40Z",
      "title": "FedRAMP: Logs and Metrics now certified",
      "updated_at": "2021-05-09T18:03:29Z",
      "type": "docs",
      "external_id": "683cc62dc2addc69602ccc714dcada9713161d6c",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "Accelerate government IT modernization ​ Protecting your data is our highest priority, which is why we achieved the US Government’s rigorous FedRAMP Moderate certification in 2020. And now we’re adding support for Logs and Metrics to our long list of supported services. ​ New Relic’s FedRAMP authority to operate enables US federal government customers (and those that work with the federal government) to get the same level of real-time insights as commercial organizations, while still ensuring compliance with established security standards ​ Access to New Relic’s FedRAMP environment is based on the following: ​ Your account must be specifically approved by New Relic. You must send your data only to New Relic’s FedRAMP-designated endpoints. Check out the Nerdlog segment below to learn more: Don’t miss the Nerdlog LIVE every Thursday at 12 p.m. PT (8 p.m. UTC) on Twitch to get the latest product updates from the people who built them. Subscribe to our weekly Nerdlog emails to get product updates like these directly in your inbox.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 343.3795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>FedRAMP</em>: <em>Logs</em> <em>and</em> <em>Metrics</em> now certified",
        "sections": "<em>FedRAMP</em>: <em>Logs</em> <em>and</em> <em>Metrics</em> now certified",
        "body": "Accelerate government IT modernization ​ Protecting your data is our highest priority, which is why we achieved the US Government’s rigorous <em>FedRAMP</em> Moderate certification in 2020. And now we’re adding support for <em>Logs</em> and <em>Metrics</em> to our long list of supported services. ​ New Relic’s <em>FedRAMP</em>"
      },
      "id": "606a22bfe7b9d2706694462a"
    },
    {
      "sections": [
        "Regulatory audits for New Relic services",
        "Customer FedRAMP obligations",
        "Time frames",
        "Audits",
        "Customer risk management"
      ],
      "title": "Regulatory audits for New Relic services",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "30dc1bcd07cce70ead8896f1c2f2a95b5da85120",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/",
      "published_at": "2021-06-20T22:24:52Z",
      "updated_at": "2021-05-28T09:38:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This list is current. Last updated 27 May 2021. This document describes New Relic's products and services as they relate to regulatory framework compliance status. For more information, download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to New Relic Full-Stack Observability Enterprise or New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features. Time frames New Relic's time frames for supported regulatory frameworks and annual audits include: SOC2 Type 2 audit: Reviews New Relic's implementation and maintenance of controls for the previous 12 months. The annual audit spans August 1 of the previous year through July 31 of the current year (for example, August 1, 2019 through July 31, 2020). FedRAMP Agency (Moderate): Reviews New Relic's implementation and maintenance of NIST 800-53 rev. 4 controls for the previous 12 months. The annual audit spans November 28 of the previous year through November 28 of the current year (for example, November 28, 2019 through November 28, 2020). Audits In the following table: A check indicates the SOC2 or FedRAMP authorized service was included in the most recent FedRAMP annual audit. An information circle icon indicates the service will be included in upcoming annual audits and assessments. A caution icon indicates the service is on the roadmap for regulatory framework compliance at a time frame to be determined. New Relic service SOC2 FedRAMP Moderate (Agency level ATO) Alerts APM AWS Metric Streams Browser monitoring Error tracking Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of log patterns) Metric API Mobile agents Programmability: New Relic One apps Plugins Proactive Detection (Applied Intelligence) Serverless Synthetic monitoring Trace API Customer risk management All New Relic services are intended to be covered by our compliance programs. However, a new service may not be covered by one or more of our compliance programs at any given time throughout the year. This is primarily dependent on the timing when the service achieved General Availability (GA) status and the timing of the specific compliance program's annual authorization, certification, or assessment. You can use any New Relic service regardless of its compliance program status. However, if a service is not yet in scope of our compliance programs, we encourage you to consider your risk appetite in the decision to use the specific New Relic product or service. If you choose to use New Relic services that are not yet in our compliance program scope, you assume the responsibility to review, understand, and risk-manage your security controls as you deem appropriate. You also have the option to wait for New Relic to authorize these services before you use them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 343.16962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Regulatory audits <em>for</em> New Relic services",
        "sections": "Customer <em>FedRAMP</em> obligations",
        "tags": "Security <em>and</em> Privacy",
        "body": " to be determined. New Relic service SOC2 <em>FedRAMP</em> Moderate (Agency level ATO) Alerts APM AWS <em>Metric</em> Streams Browser monitoring Error tracking Incident Intelligence (Applied Intelligence) Infrastructure monitoring Insights Logging (with exception of <em>log</em> patterns) <em>Metric</em> API Mobile agents"
      },
      "id": "603e81e728ccbc68bfeba794"
    }
  ],
  "/docs/full-stack-observability/index": [
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-20T10:21:48Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 849.9841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the <em>full</em> list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications &gt; (selected app"
      },
      "id": "6044186564441f1f94378ecc"
    },
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-20T03:54:27Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 826.27814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "Tip",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-06-20T20:45:21Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Tip To use Full-Stack Observability and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 753.60297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "Get started with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Full</em>-<em>Stack</em> <em>Observability</em> is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running"
      },
      "id": "603e891528ccbce6d9eba765"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/develop-own-integrations/flex-integration-dummy": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-11145/",
      "sections": [
        "Infrastructure agent v1.11.45",
        "Notes",
        "Added",
        "Changed"
      ],
      "published_at": "2021-06-20T17:34:39Z",
      "title": "Infrastructure agent v1.11.45",
      "updated_at": "2021-03-16T11:52:43Z",
      "type": "docs",
      "external_id": "2fd96bcda44c225b677b43d4ddb049dc959ef455",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Notes A new version of the agent has been released. Follow standard procedures to update your Infrastructure agent. Added SystemSample has two new attributes,MemoryUsedPercent and MemoryFreePercent. The log forwarder now supports the pattern parameter for tcp and syslog For more information on the log forwarder feature, see Forward your logs using New Relic Infrastructure. Changed The built-in Flex integration has been updated to version 1.3.1. For more information, see the Flex changelog. Fluent Bit Output plugin for New Relic has been upgraded to v1.3.0. For more information, see the changelog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 399.31198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " on the log forwarder feature, see Forward your logs using <em>New</em> <em>Relic</em> Infrastructure. Changed The built-in <em>Flex</em> <em>integration</em> has been updated to version 1.3.1. For more information, see the <em>Flex</em> changelog. Fluent Bit Output plugin for <em>New</em> <em>Relic</em> has been upgraded to v1.3.0. For more information, see the changelog."
      },
      "id": "603e9523196a675455a83dc4"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-20T19:30:44Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.4917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> <em>Flex</em>: Build your own <em>integration</em>",
        "sections": "<em>New</em> <em>Relic</em> <em>Flex</em>: Build your own <em>integration</em>",
        "tags": "Develop your own <em>integrations</em>",
        "body": " lightweight <em>Flex</em> tool (recommended, documented below) or, to build a complete on-host <em>integration</em>, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom <em>New</em> <em>Relic</em> One application that uses your own JavaScript UI functionality. What is <em>Flex</em>"
      },
      "id": "6044e44f196a678d15960f6e"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1160/",
      "sections": [
        "Infrastructure agent v1.16.0",
        "Caution",
        "Notes",
        "Added",
        "Changed",
        "Deprecated"
      ],
      "published_at": "2021-06-20T17:42:42Z",
      "title": "Infrastructure agent v1.16.0",
      "updated_at": "2021-06-20T17:42:41Z",
      "type": "docs",
      "external_id": "2992f0f80379a53de52aab096c93d74d460bb0d5",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Caution Updating RPM packages to this version will disable newrelic-infra-service. More details in #357 Notes A new version of the agent has been released. Follow standard procedures to update the Infrastructure agent. New Relic recommends that you upgrade the agent regularly and at a minimum every 3 months. Added newrelic/infrastructure agent docker image is now published as multi-arch (amd64 and arm64). Changed nri-docker built-in integration updated to v1.4.3 Log forwarder feature has updated Fluent Bit to version v1.7.2 available here and Fluent Bit Output Plugin for New Relic to v1.4.6. For more information about Logging feature, see our docs. nri-flex built-in integration updated to v1.4.0. Deprecated CentOS 5 & RHEL 5 newrelic-infra packages are no longer published due to manufacturer end of life. Please check the system requirements documentation for an updated list of supported OS and platforms.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.71327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " 3 months. Added newrelic&#x2F;infrastructure agent docker image is now published as multi-arch (amd64 and arm64). Changed nri-docker built-in <em>integration</em> updated to v1.4.3 Log forwarder feature has updated Fluent Bit to version v1.7.2 available here and Fluent Bit Output Plugin for <em>New</em> <em>Relic</em> to v1.4.6"
      },
      "id": "605e856164441f6d160c8ba9"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations": [
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-20T03:54:27Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.69838,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Instrument</em> your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Cloud services integrations",
        "AWS integrations",
        "GCP integrations",
        "Azure integrations"
      ],
      "title": "Cloud services integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Instrument core services and applications"
      ],
      "external_id": "71020c70edfb43072cbf081b3eccd3b18f9e6289",
      "image": "https://docs.newrelic.com/static/78ac85c1fc41f94776fce7235e327f01/69538/img-integration-aws%25402x.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations/",
      "published_at": "2021-06-20T20:44:47Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic you can easily instrument your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.05148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "With New Relic you can easily <em>instrument</em> your services in AWS, Google Cloud Platform, and Azure. AWS integrations Introduction to AWS integrations List of AWS integrations GCP integrations Introduction to GCP integrations List of GCP integrations Azure integrations Introduction to Azure integrations List of Azure integrations"
      },
      "id": "603e829ae7b9d20bb12a080c"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-20T19:30:44Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.43915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format"
      },
      "id": "6044e44f196a678d15960f6e"
    }
  ],
  "/docs/full-stack-observability/instrument-everything/instrument-core-services-applications/cloud-services-integrations": [
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-20T20:46:25Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.5357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " of <em>applications</em>, frameworks, <em>services</em>, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "d9e77fa458eb408a90de1ebdd60891694ea6feb2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-06-20T19:30:44Z",
      "updated_at": "2021-03-11T08:47:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.43915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of <em>services</em>. It comes bundled with our infrastructure agent. You can <em>instrument</em> any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format"
      },
      "id": "6044e44f196a678d15960f6e"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-20T10:21:48Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.317795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "2. Add tags to your <em>applications</em>",
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " a high-level overview of all your <em>applications</em> and <em>services</em>, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as &quot;My Application&quot; or &quot;PHP Application,&quot; if you don&#x27;t specify one in your New Relic"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-auto-telemetry-pixie": [
    {
      "sections": [
        "Query Auto-telemetry with Pixie data",
        "Important",
        "Metrics and specifications",
        "HTTP metrics",
        "JVM metrics",
        "HTTP server span"
      ],
      "title": "Query Auto-telemetry with Pixie data",
      "type": "docs",
      "tags": [
        "Pixie Auto-telemetry",
        "Service monitoring",
        "Kubernetes",
        "eBPF"
      ],
      "external_id": "b831bc206beeaa77720e0fed4dba93e503a9ffa3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/understand-use-data/auto-telemetry-pixie-data-model/",
      "published_at": "2021-06-20T10:11:38Z",
      "updated_at": "2021-05-26T17:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Auto-telemetry with Pixie is a supported public beta. Therefore, the features and functionality are subject to change. By joining the beta for Auto-telemetry with Pixie, you agree to the terms in the New Relic Pre-Release Policy. Auto-telemetry with Pixie pulls data from the Pixie Cloud API and sends it to the New Relic OpenTelemetry endpoint. You can build your own charts and query your Auto-telemetry with Pixie data using the query builder and the NerdGraph API. Find out more about getting started with Auto-telemetry with Pixie here. Metrics and specifications HTTP metrics Query for duration of inbound HTTP request. For example: FROM Metric SELECT average(http.server.duration) FACET service.name WHERE instrumentation.provider='pixie' Copy Event type Metric Metric name http.server.duration Spec OpenTelemetry HTTP metric spec Description Measures the duration of the inbound HTTP request. OTEL data type MetricDataTypeDoubleSummary with min(quantile=0) and max(quantile=1) Unit milliseconds Required attributes service.name Static attributes instrumentation.provider = pixie HTTP attributes http.status_code Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name JVM metrics Query to measure the time spent in a given JVM garbage collectors in milliseconds. For example: FROM Metric SELECT average(runtime.jvm.gc.collection) FACET service.name, gc WHERE instrumentation.provider='pixie' Copy Event type Metric Metric name runtime.jvm.gc.collection Spec opentelemetry.jvm.gc.collection Description Time spent in a given JVM garbage collector in milliseconds. Unit milliseconds Required attributes service.name Static attributes instrumentation.provider = pixie JVM attributes gc = young|full Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name Query to find out the number of bytes in a given JVM memory area. For example: FROM Metric SELECT average(runtime.jvm.memory.area) FACET service.name WHERE type='used' AND instrumentation.provider='pixie' Copy Event type Metric Metric name runtime.jvm.memory.area Spec opentelemetry-java-instrumentation Description Bytes of a given JVM memory area. Unit bytes Required attributes service.name Static attributes instrumentation.provider = pixie JVM attributes type = used|total|max area = heap Entity attributes service.instance.id k8s.cluster.name k8s.namespace.name k8s.pod.name k8s.container.name HTTP server span Example query: FROM Span SELECT uniques(name) WHERE span.kind='server' AND instrumentation.provider='pixie' AND service.name='orders' Copy Spec Semantic conventions for HTTP spans Event type Span Required attributes name = normalized HTTP path service.name trace.id span.id Static attributes span.kind = server instrumentation.provider = pixie HTTP attributes http.host http.method http.path http.status_code http.url http.user_agent",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 341.9218,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data",
        "sections": "Query <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> data",
        "tags": "<em>Pixie</em> <em>Auto</em>-<em>telemetry</em>",
        "body": "Important <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> is a supported public beta. Therefore, the features and functionality are subject to change. By joining the beta for <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em>, you agree to the terms in the New Relic Pre-Release Policy. <em>Auto</em>-<em>telemetry</em> with <em>Pixie</em> pulls data from the <em>Pixie</em> Cloud"
      },
      "id": "60ae8aaf28ccbcc3c477a3ec"
    },
    {
      "image": "https://docs.newrelic.com/static/3b7d4417336ed5ef2eb3beb02d4affea/ae694/kubernetes-cluster-explorer.png",
      "url": "https://docs.newrelic.com/whats-new/2021/05/pixie-kubernetes-post-5-26/",
      "sections": [
        "Instant Kubernetes observability with Pixie",
        "Get started today"
      ],
      "published_at": "2021-06-20T18:09:42Z",
      "title": "Instant Kubernetes observability with Pixie",
      "updated_at": "2021-05-28T15:26:33Z",
      "type": "docs",
      "external_id": "f132310e72ece8cefc9e318b433c15cddfafa389",
      "document_type": "nr1_announcement",
      "popularity": 1,
      "body": "We've removed the largest barriers to Kubernetes observability: The time and expertise required to manually instrument application code, by integrating Pixie Auto-Telemetry into our Kubernetes solution. Now, you can get visibility into your Kubernetes clusters and workloads instantly without installing language agents. Pixie data helps you debug faster than ever before, giving you access to everything on-cluster without sampling, then using AI/ML models to send the most relevant subset of your data to the Telemetry Data Platform for correlation with other services, intelligent alerting, and long term storage. Pixie Auto-Telemetry uses eBPF to automatically collect metrics, events, logs, and traces for your Kubernetes clusters, applications, OS, and network layers. Start fast: No code to update, new deployments, or lengthy monitoring standardization processes. Observe everything: Analyze data on-cluster using AI/ML without sampling, storing high-value telemetry data for alerting, correlation, and long term storage. Debug faster with Pixie’s developer-focused workflows, providing code-level insights. Get started today In New Relic One, choose Add more data. Choose Guided install or EU Guided install. Choose Kubernetes, and then follow the on-screen prompts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.3715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Instant <em>Kubernetes</em> observability with <em>Pixie</em>",
        "sections": "Instant <em>Kubernetes</em> observability with <em>Pixie</em>",
        "body": ", and long term storage. <em>Pixie</em> <em>Auto</em>-<em>Telemetry</em> uses <em>eBPF</em> to automatically collect metrics, events, logs, and traces for your <em>Kubernetes</em> clusters, applications, OS, and network layers. Start fast: No code to update, new deployments, or lengthy <em>monitoring</em> standardization processes. Observe everything: Analyze"
      },
      "id": "60aeed8a28ccbc146b77a392"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-20T10:11:37Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.07469,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Kubernetes</em> integration: compatibility and requirements",
        "sections": "<em>Kubernetes</em> integration: compatibility and requirements",
        "tags": "<em>Kubernetes</em> integration",
        "body": " <em>Kubernetes</em> cluster AKS Compatible with version 1.11 or higher <em>Kubernetes</em> cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane <em>monitoring</em> Compatible with version 1.11 or higher <em>Service</em> <em>monitoring</em> Compatible with version 1.13 or higher Requirements The New Relic"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability": [
    {
      "sections": [
        "New Relic guided install overview",
        "Supported APM agents",
        "Why it matters",
        "Some technical detail",
        "Important",
        "On-host integration (OHI) recipes",
        "Troubleshoot common problems",
        "MySQL: Incorrect user permissions",
        "NGINX: No status URL"
      ],
      "title": "New Relic guided install overview",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "2058522f6cb1e82dbbe111a176c22ec4aa515ae5",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview/",
      "published_at": "2021-06-20T03:54:27Z",
      "updated_at": "2021-05-09T18:29:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to get started? Click the Guided install button. If your account reports data through our EU datacenter, click EU Guided install. Guided install EU Guided install Our infrastructure agent discovers the applications and infrastructure and log sources running in your environment, and recommends which ones should be instrumented. The install automates the configuration and deployment of each system you choose to instrument. Supported APM agents If you have a .NET Windows application on IIS, the guided install configures and enables an APM agent. Guided install for .NET EU Guided install for .NET Why it matters With our guided install, you can instrument your applications and infrastructure and start seeing your data in New Relic in minutes. The guided install uses our command line interface (CLI), the infrastructure agent for your host environment, and a library of installation recipes to instrument your applications and infrastructure for you. That means less toil for you. Because our instrumentation recipes are open source, you can modify existing recipes, or build new ones, to suit your needs. Some technical detail The New Relic guided install uses open source installation recipes to instrument on-host integrations. These recipes include installation and setup commands, information about logs, and metadata related to what’s being installed. They're collected in a YAML file for each type of system and have all of the installation details necessary to install the infrastructure agent for a specific integration. Important On Windows, our guided install only supports Microsoft SQL Server, logs, and the infrastructure agent. All other integrations are only supported on Linux. On-host integration (OHI) recipes The guided install automates the discovery, configuration, and installation of OHIs. However, there may be times when you want to instrument them one-by-one using the CLI install command. To install any individual on-host integration, run this command: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=API_KEY NEW_RELIC_ACCOUNT_ID=ACCOUNT_ID /usr/local/bin/newrelic install -n INTEGRATION-FLAG Copy For example: curl -Ls https://raw.githubusercontent.com/newrelic/newrelic-cli/master/scripts/install.sh | bash && sudo NEW_RELIC_API_KEY=<API_KEY> NEW_RELIC_ACCOUNT_ID=<ACCOUNT_ID> /usr/local/bin/newrelic install -n apache-open-source-integration Copy The table lists the integrations supported by the guided install CLI command. The specific on-host integration commands are provided for your reference. Our open source integrations send performance metrics and inventory data from your servers and applications to the New Relic platform. You can view pre-built dashboards of your metric data, create alert policies, and create your own custom queries and charts. Integration Command Apache newrelic install -n apache-open-source-integration Cassandra newrelic install -n cassandra-open-source-integration Couchbase newrelic install -n couchbase-open-source-integration ElasticSearch newrelic install -n elasticsearch-open-source-integration HAProxy newrelic install -n haproxy-open-source-integration HashiCorp Consul newrelic install -n hashicorp-consul-open-source-integration JMX newrelic install -n jmx-open-source-integration Memcached newrelic install -n memcached-open-source-integration Microsoft SQL Server (Windows only) newrelic install -n mssql-server-integration-installer MongoDB newrelic install -n mongodb-open-source-integration MySQL newrelic install -n mysql-open-source-integration Nagios newrelic install -n nagios-open-source-integration Nginx newrelic install -n nginx-open-source-integration PostgreSQL newrelic install -n postgres-open-source-integration RabbitMQ newrelic install -n rabbitmq-open-source-integration Redis newrelic install -n redis-open-source-integration Varnish Cache newrelic install -n varnish-cache-open-source-integration Troubleshoot common problems As we identify areas where the guided install fails, we'll document them here and provide some troubleshooting guidance. MySQL: Incorrect user permissions To monitor MySQL health data, you need a valid username and password with specific permissions. These commands will create a user and grant the required permissions: Create a user newrelic@localhost with a specific password. sudo mysql -e \"CREATE USER 'newrelic'@'localhost' IDENTIFIED BY 'YOUR_SELECTED_PASSWORD';\" Copy Give replication privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT REPLICATION CLIENT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Give select privileges to newrelic@localhost with a maximum of 5 connections. sudo mysql -e \"GRANT SELECT ON *.* TO 'newrelic'@'localhost' WITH MAX_USER_CONNECTIONS 5;\" Copy Once done, your next guided install attempt should work. NGINX: No status URL To monitor your NGINX server, you'll need to configure a valid status URL. status_url: The URL set up to provide the metrics using the status module. If the default value of 127.0.0.1 is incorrect, substitute the address/FQDN/URL for your system. Example: status_url: http://127.0.0.1/status You can read more about the status_url in these NGINX docs: For NGINX Open Source: HTTP stub status module For NGINX Plus: HTTP status module and HTTP API module There are different ways to set status_url, depending on how NGINX was installed: If enabled via Kubernetes: See Monitor services running on Kubernetes. If enabled via Amazon ECS: See Monitor services running on ECS. If installed on-host: Edit the config in the integration's YAML config file, nginx-config.yml.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.68854,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "Instrument your systems and send telemetry data to New Relic with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent. Ready to <em>get</em> <em>started</em>? Click the Guided install button. If your"
      },
      "id": "604130a7e7b9d299cb2a07c0"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-20T20:46:25Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Tip To use integrations and infrastructure monitoring, as well as the rest of our"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-20T10:21:48Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.70775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com &gt; More &gt; service maps. To <em>get</em> <em>started</em>, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/full-stack-observability/observe-everything/get-started/new-relic-guided-install-overview": [
    {
      "sections": [
        "Get started with Full-Stack Observability",
        "Tip",
        "You’re in control because you understand your system",
        "All the answers in one place",
        "Start anywhere"
      ],
      "title": "Get started with Full-Stack Observability",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Observe everything",
        "Get started"
      ],
      "external_id": "e7fc0bf91fa26b38a11933b6570c8b1e483a1ff9",
      "image": "https://docs.newrelic.com/static/44970161aec793f3141cfcdc0fc96a57/c1b63/observability.png",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/observe-everything/get-started/get-started-full-stack-observability/",
      "published_at": "2021-06-20T20:45:21Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Full-Stack Observability is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of everything that enables your applications and devices to deliver value to your customers, from the container running a microservice in the cloud to a mobile website's shopping cart button. Tip To use Full-Stack Observability and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. You’re in control because you understand your system New Relic helps you cut through the layers of complexity surrounding your systems by bringing together and connecting data from any instrumented source and environment, without having to jump between tools. You can interrogate your data for patterns, discover them using our data platform, or get proactive results from our machine learning tools. New Relic provides answers to essential questions in one place. All the answers in one place As a full user you get access to our entire set of observability tools. All our tools are interconnected and accessible in New Relic One. All the data you bring to New Relic through agents and integrations are metrics, events, logs, and traces that feed our platform's analytics and monitoring capabilities. New Relic links your data in a meaningful way so that you can explore it, build dashboards, and set up alerts. Full-Stack Observability curated experiences allow to visualize, analyze, and troubleshoot your entire software stack in one unified platform. The New Relic Explorer consolidates all the entities in your system, and how they're connected, in a single place, so you can easily detect performance trends and issues. By automatically connecting infrastructure health with application performance and end-user behavior, you can cut through the noise to find the signal. Start anywhere Being fully-connected, New Relic allows you to start your observability journey from any element of your stack. For example, you can get to crucial infrastructure logs from traces of an application running on a problematic Kubernetes pod. The more entities you instrument, the more data you'll bring in. The more data you've brought to New Relic, the more you'll understand your metrics, events, logs, and traces. You want to instrument Start with Keep exploring Front-end applications Mobile applications User behavior and flows New Relic Explorer Browser monitoring Mobile monitoring Synthetic monitoring Single page monitoring Scripted browsers Containerized minions Workloads Backend applications Serverless applications New Relic Explorer Application monitoring Serverless monitoring Learning about Apdex Distributed tracing Logs in context APM data to infrastructure Workloads Infrastructure hosts and services (on-premise, cloud, orchestrated) Container environments and orchestration tools (Kubernetes, ECS, etc.) Infrastructure monitoring Infrastructure integrations Kubernetes integration Docker integration ECS integration Log forwarding APM data to infrastructure Custom integrations Kubernetes cluster explorer Infrastructure alerts Workloads",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.25497,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": "<em>Full</em>-<em>Stack</em> <em>Observability</em> is the power of knowing what is happening in your digital system and why, at any time, whatever solution you’re using. It’s getting the whole picture of <em>everything</em> that enables your applications and devices to deliver value to your customers, from the container running"
      },
      "id": "603e891528ccbce6d9eba765"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-20T20:46:25Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what you’ll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.03102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>Stack</em> <em>Observability</em>",
        "body": " integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Tip To use integrations and infrastructure monitoring, as well as the rest of our"
      },
      "id": "603e817f28ccbc4857eba798"
    },
    {
      "sections": [
        "APM best practices guide",
        "Tip",
        "1. Standardize application names",
        "How to do it",
        "2. Add tags to your applications",
        "Caution",
        "3. Create and evaluate alert policies",
        "4. Identify and set up key transactions",
        "5. Track deployment history",
        "6. Review APM reports",
        "7. Review your environment with service maps",
        "8. Keep current",
        "9. Manage user access",
        "Important"
      ],
      "title": "APM best practices guide",
      "type": "docs",
      "tags": [
        "New Relic solutions",
        "Best practices guides",
        "Full-stack observability"
      ],
      "external_id": "368a1a5688384d5bebf128604a9b8f190d335524",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/best-practices-guides/full-stack-observability/apm-best-practices-guide/",
      "published_at": "2021-06-20T10:21:48Z",
      "updated_at": "2021-06-08T18:52:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Application Monitoring Tips You Need To Know It's one thing to know how to use APM, but it's another thing to know how to use New Relic's application performance monitoring software well. Here are some best practices designed to help you become an APM master—and a key asset to your team! Tip To get a high-level overview of all your applications and services, use the New Relic Explorer in New Relic One. 1. Standardize application names Most New Relic agents provide a default application name, such as \"My Application\" or \"PHP Application,\" if you don't specify one in your New Relic configuration file. You don't want to end up with 20 identically named applications, be sure to select a descriptive identifier for your apps as soon you deploy them. To keep things consistent and easy to navigate, New Relic recommends standardizing your application naming (for example, all apps in Staging append [ Staging] or the like at the end of their names). Ideally, you want your new Java applications to be named automatically to reduce the chances of typographical errors and misnaming. How to do it For Java applications, automatic application naming can come from the following sources: Request attribute Servlet init parameter Filter init parameter Web app context parameter Web app context name (display name) Web app context path Choose the method that fits best your needs and follow these steps. For non-Java applications, there are no automatic naming methods, so refer to the documentation for your APM agent. 2. Add tags to your applications When several different applications use the same account, and each application spans multiple environments (for example, development, test, pre-production, production), it can be hard to find a specific application in your overview dashboard. That's why we recommend adding tags to your apps so that you can segment them into logical groups. The two most common tags that mature APM customers use are application name and environment. So, for example, if you wanted to view the billing application in Test, you could simply filter by \"billing app\" (name tag) and \"test\" (environment tag). Caution In the APM agent configuration settings files, use the labels field to add tags to your data. For example, see this description of the Python labels setting. APM is designed so that apps can roll up into an unlimited number of meaningful tag categories. How to do it Learn about tags. Learn how to add tags.. Learn how to query tags. 3. Create and evaluate alert policies When key performance indicators spike or drop, individuals and teams in your organization need to be notified. Alerting in New Relic provides a set of tools including dynamic baselines that allow you to detect problems before they impact your end users. Alert policies can be set up in two primary ways: Static threshold alerts are great when you already know the nature of an application and its normal behaviors aren't likely to change anytime soon. Apdex score, response time, error rate, throughput are some of the static thresholds you can create alert policies on. Dynamic baseline alerts make it easy to determine and set dynamic alert thresholds for applications with varying seasonal patterns and growth trends (which make it difficult to set thresholds that define normal behavior). These alerts use baselines modeled from your application’s historical metric data. Each alert policy can contain as many conditions as you need, and each alert condition includes three components: Type of condition (metric, external service, and so on) Entities that the policy targets (for example, apps monitored by New Relic APM or New Relic Browser, hosts monitored by New Relic Infrastructure, and so on) Thresholds that escalate into alerting situations with increasing severity Once you have your alerting set up, you then want to make sure you're taking advantage of all viable notification channels. After all, what good are alerts if no one knows about them? You can manage alerts by creating specific user groups and by leveraging New Relic's integrated alert channels, including Slack, PagerDuty, webhooks, and email. Be sure to evaluate alert policies on a regular basis to ensure that they are always valid. How to do it See the detailed documentation: To set up dynamic baseline alerts and choose an application, follow standard procedures. You will see a preview of the metric with the predicted baseline You can select a metric for that application and see the corresponding baseline. Then, using the threshold sliders, you can set how closely you want your threshold to follow the baseline prediction. To set up static threshold alerts for your Apdex settings, follow standard procedures. To set up your alert notification channels, follow standard procedures. 4. Identify and set up key transactions Depending on the nature of your application, some transactions may be more important to you than others. New Relic's key transactions feature is designed to help you closely monitor what you consider to be your app's most business-critical transactions, whether that's end-user or app response time, call counts, error rates, or something else. You can also set alert threshold levels for notifications when your key transactions are performing poorly. How to do it In the menu bar, select More > Key transactions, and then select Add more. Then select the app and web transaction or, from the selected transaction, select Track as key transaction. Type a name for the key transaction, and select Track key transaction. Optional: If the agent for the selected app supports custom alerting, use the default values that New Relic automatically fills, or select Edit key alert transaction policy to set the Apdex and alert threshold values. To view the key transactions dashboard details, select View new key transaction. 5. Track deployment history When development teams are pushing new code out as frequently as possible, it can be hard to measure the impact that each deployment is having on performance. One way to stay in tune with how these changes are affecting your application is with deployment reports. These reports list recent deployments and their impact on end-users and app servers' Apdex scores, along with response times, throughput, and errors. You can also view and drill down into the details to catch errors related to recent deployments, or file a ticket and share details with your team. How to do it From the New Relic menu bar, select APM > (selected app) > Events > Deployments. To view performance after a deployment, go to the selected app's Overview dashboard in the Recent events section. A blue vertical bar on a chart indicates a deployment. To view summary information about the deployment, point to the blue bar. 6. Review APM reports From SLA, deployment, and capacity to scalability, host usage reports, and more, New Relic APM offers a variety of downloadable reporting tools surfacing historical trends—all great ways to report to senior executive teams or customers. Take a look at the full list of reports and use them to your advantage. How to do it From the New Relic APM menu bar, select Applications > (selected app) > Reports. Select the report you'd like to see. If you want to save or export a report to share, select Download this report as .csv, which will create a report with comma-separated values. 7. Review your environment with service maps Use New Relic service maps, a feature included in APM, to understand how apps and services in your architecture connect and talk to each other. Service maps are visual, customizable representations of your application architecture. Maps automatically show you your app's connections and dependencies, including databases and external services. Health indicators and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com > More > service maps. To get started, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy as updating your agent. Most likely your organization already has a set of scripts for deploying application upgrades into your environment. In a similar fashion, you can also automate your New Relic agent deployment to ensure that your systems are up to date. Both Puppet and Chef scripts are great examples of deployment frameworks that make life easier by allowing you to automate your entire deployment and management process. How to do it Regularly review which version of the agent you're using so that you know when an update is needed. If the latest agent release contains a needed fix or added functionality, download it. To deploy the agent automatically (preferred as a method to avoid errors): Use existing deployment scripts, provided they can be adapted to handle the deployment. OR Create and maintain a script that specifically deploys and configures the New Relic agent. Ideally, the script would pull the agent files from a repository where the files are versioned (for rollback purposes). Once the script has been created, shut down the application (unless script handles this). Run the deployment script. Start the application (unless script handles this). If problems arise, run the script to roll back to the previous version. To deploy the agent manually: Back up the current agent directory. Deploy the updated agent into the existing agent directory. Modify configuration files by comparing new files with existing files. In particular, make sure things like license key and custom extensions are copied over to the new configuration. Restart the application. If problems arise, restore the old agent using the backup and restart. 9. Manage user access Important This is available only for accounts on our original product-based pricing plan. Enable role-based access control (RBAC) and single sign-on (SSO) New Relic allows authorized individuals to access the broadest possible amount of data, regardless of their assigned role. As an Owner or Administrator of your New Relic account, you can control the permissions of individual users or entire roles with RBAC. To find out what is possible and how to make changes, see Users and roles. Security is no doubt of utmost concern to your organization. To simplify password management for your employees and strengthen security, you may already be using SSO with your other systems. You should do the same with New Relic. Using New Relic's SSO integration feature, account administrators will be able to enforce strong passwords and restrict login via a corporate authentication mechanism. This way, New Relic users who have already authenticated using a corporate SSO system will be able to bypass the New Relic login prompt. How to do it Log in to New Relic as an admin and go to the SSO configuration page. From the New Relic title bar, select (your account name) > Account Settings > Integrations > Single Sign On. From the SAML Single Sign On page, review your New Relic SAML Service Provider details. To upload your SAML Identity Provider certificate, select Choose File, and then follow standard procedures to select and save the file. Copy and paste in (or type) the Remove login URL that your users will use for Single Sign-On. If your organization’s SAML integration provides a redirect URL for logout, copy and paste in (or type) the Logout landing URL; otherwise leave blank. Save, test, and enable.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.70773,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Full</em>-<em>stack</em> <em>observability</em>",
        "body": " and performance metrics show you the current operational status for every part of your architecture. How to do it Go to one.newrelic.com &gt; More &gt; service maps. To <em>get</em> <em>started</em>, read the instructions in Introduction to service maps. 8. Keep current With New Relic’s SaaS platform, getting new features is as easy"
      },
      "id": "6044186564441f1f94378ecc"
    }
  ],
  "/docs/gateway-api-import-data-other-observability-platforms": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Tip",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "b900b7545f9032201c212449be114e10176bf789",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-06-20T19:32:45Z",
      "updated_at": "2021-06-15T13:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 100.232765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency and <em>data</em> collection for cloud integrations",
        "sections": "Configure polling frequency and <em>data</em> collection for cloud integrations",
        "body": "Our cloud integrations get <em>data</em> <em>from</em> cloud provider APIs. In New Relic, you can change some of the <em>data</em> collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our <em>observability</em>"
      },
      "id": "603e8eef64441fcc7e4e8853"
    },
    {
      "sections": [
        "Kubernetes integration: install and configure",
        "Tip",
        "Use automated installer",
        "Installs for managed services and platforms",
        "Amazon EKS",
        "Amazon EKS Fargate",
        "Google Kubernetes Engine (GKE)",
        "OpenShift container platform",
        "Azure Kubernetes Service (AKS)",
        "Pivotal Container Service (PKS / VMware Tanzu)",
        "Custom manifest",
        "Important",
        "Make sure New Relic pods can be scheduled",
        "Unprivileged installs of the Kubernetes integration",
        "Steps to complete an unprivileged install",
        "Configure the integration",
        "Select which processes should send their data to New Relic",
        "Specify the Kubernetes API host and port",
        "Kubernetes versions 1.6 to 1.7.5: Edit manifest file",
        "Use environment variables",
        "Disable kube-state-metrics parsing",
        "Caution",
        "Specify the kube-state-metrics URL",
        "Discover kube-state-metrics pods using a label",
        "Query kube-state-metrics behind RBAC",
        "kube-state-metrics timeout: Increase the client timeout",
        "Non-default namespace deployments: Edit config file",
        "Set the TTL for the Kubernetes API responses cache",
        "Specify base URLs for control plane component endpoints",
        "Configure the infrastructure agent",
        "Update to the latest version",
        "Using the automated installer",
        "Using helm",
        "Uninstall the Kubernetes integration"
      ],
      "title": "Kubernetes integration: install and configure",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Installation"
      ],
      "external_id": "ff06c8b1d8b2940d0b23034f3057377ce571e4ab",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/kubernetes-integration-install-configure/",
      "published_at": "2021-06-20T19:36:53Z",
      "updated_at": "2021-06-15T13:05:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like Kubernetes events, Prometheus OpenMetrics, and New Relic log monitoring. Tip To use Kubernetes integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Use automated installer You can use the automated installer for servers, VMs, and unprivileged environments. The installer can also help you with managed services or platforms after you review a few preliminary notes. We also have separate instructions if you need a custom manifest or prefer to do a manual unprivileged installation. Start the installer If your New Relic account is in the EU region, access the installer from one.eu.newrelic.com. Installs for managed services and platforms Before starting our automated installer, check out these notes for your managed services or platforms: Amazon EKS The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of kubectl provided by AWS. Amazon EKS Fargate For help installing our EKS Fargate integration, see these setup options. Google Kubernetes Engine (GKE) The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms. Before starting our automated installer to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions: Go to console.cloud.google.com/iam-admin/iam and find your username. Click edit. Ensure you have permissions to create Roles and ClusterRoles: If you are not sure, add the Kubernetes Engine Cluster Admin role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions. Ensure you have a RoleBinding that grants you the same permissions to create Roles and ClusterRoles: kubectl create clusterrolebinding YOUR_USERNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUR_GCP_EMAIL Copy Creating a RoleBinding is necessary because of a known RBAC issue in Kubernetes and Kubernetes Engine versions 1.6 or higher. For more information, see Google Cloud's documentation on defining permissions in a role. OpenShift container platform To deploy the Kubernetes integration with OpenShift: Add the <>{'<release_name>'}</>-newrelic-infrastructure service account to your privileged Security Context Constraints: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:<namespace>:<release_name>-newrelic-infrastructure Copy The default <>{'<release_name>'}</> provided by the installer is nri-bundle. Complete the steps in our automated installer. If you're using signed certificates, make sure they are properly configured by using the following variables in the DaemonSet portion of your manifest to set the .pem file: - name: NRIA_CA_BUNDLE_DIR value: YOUR_CA_BUNDLE_DIR - name: NRIA_CA_BUNDLE_FILE value: YOUR_CA_BUNDLE_NAME Copy YAML key path: spec.template.spec.containers.name.env Save your changes. Azure Kubernetes Service (AKS) The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms. To deploy in Azure Kubernetes Service (AKS), complete the steps in our automated installer. Pivotal Container Service (PKS / VMware Tanzu) To deploy in PKS, we recommend that you use the automated installer, or you can follow the manual instructions provided in Install the Kubernetes integration using Helm. Custom manifest If the Kubernetes automated installer doesn't provide the settings you need, you can download our manifest template and install the integration manually. To activate the Kubernetes integration, you must deploy the newrelic-infra agent onto a Kubernetes cluster as a DaemonSet: Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy In the DaemonSet portion of your manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Recommendation: Do not change the NRIA_PASSTHROUGH_ENVIRONMENT or NRIA_DISPLAY_NAME value in your manifest. YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. YAML key path: spec.template.spec.containers.name.env env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy If you need to adapt the manifest to fit your environment, review the configure section in this doc. Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration is working: wait a few minutes, then look for data in the New Relic Kubernetes cluster explorer. If you don't see data, review the configuration procedures again, then follow the troubleshooting procedures. Important In the future, the number of labels collected on Kubernetes objects will be limited per object type (containers, pods, nodes, etc.). If objects have labels above the limit, you will be able to configure important labels that should always be sent to New Relic. When the limitation is in place, this documentation will be updated. Make sure New Relic pods can be scheduled Some of the New Relic pods are set up as DaemonSet in the manifest file so that they can run on every host. These include newrelic-infrastructure and newrelic-logging. In rare circumstances, other pods may be scheduled first and starve the New Relic pods of resources. Since each of these pods have to run on a specific host, they will stay in pending status until that host has enough resources, even if there are other hosts available. This could end up occurring for long periods of time and result in reporting gaps. To prevent this scenario, you can configure the Kubernetes scheduler to give New Relic pods a higher priority. Using the default scheduler: Ensure kube-scheduler flag disablePreemption is not set to true (by default it is false). Create a PriorityClass for the New Relic DaemonSet pods: Set the appropriate priority value, which should generally be higher than your other pods. preemptionPolicy is set to PreemptLowerPriority by default. This allows New Relic pods assigned this priority class to remove lower-priority pods that are taking up resources. Edit the manifest file to add priorityClassName to any DaemonSet specs. In the example below, the highlighted line sets the priority class for newrelic-infrastructure: apiVersion: apps/v1 kind: DaemonSet metadata: namespace: default labels: app: newrelic-infrastructure chart: newrelic-infrastructure-1.0.0 release: nri-bundle mode: privileged name: nri-bundle-newrelic-infrastructure spec: priorityClassName: your-priority-class ... Copy If you have already deployed the New Relic pods, re-deploy them and confirm they have been created: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml kubectl create -f newrelic-infrastructure-k8s-latest.yaml kubectl get daemonsets Copy Unprivileged installs of the Kubernetes integration For platforms that have stringent security requirements, we provide an unprivileged version of the Kubernetes integration. Changes from the standard Kubernetes integration are: Runs the infrastructure agent and the Kubernetes integration as a standard user instead of root No access to the underlying host filesystem No access to /var/run/docker.sock Container's root filesystem mounted as read-only allowPrivilegeEscalation is set to false hostnetwork is set to false The tradeoff is that the solution will only collect metrics from Kubernetes, but it will not collect any metric from the underlying hosts directly. Kubernetes provides some data (metrics and metadata) about its nodes (hosts). Tip Optional: To collect the underlying host metrics, the non-containerized infrastructure agent can be deployed on the underlying host. The infrastructure agent already supports running as non-root. The combination of the Kubernetes integration in its unprivileged version and the agent running on the host will report all the metrics that our standard solution for monitoring Kubernetes receives. Steps to complete an unprivileged install Install kube-state-metrics and get it running on the cluster. For example: curl -L -o kube-state-metrics- 1.9.5 .zip https://github.com/kubernetes/kube-state-metrics/archive/v 1.9.5 .zip && unzip kube-state-metrics- 1.9.5 .zip && kubectl apply -f kube-state-metrics- 1.9.5 /examples/standard Copy Download the integration manifest: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy In the manifest, add your New Relic license key and a cluster name to identify your Kubernetes cluster. Both values are required. Important YOUR_CLUSTER_NAME is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment. env: - name: NRIA_LICENSE_KEY value: YOUR_LICENSE_KEY - name: CLUSTER_NAME value: YOUR_CLUSTER_NAME Copy YAML key path: spec.template.spec.containers.name.env Confirm that kube-state-metrics is installed. kubectl get pods --all-namespaces | grep kube-state-metrics Copy Create the DaemonSet: kubectl create -f newrelic-infrastructure-k8s-unprivileged-latest.yaml Copy Confirm that the DaemonSet has been created successfully by looking for newrelic-infra in the results generated by this command: kubectl get daemonsets Copy To confirm that the integration has been configured correctly, wait a few minutes, then run this NRQL query to see if data has been reported: SELECT * FROM K8sPodSample since 5 minutes ago Copy Configure the integration The Kubernetes integration comes with a default configuration that should work in most environments. To change the configuration, modify the manifest file: Select which processes should send their data to New Relic By default, data about the processes running on your pods is not sent to New Relic. You can enable it by setting enable_process_metrics to true. To choose what metric data you want to send to New Relic, configure the include_matching_metrics environment variable in your manifest. Specify the Kubernetes API host and port This is necessary when you are using SSL and not using the default FQDN. The Kubernetes API FQDN needs to match the FQDN of the SSL certificate. You do not need to specify both variables. For example, if you only specify the HOST, the default PORT will be used. - name: \"KUBERNETES_SERVICE_HOST\" value: \"KUBERNETES_API_HOST\" - name: \"KUBERNETES_SERVICE_PORT\" value: \"KUBERNETES_API_TCP_PORT\" Copy Kubernetes versions 1.6 to 1.7.5: Edit manifest file For Kubernetes versions 1.6 to 1.7.5, uncomment these two lines in the manifest file: - name: \"CADVISOR_PORT\" # Enable direct connection to cAdvisor by specifying the port. Needed for Kubernetes versions prior to 1.7.6. value: \"4194\" Copy Use environment variables Use environment variables that can be passed to the Kubernetes integration if you use a proxy to configure its URL. Disable kube-state-metrics parsing You can disable kube-state-metrics parsing for the DaemonSet by using the following configuration: - name: \"DISABLE_KUBE_STATE_METRICS\" value: \"true\" Copy Caution Disabling kube-state-metrics also disables data collection for the following: ReplicaSets DaemonSets StatefulSets Namespaces Deployments Services Endpoints Pods (that are pending) Additionally, disabling this affects the Kubernetes Cluster Explorer in the following ways: No pending pods are shown. No filters based on services. Specify the kube-state-metrics URL If several instances of kube-state-metrics are present in the cluster, uncomment and configure the following lines to specify which one to use: - name: \"KUBE_STATE_METRICS_URL\" value: \"http://KUBE_STATE_METRICS_IP_OR_FQDN:PORT\" Copy Important Even though a KUBE_STATE_METRICS_URL is defined, the KSM service should contain one of the following labels for the auto-discovery process: k8s-app=kube-state-metrics OR app=kube-state-metrics OR ​​app.kubernetes.io/name=kube-state-metrics Important This configuration option overrides KUBE_STATE_METRICS_POD_LABEL. If you have both defined, KUBE_STATE_METRICS_POD_LABEL has no effect. Discover kube-state-metrics pods using a label If several instances of kube-state-metrics are present in the cluster, another option to easily target one of these instances with the Kubernetes integration is to use label-based discovery. - name: \"KUBE_STATE_METRICS_POD_LABEL\" value: \"LABEL_NAME\" Copy Important When a KUBE_STATE_METRICS_POD_LABEL is defined, the label should have a value equal to true. For example, if the label name is my-ksm, ensure that my-ksm=true. Important This configuration option is incompatible with KUBE_STATE_METRICS_URL. If you have both defined, KUBE_STATE_METRICS_URL is used. Query kube-state-metrics behind RBAC If your instance of kube-state-metrics is behind kube-rbac-proxy, the integration can be configured in a compatible way using the combination of the label-based discovery and two other environment variables: - name: \"KUBE_STATE_METRICS_SCHEME\" value: \"https\" - name: \"KUBE_STATE_METRICS_PORT\" value: \"KSM_RBAC_PROXY_PORT\" Copy To confirm which port should be used as the value of KUBE_STATE_METRICS_PORT, we recommend running a describe command on the kube-state-metrics pod and look for the port exposed by the container named kube-rbac-proxy-main. Important These two configuration options only work when using the KUBE_STATE_METRICS_POD_LABEL configuration described above. kube-state-metrics timeout: Increase the client timeout To increase the client timeout of kube-state-metrics, add a new environment variable, TIMEOUT, to the manifest file: env: - name: TIMEOUT value: 5000 # The default client timeout when calling kube-state-metrics, in milliseconds Copy Then, add this new environment variable to the NRIA_PASSTHROUGH_ENVIRONMENT Non-default namespace deployments: Edit config file If you want to deploy in a different namespace from default, change all values of namespace in the manifest. Set the TTL for the Kubernetes API responses cache By default, the integration will cache any retrieved information from the Kubernetes API for 5 minutes. Use the API_SERVER_CACHE_TTL environment variable to set a custom cache duration for responses from the API server. Valid time unit values are: ns, us, ms, s, m, and h. To disable caching, set to 0s. env: - name: API_SERVER_CACHE_TTL value: \"1m\" Copy Specify base URLs for control plane component endpoints Use the following environment variables if any of the Kubernetes control plane components export metrics on base URLs that are different from the defaults. This is necessary for environments such as OpenShift when a control plane component metrics endpoint is using SSL or an alternate port. Values of these environment variables must be base URLs of the form [scheme]://[host]:[port]. URLs should not include a path component. For example: - name: \"SCHEDULER_ENDPOINT_URL\" value: \"https://localhost:10259\" - name: \"ETCD_ENDPOINT_URL\" value: \"https://localhost:9979\" - name: \"CONTROLLER_MANAGER_ENDPOINT_URL\" value: \"https://localhost:10257\" - name: \"API_SERVER_ENDPOINT_URL\" value: \"https://localhost:6443\" Copy The /metrics path segment is added automatically. In addition, if the https scheme is used, authentication to the control plane component pod(s) is accomplished via service accounts. Caution If a FQDN (fully qualified domain name) is used in a multi-master cluster, inconsistent results may be returned. Therefore, it is recommended to use localhost only. Important Even though a custom base URL is defined for a given control plane component, the control plane component pod(s) must contain one of the labels supported by the auto-discovery process. Important Even though a custom ETCD_ENDPOINT_URL can be defined, ETCD will always require https and mTLS authentication to be configured. Here are some additional configurations to consider: Do more configuration for control plane monitoring Link New Relic APM to the Kubernetes integration Monitor services that run on Kubernetes Configure the infrastructure agent The Kubernetes integration image comes with a default configurations for the agent that can be modified if needed. When installing with the manifest, you can modify the infrastructure agent configuration by editing the manifest and adding any needed configuration option of the agent as environment variables of the newrelic-infrastructure DaemonSet. When installing with Helm, you can specify the needed infrastructure agent configuration options in the values.yaml as shown in the example in GitHub. The config object is used to populate the configMap that is mounted automatically in the location of the infrastructure agent configuration file in the pods created by the newrelic-infrastructure DaemonSet. Update to the latest version Using the automated installer To update a Kubernetes integration installed with the automated installer, just run the installer again. It will always offer a manifest pointing to the last released version of the integration. Using helm See Install the Kubernetes integration using Helm Custom manifest If you are already running the Kubernetes integration and want to update the newrelic-infra agent to the latest agent version: Run this NRQL query to check which version you are currently running (this will return the image name by cluster): SELECT latest(containerImage) FROM K8sContainerSample WHERE containerImage LIKE '%newrelic/infrastructure%' FACET clusterName SINCE 1 day ago Copy If you've set a name other than newrelic/infrastructure for the integration's container image, the above query won't yield results: to make it work, edit the name in the query. Download the integration manifest file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml Copy Copy the changes you made to the manifest. At a minimum, include CLUSTER_NAME and NRIA_LICENSE_KEY, and paste your changes in the manifest you downloaded. Install the latest DaemonSet with the following command (Kubernetes will automatically do a rollout upgrade for the integration's pods): kubectl apply -f newrelic-infrastructure-k8s-latest.yaml Copy Uninstall the Kubernetes integration To uninstall the Kubernetes integration: Verify that newrelic-infrastructure-k8s-latest.yaml corresponds to the filename of the manifest as you have saved it. Example: If you are using the unprivileged version of the integration, the default filename will be newrelic-infrastructure-k8s-unprivileged-latest.yaml. After you verify the filename, use the following command: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy You only need to execute this command once, regardless of the number of nodes in your cluster.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.1709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Installs for managed services and <em>platforms</em>",
        "body": " To use Kubernetes integrations and infrastructure monitoring, as well as the rest of our <em>observability</em> <em>platform</em>, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of <em>data</em> for free each month. Forever. Use automated installer You can use"
      },
      "id": "60450ae964441f0603378f15"
    },
    {
      "sections": [
        "Amazon API Gateway monitoring integration",
        "Features",
        "Requirements",
        "Tip",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Inventory data",
        "Dimensions"
      ],
      "title": "Amazon API Gateway monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "a0d3ee22f75f187dbf4fbe512d1b018e11e5684d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-api-gateway-monitoring-integration/",
      "published_at": "2021-06-20T20:53:43Z",
      "updated_at": "2021-03-11T10:43:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations include an integration for reporting your Amazon API Gateway data to New Relic. This document explains how to activate this integration and describes the data that can be reported. Features Amazon's API Gateway is a fully managed service that allows you to create, publish, maintain, monitor, and secure APIs at any scale. With the New Relic API Gateway integration, you get more data about how your API layer is working behind the scenes. You'll receive metric data about the number of API calls, the requests served, the number of errors, latency counts, and more. You can monitor and alert on your API Gateway data directly from New Relic, and query data and create dashboards. Requirements API Gateway will not send \"Call count by resource\", \"4xx error by resource\" and \"5xx errors by resource\" metrics unless you have explicitly enabled detailed CloudWatch metrics. Tip Enabling these metrics may add additional charges to your Amazon CloudWatch account pricing. To enable CloudWatch metrics, use either of these options: Go to the AWS Management Console, select the Settings option for CloudWatch, then select the option to enable detailed CloudWatch metrics. Call the stage:update action of the Amazon API Gateway REST API to update the metricsEnabled property to true. Activate integration To enable this integration follow standard procedures to Connect AWS services to New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Amazon API gateway integration: New Relic polling interval: 5 minutes Amazon CloudWatch data interval: 1 minute Find and use data To find your integration data in Infrastructure, go to one.newrelic.com > Infrastructure > AWS and select one of the API Gateway integration links. You can query and explore your data using the ApiGatewaySample event type. For more on how to use your data, see Understand and use integration data. Metric data This New Relic infrastructure integration collects the following Amazon API Gateway data: Metric Description 4XXError The number of client-side errors captured 5XXError The number of server-side errors captured. CacheHitCount The number of requests served from the API cache. CacheMissCount The number of requests served from the back end when API caching is enabled. Count The number of calls to API methods. IntegrationLatency The time in milliseconds between when API Gateway relays a request to the back end and when it receives a response from the back end. Latency The time in milliseconds between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Inventory data Inventory data provides information about the service's state and configuration. API Gateway configuration options are reported as inventory data. For more about inventory data, see Understand and use data. Object Inventory data /aws/apigateway/api apiId apiName awsRegion /aws/apigateway/resource awsRegion methods resource resourceid /aws/apigateway/stage apiName awsRegion cacheClusterEnable cacheClusterSize cacheClusterStatus lastUpdatedDate stageName /aws/apigateway/stage/variables value /aws/apigateway/stage/settings CacheDataEncrypted CacheTtlInSeconds CachingEnabled DataTraceEnabled LoginLevel MetricsEnabled RequireAuthorizationForCacheControl UnauthorizedCacheControlHeaderStrategy ThrottlingBurstLimit ThrottlingRateLimit /aws/apigateway/stage/resource-with-metrics apiName awsRegion method resource stageName Dimensions You can use the dimensions in the following table to filter API Gateway metrics. Dimensions Description ApiName Filters API Gateway metrics for an API of the specified API name. ApiName, Method, Resource, Stage Filters API Gateway metrics for an API method of the specified API, stage, resource, and method. ApiName, Stage Filters API Gateway metrics for an API stage of the specified API and stage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 86.756775,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "sections": "Amazon <em>API</em> <em>Gateway</em> monitoring integration",
        "body": ", and more. You can monitor and alert on your <em>API</em> <em>Gateway</em> <em>data</em> directly <em>from</em> New Relic, and query <em>data</em> and create dashboards. Requirements <em>API</em> <em>Gateway</em> will not send &quot;Call count by resource&quot;, &quot;4xx error by resource&quot; and &quot;5xx errors by resource&quot; metrics unless you have explicitly enabled detailed CloudWatch"
      },
      "id": "6043ee9964441fa2c3378eee"
    }
  ],
  "/docs/infrastructure/index": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.64952,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent configuration settings ",
        "sections": "<em>Infrastructure</em> agent configuration settings",
        "tags": "<em>Infrastructure</em>",
        "body": "The <em>infrastructure</em> agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-20T14:26:20Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 53.76423,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> agent",
        "sections": "Requirements for the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em>",
        "body": "Before installing our <em>infrastructure</em> agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The <em>infrastructure</em> agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "b236b0fae29853de085d0430fdec27fba74c15d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-06-20T19:34:58Z",
      "updated_at": "2021-06-20T19:34:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your Insights dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's an Insights NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's an Insights NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's an Insights NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in an Insights dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying in New Relic Insights. Here are some tips for using the different types of integration data in Insights: Metric data tips Tips for finding and using integration metric data in Insights: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data in Insights: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data in Insights: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to Insights data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found in Insights by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an Insights InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 53.307762,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> integrations",
        "body": " with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "60450a39196a67d7dc960f7c"
    }
  ],
  "/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.76099,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-20T04:25:57Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27747,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Infrastructure alerting examples",
        "Examples: Infrastructure pages",
        "Examples: Threshold options",
        "Integrations providers",
        "CPU, disk, load average, memory, swap",
        "Byte size"
      ],
      "title": "Infrastructure alerting examples",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "1ec5f86b745413b2a8d6a5b676ecbe622c674ab1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples/",
      "published_at": "2021-06-20T04:26:54Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Alert type field in infrastructure monitoring's Settings > Alerts page shows what options you can select to create infrastructure alert conditions. You can also create alert conditions from any infrastructure chart by selecting the ellipses icon and then Create alert. Examples: Infrastructure pages Here are some examples of how to create alert conditions within the context of the Infrastructure monitoring UI page you are currently viewing. To create an alerts condition from any chart, select the ellipses icon and then Create alert. New Relic will automatically select the appropriate Alert type. Example Problem and solution High CPU usage Problem: Your Ops team monitors a filtered set of host clusters in your eastern region and notices that the CPU usage is constantly high. Solution: Use the CPU chart on Infrastructure monitoring's Hosts page to create an alert condition for system metrics. Virtual memory capacity Problem: Your night shift needs to be alerted when virtual memory for a set of background workers reaches an average of 10G for at least two minutes. Solution: Use the Top memory consumers chart on Infrastructure monitoring's Processes page to create an alert condition for process metrics. Limited bandwidth Problem: You want to monitor performance based on the average number of errors received or transmitted. Solution: Use the Top bandwidth chart on Infrastructure monitoring's Network page to create an alert condition for network metrics. I/O read and write operations Problem: You are testing a new set of hosts in your staging environment, and you want to be notified when their read or write capacity rises above your test threshold level. Solution: Use the Top I/O operations chart on Infrastructure monitoring's Storage page to create an alert condition for storage metrics. Host not reporting Problem: You want to be notified when we have stopped receiving data from an infrastructure agent. Solution: From the Hosts, Processes, Network, or Storage pages, create a host not reporting alert condition. Processes not running as expected Problem: You want to be notified if any of the processes on your hosts stop reporting. OR A process you expected to start on a host (such as a new program) is not actually running. Solution: From the Processes page (or from the Hosts, Network, or Storage pages), create a process running alert condition. Examples: Threshold options Use the thresholds dropdown for the selected Alert type to further define how you want to be alerted. Here are some examples of the options available. Integrations providers With infrastructure integrations, you can create an alert condition from your Integrations page. Depending on the type of provider selected (CloudFront, DynamoDB, EBS, etc.), options will vary from the Define thresholds dropdown; for example, bytes, errors, requests, CPU, connections, memory, records, latency, etc. CPU, disk, load average, memory, swap The System metrics thresholds dropdown allows you to select various criteria for CPU, disk, load average, memory, and swap metrics. Byte size The Network metrics thresholds provide flexibility with your business needs. Depending on the size of your network, you can easily set the threshold in bytes, KB, MB, GB, or TB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>alerting</em> examples",
        "sections": "<em>Infrastructure</em> <em>alerting</em> examples",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "The <em>Alert</em> type field in <em>infrastructure</em> monitoring&#x27;s Settings &gt; <em>Alerts</em> page shows what options you can select to create <em>infrastructure</em> <em>alert</em> <em>conditions</em>. You can also create <em>alert</em> <em>conditions</em> from any <em>infrastructure</em> chart by selecting the ellipses icon and then Create <em>alert</em>. Examples: <em>Infrastructure</em>"
      },
      "id": "603eb52a28ccbc9027eba7bb"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring": [
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "b236b0fae29853de085d0430fdec27fba74c15d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-06-20T19:34:58Z",
      "updated_at": "2021-06-20T19:34:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your Insights dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's an Insights NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's an Insights NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's an Insights NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in an Insights dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying in New Relic Insights. Here are some tips for using the different types of integration data in Insights: Metric data tips Tips for finding and using integration metric data in Insights: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data in Insights: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data in Insights: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to Insights data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found in Insights by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an Insights InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 129.65845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with integration data",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. <em>Get</em> <em>started</em> with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "60450a39196a67d7dc960f7c"
    },
    {
      "sections": [
        "Activate Azure integrations",
        "Tip",
        "Requirements",
        "Step 1: Get Azure subscription and tenant IDs",
        "Step 2: Register your app and get ID",
        "Step 3: Create a client secret in Azure",
        "Step 4: Provide permissions to services",
        "Step 5: Add app to New Relic",
        "Update application details and rotate client secrets",
        "Explore app data in New Relic Infrastructure's UI"
      ],
      "title": "Activate Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f65679179e13aa1b503b4b95010e296cbe269c29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/activate-azure-integrations/",
      "published_at": "2021-06-20T12:42:18Z",
      "updated_at": "2021-06-20T12:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations allow you to report data from specific systems and supplement infrastructure's default, automatic monitoring. The Microsoft Azure integrations report data from various Azure platform services to your New Relic account. This document explains how to activate Azure integrations. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements The Azure integration activation process requires you to: Create a New Relic application and key in Azure. Grant this application access to the Azure services you want to monitor. Place required information in the New Relic's Integrations UI. To use these integration activation instructions directly from the Infrastructure UI, go to one.newrelic.com > Infrastructure > Azure > Add an Azure account. Step 1: Get Azure subscription and tenant IDs To get your Azure account's subscription id and tenantId, use your local terminal if you have Azure's tools installed, or use Azure's Cloud Shell terminal in the Azure portal. Open a terminal with access to your Azure account. Type the following: az account show Copy Copy and save the subscription id and tenantID from the output response for later use. The response should look similar to the response below. The subscription id and tenantID are highlighted. @Azure:~$ az account show { \"environmentName\": \"AzureCloud\", \"id\": \"9ffe9512-f4a2-42dd-1230-518aec34be21\" , \"isDefault\": true, \"name\": \"Beyond Team Sandbox\", \"state\": \"Enabled\", \"tenantId\": \"ac6692da-1231-422f-22a8-9eed6dbe83f1\" , \"user\": { \"name\": \"youremail@domain\", \"type\": \"user\" } Copy Step 2: Register your app and get ID You must have Azure permissions to register your application and copy its Application ID. To register your app in Azure: Sign in to the Azure portal and go to the Azure Active Directory. From Manage, select App registrations > New registration. Enter a name for the application. We recommend that you name your app NewRelic-Integrations. In Redirect URI select Weband add https://www.newrelic.com as the sign-on URI. Create the application by clicking Register. From the Overview of your app, copy the Application (client) ID, and save it for later use. Step 3: Create a client secret in Azure To create a client secret associated with your application: In Azure, under the application you've just created, select Certificates & secrets. Under Client secrets, click on New client secret and then on Add. Copy the value of Client Secret and save it for later use. Step 4: Provide permissions to services Your app must provide Reader permissions for each Azure service you want New Relic to monitor: In the Azure Subscriptions section, select the subscriptions that you want New Relic to monitor. Select Access control (IAM) > Add > Add role assignment. From the Role dropdown, select Reader. From the Select dropdown, select the app's name; for example, NewRelic-Integrations. From Selected members, verify your app name appears, then select Save. Some Azure services, including Azure CosmosDB and Azure VMs, require additional steps. See the Azure integration documentation for the services you want to enable. Step 5: Add app to New Relic Now you can activate the Azure integration in the Infrastructure UI. The UI will require the information you have saved in the previous steps, including: Your Azure account's subscription id and tenantId The application's application ID The application's client secret To add your Azure app to New Relic: Go to one.newrelic.com > Infrastructure > Azure and select the Azure Service you wish to add. Follow the steps in the UI to activate the integration in New Relic. If you have already completed the Azure account steps, skip to the end of the steps to fill out the form. (For Azure account name, enter the name you want to use to identify the account in your Integrations dashboard.) Update application details and rotate client secrets It's possible to update the application's name and authentication credentials using the Infrastructure UI or the Cloud Integrations API at any time. Follow these steps to rotate the Azure client secret in the Infratructure UI: Go to one.newrelic.com > Infrastructure > Azure and click on Manage Services on the Azure account you wish to edit. Select the edit action next to Account Name to see and edit any application value. Edit the Client Secret field with the new value and confirm with Save Changes. Explore app data in New Relic Infrastructure's UI After you activate an Azure integration, New Relic will start monitoring your Azure data at regular polling intervals. To find and use your data, use the data explorer or go to one.newrelic.com > Infrastructure > Azure",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.63783,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Step 1: <em>Get</em> Azure subscription and tenant IDs",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " the Client Secret field with the new value and confirm with Save Changes. Explore app data in New Relic <em>Infrastructure</em>&#x27;s UI After you activate an Azure integration, New Relic will <em>start</em> <em>monitoring</em> your Azure data at regular polling intervals. To find and use your data, use the data explorer or go to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Azure"
      },
      "id": "6044e5a9196a671bfa960f79"
    },
    {
      "sections": [
        "Get started with log management",
        "Tip",
        "Why New Relic for log management?",
        "Log management features",
        "Bring in your logging data",
        "View your logging data in New Relic"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-06-20T15:00:33Z",
      "updated_at": "2021-06-20T15:00:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a fast, scalable log management platform that allows you to connect your logs with the rest of your telemetry and infrastructure data. Tip To use log management and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Why New Relic for log management? As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. Log management provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. It does this by providing super-fast searching capabilities, alerts, and co-location of application, infrastructure, and log data, while visualizing everything from a single pane of glass. Log management features Log management provides a way to connect your log data with the rest of your application and infrastructure data, allowing you to get to the root cause of problems quickly, without losing context switching between tools. Log management's features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Bring in your logging data You can bring your log data into New Relic using a compatible log forwarding plugin, or with OpenTelemetry. Forward your logs using our Infrastructure agent or our Kubernetes plugin. Use our plugins for well-known log forwarders, like Fluentd, Fluent Bit, and Logstash. Stream or ship your logs from Amazon using AWS Lambda or Kinesis. Send your logs data using the Logs API. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic Logging data can be found in these locations: In our Logs UI: Logs UI for US Logs UI for EU By querying the Log data type. For example, you can use NRQL to run: SELECT * FROM Log Copy For information on querying in general, see Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.04299,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with log management",
        "sections": "<em>Get</em> <em>started</em> with log management",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " everything from a single pane of glass. Log management features Log management provides a way to connect your log data with the rest of your application and <em>infrastructure</em> data, allowing you to <em>get</em> to the root cause of problems quickly, without losing context switching between tools. Log management"
      },
      "id": "603ea62ee7b9d249432a07e2"
    }
  ],
  "/docs/infrastructure/infrastructure-monitoring/infrastructure-security/infrastructure-security": [
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths",
        "Watermarks"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-06-20T21:09:04Z",
      "updated_at": "2021-06-20T21:09:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing. Watermarks Item Example We use all caps for BETA or NR ONLY. <div id=\"watermark\">NR ONLY</div> Copy Otherwise use sentence case. <div id=\"watermark\">Legacy</div> Copy Include break (br /) for longer watermarks. <div id=\"watermark\">Limited <br /> release</div> Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 96.11549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Products <em>and</em> features",
        "body": " features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our <em>infrastructure</em> <em>monitoring</em>... not Our <em>Infrastructure</em> <em>monitoring</em>... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.29633,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install the <em>infrastructure</em> <em>monitoring</em> agent for Linux",
        "sections": "Install the <em>infrastructure</em> <em>monitoring</em> agent for Linux",
        "tags": "<em>Infrastructure</em>",
        "body": "Our <em>infrastructure</em> <em>monitoring</em> agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use <em>infrastructure</em> <em>monitoring</em> and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-20T04:30:32Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.651665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> troubleshooting",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-infrastructure/no-data-appears-infrastructure": [
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-20T04:30:32Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 201.4805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    },
    {
      "sections": [
        "Reduce the infrastructure agent's CPU footprint",
        "Problem",
        "Solution",
        "Reduce event sampling",
        "Important",
        "Reduce agent plugin reporting",
        "How to enable and disable plugins",
        "Disable SELinux semodule -l (Linux only)",
        "Reduce or disable Sysctl (Linux only)",
        "Additional plugins to reduce or disable",
        "Review on-host integrations"
      ],
      "title": "Reduce the infrastructure agent's CPU footprint",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "4eea817bfabb6b698ea3ce001b8c5eeca20d475e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/reduce-infrastructure-agents-cpu-footprint/",
      "published_at": "2021-06-20T04:30:32Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The New Relic infrastructure agent is consuming too much CPU. Solution The New Relic infrastructure agent is designed to report a broad range of system data with minimal CPU and memory consumption. However, if you have a need to reduce your CPU consumption, you can disable or decrease the sampling frequency of various samplers and plugins. This topic highlights some newrelic-infra.yml configurations that may reduce your CPU usage: Reduce event sampling Reduce agent plugin reporting Review on-host integrations Reduce event sampling The infrastructure agent reports several default events at specific frequencies. To lower the overhead, you can reduce the sampling frequency in seconds, or you can completely disable the samplers by setting the corresponding property value to -1. Important We don't recommend a sample rate larger than 60 seconds because you may see gaps in the New Relic user interface charts. The table below lists some samplers to configure: Event Sampling frequency Allow/deny list Network Network sampling rate Not available Process Process sampling rate Allow list (Windows only) Storage Storage sampling rate Deny list System System sampling rate Not available Reduce agent plugin reporting The infrastructure agent has built-in plugins that collect inventory data (specific system configuration and state information). For some systems, the CPU consumption may be relatively high if the plugins are gathering a lot of data. To reduce the footprint, you can disable or decrease the sampling frequency for specific plugins that report data you don’t want. How to enable and disable plugins Disable a single plugin: To disable a plugin, set the corresponding property value to -1. Disable all plugins: disable_all_plugins: true Enable selected plugins: To enable certain plugins, insert an exception in disable_all_plugins. For example, the following configuration disables all plugins, but the Network Interfaces plugin reports every 120 seconds: disable_all_plugins: true network_interface_interval_sec: 120 Copy Disable SELinux semodule -l (Linux only) The SELinux plugin periodically invokes the semodule -l system command to get information about the existing SELinux modules. In most CentOS/RedHat distributions, this command will generate CPU consumption peaks. To disable this functionality, insert the following configuration option in your /etc/newrelic-infra.yml file: selinux_enable_semodule: false Reduce or disable Sysctl (Linux only) The Sysctl plugin walks the whole /sys directory structure and reads values from all the files there. Disabling it or reducing the interval may decrease some CPU System time in the Infrastructure agent. You can disable inventory frequency by setting it to a negative number or reduce the frequeny by setting the sysctl_interval_sec configuration value to the number of seconds between consecutive executions of the plugin. For example, to execute the plugin once every 10 minutes: sysctl_interval_sec: 600 Copy To disable the Sysctl plugin: sysctl_interval_sec: -1 Copy The current default value for the sysctl_interval_sec property is 60. Additional plugins to reduce or disable The following inventory plugins are not especially CPU consuming, but you can still reduce their frequency or disable them by setting the corresponding configuration options. Linux plugins For configuration of these Linux plugins, see Plugin variables: Cloud Security Groups Daemon Tools DPKG Facter Kernel Modules Network interfaces RPM SELinux Supervisord Sysctl Systemd SysV Upstart Users SSHD configuration Windows plugins For configuration of these Windows plugins, see Plugin variables: Network interfaces Windows services Windows updates Review on-host integrations If you use infrastructure on-host integrations, this may have additional impacts on CPU usage. The nature of the impact and the methods to adjust the impact depend on the integration you're using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the monitoring load by adding additional infrastructure agents. For example, the Kafka integration allows a multi-agent deployment.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.34186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "sections": "Reduce the <em>infrastructure</em> agent&#x27;s CPU footprint",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " on the integration you&#x27;re using. Here are some ways to adjust on-host integration CPU usage: See if your integration has configuration options you can adjust. If possible, spread out the <em>monitoring</em> load by adding additional <em>infrastructure</em> agents. For example, the Kafka integration allows a multi-agent deployment."
      },
      "id": "603eb9dc64441fbf1f4e8847"
    },
    {
      "sections": [
        "APM data missing from infrastructure monitoring",
        "Problem",
        "Solution",
        "Restart the app server.",
        "Make sure the hostnames are the same in APM and Infrastructure.",
        "Check for replacement host FQDN recognition problems."
      ],
      "title": "APM data missing from infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "68c926e4922c558a2ab2b0f9557f2fe7973ee0af",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/apm-data-missing-infrastructure/",
      "published_at": "2021-06-20T04:29:09Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When APM and infrastructure agents are installed on the same hosts and use the same New Relic license key, APM data should appear in Infrastructure, and vice versa. If you do not see this APM-Infrastructure linkage, follow these troubleshooting tips. Solution If you completed the APM/Infrastructure integration but do not see New Relic APM data in Infrastructure, try these troubleshooting procedures. Restart the app server. If you have not restarted your APM-monitored application in a few weeks or months, the data streams from Infrastructure and APM may not be linked. Restart your app server. Generate some traffic for your app. Wait a few minutes, and then check for APM data in infrastructure monitoring. Make sure the hostnames are the same in APM and Infrastructure. If the hostnames are different in APM and infrastructure monitoring, New Relic cannot integrate the data. One common cause for this issue is that the default hostnames are different. For example, infrastructure monitoring uses a host's FQDN (such as myhost1.example.com), while APM uses the host's name (such as myhost1). Go to one[.newrelic.com](http://one.newrelic.com) > APM > (select an app). From the app's APM Overview page, look at the app's associated host name. Compare that name with the same host's name in infrastructure monitoring. If the names are different, either set the APM agent host's display_name to match its FQDN, or set the host's display_name in Infrastructure to match the one set in APM. Check for replacement host FQDN recognition problems. If the APM-Infrastructure integration previously worked but has stopped, the server may have been replaced by another server that has the same FQDN. If both servers existed simultaneously for a period of time, New Relic cannot automatically recognize the new server. That will break the connection between APM and infrastructure data. To solve this problem, get help at support.newrelic.com. To prevent this problem, make sure there is a time gap between taking down an old server going down and creating a new server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33542,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "sections": "APM data missing from <em>infrastructure</em> <em>monitoring</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem When APM and <em>infrastructure</em> agents are installed on the same hosts and use the same New Relic license key, APM data should appear in <em>Infrastructure</em>, and vice versa. If you do not see this APM-<em>Infrastructure</em> linkage, follow these <em>troubleshooting</em> tips. Solution If you completed the APM"
      },
      "id": "603e9100e7b9d2b2962a07e8"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-06-20T04:29:09Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.70634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Infrastructure agent logging behavior",
        "Logging severity levels",
        "Important",
        "Log formatting",
        "Log rotation",
        "Logrotate config file sample",
        "Tip",
        "Smart verbose mode",
        "Logging before Infrastructure agent v1.4.9",
        "Integration log management",
        "Integration STDERR expected format"
      ],
      "title": "Infrastructure agent logging behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "0dc6570e893e47c4d5b5c4232283432926c6476a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior/",
      "published_at": "2021-06-20T12:36:07Z",
      "updated_at": "2021-03-16T07:31:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure agent gathers its own data as well as integrations's logs and consolidates them in a single source. By default, logs appear in standard-output and are added to a log file. To disable logs in standard output, see the agent's config options. Logging severity levels Infrastructure uses a subset of the standard Syslog severity levels: ERROR: Error conditions met WARN: Warning conditions met INFO: Informational messages DEBUG: Contains debug-level messages (useful when troubleshooting) Important DEBUG level is only shown when the verbose mode is enabled. Log formatting For infrastructure agent v1.4.9 or higher, log messages are inlined with context values. This offers better grouping and filtering; for example: containerized agent found in container containerID: VALUE Copy By default, Infrastructure logs are formatted as text: In foreground mode, log output is colored, without a timestamp: DEBUG Sending deltas divided in blocks component=PatchSender mentityKey=ohaimaci mnumberOfBlocks=1 Copy In background mode, logs are timestamped output, used when running as a service or dumping logs to a file: time=\"2019-07-12T09:54:15+02:00\" level=info msg=\"Agent service manager shutdown completed successfully.\" component=AgentService service=newrelic-infra Copy Alternatively, logs can be formatted as a JSON file: {\"context\":{},\"level\":\"info\",\"msg\":\"upstart_interval_sec: 0\",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} {\"context\":{},\"level\":\"info\",\"msg\":\"plugin_dir: \",\"timestamp\":\"2019-07-11T18:24:03+02:00\"} Copy To change the log format, see the agent configuration settings. Log rotation The infrastructure agent does not provide any native log rotation or compression mechanism. Instead, we encourage you to use consolidated log rotation tools, such as the Linux logrotate tool, which is usually installed by default in most Linux distributions. Logrotate can be configured as an entry in /etc/logrotate.conf, or as a file in the /etc/logrotate.d directory. Logrotate config file sample A sample logrotate config file looks like this: /var/log/newrelic-infra/newrelic-infra.log { copytruncate compress daily dateext maxage 7 } Copy Where: /var/log/newrelic-infra/newrelic-infra.log: The Infrastructure agent log file. It must match the log_file configuration parameter in the /etc/newrelic-infra.yml file. copytruncate: Indicates that the log file is truncated but not deleted when it is rotated. This configuration option is mandatory, otherwise the log file will be deleted and won’t be recreated. compress: Compresses (usually in Gzip format) the rotated log files. daily: The agent rotates logs daily. dateext: Appends a date (by default, in the format YYYYMMDD) to the rotated log file (e.g. newrelic-infra.log-20190708.gz) maxage 7: Makes logrotate remove rotated files after 7 days. Tip For a complete description of the logrotate configuration options, see the Linux Logrotate documentation. Since logrotate is usually executed automatically as a cron job, verify that there is a logrotate entry in cron (for example, /etc/cron.daily/logrotate) similar to: #!/bin/sh /usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.conf EXITVALUE=$? if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\" fi exit 0 Copy Smart verbose mode For infrastructure agent versions 1.9.0 or higher, you can enable smart verbose mode for logs. Smart verbose mode prevents debug messages being logged until an error message is logged. Once an error has been logged, the cached debug messages are logged, but only the most recent number of configured debug messages. For example, if you have a configured limit of 10, after an error is logged, only the 10 most recent debug messages are logged, and older logs are discarded. For more information on how to enable smart verbose mode and the debug message limit, see Infrastructure configuration settings. Logging before Infrastructure agent v1.4.9 Here is a comparison of functionality for Infrastructure agent versions before and after v1.4.9: Agent v1.4.9 and higher Before v1.4.9 Foreground mode logged. The agent couldn't log some entries in foreground mode because the logging service wasn't able to write data until the agent was completely configured. Logs in text and JSON formats. Logs in text only. Logs displayed as inline text. Logs displayed as static literals in a single, decontextualized line. Integration log management Integrations write JSON payloads into STDOUT and plain-text (JSON structured in the future) logs into STDERR. The infrastructure agent handles integration STDERR lines and forward this output into the agent one, usually the service log. Agent handles each STDERR line as follows: when agent runs in verbose mode: it just forwards the full STDERR line as a DEBUG agent log entry placing integration line contexts within the ` msg ` field. otherwise: it parses the line against the expected format (see below) and only logs as agent ERROR level, entries produced by integrations with ` fatal ` or ` error ` severity levels. In this case fields are extracted and forwarded in structured manner (therefore if JSON output is enabled for the agent fields become queryable. Integration STDERR expected format A line is expected to be a list of key-value pairs separated by an equal character. Keys can contain any character, whereas values can have three different formats: string: < quote>any character including escaped quotes \\ \" < quote> map: & { any character} word: any character except spaces Internally agent used this regex to extract the fields: ([^\\s]*?)=(\".*?[^\\\\]\"|&{.*?}|[^\\s]*) Copy For instance, this line: time=\"2015-03-26T01:27:38-04:00\" level=error msg=\"Foo bar baz\" foo=bar Copy Will generate a structured agent log line with these fields: - \"time\": \"2015-03-26T01:27:38-04:00\" - \"level\": \"error\" - \"msg\": \"Foo bar baz\" - \"foo\": \"bar\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.69966,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "sections": "<em>Infrastructure</em> agent <em>logging</em> behavior",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "New Relic&#x27;s <em>infrastructure</em> agent gathers its own data as well as integrations&#x27;s <em>logs</em> and consolidates them in a single source. By default, <em>logs</em> appear in standard-output and are added to a <em>log</em> file. To disable <em>logs</em> in standard output, see the agent&#x27;s config options. Logging severity levels"
      },
      "id": "603eb3a228ccbc6badeba7a5"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-20T04:30:32Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.58537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/infrastructure-agent-logging-behavior": [
    {
      "sections": [
        "The agent is not starting and there are no logs",
        "Problem",
        "Solution",
        "Check requiretty",
        "Important",
        "Review log permissions"
      ],
      "title": "The agent is not starting and there are no logs",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "fefb6cf577c3c825a6908eba8e378de3ceca4cd7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/agent-not-starting-there-are-no-logs/",
      "published_at": "2021-06-20T04:29:09Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The infrastructure agent is not starting, and logs are not created. Solution Here are some troubleshooting options for non-root users if the infrastructure agent is not starting and there are no logs: Check requiretty To see if requiretty is causing logging issues: In /var/log/messages or /var/log/syslog, look for the message sudo: sorry, you must have a tty to run sudo . Important When using old Linux versions, sometimes the nri-agent user fails to execute a service because it does not have any TTY attached. If you find this message, edit your /etc/sudoers file with the visudo command and comment or remove the following line: Defaults requiretty Save and exit the file. Restart the newrelic-infra service. Review log permissions Check the agent's permission to open log_file. It's possible that the log file you are using was created when the agent was running as root, and now the nri-agent user does not have permissions to write it. To solve this, try one of these options: Change the owner of the log file. Change the log_file entry in the /etc/newrelic-infra.yml configuration file. Our installation scripts create the /var/log/newrelic-infra/ folder for that purpose, so we recommend the following value: log_file: /var/log/newrelic-infra/newrelic-infra.log Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.70634,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "The agent is not starting and there are no <em>logs</em>",
        "sections": "The agent is not starting and there are no <em>logs</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The <em>infrastructure</em> agent is not starting, and <em>logs</em> are not created. Solution Here are some <em>troubleshooting</em> options for non-root users if the <em>infrastructure</em> agent is not starting and there are no <em>logs</em>: Check requiretty To see if requiretty is causing logging issues: In &#x2F;var&#x2F;<em>log</em>&#x2F;messages"
      },
      "id": "603eba9e28ccbc5f64eba786"
    },
    {
      "sections": [
        "Generate logs for troubleshooting the infrastructure agent",
        "Problem",
        "Important",
        "Solution",
        "Smart verbose mode",
        "Forward the agent logs to New Relic Logs",
        "Notes for specific systems",
        "Containerized agent on CoreOS"
      ],
      "title": "Generate logs for troubleshooting the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot logs"
      ],
      "external_id": "a0c2ca22e3fca2b3add8c94d211adffce686661c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-troubleshooting/troubleshoot-logs/generate-logs-troubleshooting-infrastructure/",
      "published_at": "2021-06-20T11:12:41Z",
      "updated_at": "2021-03-16T06:35:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When troubleshooting your infrastructure agent, generate verbose logs for a few minutes to find and investigate errors. This can be useful for your own troubleshooting or when working with New Relic Support. Important Verbose logging generates a lot of data very quickly. When finished generating logs, be sure to set verbose: 0 to reduce disk space consumption. If you have New Relic infrastructure agent 1.4.0 or higher, you can automate this process by using the newrelic-infra-ctl command. For more information, see the troubleshooting binary documentation. Solution Generating verbose log files requires editing your configuration file. For a sample config file that includes all applicable settings, see the example template. To generate detailed logs: Step Procedures Edit your newrelic-infra.yml file: Enable verbose logging: verbose: 1. (If you use a containerized infrastructure agent on CoreOS, see system-specific notes.) Set log_file to a convenient log file location. Restart the agent so the agent notices the new settings. Let your host run at normal load for about three minutes to generate sufficient logging data. Return your settings to default: Disable verbose logging by setting verbose: 0 in newrelic-infra.yml. Optional: Disable logging to a custom file by removing the log_file line from newrelic-infra.yml. Restart the agent so the agent notices the new settings. Examine the log file for errors. If you need to send your log file to New Relic Support: Include the line in your log file that contains the agent version: New Relic infrastructure agent version X.YY.ZZZ Copy Attach the log file to your support ticket, along with your newrelic-infra.yml. Smart verbose mode Sometimes errors don't occur until after quite some time has passed. This makes debugging difficult, because typically verbose logs are only enabled for a short period time; otherwise there will be many debug logs. For example, if an error occurs one hour after the infrastructure agent has started, getting debug logs around the time of the error can be tricky or impractical. As of infrastructure agent v1.9.0 or higher, you can use smart verbose mode for logs. Smart verbose mode only logs the most recent debug messages after an error has been logged. This allows you to leave smart verbose mode running until an error occurs, without logging lots of irrelevant debug messages, and only logging the most recent debug messages. (The number of messages is determined by your configuration.) For more information on smart verbose mode, see the Infrastructure agent logging behavior docs, and use the Infrastructure configuration settings documentation for details on how to enable smart verbose mode. Forward the agent logs to New Relic Logs The Infrastructure agent can be configured to send its own logs to New Relic Logs. This can be useful for troubleshooting issues with log forwarding, the Infrastructure agent, or when contacting support. For details on how to enable log forwarding for the Infrastructure agent, see Troubleshoot log forwarding. Notes for specific systems These are some additional notes and requirements for specific systems, used to supplement the general logging instructions: Containerized agent on CoreOS If you are using a containerized infrastructure agent on CoreOS: Choose one of these options to change the log level to verbose: Recommended: Set the environment variable NRIA_VERBOSE to 1. Running this on the command line would look like: -e NRIA_VERBOSE=1 Copy OR Edit the config file to set verbose: 1. (Editing the config file in a container is not recommended, because it requires rebuilding the image twice: once to add verbose logging and once to remove it.) Use journalctl to collect the logs: journalctl -u newrelic-infra > newrelic-infra.log Copy Set the verbose logging level back to 0 after collecting logs for a few minutes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.69377,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "sections": "Generate <em>logs</em> for <em>troubleshooting</em> the <em>infrastructure</em> agent",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": " verbose mode. Forward the agent <em>logs</em> to New Relic <em>Logs</em> The <em>Infrastructure</em> agent can be configured to send its own <em>logs</em> to New Relic <em>Logs</em>. This can be useful for <em>troubleshooting</em> issues with <em>log</em> forwarding, the <em>Infrastructure</em> agent, or when contacting support. For details on how to enable <em>log</em> forwarding"
      },
      "id": "603e910028ccbc6304eba76d"
    },
    {
      "sections": [
        "Incorrect host name reported",
        "Problem",
        "Solution",
        "Restart the agent with SystemD",
        "Restart the agent with System V",
        "Restart the agent with Upstart",
        "Restart the agent in Windows",
        "Cause"
      ],
      "title": "Incorrect host name reported",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring troubleshooting",
        "Troubleshoot infrastructure"
      ],
      "external_id": "d6a81c3fae24464898bea92df4c6a57945b6c731",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/troubleshooting/incorrect-host-name-reported/",
      "published_at": "2021-06-20T04:30:32Z",
      "updated_at": "2021-05-16T07:48:02Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem The agent is working, but the infrastructure monitoring UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example: override_hostname: correct-host.domain.com Copy Use your init system to restart the agent service: Restart the agent with SystemD Use SystemD commands with CentOS 7, Debian 8, RHEL 7, and Ubuntu 15.04 or higher: sudo systemctl restart newrelic-infra Copy Restart the agent with System V Use System V commands with Debian 7: sudo /etc/init.d/newrelic-infra restart Copy Restart the agent with Upstart Use Upstart commands with Amazon Linux, CentOS 6, RHEL 6, and Ubuntu 14.10 or lower: sudo initctl restart newrelic-infra Copy Restart the agent in Windows net stop newrelic-infra net start newrelic-infra Copy Cause The New Relic infrastructure agent tries to resolve its fully qualified domain name against a domain name server, which may not be properly configured or not controlled by the same user as the New Relic infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 140.58537,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>troubleshooting</em>",
        "body": "Problem The agent is working, but the <em>infrastructure</em> <em>monitoring</em> UI shows the wrong hostname. Solution To set the correct hostname, try the following steps: Edit the newrelic-infra.yml configuration file and add the override_hostname option, whose value is your expected hostname. For example"
      },
      "id": "6043fd9028ccbc23872c60c5"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "he events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.09666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.37889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-06-20T14:25:32Z",
      "updated_at": "2021-03-09T04:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "sections": "<em>Infrastructure</em> <em>monitoring</em> Hosts page",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": "-related charts. Important APM charts in <em>infrastructure</em> <em>monitoring</em> do not have View query or Create alert options like the other <em>infrastructure</em> charts do. For more about using APM and <em>infrastructure</em> <em>monitoring</em> together, see APM data in <em>infrastructure</em>. Network tab The Network page provides real-time"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page": [
    {
      "sections": [
        "Events heatmap: Examine patterns in time range"
      ],
      "title": "Events heatmap: Examine patterns in time range",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "bc50e789884c9c4eea404d558d4070519a3eab0c",
      "image": "https://docs.newrelic.com/static/96c3e087c9dfb8b4cb4ad72b79c47e94/c1b63/infra-events-timeline.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/events-heatmap-examine-patterns-time-range/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "he events heatmap provides a snapshot of the infrastructure events occurring within the same time range as the displayed metrics. The darker the color on the heatmap, the more events occurred during that time period. By comparing the heatmap to the charts on the infrastructure page, you can quickly pinpoint issues in your ecosystem. For example, if a massive CPU spike occurs, you can click on the events heatmap for that time range to find the event that caused it. From there you can dive deeper to uncover the real issue. one.newrelic.com > Infrastructure: The heatmap on Infrastructure monitoring UI pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several Infrastructure UI pages, including: System Network Processes Storage Events",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.09666,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>monitoring</em> <em>UI</em> pages visually shows patterns with events occurring at the same time period for the displayed metrics. The heatmap appears on several <em>Infrastructure</em> <em>UI</em> pages, including: System Network Processes Storage Events"
      },
      "id": "603e8455196a67833da83dc2"
    },
    {
      "sections": [
        "Infrastructure Inventory page: Search your entire infrastructure",
        "Inventory item naming",
        "Tip",
        "Page functions",
        "Filter the data",
        "Search inventory",
        "View inventory item details",
        "View host's alert threshold violations",
        "Inventory data collection",
        "Linux built-in agent data",
        "Windows built-in agent data",
        "Amazon AWS cloud integrations inventory",
        "Inventory data retention",
        "Chart data attributes"
      ],
      "title": "Infrastructure Inventory page: Search your entire infrastructure",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "64aef10b24b74ac3c0f070358d37f3cab099e5b2",
      "image": "https://docs.newrelic.com/static/2d17c192725956ff09b5e987be5b997b/747d8/inventory-name-source-path.jpg",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infra-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure/",
      "published_at": "2021-06-20T11:57:30Z",
      "updated_at": "2021-03-11T12:47:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can collect detailed information about a system's configuration per host, including system modules, configuration files, metadata, packages, services, user sessions, etc. The Inventory page provides a real-time, filterable, searchable view into each host's configuration. Use the Inventory page to: Ensure a version update was applied successfully across all your hosts. Audit version discrepancies across your hosts. Quickly identify which hosts require an update to fix a security vulnerability. To view and search your inventory data: Go to one.newrelic.com > Infrastructure > Inventory. Inventory item naming The infrastructure inventory is a qualified namespace (structured like a directory) that organizes inventory items into names that resemble a source path. The inventory item name is comprised of three elements: Element Description Category Basic, top level type of data source, typically based on its role in the system. Common examples include config, package, kernel, user session, services, and modules. Source The specific data source for the inventory item. Label The name of the specific inventory item; for example, the filename, package name, or system setting name. Tip For detailed metadata and other information about your hosts, use tagging with New Relic One. Page functions Use Inventory page functions to find information about a particular item on your hosts: Filter the data Use Filter Sets to show only hosts matching certain criteria. Search inventory Search for an inventory item using the search function. For example, if you want to find information related to OpenSSL, search openssl. The search term is matched again the inventory item name. View inventory item details Inventory item details provide host and system information for each host it resides on according to the New Relic inventory item name. If you have different versions of the same item on other hosts, New Relic detects that and flags them on the Inventory page with the variant hosts label and lists each host running each version. Item details are attributes (key/value pairs) that are dictated by their source. Specific attributes are generally stable over time, but new ones may be added and others could be deprecated. Attributes carry the critical metadata that are at the heart of each inventory item. Common inventory item attributes include: Variant hosts (hostname) Architecture Description Essential Priority Status Version View host's alert threshold violations To view one or more host's alert threshold violations, select the host's Critical icon or Warning icon. Inventory data collection Inventory is collected from the infrastructure agent's built-in data collectors, Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the Infrastructure monitoring's user interface. Linux built-in agent data The infrastructure agent collects this data for Linux systems. Category Source Data collected using... applications apm APM Language Agent metadata config selinux sestatus -b, semodule -l selinux-policies sestatus -b, semodule -l selinux-modules sestatus -b, semodule -l sshd /etc/sshd_config (PermitRootLogin, PermitEmptyPasswords, PasswordAuthentication, and ChallengeResponseAuthentication only) kernel modules /sbin/modinfo, /sbin/lsmod, /proc/modules sysctl /proc/sys metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), hostname -f, hostname cloud_security_groups Cloud provider security-groups system uptime -s, /etc/redhat-release, /proc/cpuinfo, /etc/os-release, /proc/sys/kernel/random/boot_id, /proc/sys/kernel/osrelease, /sys/class/dmi/id/product_uuid, /sys/devices/virtual/dmi/id/sys_vendor, /sys/devices/virtual/dmi/id/product_name facter facter -p -j services daemontool ps -e, svstat systemd initctl list upstart systemctl -l, systemctl show, modinfo, lsmod supervisord /var/run/supervisor.sock unix socket connection, supervisor.getAllProcessInfo pidfile var/run, find -L -name, /proc/N/status, /proc/N/stat sessions users who system network_interfaces net.Interfaces() packages dpkg dpkg-query -W -f rpm rpm -qa Windows built-in agent data The infrastructure agent collects this data for Windows systems. Category Source Data collected using... applications apm APM language agent metadata metadata agent_config Agent's complete config file attributes Agent's custom_attributes host_aliases Agent's display_name, Cloud provider instance-id, os.Hostname(), Registry (SYSTEM \\ CurrentControlSet \\ Services \\ Tcpip \\ Parameters (Domain, DhcpDomain, Hostname) system kernel32.dll (GetPhysicallyInstalledSystemMemory), WMI (Win32_OperatingSystem, Win32_Processor), os.Hostname() services windows_services WMI (Win32_Service WHERE State = \"Running\" AND StartMode = \"Auto\") system network_interfaces net.Interfaces() packages windows_programs Registry (SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\, SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\) windows_updates WMI (Win32_QuickFixEngineering) (off by default) Amazon AWS cloud integrations inventory Data collected varies by Amazon Elastic Compute Cloud (EC2) integration. For more information, see New Relic's individual Amazon Integrations documentation. Inventory data retention Inventory data is real-time. If a host stops reporting, its inventory data still displays for up to 24 hours. Chart data attributes For a technical explanation about attributes used to populate the Inventory page, see Default infrastructure attributes and events. This includes a summary of common events by operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.38478,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "sections": "<em>Infrastructure</em> Inventory page: Search your entire <em>infrastructure</em>",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": ", Amazon Elastic Compute Cloud (EC2) integrations, agent integrations provided by New Relic, and customer-built integrations. The data appears on the Inventory page and in other places within the <em>Infrastructure</em> <em>monitoring</em>&#x27;s user interface. Linux built-in agent data The <em>infrastructure</em> agent collects"
      },
      "id": "60440a6d64441fdf50378ee7"
    },
    {
      "sections": [
        "Infrastructure Events page: Live feed of config changes",
        "Event types",
        "Events page features",
        "Chart data attributes"
      ],
      "title": "Infrastructure Events page: Live feed of config changes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "e4a87670c8671072ae7cc6531721f46edc7f925d",
      "image": "https://docs.newrelic.com/static/75373d03d819516d3cbe23f1ea65957b/c1b63/infra-events-ui.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-events-page-live-feed-every-config-change/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-03-11T11:47:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Events page is a live feed of important system and host activity, including inventory change events, configuration changes, and log analytics events. The event feed helps you understand correlations between these events and system performance. Search and filter through your events to decrease the mean time to detect and repair infrastructure issues. You can access the Events page by going to one.newrelic.com > Infrastructure > Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When a violation is opened or closed, New Relic generates an event indicating the host and associated alert condition. Agent connection When an infrastructure agent connects to New Relic, our platform generates an Agent connected event. If New Relic doesn't receive data from an agent for three minutes, the platform generates an Agent disconnected event. Inventory changes These events are generated when inventory data is added, removed, or modified. Select the source icon to to understand which category corresponds to the altered inventory path. For additional details, select an inventory event to see a side-by-side comparison of the old and new state. Inventory events can include: Kernel (includes modules and configuration): Can be added, modified, or deleted. Metadata (includes various additional information about hosts): Can be added, modified, or deleted. Packages: Can be installed, removed, or modified. Services: Can be started, stopped, or restarted. Sessions (includes users): Can be connected or disconnected. Events page features To view the live event feed: Go to one.newrelic.com > Infrastructure > E * *vents. The Events * * page includes a heatmap, which provides a snapshot of the events occurring within the selected time range. one.newrelic.com > Infrastructure > Events: Use the Events to view important, real-time activity in your infrastructure. With the Events page, you can easily search through your event log to quickly find vulnerable packages. If you want to... Do this... Focus on specific events Use the Search events field to look for specific events, config changes or agent installations. To focus on a specific set of events, select or change the filter set. Search within a particular time range Enter a time range to the right of the search bar to investigate events within a specific time range. For example, if you encountered a CPU spike around 11am on the previous day, search Yesterday at 11 am to investigate the possible cause. Compare events with host load, memory, CPU, and more View the events feed on the Hosts page. To compare infrastructure events and performance for a specific time, select a range via the time picker or drag and select a range on a chart. View events specifically related to agents, config, metadata, services, or sessions Group or sort events by selecting the filter icon be the search bar. Drill down into additional details Select an event to view additional details, such as attributes and values. To drill down further, select View in Inventory to see additional details in the Inventory page. View host's alert threshold violation Select the host's Critical icon or Warning icon. Chart data attributes For a technical explanation of the attributes used to populate the Events page, see InfrastructureEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 176.37889,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "sections": "<em>Infrastructure</em> Events page: Live feed of config changes",
        "tags": "<em>Infrastructure</em> <em>monitoring</em> <em>UI</em>",
        "body": " the mean time to detect and repair <em>infrastructure</em> issues. You can access the Events page by going to one.newrelic.com &gt; <em>Infrastructure</em> &gt; Events. Event types New Relic collects a variety of change events so you can understand each change in your environment: Events Comments Alert incidents When"
      },
      "id": "6043fa6c28ccbc13742c60a5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-20T12:11:53Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.52972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-20T14:25:32Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.63687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-20T10:43:39Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.5839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet": [
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-20T14:25:32Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.63687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-20T12:11:04Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.58765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-20T10:43:39Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.5839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-20T12:11:53Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.52972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Chef",
        "Compatibility and requirements",
        "Chef recipes",
        "Chef attributes",
        "default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED)",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['action']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['retries']",
        "default\\['newrelic_infra']\\['packages']\\['agent']\\['version']",
        "Use the basic recipe",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Chef",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "c73f19ee6533c7028bdf2ba595ea88436df6c5c6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef/",
      "published_at": "2021-06-20T14:25:32Z",
      "updated_at": "2021-03-13T07:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use New Relic's Chef recipes to install and configure New Relic's infrastructure agent. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort. Compatibility and requirements The Infrastructure Chef recipe has the following requirements: Chef versions 12 or higher Supports all operating systems compatible with the infrastructure agent Chef recipes Infrastructure monitoring has one default recipe: default. Include this recipe to install and configure the infrastructure agent. If this recipe detects an unsupported platform or version, the Chef run fails. Configuration depends on your specific setup and standards. Chef attributes The default recipe supplies the following Chef attributes: default\\['newrelic_infra']\\['config']\\['license_key'] (REQUIRED) Type String Default (none) Defines your New Relic license key. default\\['newrelic_infra']\\['packages']\\['agent']\\['action'] Type String Default install Valid values install, upgrade, or remove Select what type of package resource actions action you want to perform: install: Installs the infrastructure agent. If [agent_version] is specified, that version will be installed. The first time the cookbook runs on each host, it will install the latest infrastructure agent. However, the agent will not be upgraded with install on subsequent Chef runs. Use upgrade to install newer versions. upgrade: Upgrades hosts to the latest infrastructure agent version. remove: Uninstalls the infrastructure agent. default\\['newrelic_infra']\\['packages']\\['agent']\\['retries'] Type Integer Default 0 The number of times to catch exceptions and retry the resource. default\\['newrelic_infra']\\['packages']\\['agent']\\['version'] Type String Default (none) Use with 'install' to set a specific agent version. If no value is set, the recipe defaults to the latest agent version. Use the basic recipe The New Relic cookbook is available from the public Chef Supermarket. To install and configure New Relic's infrastructure agent using Chef: Add the newrelic-infra dependency in your own Chef metadata.rb or Berksfile. Set the New Relic license key attribute. For example, add the following to your recipes/default.rb: default['newrelic_infra']['config']['license_key'] = 'YOUR_LICENSE_KEY' Copy Optional: To control version usage and updating, customize the recipe with Chef attributes. Include the default New Relic recipe by using include_recipe ‘newrelic-infra::default' or by adding the recipe to your run list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-chef on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.63687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Chef",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use New Relic&#x27;s Chef recipes to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em>. For instructions on how to use Chef recipes, see the Chef documentation. The New Relic cookbook is available from the public Chef Supermarket. This is a community-supported effort"
      },
      "id": "60440aa264441f8cff378ee5"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-20T12:11:04Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.58765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-chef": [
    {
      "sections": [
        "Configure the infrastructure agent with Puppet",
        "Requirements",
        "Module description",
        "Run newrelic-infra module",
        "Install the infrastructure agent with the module",
        "Puppet parameters",
        "For more help"
      ],
      "title": "Configure the infrastructure agent with Puppet",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "d78919080b3cac0164fd79d2f4e4c36009e0711a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-puppet/",
      "published_at": "2021-06-20T12:11:53Z",
      "updated_at": "2021-03-16T08:31:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to use Puppet to install and configure New Relic's infrastructure agent using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration management tool. Detailed configuration will have to conform to your company standards. Requirements The Infrastructure Puppet module has these requirements: Infrastructure-supported Linux operating systems Puppet version 3.0 or higher Module description Use the newrelic-infra module to: Add the New Relic's infrastructure agent package repository source. Install, configure, and manage the New Relic infrastructure agent. The New Relic Puppet module is available on Puppet Forge. Run newrelic-infra module To run the default newrelic-infra module, declare the main ::agent class. Install the infrastructure agent with the module All interactions with newrelic-infra are done through the main agent class. To install New Relic's infrastructure agent using Puppet, use: class { 'newrelic_infra::agent': ensure => 'latest', license_key => 'YOUR_LICENSE_KEY', } Copy Puppet parameters Here are the parameters for the newrelic_infra::agent public class: Parameter Parameter description custom_configs A hash of key-value pairs. Corresponds directly with the available general configuration settings. ensure Specifies the Infrastructure agent ensure status. Valid values include: 'latest' - (default) Installs the latest agent version 'absent' - Uninstalls the agent VERSION_STRING - A string containing a specific version to pin license_key Specifies the New Relic license key to use. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-puppet on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 345.52972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> with Puppet",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em> with the module",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to use Puppet to <em>install</em> and configure New Relic&#x27;s <em>infrastructure</em> <em>agent</em> using the newrelic-infra module. For an explanation of how to use Puppet, see Puppet documentation. This is a community-supported effort. Here we provide basic information needed to use this configuration"
      },
      "id": "603e88b4e7b9d299092a07d9"
    },
    {
      "sections": [
        "Configure the infrastructure agent on AWS Elastic Beanstalk",
        "Requirements",
        "Install the infrastructure agent",
        "Amazon Linux AMI",
        "Amazon Linux 2",
        "Windows",
        "Uninstall the infrastructure agent"
      ],
      "title": "Configure the infrastructure agent on AWS Elastic Beanstalk",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "63fee84da30d8fb761d1cab41d31aa7bad9f3adf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-aws-elastic-beanstalk/",
      "published_at": "2021-06-20T12:11:04Z",
      "updated_at": "2021-03-13T03:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Amazon Web Services (AWS) Elastic Beanstalk is a dynamic service that allows easy deployment and scalability for your applications. Follow these instructions to deploy the infrastructure agent to the instances launched with your AWS Elastic Beanstalk applications. In addition to deploying the infrastructure agent you can also integrate New Relic with AWS and bring Elastic Beanstalk monitoring information into New Relic. If you haven't already done so, follow these instructions for Amazon integrations with infrastructure monitoring. Requirements Make sure you have a supported Amazon Web Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. Install the infrastructure agent To install the infrastructure agent on instances launched with AWS Elastic Beanstalk: In the .ebextensions folder inside your Elastic BeanStalk application, create a new file named newrelic.config. Based on the operating system, add the following content to the file, replacing YOUR_LICENSE_KEY with your New Relic license key. Amazon Linux AMI files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Amazon Linux 2 files: \"/etc/newrelic-infra.yml\" : mode: \"000644\" owner: root group: root content: | license_key: YOUR_LICENSE_KEY commands: # Create the agent’s yum repository \"01-agent-repository\": command: sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo # # Update your yum cache \"02-update-yum-cache\": command: yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' # # Run the installation script \"03-run-installation-script\": command: sudo yum install newrelic-infra -y Copy Windows packages: msi: infrastructure: https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi files: \"C:\\\\Program Files\\\\New Relic\\\\newrelic-infra\\\\newrelic-infra.yml\": content: | license_key: YOUR_LICENSE_KEY commands: 01_stop-newrelic-infra: command: net stop newrelic-infra ignoreErrors: true 02_start-newrelic-infra: command: net start newrelic-infra ignoreErrors: true Copy Push your app to Elastic BeanStalk: In general, use eb deploy. If you are still using Eb CLI 2.6 , use git aws.push if required. Optional: Use the AWS Console UI. After a successful setup, it can take up to fifteen minutes before metrics begin to appear in New Relic. View your host's infrastructure pages at one.newrelic.com. Uninstall the infrastructure agent To uninstall the agent, remove newrelic.config from .ebextensions, then deploy using the CLI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.58765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> on AWS Elastic Beanstalk",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " Services account. In addition, for any New Relic installation, you will need your New Relic license key. This is a 40-character hexadecimal string that New Relic provides when you sign up for your account. <em>Install</em> the <em>infrastructure</em> <em>agent</em> To <em>install</em> the <em>infrastructure</em> <em>agent</em> on instances launched with AWS"
      },
      "id": "60440a6d28ccbc37982c60c5"
    },
    {
      "sections": [
        "Configure the infrastructure agent using Ansible",
        "Sample code",
        "Compatibility and requirements",
        "Set up Ansible with New Relic",
        "Tip",
        "Role configuration variables",
        "For more help"
      ],
      "title": "Configure the infrastructure agent using Ansible",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Config management tools"
      ],
      "external_id": "1f13326e09d6da78f08f645bc069c22342fbac6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/config-management-tools/configure-infrastructure-agent-using-ansible/",
      "published_at": "2021-06-20T10:43:39Z",
      "updated_at": "2021-03-13T02:47:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's Ansible role to install and configure our infrastructure monitoring agent. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration management sample code to help you install our infrastructure monitoring agent using workflows and tools that are common with many Ops teams. This is a basic Ansible role and is intended to be used as a starting place for creating your own customized workflow. Configuration depends on your specific setup and standards. To view an Ansible sample role and more integration information, see the Ansible Galaxy documentation. Compatibility and requirements The Ansible role with New Relic's infrastructure monitoring agent requires a supported Linux operating system. Set up Ansible with New Relic Tip To use Ansible configurations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. The newrelic.newrelic-infra role: Adds the New Relic infrastructure agent package repository source. Installs and configures the infrastructure agent. To get started using this role: Include the role in your playbook. Customize the required variables. All typical interactions with newrelic.newrelic-infra use role configuration. Here is an example of configuring your role to install the infrastructure agent: - hosts: ap_northeast_1 roles: - name: newrelic.newrelic-infra vars: nrinfragent_os_name: YOUR_OS_NAME nrinfragent_os_version: YOUR_OS_VERSION nrinfragent_config: license_key: YOUR_LICENSE_KEY log_file: /var/log/newrelic/nr-infra.log log_to_stdout: false Copy Role configuration variables Here are available variables for configuring the newrelic.newrelic-infra role: Variable Description nrinfragent_config Required. A map of key-value pairs. Corresponds directly with the available general configuration settings. nrinfragent_state Describes what you want to do with the agent: 'latest': Default. Installs the latest version of the infrastructure agent. 'absent': Uninstall the agent. nrinfragent_version The version of the agent you want to install: '*': Default. Installs the latest version of the infrastructure agent. 'x.y.zzz': String specifying a specific agent version number you want to install; for example, 1.0.682. nrinfragent_os_name Specifies the target OS that the infrastructure agent will be installed on. See the meta/main.yml file for the latest list. nrinfragent_os_version Specifies the OS version of the installer package needed for this machine. See the meta/main.yml file for the latest list. For more help If you need additional help, file an issue at newrelic/infrastructure-agent-ansible on GitHub.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 344.5839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "sections": "Configure the <em>infrastructure</em> <em>agent</em> using Ansible",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can use New Relic&#x27;s Ansible role to <em>install</em> and configure our <em>infrastructure</em> monitoring <em>agent</em>. For instructions on how to use Ansible, see the Ansible documentation. This is a community-supported effort. Sample code New Relic provides configuration <em>management</em> sample code to help you <em>install</em> our"
      },
      "id": "60440aa3196a675fb6960f5c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/config-file-template-newrelic-infrayml": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 408.26935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-20T14:26:20Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.0251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.96901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 408.26935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> <em>configuration</em> settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> has a large set of <em>configuration</em> settings to fine-tune its behavior. Here we: List all the <em>configuration</em> options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-20T14:26:20Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.0251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.96901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-20T14:26:20Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.02502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.96898,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for Linux",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " tutorial in the next section. Step-by-step instructions To <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> in Linux, follow these instructions: Create the <em>configuration</em> file and add your license key: echo &quot;license_key: YOUR_LICENSE_KEY&quot; | sudo tee -a &#x2F;etc&#x2F;newrelic-infra.yml Copy Determine the distribution"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Config file template (newrelic-infra.yml)",
        "Tip",
        "Important"
      ],
      "title": "Config file template (newrelic-infra.yml)",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "bddd191ab46f54062379c4c62ffdec8ca7a63e44",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/config-file-template-newrelic-infrayml/",
      "published_at": "2021-06-20T10:43:38Z",
      "updated_at": "2021-03-13T04:08:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent reads the newrelic-infra.yml file for its configuration. You can find the latest configuration template in the infra-agent repository on GitHub. Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. For more information on each setting, see Infrastructure configuration settings. Important Always restart the agent or your web server after changing settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.2982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> reads the newrelic-infra.yml file for its <em>configuration</em>. You can find the latest <em>configuration</em> template in the infra-<em>agent</em> repository on GitHub. Tip We recommend linting the YAML <em>configuration</em> files before using them to avoid formatting issues. For more information on each setting, see <em>Infrastructure</em> <em>configuration</em> settings. Important Always restart the <em>agent</em> or your web server after changing settings."
      },
      "id": "60440acae7b9d2f1815799ff"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent": [
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-20T14:26:20Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 340.42834,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "sections": "Requirements for the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized <em>agent</em>. On EKS, <em>install</em> the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The <em>infrastructure</em> <em>agent</em> uses the hostname to uniquely identify each server. To avoid"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "b236b0fae29853de085d0430fdec27fba74c15d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-06-20T19:34:58Z",
      "updated_at": "2021-06-20T19:34:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your Insights dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's an Insights NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's an Insights NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's an Insights NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in an Insights dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying in New Relic Insights. Here are some tips for using the different types of integration data in Insights: Metric data tips Tips for finding and using integration metric data in Insights: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data in Insights: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data in Insights: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to Insights data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found in Insights by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an Insights InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.90152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with integration data",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. <em>Get</em> <em>started</em> with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "60450a39196a67d7dc960f7c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Install the infrastructure agent",
        "Tip",
        "Quick start: Use our guided install",
        "One agent, many capabilities",
        "Install the infrastructure monitoring agent",
        "Linux",
        "Windows Server and 10",
        "Other installation scenarios",
        "Check the source code",
        "What's next"
      ],
      "title": "Install the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "ccb11bfd79824202d189a3e743771cfc81e77710",
      "image": "https://docs.newrelic.com/static/6bf45ccf002250f7ebaa69cbe3ff706c/c1b63/guided-install-cli.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent/",
      "published_at": "2021-06-20T15:20:05Z",
      "updated_at": "2021-03-30T08:28:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's infrastructure monitoring agent is a lightweight executable file that collects data about your hosts. It also forwards data from infrastructure integrations to New Relic, as well as log data for log analytics. There are multiple ways to install and deploy the infrastructure monitoring agent, depending on your setup and needs. This document describes how the infrastructure monitoring agent works and how to install it. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start: Use our guided install The quickest way to get started with our infrastructure monitoring agent is through our guided install. Ready to get started? Click one of these button to try it out. Guided install EU Guided install Our guided install not only installs the infrastructure agent, but also discovers the applications and log sources running in your environment. It recommends which ones you should instrument. The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your infrastructure. One agent, many capabilities Our infrastructure monitoring agent collects performance and health data about the system resources and processes of the host where it's enabled (on-premises or virtualized). At the same time, it acts as a forwarder for two types of data: core services metrics, which are collected by on-host integrations, and logs. If you want to collect data about core services running on your host, you need to install the infrastructure monitoring agent first, and then install or enable on-host integrations. Our infrastructure monitoring agent and its integrations collect data from the system and core services. It can also forward logs to New Relic. Backend application metrics (APM) are collected by separate language agents. Notice how each integration and forwarder feed different data types in the New Relic database (NRDB). Install the infrastructure monitoring agent If our guided install doesn't work for your setup, follow the instructions for your Linux, Windows, or other setup. The infrastructure monitoring agent can currently run on many Linux distributions, as well as Windows Server. For more information on where you can run the agent, check the compatibility and requirements page. Linux The preferred way to install the Linux agent is through the package manager of your distribution. Select your distribution from the list for step-by-step instructions. Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use these installation links, you must be logged to your New Relic account. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial. For advanced install needs, you can deploy the agent using our tarball files in assisted or manual mode. Windows Server and 10 To deploy the agent on a Windows Server host, install it using our MSI installer. For a guided procedure, click the button below and follow the step-by-step instructions: Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our tutorial. For advanced installation needs, you can deploy the agent using our zip files in assisted or manual mode. Other installation scenarios The infrastructure monitoring agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Check the source code The infrastructure monitoring agent is open source software. That means you can browse its source code and send improvements, or create your own fork and build it. For more information, see the README. What's next After you've installed the infrastructure monitoring agent: Learn how to configure the agent or edit the config template. Install on-host integrations (for example, for Apache or MySQL). Enable log forwarding using the infrastructure agent. Learn how to manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.22247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". Then ingest up to 100GB of data for free each month. Forever. Quick <em>start</em>: Use our guided <em>install</em> The quickest way to <em>get</em> <em>started</em> with our <em>infrastructure</em> monitoring <em>agent</em> is through our guided <em>install</em>. Ready to <em>get</em> <em>started</em>? Click one of these button to try it out. Guided <em>install</em> EU Guided <em>install</em>"
      },
      "id": "603e79bd64441f99814e8888"
    },
    {
      "sections": [
        "Use integration data in New Relic dashboards",
        "Get started with integration data",
        "Example NRQL queries",
        "AWS EBS query example",
        "Azure Service Bus query example",
        "Azure Functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Inventory change query example",
        "Tip",
        "Tips for using different data types",
        "Metric data tips",
        "Event data tips",
        "Inventory data tips"
      ],
      "title": "Use integration data in New Relic dashboards",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Get started"
      ],
      "external_id": "b236b0fae29853de085d0430fdec27fba74c15d4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/get-started/use-integration-data-new-relic-dashboards/",
      "published_at": "2021-06-20T19:34:58Z",
      "updated_at": "2021-06-20T19:34:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Most data generated by integrations is available in New Relic One dashboards, where you can query your data using NRQL and build custom dashboards. The following tips and sample queries were created for New Relic-built integrations, but most will also apply to integrations built with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. Get started with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com > Infrastructure > Third-party services page, select an integration dashboard. There, you can view the NRQL queries that generated a chart. For examples of NRQL queries for integration data, see the example queries. Use the data explorer or the dashboards to explore and understand the available data. Read the documentation for a specific integration to learn about the reported data. When you create a useful query you'd like to add to your Insights dashboard, select Add to dashboard. Example NRQL queries Here are some examples of NRQL queries that use integration data: AWS EBS query example Here's a NRQL query for the AWS EBS service, showing the total write time metric, faceted by entityName: SELECT sum('provider.volumeTotalWriteTime.Sum') FROM BlockDeviceSample WHERE provider = 'EbsVolume' FACET entityName Copy Azure Service Bus query example Here's an Insights NRQL query for the maximum number of messages in an Azure Service Bus topic queue, faceted by resource group: SELECT max(activeMessages.Maximum) FROM AzureServiceBusTopicSample FACET resourceGroupName Copy Azure Functions query example Here's an Insights NRQL query for Azure Functions, showing the count of executed functions over the past six hours by region over time: SELECT sum(functionExecutionCount.Total) FROM AzureFunctionsAppSample FACET regionName TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Here's an Insights NRQL query for Azure VMs that compares the count of VM events over the past thirty minutes with the same time a week ago: SELECT uniqueCount(vMName) FROM AzureVirtualMachineScaleSetSample FACET name SINCE 30 minutes ago COMPARE WITH 1 week ago Copy NGINX query example Here's an example of a query that you might run on your NGINX integration data and place in an Insights dashboard. This query creates a chart showing the average value of NGINX requests per second over time: SELECT average(net.requestsPerSecond) FROM NginxSample TIMESERIES Copy For more on how to create queries, see NRQL syntax. MySQL query example Here's an example of a query that you might run on your MySQL integration data. This query generates a chart showing the maximum number of used MySQL connections: SELECT max(net.maxUsedConnections) FROM MysqlSample Copy For more on how to create queries, see NRQL syntax. Inventory change query example Here's an example of a query that groups inventory change events from the last day by the type of change: SELECT count(*) FROM InfrastructureEvent WHERE format='inventoryChange' FACET changeType SINCE 1 DAY AGO Copy Tip You can also perform these queries using dimensional metrics. Tips for using different data types Integrations can generate metric, event, and inventory data, all of which are available for querying in New Relic Insights. Here are some tips for using the different types of integration data in Insights: Metric data tips Tips for finding and using integration metric data in Insights: All integration data is attached to a data type known as an event (not to be confused with events reported by integrations, which represent important activity in your host/service). This means that all integration data can be found via the data explorer. For more about these two basic New Relic data types, see New Relic data collection. Metric values are treated as attributes: key-value pairs attached to an event. For example, the MySQL integration has an 'active connections' metric; this would be found by querying the connectionsActive attribute of the MysqlSample event. For general information about metrics, see Integration metric data. Event data tips Here are some tips for finding and using integration event data in Insights: Most integration events are inventory change events. When inventory is changed, it generates an InfrastructureEvent with a format value of inventoryChange. Integration data can be found via the data explorer. For general information about events, see Event data. Inventory data tips Here are some tips for finding and using integration inventory data in Insights: For general information about inventory data, see Integration inventory data. Some inventory data is added as attributes (key-value pairs) to Insights data. For example, the AWS EC2 integration collects awsRegion as inventory data; this would be found in Insights by querying the awsRegion attribute of the ComputeSample event type and provider Ec2Instance. When inventory data changes, an Insights InfrastructureEvent event type is generated with a format value of inventoryChange. See the query examples for an example of querying this data. For more on using NRQL queries, see Intro to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.9014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Get</em> <em>started</em> with integration data",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " with the Integrations SDK. For a general look at how to find and use integration data, see New Relic data types. <em>Get</em> <em>started</em> with integration data Here are some tips for finding and exploring your integration data in New Relic: From the one.newrelic.com &gt; <em>Infrastructure</em> &gt; Third-party services page, select"
      },
      "id": "60450a39196a67d7dc960f7c"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/azure-extensions-infrastructure": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.13043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.76904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-container-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.1304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.76886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.1304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.76886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.7687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    },
    {
      "sections": [
        "Tarball assisted install of the infrastructure agent for Linux",
        "Important",
        "Install the agent",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Tarball assisted install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "fd6735d0ef7034ddb5435a01658e07dca45efd57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Linux, you can make the changes you need to the installation script and configuration file we provide so you can adapt it to your environment. Important Assisted install only works for the Systemd, Upstart, and SysV service managers. If you use any other service manager, proceed with the manual install. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Update your license key in config_defaults.sh. Optional: Update any other environment parameters in the configuration file. Execute installer.sh with admin rights. The script automatically identifies your service manager. If it fails, it will prompt you to manually update it. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Configure your installation The configuration file config_defaults.sh serves as a source of reference for all the configuration options. It contains the following environment parameters: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: /var/db/newrelic-infra/ Copy NRIA_BIN_DIR Required at installation. The path to the agent binary folder. Default: /usr/local/bin Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: /etc/newrelic-infra/yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The infrastructure agent license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: /var/run/newrelic-infra/newrelic-infra.log Copy NRIA_MODE Required at installation. The privilege level for the agent. Possible values are ROOT, PRIVILEGED or UNPRIVILEGED. For more info see our documentation on agent running modes. Default: ROOT Copy NRIA_PID_FILE Required at agent startup. The location where the agent will place its PID file. Default: /var/run/newrelic-infra/newrelic-infra.pid Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: /etc/newrelic-infra/integrations.d/ Copy NRIA_USER Required at installation time only when the running mode is set to either PRIVILEGED or UNPRIVILEGED. The user that will run the agent binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>, you can make the changes you need to the <em>installation</em> script and configuration file we provide so you can adapt it to your environment. Important Assisted <em>install</em> only works for the Systemd, Upstart, and SysV service managers. If you"
      },
      "id": "603ea54064441f6bb64e8859"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.13037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.7687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Tarball assisted install of the infrastructure agent for Linux",
        "Important",
        "Install the agent",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Tarball assisted install of the infrastructure agent for Linux ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "fd6735d0ef7034ddb5435a01658e07dca45efd57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Linux, you can make the changes you need to the installation script and configuration file we provide so you can adapt it to your environment. Important Assisted install only works for the Systemd, Upstart, and SysV service managers. If you use any other service manager, proceed with the manual install. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: newrelic-infra |-- config_defaults.sh |-- etc | |-- init_scripts | | |-- systemd | | | `-- newrelic-infra.service | | |-- sysv | | | `-- newrelic-infra | | `-- upstart | | `-- newrelic-infra | `-- newrelic-infra | `-- integrations.d |-- installer.sh |-- usr | `-- bin | |-- newrelic-infra | |-- newrelic-infra-ctl | `-- newrelic-infra-service `-- var |-- db | `-- newrelic-infra | |-- custom-integrations | |-- integrations.d | |-- LICENSE.txt | `-- newrelic-integrations |-- log | `-- newrelic-infra `-- run `-- newrelic-infra Copy Update your license key in config_defaults.sh. Optional: Update any other environment parameters in the configuration file. Execute installer.sh with admin rights. The script automatically identifies your service manager. If it fails, it will prompt you to manually update it. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Configure your installation The configuration file config_defaults.sh serves as a source of reference for all the configuration options. It contains the following environment parameters: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: /var/db/newrelic-infra/ Copy NRIA_BIN_DIR Required at installation. The path to the agent binary folder. Default: /usr/local/bin Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: /etc/newrelic-infra/yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The infrastructure agent license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: /var/run/newrelic-infra/newrelic-infra.log Copy NRIA_MODE Required at installation. The privilege level for the agent. Possible values are ROOT, PRIVILEGED or UNPRIVILEGED. For more info see our documentation on agent running modes. Default: ROOT Copy NRIA_PID_FILE Required at agent startup. The location where the agent will place its PID file. Default: /var/run/newrelic-infra/newrelic-infra.pid Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: /etc/newrelic-infra/integrations.d/ Copy NRIA_USER Required at installation time only when the running mode is set to either PRIVILEGED or UNPRIVILEGED. The user that will run the agent binary. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em> ",
        "sections": "Tarball assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Linux</em>, you can make the changes you need to the <em>installation</em> script and configuration file we provide so you can adapt it to your environment. Important Assisted <em>install</em> only works for the Systemd, Upstart, and SysV service managers. If you"
      },
      "id": "603ea54064441f6bb64e8859"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.13037,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.7687,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux": [
    {
      "sections": [
        "Install the infrastructure monitoring agent for Linux",
        "Tip",
        "Quick start",
        "Install using the launcher",
        "Step-by-step instructions",
        "Debian",
        "Ubuntu",
        "Amazon Linux, CentOS, RHEL",
        "SLES",
        "Important",
        "Amazon Linux",
        "CentOS / RHEL",
        "Root (default)",
        "Privileged user",
        "Unprivileged user",
        "Install using configuration management tools",
        "Install for Docker containers on instrumented hosts",
        "Install using Azure extensions",
        "Install using tarball files",
        "Update the agent",
        "What's next?"
      ],
      "title": "Install the infrastructure monitoring agent for Linux",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "060512e99d6143e7a7e8e6d16ba96cdcc7534e57",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-06-03T13:38:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our infrastructure monitoring agent for Linux can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic installation. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Quick start The quickest way to get started with our infrastructure monitoring agent is through our guided install. Tip Try our guided install for yourself. (If you're hosted in the EU, use our EU guided install.) Install using the launcher Before installing our infrastructure monitoring agent for Linux, be sure to: Review the requirements. Have a valid New Relic license key. To install our infrastructure monitoring agent, click the button for your Linux distribution, then follow the instructions: Amazon Linux CentOS Container (Docker) Debian RHEL SLES Ubuntu Other Linux distros To use the links above, you must be logged to your New Relic account. If you don't have a New Relic account yet, or prefer to follow the procedure manually, see our step-by-step tutorial in the next section. Step-by-step instructions To install the infrastructure monitoring agent in Linux, follow these instructions: Create the configuration file and add your license key: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy Determine the distribution version number: Debian cat /etc/os-release Copy Ubuntu cat /etc/lsb-release Copy Amazon Linux, CentOS, RHEL cat /etc/os-release Copy SLES cat /etc/os-release | grep VERSION_ID Copy Enable New Relic's GPG key. Debian curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Ubuntu curl -s https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg | sudo apt-key add - Copy Amazon Linux, CentOS, RHEL yum automatically installs the GPG key using the value in gpgkey. SLES curl https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg -s | sudo gpg --import Copy Important There's a known issue with the zypper package manager where GPG keys may not be validated as expected. If you get errors such as Signature verification failed, see New Relic's Explorers Hub for more information. Add the infrastructure monitoring agent repository: Debian Debian 8 (\"Jessie\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt jessie main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 9 (\"Stretch\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt stretch main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Debian 10 (\"Buster\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt buster main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu Ubuntu 12 (\"Precise\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt precise main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 14 (\"Trusty\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt trusty main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 16 (\"Xenial\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt xenial main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 18 (\"Bionic\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt bionic main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Ubuntu 20 (\"Focal\") printf \"deb https://download.newrelic.com/infrastructure_agent/linux/apt focal main\" | sudo tee -a /etc/apt/sources.list.d/newrelic-infra.list Copy Amazon Linux Amazon Linux 2 (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy Amazon Linux 2 (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS / RHEL CentOS 7.x, RHEL 7.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64/newrelic-infra.repo Copy CentOS 7.x, RHEL 7.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/aarch64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (x86) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/x86_64/newrelic-infra.repo Copy CentOS 8.x, RHEL 8.x (arm64) sudo curl -o /etc/yum.repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/yum/el/8/aarch64/newrelic-infra.repo Copy SLES SLES 12.1 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/x86_64/newrelic-infra.repo Copy SLES 12.1 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.1/aarch64/newrelic-infra.repo Copy SLES 12.2 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/x86_64/newrelic-infra.repo Copy SLES 12.2 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.2/aarch64/newrelic-infra.repo Copy SLES 12.3 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/x86_64/newrelic-infra.repo Copy SLES 12.3 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.3/aarch64/newrelic-infra.repo Copy SLES 12.4 (x86) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/x86_64/newrelic-infra.repo Copy SLES 12.4 (ARM) sudo curl -o /etc/zypp/repos.d/newrelic-infra.repo https://download.newrelic.com/infrastructure_agent/linux/zypp/sles/12.4/aarch64/newrelic-infra.repo Copy Refresh the repositories: Debian sudo apt-get update Copy Ubuntu sudo apt-get update Copy Amazon Linux, CentOS, RHEL sudo yum -q makecache -y --disablerepo='*' --enablerepo='newrelic-infra' Copy SLES sudo zypper -n ref -r newrelic-infra Copy Install the newrelic-infra package in root (default), privileged user, or unprivileged user mode. For more information on each running mode, see Linux agent running modes. Root (default) Debian and Ubuntu: sudo apt-get install newrelic-infra -y Copy Amazon Linux, CentOS, RHEL: sudo yum install newrelic-infra -y Copy SLES: sudo zypper -n install newrelic-infra Copy Privileged user Install the libcap library and set the NRIA_MODE environment variable to PRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"PRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"PRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"PRIVILEGED\" zypper install newrelic-infra Copy Unprivileged user Install the libcap library and set the NRIA_MODE environment variable to UNPRIVILEGED. Debian and Ubuntu: sudo apt-get install libcap2-bin Copy sudo NRIA_MODE=\"UNPRIVILEGED\" apt-get install newrelic-infra Copy Amazon Linux, CentOS, RHEL: sudo yum install libcap Copy sudo NRIA_MODE=\"UNPRIVILEGED\" yum install newrelic-infra Copy SLES: sudo zypper install libcap-progs Copy sudo NRIA_MODE=\"UNPRIVILEGED\" zypper install newrelic-infra Copy Once the infrastructure monitoring agent is installed or updated, you can start, stop, or check the agent status. Important As of version 1.4.0, the infrastructure monitoring agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. Install using configuration management tools To install the infrastructure monitoring agent with a configuration management tool, see the documentation for: Ansible Chef Docker (install as container) Elastic Beanstalk Puppet Install for Docker containers on instrumented hosts See Docker instrumentation for infrastructure monitoring. Install using Azure extensions See Azure extensions for infrastructure monitoring. Install using tarball files For custom setup scenarios, you can install the infrastructure monitoring agent using our tarball files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment, or to install the infrastructure monitoring agent on distributions that lack the newrelic-infra package in their repositories. Important Installing the agent using tarball files is officially supported only for the AWS Graviton 2 processor. Update the agent Follow standard procedures to update the infrastructure monitoring agent. If you are using sudo to install or update the agent, use the -E argument to allow bypassing the environment variables, or specify the NRIA_MODE environment variable just after sudo. export NRIA_MODE=\"SET_MODE_HERE\" Copy OR sudo -E YOUR_PACKAGE_MANAGER_UPDATE_COMMAND Copy What's next? Generate some traffic and wait a few minutes, then view your hosts in the New Relic One UI. If necessary, follow our troubleshooting procedures if no data appears. Important The hostname for your server cannot be localhost. Data will not be reported for servers with that name. Make sure the host name uses a unique name. The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.13034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our <em>infrastructure</em> monitoring <em>agent</em> for <em>Linux</em> can be installed using several package managers. You can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. Tip To use <em>infrastructure</em> monitoring and the rest of our observability platform, join the New Relic"
      },
      "id": "6043edce64441f5335378f15"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 296.76855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Linux agent running modes",
        "Metrics and inventory provided",
        "Run integrations",
        "On-host integrations",
        "Custom integrations",
        "Set the running mode for your agent",
        "Tip",
        "Switch running modes",
        "From root to privileged/unprivileged",
        "From privileged/unprivileged to any other mode",
        "Update the agent"
      ],
      "title": "Linux agent running modes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Linux installation"
      ],
      "external_id": "3b639657001e3b6d4456132ec586f24898e8ca99",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/",
      "published_at": "2021-06-20T04:37:54Z",
      "updated_at": "2021-03-16T08:32:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent for Linux environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root mode. However, privileged mode can collect more metrics than unprivileged mode, including most of the inventory. This is because at installation time, the /usr/bin/newrelic-infra executable is granted with CAP_SYS_PTRACE and CAP_DAC_READ_SEARCH kernel capabilities. Unprivileged Runs as a non-privileged user named nri-agent that is created automatically during the installation process. This mode is the most restricted. Normal users do not have READ access to all the system metrics, so the agent will not be able to report all the metrics of the root or privileged modes. Metrics and inventory provided The agent provides different metrics and inventory depending on the running mode: Mode Metrics and inventory Root All of the documented data and instrumentation values. Privileged All of the values from root mode, except: SELinux inventory: This depends on the semodule command, which requires root access. Docker process metrics: These are not enabled by default. However, you can manually enable them by giving access rights to the nri-agent user. Unprivileged All of the values from privileged mode, except: Process samples do not report these metrics: File descriptor count I/O read bytes per second I/O read count per second I/O total read bytes I/O total read count I/O total write bytes I/O total write count I/O write bytes per second I/O write count per second The following inventory sources are not reported: config/sshd kernel/sysctl packages/rpm packages/dpkg services/pidfile on SysV-based distributions Run integrations As root, integrations will run as usual. When running as privileged or unprivileged user, integrations will execute properly, although some custom integrations (for example, built by customers or technical sales staff) that depend on access to root may need additional configuration. On-host integrations In general, on-host integrations will run with the non-root agent as long as the nri-agent has permissions on the integration cache files. The default path where the integration cache files are stored is /tmp. To change the path, set the environment variable NRIA_CACHE_PATH. In this situation, use the following instructions to target the provided cache path folder instead of /tmp. On-host integrations Cache path folder Apache sudo chown nri-agent:nri-agent -R /tmp/nr-apache.json Copy Cassandra sudo chown nri-agent:nri-agent -R /tmp/nr-integrations Copy MySQL sudo chown nri-agent:nri-agent -R /tmp/nr-mysql.json Copy Nginx sudo chown nri-agent:nri-agent -R /tmp/nr-nginx.json Copy Redis sudo chown nri-agent:nri-agent -R /tmp/nr-redis.json Copy Custom integrations If your custom integration doesn't require root privileges, then it’s compatible with the rootless mode. To run it, you just need to change the owner:group of the cache file as explained above. If your integration requires to be executed with a privileged user, you can use the integration_user argument in the configuration integration. Set the running mode for your agent Tip When deciding which run mode to use, consider how much data you want to be able to collect and analyze, or how much data you want to restrict. For default and assisted installations, you can set the running mode by including the NRIA_MODE environment variable set to either ROOT, PRIVILEGED, or UNPRIVILEGED. For manual installations, follow the instructions described in our docs. Switch running modes From root to privileged/unprivileged To switch the running mode from root to privileged or unprivileged, follow the installation/update instructions in this doc. From privileged/unprivileged to any other mode To change the running mode from privileged or unprivileged to any other mode: Follow these steps: Debian/Ubuntu dpkg --purge newrelic-infra Copy OR sudo apt-get remove --purge newrelic-infra Copy Centos/Suse/RedHat/Amazon rpm -e newrelic-infra Copy OR sudo yum remove newrelic-infra Copy OR sudo zypper rm newrelic-infra Copy After making sure the agent is completely removed, reinstall the agent with the selected mode. Update the agent Follow standard procedures to update the infrastructure agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.60327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Linux</em> <em>agent</em> running modes",
        "sections": "<em>Linux</em> <em>agent</em> running modes",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "The <em>infrastructure</em> <em>agent</em> for <em>Linux</em> environments can run as root, privileged, or unprivileged user, which are described below: Mode Overview Root Installed by default. Runs as root and has total access to all the system metrics and inventory. Privileged Runs as a non-privileged user named nri-<em>agent</em>"
      },
      "id": "603ea28464441f30a54e888a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " the <em>Infrastructure</em> <em>agent</em>. You can use this metadata to build filter sets, group <em>your</em> results, and annotate <em>your</em> data. For example, you might indicate a machine&#x27;s environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-20T04:40:02Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-06-20T04:41:12Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.44907,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " the <em>Infrastructure</em> <em>agent</em>. You can use this metadata to build filter sets, group <em>your</em> results, and annotate <em>your</em> data. For example, you might indicate a machine&#x27;s environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-20T04:39:00Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    },
    {
      "sections": [
        "Troubleshoot a running infrastructure agent",
        "Linux newrelic-infra-ctl",
        "Important",
        "Windows newrelic-infra-ctl"
      ],
      "title": "Troubleshoot a running infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "e1f206feb686f819c00db0619a8534609fe19c53",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent/",
      "published_at": "2021-06-20T04:41:12Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can troubleshoot our infrastructure agent using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the agent: Enables verbose logs for a period of five minutes, then reverts the log level to its previous setting. Logs all the agent config options. Logs all the integrations config options. Executes a health check for every loaded integration. (A health check is an immediate execution of the integration with extra logs and output validation.) Linux newrelic-infra-ctl In Linux systems, the troubleshooting binary is /usr/bin/newrelic-infra-ctl, available in both the package manager or the tarball assisted install methods. Important When running on Linux, newrelic-infra-ctl must be executed by either the root user or the same user running the newrelic-infra process. The newrelic-infra-ctl binary can automatically detect the agent process running in the host. It can also detect whether the agent is running inside a container. To change the default settings of newrelic-infra-ctl: To change... Execute pid newrelic-infra-ctl -pid 14580 cid (when using a containerized version of the agent) newrelic-infra-ctl -cid 8fddbcbb101c docker-api-version newrelic-infra-ctl -docker-api-version 1.24 Windows newrelic-infra-ctl In Windows, using the MSI installer, the troubleshooting binary is C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra-ctl.exe. Important In Windows, the agent process is always automatically detected. It does not depend on the pid or the cid.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.44907,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "sections": "Troubleshoot a running <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "You can troubleshoot our <em>infrastructure</em> <em>agent</em> using our newrelic-infra-ctl utility. This binary is also included in the installation package, in the same directory as the newrelic-infra default binary. Upon receiving the newrelic-infra-ctl command, the <em>agent</em>: Enables verbose logs for a period"
      },
      "id": "603eb3dee7b9d22a5f2f736b"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " the <em>Infrastructure</em> <em>agent</em>. You can use this metadata to build filter sets, group <em>your</em> results, and annotate <em>your</em> data. For example, you might indicate a machine&#x27;s environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-20T04:40:02Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-20T04:39:00Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " the <em>Infrastructure</em> <em>agent</em>. You can use this metadata to build filter sets, group <em>your</em> results, and annotate <em>your</em> data. For example, you might indicate a machine&#x27;s environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-20T04:40:02Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-20T04:39:00Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/manage-your-agent/troubleshoot-running-infrastructure-agent": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01068,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " the <em>Infrastructure</em> <em>agent</em>. You can use this metadata to build filter sets, group <em>your</em> results, and annotate <em>your</em> data. For example, you might indicate a machine&#x27;s environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Infrastructure agent behavior",
        "Agent service",
        "Agent startup",
        "Monitoring and resource caps",
        "Integration data",
        "Agent shutdown",
        "Maintenance",
        "Retry behavior",
        "Manage data reporting"
      ],
      "title": "Infrastructure agent behavior",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "704d0716fb7aa5a09d0db4a9fff12e53adb31758",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-behavior/",
      "published_at": "2021-06-20T04:40:02Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the infrastructure agent, you can monitor not only individual servers, but also understand how your service performs as a whole. The agent supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these agent versions exhibit a common set of behaviors. Agent service As of infrastructure agent v1.5.59, the agent bundles a binary named newrelic-infra-service. This binary can be managed by the OS service manager. At service startup time, this binary spawns (executes) the usual newrelic-infra process and supervises its child execution. Therefore agent service process should never be restarted, unless triggered via OS service manager. Agent startup During startup the agent will: Register a signal handler. Set the loggers. Load the configuration from file, environment variables, and call arguments. Register plugins for harvesting inventory, samplers, and integrations. StatsD integration with http_server_enabled\" Open an http port (by default, 8001) for receiving data. Startup duration before harvesting and sending data is usually less than six seconds. Monitoring and resource caps By default, the infrastructure agent runs in a single core. Every second it checks if there are events to send and, if there are, it sends them to the New Relic collector. Events that may be sent include: Default infrastructure events Events recorded by New Relic integrations. For descriptions of the default infrastructure events and their collection frequencies, see Infrastructure events. Integration data Integration monitoring is done by executing integration commands at given intervals (set in the config files) and reading their stout/err. The more integrations you enable, the greater the footprint of the agent. For more information, see the documentation for specific integrations. Agent shutdown When a shutdown signal is received, the agent stops all the registered plugins and integration processes. Maintenance The agent runs as a service. On installation, we set up all the service manager-required files, such as the systemD. service file. In case of a catastrophic failure, the service manager configuration will restart the agent. There are no automatic updates to agents. To install a new agent version: Linux: Manually install agent versions through the appropriate package manager (apt, yum, zypper). Windows: Manually download the msi package and install it with msiexec.exe. Retry behavior If a request made to the ingest service is unsuccessful, the payload is discarded; subsequent requests follow an exponential backoff pattern until one succeeds. For inventory, we store the deltas between system states in cache files. On failure, these deltas are not deleted but are reused on requests that follow. Manage data reporting For information about configuring reporting of data, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> behavior",
        "sections": "<em>Infrastructure</em> <em>agent</em> behavior",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the <em>infrastructure</em> <em>agent</em>, you can monitor not only individual servers, but also understand how <em>your</em> service performs as a whole. The <em>agent</em> supports Amazon Linux, CentOS, Debian, RHEL, and Ubuntu as well as Windows Server. All of these <em>agent</em> versions exhibit a common set of behaviors. <em>Agent</em>"
      },
      "id": "603eb68428ccbc8576eba7a5"
    },
    {
      "sections": [
        "Agent message size"
      ],
      "title": "Agent message size",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "a762f70a367322dd6fa16c0825cbf3c3495b6b6c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/agent-message-size/",
      "published_at": "2021-06-20T04:39:00Z",
      "updated_at": "2021-03-16T08:32:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Since infrastructure agent version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.45877,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Agent</em> message size",
        "sections": "<em>Agent</em> message size",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Since <em>infrastructure</em> <em>agent</em> version 1.0.989, the maximum message size is 1MB (10^6 bytes), and it can include events, metrics, and inventory integrations indistinctly. Previously, the maximum message size was 5MB, although inventory data was limited to 3MB."
      },
      "id": "603ea87628ccbc6062eba74a"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent": [
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-06-20T04:42:34Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.82916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-06-20T04:42:35Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.82916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations": [
    {
      "sections": [
        "Update the infrastructure agent",
        "Tip",
        "View the infrastructure agent version",
        "Update the agent for installs using the package manager",
        "Update using apt (Debian, Ubuntu)",
        "Update using yum (Amazon Linux, CentOS, RHEL)",
        "Update using Zypper (SLES)",
        "Update on Windows Server (32 bits)",
        "Update on Windows Server (64 bits)",
        "Update with config management tools",
        "Update the agent for assisted and manual tarball installs",
        "Important",
        "Update the containerized version of the agent",
        "Identify outdated agent versions from the UI"
      ],
      "title": "Update the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1ddaa00ceaf5936084d25f207f868d89fd0957f6",
      "image": "https://docs.newrelic.com/static/06b72c159cd2d6b502bb7cbab7a98e67/103b3/ebs.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent/",
      "published_at": "2021-06-20T04:42:35Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to update the infrastructure agent to the latest version for Linux and Windows servers. Tip To install the infrastructure agent for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To uninstall the infrastructure agent, see Uninstall the Infrastructure agent. View the infrastructure agent version The infrastructure agent does not update itself automatically. Check the infrastructure agent release notes to make sure you have the latest agent version. To view the current infrastructure agent version for a host, use any of these options: Go to one.newrelic.com > Infrastructure > Settings > Agents > Agent version. Go to one.newrelic.com > Infrastructure > Hosts > (select a host). Create a query for SystemSample. Update the agent for installs using the package manager If you used the default installation process, use your package manager to update the program and its dependencies to the latest version. Here are examples for some common systems: Update using apt ( Debian, Ubuntu) To manually update the infrastructure agent with apt-get: sudo apt-get update && sudo apt-get install --only-upgrade newrelic-infra -y Copy Update using yum ( Amazon Linux, CentOS, RHEL) To manually update the infrastructure agent with yum: sudo yum update newrelic-infra -y Copy After updating you may need to start the agent. Update using Zypper ( SLES) To manually update the infrastructure agent with Zypper: sudo zypper -n update newrelic-infra Copy After updating you may need to start the agent. Update on Windows Server (32 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy After updating you may need to start the agent. Update on Windows Server (64 bits) To manually update the infrastructure agent on Windows Server: Download the latest .MSI installer image from download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Run the install script. To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy After updating you may need to start the agent. Update with config management tools To update the infrastructure agent using your configuration management tool, see the documentation for your tool: Configure with Ansible Configure with Chef Configure with AWS Elastic Beanstalk Configure with Puppet Update the agent for assisted and manual tarball installs Important Since there are are no automated scripts, old files may remain when you update. Be sure to manually remove outdated files. To update the agent, download the file again and follow the installation procedure for Linux (assisted or manual) or Windows (assisted or manual). This will overwrite your old installation. Update the containerized version of the agent Use the latest label to ensure that our Docker image is automatically updated. Identify outdated agent versions from the UI You can use the Infrastructure monitoring UI to search for outdated agent versions: Go to one.newrelic.com > Infrastructure > Inventory * * * * . In the search bar, type newrelic-infra. Select a group's dropdown to see the agent versions for that group. To manually check the infrastructure agent versions, you can log onto a server and run newrelic-infra --version, or the applicable command for your package manager.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.82916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Update</em> the <em>infrastructure</em> <em>agent</em>",
        "sections": "<em>Update</em> <em>the</em> <em>agent</em> for <em>installs</em> using <em>the</em> package manager",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Read on to learn how to <em>update</em> the <em>infrastructure</em> <em>agent</em> to the latest version for Linux and Windows servers. Tip To <em>install</em> the <em>infrastructure</em> <em>agent</em> for the first time, see the installation documentation for Linux, Windows, or configuration management tools. To <em>uninstall</em> the <em>infrastructure</em> <em>agent</em>"
      },
      "id": "60440e8fe7b9d252a2579a19"
    },
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-06-20T04:41:13Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.4931,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/update-infrastructure-agent": [
    {
      "sections": [
        "Uninstall infrastructure integrations",
        "Cloud integrations",
        "AWS",
        "Azure",
        "Google Cloud Platform (GCP)",
        "On-host integrations",
        "Apache",
        "Cassandra",
        "Kubernetes",
        "MySQL",
        "NGINX",
        "Redis",
        "StatsD",
        "Moving away from the integrations package",
        "Uninstall package"
      ],
      "title": "Uninstall infrastructure integrations",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "1e9232193cbf71bdbe1a6c6d0374ed0d6b7e7b0f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-integrations/",
      "published_at": "2021-06-20T04:42:34Z",
      "updated_at": "2021-05-16T10:05:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Uninstalling the infrastructure agent does not directly affect any of your infrastructure Integrations: if you uninstall the agent, your integrations will remain. Similarly, if you disable or uninstall your integrations, the infrastructure agent will remain. To uninstall any of your integrations, follow the procedure corresponding to the type of integration. Cloud integrations AWS You can disable infrastructure AWS integrations and still retain the connection between your AWS account and New Relic. We recommend not to disable your EC2 and EBS integrations because those add important metadata to your infrastructure data. If you want to... Do this Disable one or more AWS service integrations To disable services while keeping your AWS account linked to New Relic: From one.newrelic.com > Infrastructure, select AWS > Manage services. From your Edit AWS account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all AWS integrations To disconnect your AWS account completely from New Relic, you need to unlink your AWS account. This disables all New Relic integrations associated with that AWS account. Go to one.newrelic.com > Infrastructure > AWS > Manage services. From your Edit AWS account page, select Unlink this account. Save your changes. Sign in to AWS and select Services > IAM > Roles. Select the checkbox for the role you want to delete, then select Role Actions > Delete Role. Unlinking your AWS account will disable the trust relationship set up via your ARN. Azure If you want to... Do this Disable one or more Azure service integrations To disable services while keeping your Azure account linked to New Relic: Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all Azure integrations To disconnect your Azure account completely from New Relic, you need to unlink your Azure account. This requires being either the user who registered the app or an administrator. This procedure will disable all New Relic integrations associated with that Azure account. Go to one.newrelic.com > Infrastructure > Azure > Manage services. From your Edit Azure account page, select Unlink this account. Save your changes. Sign in to Azure and go into All Services > Identity > App registrations, or go to Azure Active Directory service and select App registrations. Find the registered app (the recommended name is NewRelic-Integrations). To see the full list of available apps, select the dropdown menu beside the search field and select All apps. Select the app and, on the panel that opens, select Delete. Google Cloud Platform (GCP) If you want to... Do this Disable one or more GCP service integrations To disable services while keeping your GCP account linked to New Relic: From one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, clear the checkbox for each active service you want to disable. Save your changes. Disable all GCP integrations To disconnect your GCP account completely from New Relic, you need to unlink your GCP account. This disables all New Relic integrations associated with that GCP account. If you registered the GCP project using a User account, follow these steps. Go to one.newrelic.com > Infrastructure > GCP > Manage services. From your Edit GCP account page, select Unlink this account. Save your changes. If you registered the GCP project using a Service account, follow these steps. If you are deleting a custom role, be aware that this role may be used for other purposes besides New Relic access. Sign in to New Relic and go to Infrastructure > Integrations > Google Cloud Platform. For a standard (non-custom) user role, select Manage Services for the account you want to remove. Copy the value of User and save it. OR For a custom user role, go to IAM > admin > Roles, search for the role, select it, and select DELETE. You are now finished and can skip the remaining steps. Standard (non-custom) user role: Sign in to Google Cloud and select the correct project in the Select a project box. From the navigation menu, select IAM & admin > IAM. Search for and select the user value you saved, then select REMOVE. On-host integrations If you used the integrations package, see the integrations package instructions. Here are some examples: Apache Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-apache yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-apache zypper (SLES) sudo zypper -n remove nri-apache Cassandra Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-cassandra yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-cassandra zypper (SLES) sudo zypper -n remove nri-cassandra Kubernetes Each cluster will have a single node where kubectl is running. To uninstall the Kubernetes integration, use the following command on each of these nodes: kubectl delete -f newrelic-infrastructure-k8s-latest.yaml Copy MySQL Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-mysql yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-mysql zypper (SLES) sudo zypper -n remove nri-mysql NGINX Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-nginx yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-nginx zypper (SLES) sudo zypper -n remove nri-nginx Redis Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove nri-redis yum (Amazon Linux, CentOS, or RHEL) sudo yum remove nri-redis zypper (SLES) sudo zypper -n remove nri-redis StatsD cd /path/to/statsd npm uninstall @newrelic/statsd-infra-backend From the StatsD config.js, remove the \"@newrelic/statsd-infra-backend\" entry from the list of backends. Restart StatsD. Moving away from the integrations package While it is still possible to use the integrations package, we recommend removing it completely and working with integrations on an individual basis. The last integration package contains the following versions of the integrations: Apache 1.1.2 Cassandra 2.0.3 MySQL 1.1.5 Nginx 1.0.2 Redis 1.0.1 If you remove the integrations package and want to continue using the related on-host integrations, you will need to install them one by one. To uninstall the package and re-install your integrations: Remove the integrations package by following these instructions. The config files from the old integrations will not be deleted, so you won’t have to configure them again. Uninstall package Package manager Uninstall instructions apt (Debian or Ubuntu) sudo apt-get remove newrelic-infra-integrations sudo apt-get autoremove yum (Amazon Linux, CentOS, or RHEL) sudo yum remove newrelic-infra-integrations sudo yum autoremove zypper (SLES) sudo zypper -n remove newrelic-infra-integrations --clean-deps Copy Install your integrations one by one following these instructions. To replicate the integrations package, you will need to install all the available integrations again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.82916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "sections": "<em>Uninstall</em> <em>infrastructure</em> integrations",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Uninstalling the <em>infrastructure</em> <em>agent</em> does not directly affect any of your <em>infrastructure</em> Integrations: if you <em>uninstall</em> the <em>agent</em>, your integrations will remain. Similarly, if you disable or <em>uninstall</em> your integrations, the <em>infrastructure</em> <em>agent</em> will remain. To <em>uninstall</em> any of your integrations"
      },
      "id": "603ea831196a67fc6fa83db5"
    },
    {
      "sections": [
        "Uninstall the infrastructure agent",
        "Uninstall the Linux infrastructure agent",
        "Uninstall with apt (Debian, Ubuntu)",
        "Uninstall with yum (Amazon Linux, CentOS, RHEL)",
        "Uninstall with Zypper (SLES)",
        "Important",
        "Uninstall the Windows infrastructure agent",
        "Tip",
        "Uninstall using config management tools",
        "Optional: Purge remaining files"
      ],
      "title": "Uninstall the infrastructure agent ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Update or uninstall"
      ],
      "external_id": "d99fe6244698657f7f2e67bc6f6fcbfc9d8ffbf9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/update-or-uninstall/uninstall-infrastructure-agent/",
      "published_at": "2021-06-20T04:41:13Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Your hosts are added automatically when you install the infrastructure agent for your Linux or Windows operating system, or update the agent. Similarly, your hosts disappear automatically when you uninstall the agent. You do not need to manually add or remove your hosts. Uninstalling the agent does not directly affect any of your integrations. To uninstall an integration, see Uninstall integrations. Uninstall the Linux infrastructure agent If you used the default install procedure for your infrastructure agent for Linux environments, use your package management tools to uninstall it. You do not need to stop the service before running the uninstall command. Uninstall with apt ( Debian, Ubuntu) Execute the following command as root: sudo apt-get remove newrelic-infra Copy Uninstall with yum ( Amazon Linux, CentOS, RHEL) Execute the following command as root: sudo yum remove newrelic-infra Copy Uninstall with Zypper ( SLES) Execute the following command as root: sudo zypper -n remove newrelic-infra Copy If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall the Windows infrastructure agent Tip Requires Administrator rights in your Windows admin group. If you used the default install procedure for the infrastructure agent for Windows environments, to uninstall: Stop the infrastructure agent. From the Windows Control Panel, use the Add/Remove Programs and Features tool to uninstall the infrastructure agent. From the Windows Program Files, manually delete the New Relic folder to delete all files associated with the infrastructure agent for Windows. If you followed an assisted or manual installation process, you need to manually delete all the files created when you unpacked the agent file. Important Since there are are no automated scripts, old files may remain when you uninstall. Be sure to manually remove outdated files. Uninstall using config management tools To uninstall the infrastructure agent if you used a configuration management tool: Config management tools Uninstall New Relic infrastructure agent Ansible Set the 'agent_state' parameter to 'absent' Chef Set the 'agent_action' node to uninstall AWS Elastic Beanstalk Remove newrelic.config from .ebextensions, then deploy. Puppet Set the 'ensure' parameter to 'absent' Optional: Purge remaining files If you use standard package management tools for your selected platform, the uninstall process typically leaves configuration and other miscellaneous files. If you need to completely purge any of the remaining files after uninstalling the New Relic infrastructure agent, follow standard procedures for your operating system.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 317.49307,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em> ",
        "sections": "<em>Uninstall</em> the <em>infrastructure</em> <em>agent</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Your hosts are added automatically when you <em>install</em> the <em>infrastructure</em> <em>agent</em> for your Linux or Windows operating system, or <em>update</em> the <em>agent</em>. Similarly, your hosts disappear automatically when you <em>uninstall</em> the <em>agent</em>. You do not need to manually add or remove your hosts. Uninstalling the <em>agent</em> does"
      },
      "id": "603ea0e964441f31114e885c"
    },
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " = &#x27;production&#x27; Copy enable_process_metrics Important Requires <em>infrastructure</em> <em>agent</em> version 1.12.0 or higher. Accounts created before July 20, 2020 and&#x2F;or <em>infrastructure</em> agents installed using the new Guided <em>Install</em> have this variable enabled by default. Enables the sending of process metrics to New"
      },
      "id": "603ea542196a67a38aa83dd8"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.01038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-06-20T04:43:40Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.2306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-06-20T04:43:40Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.71106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.0102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Zip manual install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Install the service script",
        "Configuration file",
        "Changing the config file's location",
        "Configure the plugin directory",
        "Configure the agent directory",
        "Configure the log file",
        "What's next?"
      ],
      "title": "Zip manual install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "f7c89a92aefa26a400384c4334bcdc876dd07546",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows/",
      "published_at": "2021-06-20T04:43:40Z",
      "updated_at": "2021-03-16T08:33:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our custom installation process for the infrastructure agent for Windows allows you to tailor all aspects of the installation, and place files and folders wherever you want on your filesystem. This method gives you full control of the installation: you are responsible for placing the files in the correct folders, providing the correct configuration values, and ensuring the agent has all the right permissions. Before installation, check the compatibility and requirements. Install the agent To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Install the service script. Optionally, you can: Change the location of the configuration file. Configure the plugin directory. Configure the agent directory. Configure the log file. Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. Install the service script To proceed with the installation, you need to create the service. Check the file provided in the zip file for reference: C:\\Program Files\\New Relic\\newrelic-infra\\installer.ps1 Copy Configuration file The Infrastructure agent depends on a configuration file, usually named newrelic-infra.yml, placed in the same folder with the agent, to configure the agent's behavior. You can create a new config file based on config file template. For more information, see how to configure the agent. Changing the config file's location By default, the configuration file is located in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml. To change the location of the configuration file: Execute the command regedit.exe. Browse to the folder Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\newrelic-infra\\ImagePath. Retrieve the ImagePath key. If the agent binary is on the default path, look for the key at C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe. Use the -config flag to add the new location of the configuration file to the key: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.exe -config c:\\config.yaml Copy Configure the plugin directory The Infrastructure agent allows you to install integrations that monitor and report data from popular services such as Kubernetes, AWS, MySQL, Redis, Kafka, etc. Each integration has its own configuration file, named by default integration-name-config.yml, placed in the predefined location C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d. On initialization, the agent loads the config file. To overwrite the predefined location of the integration configuration file, use one of the following methods: Set the location in the NRIA_PLUGIN_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the plugin_dir field. Pass it as a command line argument using -plugin_dir when you run the newrelic-infra binary. Configure the agent directory The agent requires its own defined directory to run the installed integrations, caching data (inventory), etc. The default location is C:\\Program Files\\New Relic\\newrelic-infra\\. The agent directory has the following structure and content: LICENSE: Text file containing the New Relic Infrastructure agent license. custom-integrations: Directory that stores the installed the custom integrations. newrelic-integrations: Directory that stores the New Relic official integrations. Additionally, the agent uses a different folder, app_data_dir, to store data. By default it points to C:\\ProgramData\\New Relic\\newrelic-infra\\. To overwrite the predefined location of the agent directory, use one of the following methods: Set the location in the NRIA_AGENT_DIR environment variable. Set the custom path in the newrelic-infra.yml configuration file using the agent_dir field. Pass it as a command line argument using -agent_dir when you run the newrelic-infra binary. Configure the log file By default the agent stores the log files in C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log. To overwrite the predefined location of the log file, use one of the following methods: Set the location in the NRIA_LOG_FILE environment variable. Set the custom path in the newrelic-infra.yml configuration file using the log_file field. Pass it as a command line argument using -log_file when you run the newrelic-infra binary. What's next? You may also want to: Add custom attributes to annotate your Infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic Infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 279.71106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip manual <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "Our custom <em>installation</em> process for the <em>infrastructure</em> <em>agent</em> for <em>Windows</em> allows you to tailor all aspects of the <em>installation</em>, and place files and folders wherever you want on your filesystem. This method gives you full control of the <em>installation</em>: you are responsible for placing the files"
      },
      "id": "603ea57b196a678ad3a83dbf"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Tip",
        "Install for Windows Server and Windows 10 using our wizard",
        "Step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "What's next?",
        "Install using zip files",
        "Caution",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-06-20T04:42:34Z",
      "updated_at": "2021-03-13T01:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure. The infrastructure monitoring agent supports Windows Server and Windows 10. You can also install with Chef. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install for Windows Server and Windows 10 using our wizard Before installation, be sure to review the requirements. Then, to install the infrastructure monitoring agent for Windows, you can use our launcher, or follow the instructions in this document to complete a basic installation. Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, follow our step-by-step tutorial, which follows. Step-by-step instructions To install the infrastructure monitoring agent, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Tip As of version 1.4.0, the infrastructure monitoring agent package includes newrelic-infra-ctl, which is used to help troubleshoot a running agent. We recommend adding it to PATH. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.9369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our wizard Before <em>installation</em>, be sure to review the requirements. Then, to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. <em>Windows</em> If you don&#x27;t"
      },
      "id": "6044672464441f9bb6378ed9"
    }
  ],
  "/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-manual-install-infrastructure-agent-windows": [
    {
      "sections": [
        "Infrastructure agent configuration settings",
        "Important",
        "Agent variables",
        "license_key (REQUIRED)",
        "fedramp",
        "max_procs",
        "payload_compression_level",
        "startup_connection_retries",
        "startup_connection_retry_time",
        "startup_connection_timeout",
        "Cloud variables",
        "cloud_max_retry_count",
        "cloud_metadata_expiry_sec",
        "cloud_retry_backoff_sec",
        "disable_cloud_instance_id",
        "disable_cloud_metadata",
        "Debug variables",
        "trace",
        "Docker variables",
        "container_cache_metadata_limit",
        "docker_api_version",
        "File system variables",
        "custom_supported_file_systems",
        "file_devices_ignored",
        "Hostname variables",
        "display_name",
        "dns_hostname_resolution",
        "override_hostname",
        "override_hostname_short",
        "Installation variables",
        "agent_dir",
        "plugin_dir",
        "custom_plugin_installation_dir",
        "Integrations variables",
        "passthrough_environment",
        "entityname_integrations_v2_update",
        "http_server_enabled",
        "http_server_host",
        "http_server_port",
        "remove_entities_period",
        "Inventory variables",
        "offline_time_to_reset",
        "ignored_inventory",
        "Linux variables",
        "pid_file",
        "ignore_reclaimable",
        "Logging variables",
        "log_file",
        "log_format",
        "log_to_stdout",
        "verbose",
        "smart_verbose_mode_entry_limit",
        "Metrics variables",
        "custom_attributes",
        "Tip",
        "enable_process_metrics",
        "include_matching_metrics",
        "network_interface_filters",
        "Linux",
        "Windows",
        "disable_zero_mem_process_filter",
        "Plugins variables",
        "disable_all_plugins",
        "cloud_security_group_refresh_sec",
        "daemontools_interval_sec",
        "dpkg_interval_sec",
        "facter_interval_sec",
        "kernel_modules_refresh_sec",
        "network_interface_interval_sec",
        "rpm_interval_sec",
        "selinux_interval_sec",
        "sshd_config_refresh_sec",
        "supervisor_interval_sec",
        "sysctl_interval_sec",
        "systemd_interval_sec",
        "sysvinit_interval_sec",
        "upstart_interval_sec",
        "users_refresh_sec",
        "supervisor_rpc_sock",
        "facter_home_dir",
        "Proxy variables",
        "proxy",
        "ignore_system_proxy",
        "ca_bundle_dir",
        "ca_bundle_file",
        "proxy_validate_certificates",
        "proxy_config_plugin",
        "Samples variables",
        "metrics_network_sample_rate",
        "metrics_process_sample_rate",
        "metrics_storage_sample_rate",
        "metrics_system_sample_rate",
        "metrics_nfs_sample_rate",
        "detailed_nfs",
        "Security variables",
        "selinux_enable_semodule",
        "strip_command_line",
        "Windows variables",
        "windows_services_refresh_sec",
        "windows_updates_refresh_sec",
        "app_data_dir",
        "enable_win_update_plugin",
        "legacy_storage_sampler",
        "win_process_priority_class",
        "win_removable_drives",
        "What's next?"
      ],
      "title": "Infrastructure agent configuration settings ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Configuration"
      ],
      "external_id": "7d016d3f5af6ed1615904578f0ed8bce02aa335b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/",
      "published_at": "2021-06-20T17:54:17Z",
      "updated_at": "2021-06-20T17:54:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent has a large set of configuration settings to fine-tune its behavior. Here we: List all the configuration options (in both their YAML and the environment variable names). Explain what the settings do and when to use them. Give the variable type and default value (if any). List the minimum required agent version as applicable. For an example of how all these variables can be used, see our sample configuration template. Important license_key is the only required setting. Agent variables license_key (REQUIRED) Specifies the license key for your New Relic account. The agent uses this key to associate your server's metrics with your New Relic account. This setting is created as part of the standard installation process. YML option name Environment variable Type Default Version license_key NRIA_LICENSE_KEY string Example: license_key: 1234567890abcdefghijklmnopqrstuvwxyz1234 Copy fedramp Specifies whether Fedramp endpoints should be used. YML option name Environment variable Type Default Version fedramp NRIA_FEDRAMP boolean false 1.15.0 max_procs Specifies the number of logical processors available to the agent. Increasing this value helps to distribute the load between different cores. If set to -1, the agent will try to read the environment variable GOMAXPROCS. If this variable is not set, the default value will be the total number of cores available in the host. YML option name Environment variable Type Default Version max_procs NRIA_MAX_PROCS integer 1 1.0.1002 payload_compression_level Since version 1.0.804 or higher, data sent from the agent is compressed by default. To disable payload compression, set payload_compression_level to 0. Important Recommendation: Do not change this setting. YML option name Environment variable Type Default Version payload_compression_level NRIA_PAYLOAD_COMPRESSION_LEVEL integer 6 1.0.804 startup_connection_retries Number of times the agent will retry the request to check New Relic's platform availability at startup before throwing an error. If set to a negative value, the agent will keep checking the connection until it succeeds. YML option name Environment variable Type Default Version startup_connection_retries NRIA_STARTUP_CONNECTION_RETRIES integer 6 1.0.936 startup_connection_retry_time After a request has timed out, time the agent waits to retry a request to check New Relic's platform availability at startup. YML option name Environment variable Type Default Version startup_connection_retry_time NRIA_STARTUP_CONNECTION_RETRY_TIME string 5s 1.0.936 - 1.2.30 startup_connection_timeout Time the agent waits until a request to check New Relic's platform availability at startup is considered timed out. YML option name Environment variable Type Default Version startup_connection_timeout NRIA_STARTUP_CONNECTION_TIMEOUT string 10s 1.0.936 Cloud variables If the agent is running in a cloud instance, the agent will try to detect the cloud type and fetch metadata. cloud_max_retry_count Sets the number of times the agent retries to connect in case that cloud detection fails. If cloud detection fails during the initialization of the agent, the agent will retry after waiting for CloudRetryBackOffSec seconds. YML option name Environment variable Type Default Version cloud_max_retry_count NRIA_CLOUD_MAX_RETRY_COUNT integer 10 1.2.6 cloud_metadata_expiry_sec Sets the interval of time the agent will wait until discarding the metadata, in seconds. After this period metadata expires and the agent will fetch it again. YML option name Environment variable Type Default Version cloud_metadata_expiry_sec NRIA_CLOUD_METADATA_EXPIRY_SEC integer 300 1.2.6 cloud_retry_backoff_sec Sets the interval of time the agent waits between cloud detection retries in case that cloud detection failed, in seconds. If cloud detection fails during the initialization of the agent, it will retry for CloudMaxRetryCount times. YML option name Environment variable Type Default Version cloud_retry_backoff_sec NRIA_CLOUD_RETRY_BACKOFF_SEC integer 60 1.2.6 disable_cloud_instance_id Similar to DisableCloudMetadata, but it disables the collection of cloud metadata only for the host alias plugin. YML option name Environment variable Type Default Version disable_cloud_instance_id NRIA_DISABLE_CLOUD_INSTANCE_ID boolean false 1.0.220 disable_cloud_metadata Disables the collection of cloud metadata. YML option name Environment variable Type Default Version disable_cloud_metadata NRIA_DISABLE_CLOUD_METADATA boolean false 1.0.690 Debug variables trace Enables traces to be printed in the logs for the given features. Traces are additional log entries used for debugging purposes of specific features, they are only shown when the verbose log config option is enabled. Currently two features have traces defined: connect and attributes. YML option name Environment variable Type Default Version trace NRIA_TRACE [ ]string [] 1.0.1015 Example as a YAML attribute: trace: [connect, attributes] Copy Example as an environment variable: NRIA_TRACE='connect, attributes' Copy Docker variables container_cache_metadata_limit Time, in seconds, before the cached containers metadata expires and the agent needs to fetch them again. YML option name Environment variable Type Default Version container_cache_metadata_limit NRIA_CONTAINER_CACHE_METADATA_LIMIT integer 60 1.0.801 docker_api_version Specifies the Docker client API version. YML option name Environment variable Type Default Version docker_api_version NRIA_DOCKER_API_VERSION string 1.24 1.1.4 File system variables custom_supported_file_systems List of the types of file systems that the agent supports. This value needs to be a subset of the default list, and items that are not in the default list will be discarded. YML option name Environment variable Type Default Version custom_supported_file_systems NRIA_CUSTOM_SUPPORTED_FILESYSTEMS [ ]string Linux: [\"xfs\", \"btrfs\", \"ext\", \"ext2\", \"ext3\", \"ext4\", \"hfs\", \"vxfs\"] Windows: [\"NTFS\", \"ReFS\"] 1.0.220 file_devices_ignored List of storage devices to be ignored by the agent when gathering StorageSample data. YML option name Environment variable Type Default Version file_devices_ignored NRIA_FILE_DEVICES_IGNORED [ ]string 1.0.220 Example as a YAML attribute: file_devices_ignored: - sda1 - sda2 Copy Example as an environment variable: FILE_DEVICES_IGNORED=\"sda1,sda2\" Copy Hostname variables display_name Overrides the auto-generated hostname for reporting. This is useful when you have multiple hosts with the same name, since our infrastructure monitoring uses the hostname as the unique identifier for each host. Keep in mind this value is also used for the loopback address replacement on entity names. For more information, see our documentation on how entity name resolution works. YML option name Environment variable Type Default Version display_name NRIA_DISPLAY_NAME string empty 1.0.266 Example: display_name: teslaOne Copy dns_hostname_resolution When true, the full hostname is resolved by performing a reverse lookup of the host's address. Otherwise, it will be retrieved with the hostname command on Linux and from the TCP/IP parameters of the registry on Windows. YML option name Environment variable Type Default Version dns_hostname_resolution NRIA_DNS_HOSTNAME_RESOLUTION boolean true 1.2.6 override_hostname When set, this is the value that will be reported for the full hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname NRIA_OVERRIDE_HOSTNAME string 1.0.1015 Example: my.custom-hostname.co.org Copy override_hostname_short When set, this is the value that will be reported for the hostname; otherwise, the agent will perform the normal lookup behavior. YML option name Environment variable Type Default Version override_hostname_short NRIA_OVERRIDE_HOSTNAME_SHORT string 1.0.1015 Example: my.custom-hostname Copy Installation variables agent_dir Directory where the agent stores files for cache, inventory, integrations, etc. YML option name Environment variable Type Default Version agent_dir NRIA_AGENT_DIR string Linux: /var/db/newrelic-infra Windows: C:\\Program Files\\NewRelic\\newrelic-infra\\ 1.0.2 plugin_dir Directory containing the configuration files of the integrations. Each integration has its own configuration file, named by default <integration_name>-config.yml, placed in a predefined location from which the agent loads on initialization. YML option name Environment variable Type Default Version plugin_dir NRIA_PLUGIN_DIR string Linux: etc/newrelic-infra/integrations.d/ Windows: \\Program Files\\NewRelic\\newrelic-infra\\inregrations.d 1.0.2 Important With secrets management, you can configure on-host integrations with New Relic Infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see Secrets management. custom_plugin_installation_dir Specifies a custom path to install integrations, which allows to install them outside the agent_dir. It has priority when the agent is looking for installed integrations. YML option name Environment variable Type Default Version custom_plugin_installation_dir NRIA_CUSTOM_PLUGIN_INSTALLATION_DIR string Empty 1.0.2 Integrations variables passthrough_environment A list of environment variables that will be passed to all integrations. If an integration already has an existing configuration option with the same name, then the environment variable takes precedence. YML option name Environment variable Type Default Version passthrough_environment NRIA_PASSTHROUGH_ENVIRONMENT [ ]string Empty 1.0.719 Example as a YAML attribute (inside the agent's configuration file, located by default in /etc/newrelic-infra.yml): passthrough_environment: - HOST - PORT Copy Example as an environment variable: NRIA_PASSTHROUGH_ENVIRONMENT=\"HOST,PORT\" Copy entityname_integrations_v2_update The agent enables loopback-address replacement on the entity name (and therefore key) automatically for version 3 of the integration protocol. If you are using version 2 of the protocol and want this behavior, enable the entityname_integrations_v2_update option. YML option name Environment variable Type Default Version entityname_integrations_v2_update NRIA_ENTITYNAME_INTEGRATIONS_V2_UPDATE boolean false 1.2.15 http_server_enabled By setting this configuration parameter to true the agent will open an HTTP port (by default, 8001) to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_enabled NRIA_HTTP_SERVER_ENABLED boolean false 1.0.818 http_server_host By setting this value, the agent will start listening on the HTTPServerPort to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_host NRIA_HTTP_SERVER_HOST string localhost 1.0.818 http_server_port Sets the port for the http server to receive data from the New Relic StatsD backend. YML option name Environment variable Type Default Version http_server_port NRIA_HTTP_SERVER_PORT integer 8001 1.0.818 remove_entities_period Starts the process of deleting entities that haven't reported information during this interval. Valid time units: s (seconds), m (minutes), and h (hour). YML option name Environment variable Type Default Version remove_entities_period NRIA_REMOVE_ENTITIES_PERIOD string 48h 1.0.859 Example: 1h Copy Inventory variables offline_time_to_reset If the cached inventory becomes older than this value (for example, because the agent is offline), the agent automatically removes and recreates the delta store. YML option name Environment variable Type Default Version offline_time_to_reset NRIA_OFFLINE_TIME_TO_RESET string 24h 1.0.888 ignored_inventory The list of inventory paths ignored by the agent. YML option name Environment variable Type Default Version ignored_inventory NRIA_IGNORED_INVENTORY string [ ] Empty list 1.0.336 Example as a YAML attribute: ignored_inventory: - files/config/stuff.bar - files/config/stuff.foo Copy Example as an environment variable: NRIA_IGNORED_INVENTORY=\"files/config/stuff.bar,files/config/stuff.foo\" Copy Linux variables pid_file Location on Linux where the pid file of the agent process is created. It is used at startup to ensure that no other instances of the agent are running. YML option name Environment variable Type Default Version pid_file NRIA_PID_FILE string /var/run/newrelic-infra/newrelic-infra.pid 1.0.2 ignore_reclaimable When true, formulation of the host virtual memory considers SReclaimable as available memory; otherwise SReclaimable will be considered part of the used memory. YML option name Environment variable Type Default Version ignore_reclaimable NRIA_IGNORE_RECLAIMABLE boolean false 1.2.6 Logging variables log_file Defines the file path for the logs. The default installation creates a log directory and it sets this filepath value in the log_file configuration option for you. This log directory is different for each OS, as shown below. Change this configuration option to customize the file path for the logs. YML option name Environment variable Type Default Version log_file NRIA_LOG_FILE string See below * Default paths: Linux: If not defined, it logs only in the standard output. Windows, agent version 1.0.752 or lower: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.775 to 1.0.944: C:\\%APPDATA%\\Roaming\\New Relic\\newrelic-infra\\newrelic-infra.log Copy Windows, agent version 1.0.944 or higher: C:\\%ProgramData%\\New Relic\\newrelic-infra\\newrelic-infra.log Copy If the directory can't be created: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy log_format Defines the log output format. Available values: text: Plain text output, one line per log entry. json: JSON-formatted output, one line per log entry. YML option name Environment variable Type Default Version log_format NRIA_LOG_FORMAT string text 1.4.9 log_to_stdout By default all logs are displayed in both standard output and a log file. To disable logs in the standard output, set this configuration option to false. YML option name Environment variable Type Default Version log_to_stdout NRIA_LOG_TO_STDOUT boolean true 1.0.703 verbose When verbose is set to 0, verbose logging is off, but the agent still creates logs. Set this to 1 to create verbose logs to use in troubleshooting the agent; set verbose to 2 to use the smart verbose mode logging. Smart verbose mode logs the last smart_verbose_mode_entry_limit debug messages when an error is logged. Setting verbose to 3 enables forwarding the agent logs to New Relic Logs. Important Verbose logging can generate a lot of data very quickly. Run the agent in verbose mode only for as long as necessary to reproduce your issue, then set verbose: 0 and restart your agent to disable verbose logging. Alternatively, you can set verbose: 2, which will enable smart verbose mode. YML option name Environment variable Type Default Version verbose NRIA_VERBOSE Integer (0, 1, 2 or 3) 0 1.9.0 when using smart mode (2) 1.11.4 when forwarding the New Relic Logs (3) smart_verbose_mode_entry_limit smart_verbose_mode_entry_limit refers to the number of previous debug messages that will be logged when an error is logged. For example, if the limit is set to 5, debug logs will be cached in memory until an error is logged, at which point the previous 5 debug messages will also be logged Important This configuration option is only used when verbose is set to 2 (Smart Verbose Mode enabled). YML option name Environment variable Type Default Version smart_verbose_mode_entry_limit NRIA_SMART_VERBOSE_MODE_ENTRY_LIMIT Integer 1000 1.9.0 Metrics variables custom_attributes Custom attributes are key-value pairs (similar to tags in other tools) used to annotate the data from the Infrastructure agent. You can use this metadata to build filter sets, group your results, and annotate your data. For example, you might indicate a machine's environment (staging or production), the service a machine hosts (login service, for example), or the team responsible for that machine. Tip The agent collects many details about your environment as part of its default attributes, including Amazon Elastic Compute Cloud (Amazon EC2) tags. YML option name Environment variable Type custom_attributes NRIA_CUSTOM_ATTRIBUTES map [ string]interface { } Use a list of custom attributes to annotate the data from this agent instance. Separate keys and values with colons :, as in KEY: VALUE, and separate each key-value pair with a line break. Keys can be any valid YAML except slashes /. Values can be any YAML string, including spaces. Example as a YAML attribute: custom_attributes: environment: production service: login service team: alpha-team Copy Example as an environment variable: NRIA_CUSTOM_ATTRIBUTES='{\"customAttribute_1\":\"SOME_ATTRIBUTE\",\"customAttribute_2\": \"SOME_ATTRIBUTE_2\"}' Copy NRQL example filtering by custom attribute: FROM SystemSample SELECT * WHERE environment = 'production' Copy enable_process_metrics Important Requires infrastructure agent version 1.12.0 or higher. Accounts created before July 20, 2020 and/or infrastructure agents installed using the new Guided Install have this variable enabled by default. Enables the sending of process metrics to New Relic. By default, the infrastructure agent doesn't send data about the operating system's processes. The agent still collects such data, unless metrics_process_sample_rate is set to -1. To report metric data about all the operating system's processes, set enable_process_metrics to true. To disable, set to false. Sending all process data could increase the volume of data sent to New Relic. To fine-tune which processes you want to monitor, configure include_matching_metrics. By default, processes using low memory are excluded from being sampled. For more information, see disable-zero-mem-process-filter. YML option name Environment variable Type Default Version enable_process_metrics NRIA_ENABLE_PROCESS_METRICS boolean false include_matching_metrics Important Currently, this setting only applies to an operating system's processes metrics. You can control how much data is sent to New Relic by configuring include_matching_metrics, which allows you to restrict the transmission of metric data based on the values of metric attributes. You include metric data by defining literal or partial values for any of the attributes of the metric. For example, you can choose to send the host.process.cpuPercent of all processes whose process.name match the ^java regular expression. In this example, we include process metrics using executable files and names: include_matching_metrics: # You can combine attributes from different metrics process.name: - regex “^java” # Include all processes starting with \"java\" process.executable: - “/usr/bin/python2” # Include the Python 2.x executable - regex “\\\\System32\\\\svchost” # Include all svchost executables Copy If you need to include command line arguments in any of the values, set strip_command_line to false (the infrastructure agents removes CLI arguments by default to prevent secrets from leaking). To configure include_matching_metrics as an environment variable for the Kubernetes integration, add it in the manifest inside the env: object: env: - name: NRIA_INCLUDE_MATCHING_METRICS value: | process.name: - regex \"^java\" process.executable: - \"/usr/bin/python2\" - regex \"\\\\System32\\\\svchost\" Copy Default YML option name Environment variable Type Default Version include_matching_metrics NRIA_INCLUDE_MATCHING_METRICS metric.attribute: - regex \"pattern\" - \"string\" - \"string-with-wildcard * \" network_interface_filters You can use the network interface filters configuration to hide unused or uninteresting network interfaces from the infrastructure agent. This helps reduce resource usage, work, and noise in your data. Important Environment variables are not supported for this configuration setting. The configuration uses a simple pattern-matching mechanism that can look for interfaces that start with a specific sequence of letters or numbers following either pattern: {name}[other characters], where you specify the name using the prefix option [number]{name}[other characters], where you specify the name using the index-1 option New Relic infrastructure implements a curated default list of filters, available for both Linux and Windows, that you can modify. YML option name Environment variable Type Default Version network_interface_filters not supported map [ string] [ ]string 1.0.220 Linux Default network interface filters for Linux: Network interfaces that start with dummy, lo, vmnet, sit, tun, tap, or veth Network interfaces that contain tun or tap The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with dummy or lo , or contain tun preceded by a sequence of numbers, and followed by other characters: network_interface_filters: prefix: - dummy - lo index-1: - tun Copy Windows Default network interface filters for Windows: Network interfaces that start with Loop, isatap, or Local The following example (added to your configuration file) overrides the default filters. This will ignore network interfaces that start with Loop: network_interface_filters: prefix: - Loop Copy disable_zero_mem_process_filter The ZeroRSSFilter excludes processes that are not using memory from being sampled. Disable the filter so that the agent includes these processes in the ProcessSample. YML option name Environment variable Type Default Version disable_zero_mem_process_filter NRIA_DISABLE_ZERO_MEM_PROCESS_FILTER boolean false 1.0.832 Plugins variables Tip You can quickly disable all the variables by setting DisableAllPlugins to true, and turn on only those options you need. disable_all_plugins To disable all the plugins, set this option to true. YML option name Environment variable Type Default Version disable_all_plugins NRIA_DISABLE_ALL_PLUGINS boolean false 1.2.1 cloud_security_group_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important This plugin is activated only if the agent is running in an AWS instance. YML option name Environment variable Type Default Version cloud_security_group_refresh_sec NRIA_CLOUD_SECURITY_GROUP_REFRESH_SEC int64 60 1.0.692 daemontools_interval_sec Sampling period for the Daemontoolsplugin, in seconds. The minimum value is a 10. To disable it, set it to -1. YML option name Environment variable Type Default Version daemontools_interval_sec NRIA_DAEMONTOOLS_INTERVAL_SEC int64 15 1.0.316 dpkg_interval_sec Sampling period for the Dpkg plugin, in seconds. The minimum value is 30. To disable it, set it to -1. If the parameter is not explicitly set in the config file, it can be disabled by setting DisableAllPlugins to true. Important This is only activated in root or privileged running modes and on Debian-based distributions. YML option name Environment variable Type Default Version dpkg_interval_sec NRIA_DPKG_INTERVAL_SEC int64 30 1.0.316 facter_interval_sec Sampling period for the Facter plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version facter_interval_sec NRIA_FACTER_INTERVAL_SEC int64 30 1.0.316 kernel_modules_refresh_sec Sampling period for the CloudSecurityGroups plugin, in seconds. The minimum value is 10. To disable it, set it to -1. Important kernel_modules_refresh_sec is only activated in root or privileged running modes. YML option name Environment variable Type Default Version kernel_modules_refresh_sec NRIA_KERNEL_MODULES_REFRESH_SEC int64 10 1.0.755 network_interface_interval_sec Sampling period for the NetworkInterface plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version network_interface_interval_sec NRIA_NETWORK_INTERFACE_INTERVAL_SEC int64 60 1.0.329 rpm_interval_sec Sampling period for the Rpm plugin, in seconds. The minimum value is 30. To disable it, set it to -1. Important rpm_interval_sec is only activated when the agent runs in root or privileged modes for RedHat, RedHat AWS, or SUSE distributions. YML option name Environment variable Type Default Version rpm_interval_sec NRIA_RPM_INTERVAL_SEC int64 30 1.0.316 selinux_interval_sec Sampling period for the SELinux plugin, in seconds. The minimum value is 30. To disable it, set it to -1. This option is ignored if SelinuxEnableSemodule is set to false. For more information, see our troubleshooting doc on disabling the SELinux module. Important SELinux is only activated when the agent runs in root mode. YML option name Environment variable Type Default Version selinux_interval_sec NRIA_SELINUX_INTERVAL_SEC int64 30 1.0.316 sshd_config_refresh_sec Sampling period for the Sshd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sshd_config_refresh_sec NRIA_SSHD_CONFIG_REFRESH_SEC int64 15 1.0.755 supervisor_interval_sec Sampling period for the Supervisor plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version supervisor_interval_sec NRIA_SUPERVISOR_INTERVAL_SEC int64 15 1.0.316 sysctl_interval_sec Sampling period for the Sysctl plugin, in seconds. The minimum value is 30. To disable it, set it to -1. YML option name Environment variable Type Default Version sysctl_interval_sec NRIA_SYSCTL_INTERVAL_SEC int64 60 1.0.316 systemd_interval_sec Sampling period for the Systemd plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version systemd_interval_sec NRIA_SYSTEMD_INTERVAL_SEC int64 30 1.0.316 sysvinit_interval_sec Sampling period for the sysv plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version sysvinit_interval_sec NRIA_SYSVINIT_INTERVAL_SEC int64 30 1.0.316 upstart_interval_sec Sampling period for the Upstart plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version upstart_interval_sec NRIA_UPSTART_INTERVAL_SEC int64 30 1.0.316 users_refresh_sec Sampling period for the Users plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version users_refresh_sec NRIA_USERS_REFRESH_SEC int64 30 1.0.755 supervisor_rpc_sock Location of the supervisor socket. YML option name Environment variable Type Default Version supervisor_rpc_sock NRIA_SUPERVISOR_RPC_SOCK string /var/run/supervisor.sock 1.0.2 facter_home_dir Sets the HOME environment variable for Puppet's Facter. If not defined, it defaults to the current user's home directory. YML option name Environment variable Type Default Version facter_home_dir NRIA_FACTER_HOME_DIR string 1.1.7 Proxy variables For infrastructure agent version 1.3.1 or higher, the precedence of the proxy configuration settings is: NRIA_PROXY proxy HTTP_PROXY HTTPS_PROXY proxy Your system may have firewall rules that require the agent to use a proxy to communicate with New Relic. If so, set the proxy URL in the form https://user:password@hostname:port. It can be HTTP or HTTPS. YML option name Environment variable Type Default Version proxy NRIA_PROXY string Empty 1.0.308 Example: https://proxy_user.access_10@proxy_01:1080 Copy ignore_system_proxy When set to true, the HTTPS_PROXY and HTTP_PROXY environment variables are ignored. This is useful when the agent needs to connect directly to the metrics collector and skip the existing system proxy. YML option name Environment variable Type Default Version ignore_system_proxy NRIA_IGNORE_SYSTEM_PROXY boolean false 1.0.1002 ca_bundle_dir If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the the directory where the proxy certificate is available. The certificates in the directory must end with the .pem extension. YML option name Environment variable Type Default Version ca_bundle_dir NRIA_CA_BUNDLE_DIR string 1.0.296 ca_bundle_file If the HTTPS_PROXY option references to a proxy with self-signed certificates, this option specifies the path to the certificate file. YML option name Environment variable Type Default Version ca_bundle_file NRIA_CA_BUNDLE_FILE string 1.0.296 proxy_validate_certificates If set to true, when the proxy is configured to use an HTTPS connection, it will only work: If the HTTPS proxy has certificates from a valid Certificate Authority. If the ca_bundle_file or ca_bundle_dir configuration properties contain the HTTPS proxy certificates. YML option name Environment variable Type Default Version proxy_validate_certificates NRIA_PROXY_VALIDATE_CERTIFICATES boolean false 1.3.0 proxy_config_plugin Sends the following proxy configuration information as inventory: HTTPS_PROXY HTTP_PROXY proxy ca_bundle_dir ca_bundle_file ignore_system_proxy proxy_validate_certificates YML option name Environment variable Type Default Version proxy_config_plugin NRIA_PROXY_CONFIG_PLUGIN boolean true 1.3.0 If you are having problems with proxy configuration, see Proxy troubleshooting. Samples variables metrics_network_sample_rate Sample rate of network samples, in seconds. Minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_network_sample_rate NRIA_METRICS_NETWORK_SAMPLE_RATE integer 10 1.0.308 metrics_process_sample_rate Sample rate of process samples, in seconds. Minimum value is 20. To disable process samples entirely, set metrics_process_sample_rate to -1. YML option name Environment variable Type Default Version metrics_process_sample_rate NRIA_METRICS_PROCESS_SAMPLE_RATE integer 20 1.0.308 metrics_storage_sample_rate Sample rate of storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_storage_sample_rate NRIA_METRICS_STORAGE_SAMPLE_RATE integer 5 1.0.308 metrics_system_sample_rate Sample rate of system samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_system_sample_rate NRIA_METRICS_SYSTEM_SAMPLE_RATE integer 5 1.0.308 metrics_nfs_sample_rate Sample rate of NFS storage samples, in seconds. Minimum value is 5. To disable it, set it to -1. YML option name Environment variable Type Default Version metrics_nfs_sample_rate NRIA_METRICS_NFS_SAMPLE_RATE integer 20 1.5.40 detailed_nfs Detailed NFS metrics. When enabled, the agent will provide a complete list of NFS metrics. YML option name Environment variable Type Default Version detailed_nfs NRIA_DETAILED_NFS boolean false 1.5.40 Security variables selinux_enable_semodule Get versions of policy modules installed using SEModule. If disabled, the SELinux plugin will only retrieve the status using SEStatus. YML option name Environment variable Type Default Version selinux_enable_semodule NRIA_SELINUX_ENABLE_SEMODULE boolean true 1.0.864 strip_command_line When true, the agent removes the command arguments from the commandLine attribute of the ProcessSample. Tip This is a security measure to prevent leaking sensitive information. YML option name Environment variable Type Default Version strip_command_line NRIA_STRIP_COMMAND_LINE boolean true 1.0.149 Windows variables windows_services_refresh_sec Sampling period for the Windows services plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_services_refresh_sec NRIA_WINDOWS_SERVICES_REFRESH_SEC int64 30 1.0.755 windows_updates_refresh_sec Sampling period for the Windows updates plugin, in seconds. The minimum value is 10. To disable it, set it to -1. YML option name Environment variable Type Default Version windows_updates_refresh_sec NRIA_WINDOWS_UPDATES_REFRESH_SEC int64 60 1.0.755 app_data_dir Defines the path to store data in a different path than the program files directory: %AppDir%/data: Used for storing the delta data %AppDir%/user_data: External directory for user-generated JSON files %AppDir%/newrelic-infra.log: If log file config option is not defined, then we use this directory path as default. YML option name Environment variable Type Default Version app_data_dir NRIA_APP_DATA_DIR string Windows: env(ProgramData)\\New Relic\\newrelic-infra Linux: Not applicable 1.0.755 enable_win_update_plugin Enables the Windows updates plugin, which retrieves the lists of hotfixes that are installed on the host. YML option name Environment variable Type Default Version enable_win_update_plugin NRIA_ENABLE_WIN_UPDATE_PLUGIN boolean false 1.0.274 legacy_storage_sampler If true, the agent will be forced to use Windows WMI (the agent's legacy method to grab metrics for Windows; for example, StorageSampler) and will disable the new method (which uses the PDH library). YML option name Environment variable Type Default Version legacy_storage_sampler NRIA_LEGACY_STORAGE_SAMPLER boolean 1.0.1051 win_process_priority_class This configuration option allows to increase the newrelic-infra.exe process priority to any of the following values: Normal Idle High RealTime BelowNormal AboveNormal YML option name Environment variable Type Default Version win_process_priority_class NRIA_WIN_PROCESS_PRIORITY_CLASS string 1.0.989 Example: Normal Copy win_removable_drives Enables the Windows agent to report drives A: and B: when they are mapped as removable drives. YML option name Environment variable Type Default Version win_removable_drives NRIA_WIN_REMOVABLE_DRIVES boolean true 1.3.1 What's next? You can also: Further understand the configuration of the agent. Create a configuration file using our template. See how you can manage the agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 309.0102,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>agent</em> configuration settings ",
        "sections": "<em>Infrastructure</em> <em>agent</em> configuration settings",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": " management, you can configure on-host integrations with New Relic <em>Infrastructure</em>&#x27;s <em>agent</em> to use sensitive data (such as passwords) without having to write them as plain text into the integration&#x27;s configuration file. For more information, see Secrets management. custom_plugin_<em>installation</em>_dir Specifies"
      },
      "id": "603ea542196a67a38aa83dd8"
    },
    {
      "sections": [
        "Zip assisted install of the infrastructure agent for Windows",
        "Install the agent",
        "Important",
        "Configure your installation",
        "What's next?"
      ],
      "title": "Zip assisted install of the infrastructure agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "fcadbeed626401863b6b16e5c52e9a472a5ac13e",
      "image": "https://docs.newrelic.com/static/6ca3d6d18f535376b153baaece37fdcb/0abdd/Infra-windows-files.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/zip-assisted-install-infrastructure-agent-windows/",
      "published_at": "2021-06-20T04:43:40Z",
      "updated_at": "2021-04-16T02:59:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the assisted install of the infrastructure agent for Windows, you can make the changes you need to the installation script we provide so you can adapt it to your environment. Before installation, make sure to check the compatibility and requirements. Install the agent Important As of version 1.4.0, the infrastructure agent package includes the additional newrelic-infra-ctl binary, which is used to help troubleshoot a running agent. Although this binary is not required to execute the agent, we recommend to add it in your path. See our docs for more information. To install the agent: Download the packaged agent file. Unpack the file. Make sure the file unpacks with the following structure: Once it's unpacked, access and edit the installation PowerShell script installer.ps1. Update your license key. Optional: Update any other parameters. Execute installer.ps1 with admin rights. Configure your installation Important Make sure any custom folder defined in the installation settings has permissions limitations properly defined. The infrastructure agent might execute any integration defined in the NRIA_PLUGIN_DIR directory with Administrator permissions. You can configure the following parameters during the assisted install for Windows: Variable Description NRIA_AGENT_DIR Required at agent startup. The agent home directory. Default: C:\\Program Files\\New Relic\\newrelic-infra Copy NRIA_APP_DATA_DIR This configures the data directory to store inventory and other agent files. Default: C:\\%ProgramData%\\New Relic\\newrelic-infra Copy NRIA_CONFIG_FILE Required at installation. The agent configuration file's location. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.yml Copy NRIA_LICENSE_KEY Only configuration option required at startup. The New Relic license key. NRIA_LOG_FILE Required at agent startup. The location where the agent will log. Default: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-infra.log Copy NRIA_OVERWRITE By default and for security reasons, Windows does not install a service if there's another service with the same name already installed. To bypass this check, make sure this setting NRIA_OVERWRITE is TRUE. Default: TRUE Copy NRIA_PLUGIN_DIR Required at agent startup. The directory containing the configuration files of the integrations. Default: C:\\Program Files\\NewRelic\\newrelic-infra\\inregrations.d Copy NRIA_SERVICE_NAME This provides the name for the Windows service. What's next? You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Add other New Relic infrastructure integrations to collect data from external services. Manually start, stop, restart, or check the agent status.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 290.23056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "sections": "Zip assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": "With the assisted <em>install</em> of the <em>infrastructure</em> <em>agent</em> for <em>Windows</em>, you can make the changes you need to the <em>installation</em> script we provide so you can adapt it to your environment. Before <em>installation</em>, make sure to check the compatibility and requirements. <em>Install</em> the <em>agent</em> Important As of version"
      },
      "id": "603ea7af196a67dab0a83d9d"
    },
    {
      "sections": [
        "Install the infrastructure monitoring agent for Windows",
        "Tip",
        "Install for Windows Server and Windows 10 using our wizard",
        "Step-by-step instructions",
        "PowerShell install",
        "32-bit Windows",
        "64-bit Windows",
        "Step-by-step install",
        "Important",
        "Scripted installation",
        "What's next?",
        "Install using zip files",
        "Caution",
        "Update the agent"
      ],
      "title": "Install the infrastructure monitoring agent for Windows",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Windows installation"
      ],
      "external_id": "32766f16044664c9c7d66075801930ff53ca5c49",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/",
      "published_at": "2021-06-20T04:42:34Z",
      "updated_at": "2021-03-13T01:56:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's infrastructure monitoring agent for Windows, you can monitor individual servers and also analyze how your service performs as a whole. The Windows agent can run on your own hardware or in cloud systems such as Amazon EC2 or Windows Azure. The infrastructure monitoring agent supports Windows Server and Windows 10. You can also install with Chef. Tip To use infrastructure monitoring and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Install for Windows Server and Windows 10 using our wizard Before installation, be sure to review the requirements. Then, to install the infrastructure monitoring agent for Windows, you can use our launcher, or follow the instructions in this document to complete a basic installation. Windows If you don't have a New Relic account yet, or prefer to follow the procedure manually, follow our step-by-step tutorial, which follows. Step-by-step instructions To install the infrastructure monitoring agent, use our PowerShell script, or follow the step-by-step instructions: PowerShell install Review the agent requirements and supported operating systems. Open the PowerShell as administrator and run the following command: 32-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy 64-bit Windows $LICENSE_KEY=\"YOUR_LICENSE_KEY\"; ` (New-Object System.Net.WebClient).DownloadFile(\"https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi\", \"$env:TEMP\\newrelic-infra.msi\"); ` msiexec.exe /qn /i \"$env:TEMP\\newrelic-infra.msi\" GENERATE_CONFIG=true LICENSE_KEY=\"$LICENSE_KEY\" | Out-Null; ` net start newrelic-infra Copy For a scripted installation, you can pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Step-by-step install Review the infrastructure monitoring agent requirements and supported operating systems. Download the latest .MSI installer image from: 32-bit Windows https://download.newrelic.com/infrastructure_agent/windows/386/newrelic-infra-386.msi​ Copy 64-bit Windows https://download.newrelic.com/infrastructure_agent/windows/newrelic-infra.msi Copy Important Do not double-click the installer. This will not fully install the local agent and can result in permissions issues. In an admin account, run the install script using an absolute path. 32-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra-386.msi Copy 64-bit Windows To install from the Windows command prompt, run: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy Scripted installation For a scripted installation, you can also pass in configuration parameters. You must first add GENERATE_CONFIG=true and LICENSE_KEY=YOUR_LICENSE_KEY. You may then add these optional config settings: DISPLAY_NAME=YOUR_DISPLAY_NAME PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1','ATTRIBUTE_2':'VALUE_2'}\" The following example sets the license key and configures a proxy server for outbound communication, as well as adding one custom attribute: msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi GENERATE_CONFIG=true LICENSE_KEY=YOUR_LICENSE_KEY PROXY=http://YOUR_PROXY_SERVER:PROXY_PORT CUSTOM_ATTRIBUTES=\"{'ATTRIBUTE_1':'VALUE_1'}\" Copy Add your New Relic license key to the license_key attribute in newrelic-infra.yml, located in C:\\Program Files\\New Relic\\newrelic-infra\\. When finished, the contents of newrelic-infra.yml should resemble the following: license_key: YOUR_LICENSE_KEY Copy Start the newrelic-infra service. To start from the Windows command prompt, run: net start newrelic-infra Copy Wait a few minutes, then view your server in the Infrastructure UI. If no data appears after waiting a few minutes, follow the troubleshooting steps. Tip As of version 1.4.0, the infrastructure monitoring agent package includes newrelic-infra-ctl, which is used to help troubleshoot a running agent. We recommend adding it to PATH. What's next? The only required configuration option is the license_key setting, which is created as part of the installation procedures. You may also want to: Add custom attributes to annotate your infrastructure data. Connect your AWS account if your servers are hosted on Amazon EC2. Enable log forwarding. Add other New Relic infrastructure integrations to collect data from external services. Install using zip files For custom setup scenarios, you can install the infrastructure monitoring agent using our zip files in assisted or manual modes. This is especially useful when you need to adapt the default installation settings to your environment. Caution Installing the infrastructure monitoring agent using zip files is not supported. Update the agent To upgrade to the latest version, follow standard procedures to update the infrastructure monitoring agent.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.9369,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "sections": "<em>Install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>",
        "tags": "<em>Install</em> the <em>infrastructure</em> <em>agent</em>",
        "body": ". <em>Install</em> for <em>Windows</em> Server and <em>Windows</em> 10 using our wizard Before <em>installation</em>, be sure to review the requirements. Then, to <em>install</em> the <em>infrastructure</em> monitoring <em>agent</em> for <em>Windows</em>, you can use our launcher, or follow the instructions in this document to complete a basic <em>installation</em>. <em>Windows</em> If you don&#x27;t"
      },
      "id": "6044672464441f9bb6378ed9"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-21T00:02:45Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.48196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-20T22:10:28Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.94,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-20T09:29:28Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-21T00:02:45Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.48196,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-20T09:29:28Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-20T06:20:14Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics": [
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-20T22:10:28Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "Manage infrastructure data reporting"
      ],
      "title": "Manage infrastructure data reporting",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "7cd87ba8f7686e9233f4171021607d499bf6bc72",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting/",
      "published_at": "2021-06-20T09:29:28Z",
      "updated_at": "2021-03-16T07:33:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you use the infrastructure agent or on-host integrations that report data via the infrastructure agent, there are several ways to configure data reporting. Here are two common options for managing data reporting: Enable/disable process metrics Select specific attributes to report For other agent configuration options, see Configuration. For our infrastructure integrations, you can also change the frequency of data reporting: For on-host integrations: use a specific integration's interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic data management in general, see Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "sections": "<em>Manage</em> <em>infrastructure</em> <em>data</em> reporting",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " configuration options, see Configuration. For our <em>infrastructure</em> integrations, you can also change the frequency of <em>data</em> reporting: For on-host integrations: use a specific integration&#x27;s interval configuration setting. For cloud integrations (AWS, Azure, Google Cloud): edit the polling frequency. For more about New Relic <em>data</em> management in general, see <em>Manage</em> <em>data</em>."
      },
      "id": "603e775a196a67f470a83de4"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-20T06:20:14Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/manage-your-data/data-instrumentation/manage-infrastructure-data-reporting": [
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-21T00:02:45Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.48187,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-20T22:10:28Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.93999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host filter sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    },
    {
      "sections": [
        "APM data in infrastructure monitoring",
        "How to integrate APM and infrastructure data",
        "View APM charts",
        "Filter by application data",
        "Tip",
        "Switch between infrastructure and APM",
        "APM data in Inventory and Events",
        "View host data in APM",
        "Troubleshoot missing APM data"
      ],
      "title": "APM data in infrastructure monitoring",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "ac221ae748f8f2eb5a0ab7373853c5ea78974e41",
      "image": "https://docs.newrelic.com/static/4ab30e9528ae8a5121a1691143f80d44/ff42b/Infrastructure-APM-application-data-chart.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/apm-data-infrastructure-monitoring/",
      "published_at": "2021-06-20T06:20:14Z",
      "updated_at": "2021-03-16T07:33:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The integration of APM and infrastructure data lets you see your APM data and infrastructure data side by side so you can find the root cause of problems more quickly. Let's look at how the APM-Infrastructure integration works and how to make use of the shared data. The main ways to find and use APM data in infrastructure monitoring are: View APM charts on Infrastructure monitoring UI pages Filter hosts by application data Switch between Infrastructure and APM Examine APM data in Inventory and Events pages Infrastructure data appears in APM in the host table on the APM Summary page. How to integrate APM and infrastructure data For APM and infrastructure data to be integrated, all of the following must be true: The APM agent and the infrastructure agent must be installed on the same host. Both agents must use the same New Relic license key. They must use the same hostname. If the integration is not working, see Troubleshooting the APM-Infrastructure integration. View APM charts When your APM and infrastructure data is linked, you have access to APM data charts on these Infrastructure monitoring UI pages: Hosts, Network, Storage, and Processes. To switch to different charts: select the dropdown beside a chart's name and choose a new chart. Application-related charts will be near the top. one.newrelic.com > Infrastructure > Hosts: If your APM and Infrastructure data is linked, the charts in Infrastructure monitoring can be changed to show your application data. Filter by application data When your APM and infrastructure data is linked, you can filter displayed host data using Applications: From the host filter, select Applications. Select the application you want to filter on. Tip On the Hosts page, you can also filter by selecting items in the Applications column. Switch between infrastructure and APM When your APM and infrastructure accounts are linked, you can switch over from infrastructure to APM and vice versa for the same selected time range. You can switch from infrastructure to APM from these locations: From the host filter Applications menu On the Hosts page, when selecting applications in the Applications table column. You can switch from APM to infrastructure from the host table on the APM Summary page. APM data in Inventory and Events When your APM and infrastructure data is linked, you can view and filter on application data on the Infrastructure monitoring UI's Inventory page and the Events page. View host data in APM When your APM and infrastructure data is linked, you have more available host data in APM. The APM Summary page contains a table with data about your app's hosts and instances, including: Apdex Response time Throughput Error rate CPU usage Memory You can toggle between a table view or breakout metric details for the individual hosts by selecting View table or Break out each metric by host. For more information on host data on the APM Summary page, see host details. Troubleshoot missing APM data APM/Infrastructure integration should happen automatically if you have both the APM agent and the infrastructure agent installed on the same host(s) and they use the same New Relic license key and have the same hostname set. If you do not see APM data in infrastructure monitoring, see Troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.3609,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "sections": "APM <em>data</em> in <em>infrastructure</em> monitoring",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "The integration of APM and <em>infrastructure</em> <em>data</em> lets you see <em>your</em> APM <em>data</em> and <em>infrastructure</em> <em>data</em> side by side so you can find the root cause of problems more quickly. Let&#x27;s look at how the APM-<em>Infrastructure</em> integration works and how to make use of the shared <em>data</em>. The main ways to find and use"
      },
      "id": "603e88b2e7b9d246932a07f6"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts": [
    {
      "sections": [
        "Group infrastructure results by specific attributes",
        "Group charts by specific attributes",
        "Combine filter sets and grouping",
        "Increased CPU usage on a single host"
      ],
      "title": "Group infrastructure results by specific attributes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "8436b1d0391cd7caa2a79c4080528697ff7a012d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes/",
      "published_at": "2021-06-20T20:53:44Z",
      "updated_at": "2021-03-11T10:49:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our infrastructure monitoring tool, you can use the Group by feature to group chart results by specific attributes. For example, on the Hosts page, you might display the AWS regions with the highest CPU usage grouped by awsRegion. Group by is available near the top of some infrastructure monitoring UI pages. Group charts by specific attributes On some infrastructure pages you can use Group by to group page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to group by will depend on your system setup. These may include: Default infrastructure attributes Custom attributes APM-related attributes To group infrastructure results by a specific attribute: On pages that have this feature, select Group by (located beside the time picker). From the dropdown, select an attribute to group by. Combine filter sets and grouping Grouping applies to any filter sets you have selected. By combining filter sets with Group by, you can find detailed system information quickly. Increased CPU usage on a single host On the Filter sets sidebar, you see alert threshold violations as Critical icon or Warning icon on one of your filter sets. To view only the hosts related to the filter set on your Hosts page, click the filter set name. To determine which of the hosts is causing the problem, select Group by, then select the hostname attribute. Review the charts which now show the hosts, by name, with the highest CPU usage.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.77629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "sections": "<em>Group</em> <em>infrastructure</em> results by specific attributes",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " monitoring UI pages. <em>Group</em> charts by specific attributes On some <em>infrastructure</em> pages you can use <em>Group</em> by to <em>group</em> page results and charts by a specific attribute, such as host name, entity ID, or AWS region. The attributes available to <em>group</em> by will depend on <em>your</em> system setup. These may include: Default"
      },
      "id": "6043edcd64441fd920378ecf"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-21T00:02:45Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.06235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-20T22:10:28Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.36444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/filter-group/group-infrastructure-results-specific-attributes": [
    {
      "sections": [
        "Filter sets: Organize your hosts",
        "Benefits of filter sets",
        "Create filter sets",
        "Edit filter sets",
        "Delete filter sets",
        "Combine filter sets with grouping",
        "Copy filters from filter set to alerts",
        "Important",
        "Filter set logic",
        "Inclusion and exclusion",
        "Recommended: Select values by matching a string",
        "Tip",
        "Select values individually",
        "And/Or"
      ],
      "title": "Filter sets: Organize your hosts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Filter and group"
      ],
      "external_id": "ae70ce239865f3cb006e2ed47fc9bf3fc0598d81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/filter-group/filter-sets-organize-your-infrastructure-hosts/",
      "published_at": "2021-06-20T04:25:56Z",
      "updated_at": "2021-03-11T08:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic infrastructure monitoring, you can combine filters into a filter set to organize hosts based on criteria that matter the most to you. Read on to learn about the benefits, use, and logic of filter sets. Benefits of filter sets You can create filter sets using available attributes or tags. For example, you can organize your infrastructure into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share filter sets with other people in your account, and you can quickly identify infrastructure problems by checking the color-coded health status of each host in the filter set. Create filter sets The default infrastructure filter set is All hosts, and it serves as a template for you to create filter sets. To create a filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. If All hosts is not displayed in the left sidebar, open that filter set by selecting Saved filter sets > All hosts. In All hosts, click Filter hosts. In the list, click an item to see a list of values. Click Include or Exclude (see Filter set logic). Click values individually or enter text to match multiple values. Continue adding filters until you have the filter set you want. To name your filter, click the icon, type a name, and click Save. Edit filter sets To change an existing filter set: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. In the sidebar, click an option to update your filter set, and then save. Delete filter sets You can delete any saved filter set except the default All hosts. Go to one.newrelic.com > Infrastructure > Settings > Filter sets. Click to delete the filter set. Combine filter sets with grouping On some pages you can use Group by to group chart results by specific attributes. For example, on the Hosts page, you can group by awsRegion to display the AWS regions with the highest CPU usage. Grouping applies to the selected filter sets. By combining filter sets with grouping, you can find detailed system information quickly. For an example of using these tools to troubleshoot a problem, see Combining filter sets and grouping. Copy filters from filter set to alerts When you create an alert condition, you can build filters individually, or you can copy all the filters from a filter set into a new alert condition. This is a quick shortcut to populate a new alert condition with some filters. Important When you copy filter set filters to a new alert condition, these filters are no longer tied to the filter set. If you make changes to the filter set, the alert filters are not affected. To copy filter set filters to a new alert condition: Go to one.newrelic.com > Infrastructure and click Hosts, Inventory, or Events. In the sidebar, click Saved filter sets to open a list. Locate the filter set by scrolling or by entering a search term. Click the filter set to open it. Mouse over any chart and click > Create alert. Enter an alert condition name. Make adjustments to filters as necessary. Complete the remaining alert fields (see Create alert conditions). Filter set logic When you create a filter set, you generate a list of attributes and/or tags that narrow the results. This section explains how filter sets apply various rules to the list. Inclusion and exclusion As part of building a filter set, you designate whether a filter should include or exclude entities that match certain values. The way the inclusion or exclusion works depends on how you select values: Recommended: Select values by matching a string You can generate a list of values by entering a string that you want values to match. This is useful for matching multiple values. Tip String matching efficiently generates a list of values, and this approach scales as you add new entities. Here is the logic filter sets use with string matching: Comparator Logic Include If you click Include and then enter a string that you want values to match, the filter uses the comparator LIKE, which means the results include any entities that are like the string. For example, you could filter by the term East-, and all entities that contain that term are returned. Exclude If you click Exclude and then enter a string that you want values to match, the filter uses the comparator NOT LIKE, which means the results exclude any entities that are like the string. For example, you could filter by the term West-, and all entities that do not contain that term are returned. Select values individually You can click through the list of attributes/tags to identify individual values. Tip This approach does not scale well if you add new entities. Here is the logic filter sets use with individual value selection: Comparator Logic Include If you click Include and then click specific values, the filter uses the comparator IN, which means the filter looks for entities that exactly match one or more values in your list of selections. Exclude If you click Exclude and then click specific values, the filter set uses the comparator NOT IN, which means the filter returns all entities that do not exactly match one or more values in your list of selections. And/Or Filter sets use the logical operators AND and OR behind the scenes to join the data. Here are the rules for AND and OR: When you click values from multiple attributes or tags, they are joined by AND. When you click values from within an attribute or tags, they are joined by OR. The filter results display hosts for which both of the following are true: Hosts containing any one of the selected infrastructure agent versions Hosts in any one of the selected AWS availability zones",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.7629,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "sections": "<em>Filter</em> sets: Organize <em>your</em> hosts",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": " or tags. For example, you can organize <em>your</em> <em>infrastructure</em> into categories such as: Regions Operating system versions Hosts associated with Docker containers Test environments You can share <em>filter</em> sets with other people in <em>your</em> account, and you can quickly identify <em>infrastructure</em> problems by checking"
      },
      "id": "6043ed8ee7b9d289955799cb"
    },
    {
      "sections": [
        "On-host integrations metrics",
        "New Relic Integrations Metrics"
      ],
      "title": "On-host integrations metrics",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "fe96c0c4950380504b1a33c3ad861bcb17507cba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/host-integrations-metrics/",
      "published_at": "2021-06-21T00:02:45Z",
      "updated_at": "2021-06-15T01:04:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our infrastructure integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent cpuPercent Agent host.cpuStealPercent cpuStealPercent Agent host.cpuSystemPercent cpuSystemPercent Agent host.cpuUserPercent cpuUserPercent Agent host.disk.avgQueueLen avgQueueLen Agent host.disk.avgReadQueueLen avgReadQueueLen Agent host.disk.avgWriteQueueLen avgWriteQueueLen Agent host.disk.currentQueueLen currentQueueLen Agent host.disk.freeBytes diskFreeBytes Agent host.disk.freePercent diskFreePercent Agent host.disk.inodesFree inodesFree Agent host.disk.inodesTotal inodesTotal Agent host.disk.inodesUsed inodesUsed Agent host.disk.inodesUsedPercent inodesUsedPercent Agent host.disk.readBytesPerSecond readBytesPerSecond Agent host.disk.readIoPerSecond readIoPerSecond Agent host.disk.readUtilizationPercent readUtilizationPercent Agent host.disk.readWriteBytesPerSecond readWriteBytesPerSecond Agent host.disk.totalBytes diskTotalBytes Agent host.disk.totalUtilizationPercent totalUtilizationPercent Agent host.disk.usedBytes diskUsedBytes Agent host.disk.usedPercent diskUsedPercent Agent host.disk.writeBytesPerSecond writeBytesPerSecond Agent host.disk.writeIoPerSecond writeIoPerSecond Agent host.disk.writeUtilizationPercent writeUtilizationPercent Agent host.diskFreeBytes diskFreeBytes Agent host.diskFreePercent diskFreePercent Agent host.diskReadsPerSecond diskReadsPerSecond Agent host.diskReadUtilizationPercent diskReadUtilizationPercent Agent host.diskTotalBytes diskTotalBytes Agent host.diskUsedBytes diskUsedBytes Agent host.diskUsedPercent diskUsedPercent Agent host.diskUtilizationPercent diskUtilizationPercent Agent host.diskWritesPerSecond diskWritesPerSecond Agent host.diskWriteUtilizationPercent diskWriteUtilizationPercent Agent host.loadAverageFifteenMinute loadAverageFifteenMinute Agent host.loadAverageFiveMinute loadAverageFiveMinute Agent host.loadAverageOneMinute loadAverageOneMinute Agent host.memoryFreeBytes memoryFreeBytes Agent host.memoryFreePercent memoryFreePercent Agent host.memoryTotalBytes memoryTotalBytes Agent host.memoryUsedBytes memoryUsedBytes Agent host.memoryUsedPercent memoryUsedPercent Agent host.net.receiveBytesPerSecond receiveBytesPerSecond Agent host.net.receiveDroppedPerSecond receiveDroppedPerSecond Agent host.net.receiveErrorsPerSecond receiveErrorsPerSecond Agent host.net.receivePacketsPerSecond receivePacketsPerSecond Agent host.net.transmitBytesPerSecond transmitBytesPerSecond Agent host.net.transmitDroppedPerSecond transmitDroppedPerSecond Agent host.net.transmitErrorsPerSecond transmitErrorsPerSecond Agent host.net.transmitPacketsPerSecond transmitPacketsPerSecond Agent host.process.cpuPercent cpuPercent Agent host.process.cpuSystemPercent cpuSystemPercent Agent host.process.cpuUserPercent cpuUserPercent Agent host.process.fileDescriptorCount fileDescriptorCount Agent host.process.ioReadBytesPerSecond ioReadBytesPerSecond Agent host.process.ioReadCountPerSecond ioReadCountPerSecond Agent host.process.ioTotalReadBytes ioTotalReadBytes Agent host.process.ioTotalReadCount ioTotalReadCount Agent host.process.ioTotalWriteBytes ioTotalWriteBytes Agent host.process.ioTotalWriteCount ioTotalWriteCount Agent host.process.ioWriteBytesPerSecond ioWriteBytesPerSecond Agent host.process.ioWriteCountPerSecond ioWriteCountPerSecond Agent host.process.memoryResidentSizeBytes memoryResidentSizeBytes Agent host.process.memoryVirtualSizeBytes memoryVirtualSizeBytes Agent host.process.threadCount threadCount Agent host.swapFreeBytes swapFreeBytes Agent host.swapTotalBytes swapTotalBytes Agent host.swapUsedBytes swapUsedBytes Apache apache.server.busyWorkers server.busyWorkers Apache apache.server.idleWorkers server.idleWorkers Apache apache.server.net.bytesPerSecond net.bytesPerSecond Apache apache.server.net.requestsPerSecond net.requestsPerSecond Apache apache.server.scoreboard.closingWorkers server.scoreboard.closingWorkers Apache apache.server.scoreboard.dnsLookupWorkers server.scoreboard.dnsLookupWorkers Apache apache.server.scoreboard.finishingWorkers server.scoreboard.finishingWorkers Apache apache.server.scoreboard.idleCleanupWorkers server.scoreboard.idleCleanupWorkers Apache apache.server.scoreboard.keepAliveWorkers server.scoreboard.keepAliveWorkers Apache apache.server.scoreboard.loggingWorkers server.scoreboard.loggingWorkers Apache apache.server.scoreboard.readingWorkers server.scoreboard.readingWorkers Apache apache.server.scoreboard.startingWorkers server.scoreboard.startingWorkers Apache apache.server.scoreboard.totalWorkers server.scoreboard.totalWorkers Apache apache.server.scoreboard.writingWorkers server.scoreboard.writingWorkers Cassandra cassandra.node.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.node.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.node.client.connectedNativeClients client.connectedNativeClients Cassandra cassandra.node.commitLogCompletedTasksPerSecond db.commitLogCompletedTasksPerSecond Cassandra cassandra.node.commitLogPendingTasks db.commitLogPendindTasks Cassandra cassandra.node.commitLogTotalSizeBytes db.commitLogTotalSizeBytes Cassandra cassandra.node.droppedBatchRemoveMessagesPerSecond db.droppedBatchRemoveMessagesPerSecond Cassandra cassandra.node.droppedBatchStoreMessagesPerSecond db.droppedBatchStoreMessagesPerSecond Cassandra cassandra.node.droppedCounterMutationMessagesPerSecond db.droppedCounterMutationMessagesPerSecond Cassandra cassandra.node.droppedHintMessagesPerSecond db.droppedHintMessagesPerSecond Cassandra cassandra.node.droppedMutationMessagesPerSecond db.droppedMutationMessagesPerSecond Cassandra cassandra.node.droppedPagedRangeMessagesPerSecond db.droppedPagedRangeMessagesPerSecond Cassandra cassandra.node.droppedRangeSliceMessagesPerSecond db.droppedRangeSliceMessagesPerSecond Cassandra cassandra.node.droppedReadMessagesPerSecond db.droppedReadMessagesPerSecond Cassandra cassandra.node.droppedReadRepairMessagesPerSecond db.droppedReadRepairMessagesPerSecond Cassandra cassandra.node.droppedRequestResponseMessagesPerSecond db.droppedRequestResponseMessagesPerSecond Cassandra cassandra.node.droppedTraceMessagesPerSecond db.droppedTraceMessagesPerSecond Cassandra cassandra.node.keyCacheCapacityBytes db.keyCacheCapacityBytes Cassandra cassandra.node.keyCacheHitRate db.keyCacheHitRate Cassandra cassandra.node.keyCacheHitsPerSecond db.keyCacheHitsPerSecond Cassandra cassandra.node.keyCacheRequestsPerSecond db.keyCacheRequestsPerSecond Cassandra cassandra.node.keyCacheSizeBytes db.keyCacheSizeBytes Cassandra cassandra.node.liveSsTableCount db.liveSSTableCount Cassandra cassandra.node.loadBytes db.loadBytes Cassandra cassandra.node.query.casReadRequestsPerSecond query.CASReadRequestsPerSecond Cassandra cassandra.node.query.casWriteRequestsPerSecond query.CASWriteRequestsPerSecond Cassandra cassandra.node.query.rangeSliceRequestsPerSecond query.rangeSliceRequestsPerSecond Cassandra cassandra.node.query.rangeSliceTimeoutsPerSecond query.rangeSliceTimeoutsPerSecond Cassandra cassandra.node.query.rangeSliceUnavailablesPerSecond query.rangeSliceUnavailablesPerSecond Cassandra cassandra.node.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.node.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.node.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.node.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.node.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.node.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.node.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.node.query.readTimeoutsPerSecond query.readTimeoutsPerSecond Cassandra cassandra.node.query.readUnavailablesPerSecond query.readUnavailablesPerSecond Cassandra cassandra.node.query.viewWriteRequestsPerSecond query.viewWriteRequestsPerSecond Cassandra cassandra.node.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.node.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.node.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.node.query.writeTimeoutsPerSecond query.writeTimeoutsPerSecond Cassandra cassandra.node.query.writeUnavailablesPerSecond query.writeUnavailablesPerSecond Cassandra cassandra.node.rowCacheCapacityBytes db.rowCacheCapacityBytes Cassandra cassandra.node.rowCacheHitRate db.rowCacheHitRate Cassandra cassandra.node.rowCacheHitsPerSecond db.rowCacheHitsPerSecond Cassandra cassandra.node.rowCacheRequestsPerSecond db.rowCacheRequestsPerSecond Cassandra cassandra.node.rowCacheSizeBytes db.rowCacheSizeBytes Cassandra cassandra.node.storage.exceptionCount storage.exceptionCount Cassandra cassandra.node.threadPool.antiEntropyStage.activeTasks db.threadpool.internalAntiEntropyStageActiveTasks Cassandra cassandra.node.threadPool.antiEntropyStage.completedTasks db.threadpool.internalAntiEntropyStageCompletedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.currentlyBlockedTasks db.threadpool.internalAntiEntropyStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.antiEntropyStage.pendingTasks db.threadpool.internalAntiEntropyStagePendingTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.activeTasks db.threadpool.internalCacheCleanupExecutorActiveTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.completedTasks db.threadpool.internalCacheCleanupExecutorCompletedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.currentlyBlockedTasks db.threadpool.internalCacheCleanupExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.cacheCleanupExecutor.pendingTasks db.threadpool.internalCacheCleanupExecutorPendingTasks Cassandra cassandra.node.threadPool.compactionExecutor.activeTasks db.threadpool.internalCompactionExecutorActiveTasks Cassandra cassandra.node.threadPool.compactionExecutor.completedTasks db.threadpool.internalCompactionExecutorCompletedTasks Cassandra cassandra.node.threadPool.compactionExecutor.currentlyBlockedTasks db.threadpool.internalCompactionExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.compactionExecutor.pendingTasks db.threadpool.internalCompactionExecutorPendingTasks Cassandra cassandra.node.threadPool.counterMutationStage.activeTasks db.threadpool.requestCounterMutationStageActiveTasks Cassandra cassandra.node.threadPool.counterMutationStage.completedTasks db.threadpool.requestCounterMutationStageCompletedTasks Cassandra cassandra.node.threadPool.counterMutationStage.currentlyBlockedTasks db.threadpool.requestCounterMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.counterMutationStage.pendingTasks db.threadpool.requestCounterMutationStagePendingTasks Cassandra cassandra.node.threadPool.gossipStage.activeTasks db.threadpool.internalGossipStageActiveTasks Cassandra cassandra.node.threadPool.gossipStage.completedTasks db.threadpool.internalGossipStageCompletedTasks Cassandra cassandra.node.threadPool.gossipStage.currentlyBlockedTasks db.threadpool.internalGossipStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.gossipStage.pendingTasks db.threadpool.internalGossipStagePendingTasks Cassandra cassandra.node.threadPool.hintsDispatcher.activeTasks db.threadpool.internalHintsDispatcherActiveTasks Cassandra cassandra.node.threadPool.hintsDispatcher.completedTasks db.threadpool.internalHintsDispatcherCompletedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.currentlyBlockedTasks db.threadpool.internalHintsDispatcherCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.hintsDispatcher.pendingTasks db.threadpool.internalHintsDispatcherPendingTasks Cassandra cassandra.node.threadPool.internalResponseStage.activeTasks db.threadpool.internalInternalResponseStageActiveTasks Cassandra cassandra.node.threadPool.internalResponseStage.completedTasks db.threadpool.internalInternalResponseStageCompletedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pCurrentlyBlockedTasks db.threadpool.internalInternalResponseStagePCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.internalResponseStage.pendingTasks db.threadpool.internalInternalResponseStagePendingTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.activeTasks db.threadpool.internalMemtableFlushWriterActiveTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.completedTasks db.threadpool.internalMemtableFlushWriterCompletedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.currentlyBlockedTasks db.threadpool.internalMemtableFlushWriterCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableFlushWriter.pendingTasks db.threadpool.internalMemtableFlushWriterPendingTasks Cassandra cassandra.node.threadPool.memtablePostFlush.activeTasks db.threadpool.internalMemtablePostFlushActiveTasks Cassandra cassandra.node.threadPool.memtablePostFlush.completedTasks db.threadpool.internalMemtablePostFlushCompletedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.currentlyBlockedTasks db.threadpool.internalMemtablePostFlushCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtablePostFlush.pendingTasks db.threadpool.internalMemtablePostFlushPendingTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.activeTasks db.threadpool.internalMemtableReclaimMemoryActiveTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.completedTasks db.threadpool.internalMemtableReclaimMemoryCompletedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.currentlyBlockedTasks db.threadpool.internalMemtableReclaimMemoryCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.memtableReclaimMemory.pendingTasks db.threadpool.internalMemtableReclaimMemoryPendingTasks Cassandra cassandra.node.threadPool.migrationStage.activeTasks db.threadpool.internalMigrationStageActiveTasks Cassandra cassandra.node.threadPool.migrationStage.completedTasks db.threadpool.internalMigrationStageCompletedTasks Cassandra cassandra.node.threadPool.migrationStage.currentlyBlockedTasks db.threadpool.internalMigrationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.migrationStage.pendingTasks db.threadpool.internalMigrationStagePendingTasks Cassandra cassandra.node.threadPool.miscStage.activeTasks db.threadpool.internalMiscStageActiveTasks Cassandra cassandra.node.threadPool.miscStage.completedTasks db.threadpool.internalMiscStageCompletedTasks Cassandra cassandra.node.threadPool.miscStage.currentlyBlockedTasks db.threadpool.internalMiscStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.miscStage.pendingTasks db.threadpool.internalMiscStagePendingTasks Cassandra cassandra.node.threadPool.mutationStage.activeTasks db.threadpool.requestMutationStageActiveTasks Cassandra cassandra.node.threadPool.mutationStage.completedTasks db.threadpool.requestMutationStageCompletedTasks Cassandra cassandra.node.threadPool.mutationStage.currentlyBlockedTasks db.threadpool.requestMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.mutationStage.pendingTasks db.threadpool.requestMutationStagePendingTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.activeTasks db.threadpool.internalPendingRangeCalculatorActiveTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.completedTasks db.threadpool.internalPendingRangeCalculatorCompletedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.currentlyBlockedTasks db.threadpool.internalPendingRangeCalculatorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.pendingRangeCalculator.pendingTasks db.threadpool.internalPendingRangeCalculatorPendingTasks Cassandra cassandra.node.threadPool.readRepairStage.activeTasks db.threadpool.requestReadRepairStageActiveTasks Cassandra cassandra.node.threadPool.readRepairStage.completedTasks db.threadpool.requestReadRepairStageCompletedTasks Cassandra cassandra.node.threadPool.readRepairStage.currentlyBlockedTasks db.threadpool.requestReadRepairStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readRepairStage.pendingTasks db.threadpool.requestReadRepairStagePendingTasks Cassandra cassandra.node.threadPool.readStage.activeTasks db.threadpool.requestReadStageActiveTasks Cassandra cassandra.node.threadPool.readStage.completedTasks db.threadpool.requestReadStageCompletedTasks Cassandra cassandra.node.threadPool.readStage.currentlyBlockedTasks db.threadpool.requestReadStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.readStage.pendingTasks db.threadpool.requestReadStagePendingTasks Cassandra cassandra.node.threadPool.requestResponseStage.activeTasks db.threadpool.requestRequestResponseStageActiveTasks Cassandra cassandra.node.threadPool.requestResponseStage.completedTasks db.threadpool.requestRequestResponseStageCompletedTasks Cassandra cassandra.node.threadPool.requestResponseStage.currentlyBlockedTasks db.threadpool.requestRequestResponseStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.requestResponseStage.pendingTasks db.threadpool.requestRequestResponseStagePendingTasks Cassandra cassandra.node.threadPool.sampler.activeTasks db.threadpool.internalSamplerActiveTasks Cassandra cassandra.node.threadPool.sampler.completedTasks db.threadpool.internalSamplerCompletedTasks Cassandra cassandra.node.threadPool.sampler.currentlyBlockedTasks db.threadpool.internalSamplerCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.sampler.pendingTasks db.threadpool.internalSamplerPendingTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.activeTasks db.threadpool.internalSecondaryIndexManagementActiveTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.completedTasks db.threadpool.internalSecondaryIndexManagementCompletedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.currentlyBlockedTasks db.threadpool.internalSecondaryIndexManagementCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.secondaryIndexManagement.pendingTasks db.threadpool.internalSecondaryIndexManagementPendingTasks Cassandra cassandra.node.threadPool.validationExecutor.activeTasks db.threadpool.internalValidationExecutorActiveTasks Cassandra cassandra.node.threadPool.validationExecutor.completedTasks db.threadpool.internalValidationExecutorCompletedTasks Cassandra cassandra.node.threadPool.validationExecutor.currentlyBlockedTasks db.threadpool.internalValidationExecutorCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.validationExecutor.pendingTasks db.threadpool.internalValidationExecutorPendingTasks Cassandra cassandra.node.threadPool.viewMutationStage.activeTasks db.threadpool.requestViewMutationStageActiveTasks Cassandra cassandra.node.threadPool.viewMutationStage.completedTasks db.threadpool.requestViewMutationStageCompletedTasks Cassandra cassandra.node.threadPool.viewMutationStage.currentlyBlockedTasks db.threadpool.requestViewMutationStageCurrentlyBlockedTasks Cassandra cassandra.node.threadPool.viewMutationStage.pendingTasks db.threadpool.requestViewMutationStagePendingTasks Cassandra cassandra.node.totalHintsInProgress db.totalHintsInProgress Cassandra cassandra.node.totalHintsPerSecond db.totalHintsPerSecond Cassandra cassandra.columnFamily.allMemtablesOffHeapSizeBytes db.allMemtablesOffHeapSizeBytes Cassandra cassandra.columnFamily.allMemtablesOnHeapSizeBytes db.allMemtablesOnHeapSizeBytes Cassandra cassandra.columnFamily.bloomFilterFalseRatio db.bloomFilterFalseRatio Cassandra cassandra.columnFamily.liveDiskSpaceUsedBytes db.liveDiskSpaceUsedBytes Cassandra cassandra.columnFamily.liveSsTableCount db.liveSSTableCount Cassandra cassandra.columnFamily.maxRowSize db.maxRowSize Cassandra cassandra.columnFamily.meanRowSize db.meanRowSize Cassandra cassandra.columnFamily.memtableLiveDataSize db.memtableLiveDataSize Cassandra cassandra.columnFamily.minRowSize db.minRowSize Cassandra cassandra.columnFamily.pendingCompactions db.pendingCompactions Cassandra cassandra.columnFamily.query.readLatency50ThPercentileMilliseconds query.readLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency75ThPercentileMilliseconds query.readLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency95ThPercentileMilliseconds query.readLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency98ThPercentileMilliseconds query.readLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency999ThPercentileMilliseconds query.readLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readLatency99ThPercentileMilliseconds query.readLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.readRequestsPerSecond query.readRequestsPerSecond Cassandra cassandra.columnFamily.query.writeLatency50ThPercentileMilliseconds query.writeLatency50thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency75ThPercentileMilliseconds query.writeLatency75thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency95ThPercentileMilliseconds query.writeLatency95thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency98ThPercentileMilliseconds query.writeLatency98thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency999ThPercentileMilliseconds query.writeLatency999thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeLatency99ThPercentileMilliseconds query.writeLatency99thPercentileMilliseconds Cassandra cassandra.columnFamily.query.writeRequestsPerSecond query.writeRequestsPerSecond Cassandra cassandra.columnFamily.speculativeRetries db.speculativeRetries Cassandra cassandra.columnFamily.ssTablesPerRead50ThPercentileMilliseconds db.SSTablesPerRead50thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead75ThPercentileMilliseconds db.SSTablesPerRead75thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead95ThPercentileMilliseconds db.SSTablesPerRead95thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead98ThPercentileMilliseconds db.SSTablesPerRead98thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead999ThPercentileMilliseconds db.SSTablesPerRead999thPercentileMilliseconds Cassandra cassandra.columnFamily.ssTablesPerRead99ThPercentileMilliseconds db.SSTablesPerRead99thPercentileMilliseconds Cassandra cassandra.columnFamily.tombstoneScannedHistogram50ThPercentile db.tombstoneScannedHistogram50thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram75ThPercentile db.tombstoneScannedHistogram75thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram95ThPercentile db.tombstoneScannedHistogram95thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram98ThPercentile db.tombstoneScannedHistogram98thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram999ThPercentile db.tombstoneScannedHistogram999thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogram99ThPercentile db.tombstoneScannedHistogram99thPercentile Cassandra cassandra.columnFamily.tombstoneScannedHistogramCount db.tombstoneScannedHistogramCount Consul consul.datacenter.catalog.criticalNodes catalog.criticalNodes Consul consul.datacenter.catalog.passingNodes catalog.passingNodes Consul consul.datacenter.catalog.registeredNodes catalog.registeredNodes Consul consul.datacenter.catalog.upNodes catalog.upNodes Consul consul.datacenter.catalog.warningNodes catalog.warningNodes Consul consul.datacenter.cluster.flaps cluster.flaps Consul consul.datacenter.cluster.suspects cluster.suspects Consul consul.datacenter.raft.commitTime raft.commitTimes Consul consul.datacenter.raft.commitTimeAvgInMilliseconds raft.commitTimeAvgInMilliseconds Consul consul.datacenter.raft.commitTimeMaxInMilliseconds raft.commitTimeMaxInMilliseconds Consul consul.datacenter.raft.completedLeaderElections raft.completedLeaderElections Consul consul.datacenter.raft.initiatedLeaderElections raft.initiatedLeaderElections Consul consul.datacenter.raft.lastContactAvgInMilliseconds raft.lastContactAvgInMilliseconds Consul consul.datacenter.raft.lastContactMaxInMilliseconds raft.lastContactMaxInMilliseconds Consul consul.datacenter.raft.lastContacts raft.lastContacts Consul consul.datacenter.raft.logDispatchAvgInMilliseconds raft.logDispatchAvgInMilliseconds Consul consul.datacenter.raft.logDispatches raft.logDispatches Consul consul.datacenter.raft.logDispatchMaxInMilliseconds raft.logDispatchMaxInMilliseconds Consul consul.datacenter.raft.txns raft.txns Consul consul.agent.aclCacheHitPerSecond agent.aclCacheHit Consul consul.agent.aclCacheMissPerSecond agent.aclCacheMiss Consul consul.agent.client.rpcFailed client.rpcFailed Consul consul.agent.client.rpcLoad client.rpcLoad Consul consul.agent.kvStores agent.kvStoress Consul consul.agent.kvStoresAvgInMilliseconds agent.kvStoresAvgInMilliseconds Consul consul.agent.kvStoresMaxInMilliseconds agent.kvStoresMaxInMilliseconds Consul consul.agent.net.agent.maxLatencyInMilliseconds net.agent.maxLatencyInMilliseconds Consul consul.agent.net.medianLatencyInMilliseconds net.agent.medianLatencyInMilliseconds Consul consul.agent.net.minLatencyInMilliseconds net.agent.minLatencyInMilliseconds Consul consul.agent.net.p25LatencyInMilliseconds net.agent.p25LatencyInMilliseconds Consul consul.agent.net.p75LatencyInMilliseconds net.agent.p75LatencyInMilliseconds Consul consul.agent.net.p90LatencyInMilliseconds net.agent.p90LatencyInMilliseconds Consul consul.agent.net.p95LatencyInMilliseconds net.agent.p95LatencyInMilliseconds Consul consul.agent.net.p99LatencyInMilliseconds net.agent.p99LatencyInMilliseconds Consul consul.agent.peers agent.peers Consul consul.agent.runtime.allocations runtime.allocations Consul consul.agent.runtime.allocationsInBytes runtime.allocationsInBytes Consul consul.agent.runtime.frees runtime.frees Consul consul.agent.runtime.gcCycles runtime.gcCycles Consul consul.agent.runtime.gcPauseInMilliseconds runtime.gcPauseInMilliseconds Consul consul.agent.runtime.goroutines runtime.goroutines Consul consul.agent.runtime.heapObjects runtime.heapObjects Consul consul.agent.runtime.virtualAddressSpaceInBytes runtime.virtualAddressSpaceInBytes Consul consul.agent.staleQueries agent.staleQueries Consul consul.agent.txnAvgInMilliseconds agent.txnAvgInMilliseconds Consul consul.agent.txnMaxInMilliseconds agent.txnMaxInMilliseconds Consul consul.agent.txns agent.txns Couchbase couchbase.bucket.activeItemsEnteringDiskQueuePerSecond bucket.activeItemsEnteringDiskQueuePerSecond Couchbase couchbase.bucket.activeItemsInMemory bucket.activeItemsInMemory Couchbase couchbase.bucket.activeResidentItemsRatio bucket.activeResidentItemsRatio Couchbase couchbase.bucket.averageDiskCommitTimeInMilliseconds bucket.averageDiskCommitTimeInMilliseconds Couchbase couchbase.bucket.averageDiskUpdateTimeInMilliseconds bucket.averageDiskUpdateTimeInMilliseconds Couchbase couchbase.bucket.cacheMisses bucket.cacheMisses Couchbase couchbase.bucket.cacheMissRatio bucket.cacheMissRatio Couchbase couchbase.bucket.casHits bucket.casHits Couchbase couchbase.bucket.casMisses bucket.casMisses Couchbase couchbase.bucket.couchDocsFragmentationPercent bucket.couchDocsFragmentationPercent Couchbase couchbase.bucket.currentConnections bucket.currentConnections Couchbase couchbase.bucket.dataUsedInBytes bucket.dataUsedInBytes Couchbase couchbase.bucket.decrementHitsPerSecond bucket.decrementHitsPerSecond Couchbase couchbase.bucket.decrementMissesPerSecond bucket.decrementMissesPerSecond Couchbase couchbase.bucket.deleteHitsPerSecond bucket.deleteHitsPerSecond Couchbase couchbase.bucket.deleteMissesPerSecond bucket.deleteMissesPerSecond Couchbase couchbase.bucket.diskCreateOperationsPerSecond bucket.diskCreateOperationsPerSecond Couchbase couchbase.bucket.diskFetchesPerSecond bucket.diskFetchesPerSecond Couchbase couchbase.bucket.diskReadsPerSecond bucket.diskReadsPerSecond Couchbase couchbase.bucket.diskUpdateOperationsPerSecond bucket.diskUpdateOperationsPerSecond Couchbase couchbase.bucket.diskUsedInBytes bucket.diskUsedInBytes Couchbase couchbase.bucket.diskWriteQueue bucket.diskWriteQueue Couchbase couchbase.bucket.drainedItemsInQueue bucket.drainedItemsInQueue Couchbase couchbase.bucket.drainedItemsOnDiskQueue bucket.drainedItemsOnDiskQueue Couchbase couchbase.bucket.drainedPendingItemsInQueue bucket.drainedPendingItemsInQueue Couchbase couchbase.bucket.ejectionsPerSecond bucket.ejectionsPerSecond Couchbase couchbase.bucket.evictionsPerSecond bucket.evictionsPerSecond Couchbase couchbase.bucket.getHitsPerSecond bucket.getHitsPerSecond Couchbase couchbase.bucket.getMissesPerSecond bucket.getMissesPerSecond Couchbase couchbase.bucket.hitRatio bucket.hitRatio Couchbase couchbase.bucket.incrementHitsPerSecond bucket.incrementHitsPerSecond Couchbase couchbase.bucket.incrementMissesPerSecond bucket.incrementMissesPerSecond Couchbase couchbase.bucket.itemCount bucket.itemCount Couchbase couchbase.bucket.itemsBeingWritten bucket.itemsBeingWritten Couchbase couchbase.bucket.itemsEjectedFromMemoryToDisk bucket.itemsEjectedFromMemoryToDisk Couchbase couchbase.bucket.itemsOnDiskQueue bucket.itemsOnDiskQueue Couchbase couchbase.bucket.itemsQueuedForStorage bucket.itemsQueuedForStorage Couchbase couchbase.bucket.maximumMemoryUsage bucket.maximumMemoryUsage Couchbase couchbase.bucket.memoryHighWaterMarkInBytes bucket.memoryHighWaterMarkInBytes Couchbase couchbase.bucket.memoryLowWaterMarkInBytes bucket.memoryLowWaterMarkInBytes Couchbase couchbase.bucket.memoryUsedInBytes bucket.memoryUsedInBytes Couchbase couchbase.bucket.metadataInRamInBytes bucket.metadataInRAMInBytes Couchbase couchbase.bucket.missesPerSecond bucket.missesPerSecond Couchbase couchbase.bucket.outOfMemoryErrorsPerSecond bucket.outOfMemoryErrorsPerSecond Couchbase couchbase.bucket.overheadInBytes bucket.overheadInBytes Couchbase couchbase.bucket.pendingItemsInDiskQueue bucket.pendingItemsInDiskQueue Couchbase couchbase.bucket.pendingResidentItemsRatio bucket.pendingResidentItemsRatio Couchbase couchbase.bucket.quotaUtilization bucket.quotaUtilization Couchbase couchbase.bucket.readOperationsPerSecond bucket.readOperationsPerSecond Couchbase couchbase.bucket.readRatePerSecond bucket.readRatePerSecond Couchbase couchbase.bucket.recoverableOutOfMemoryCount bucket.recoverableOutOfMemoryCount Couchbase couchbase.bucket.replicaIndex bucket.replicaIndex Couchbase couchbase.bucket.replicaNumber bucket.replicaNumber Couchbase couchbase.bucket.replicaResidentItemsRatio bucket.replicaResidentItemsRatio Couchbase couchbase.bucket.residentItemsRatio bucket.residentItemsRatio Couchbase couchbase.bucket.temporaryOutOfMemoryErrorsPerSecond bucket.temporaryOutOfMemoryErrorsPerSecond Couchbase couchbase.bucket.threadsNumber bucket.threadsNumber Couchbase couchbase.bucket.totalItems bucket.totalItems Couchbase couchbase.bucket.totalOperationsPerSecond bucket.totalOperationsPerSecond Couchbase couchbase.bucket.viewFragmentationPercent bucket.viewFragmentationPercent Couchbase couchbase.bucket.writeOperationsPerSecond bucket.writeOperationsPerSecond Couchbase couchbase.bucket.writeRatePerSecond bucket.writeRatePerSecond Couchbase couchbase.cluster.autoFailoverCount cluster.autoFailoverCount Couchbase couchbase.cluster.autoFailoverEnabled cluster.autoFailoverEnabled Couchbase couchbase.cluster.databaseFragmentationThreshold cluster.databaseFragmentationThreshold Couchbase couchbase.cluster.diskFreeInBytes cluster.diskFreeInBytes Couchbase couchbase.cluster.diskQuotaTotalInBytes cluster.diskQuotaTotalInBytes Couchbase couchbase.cluster.diskTotalInBytes cluster.diskTotalInBytes Couchbase couchbase.cluster.diskUsedByDataInBytes cluster.diskUsedByDataInBytes Couchbase couchbase.cluster.diskUsedInBytes cluster.diskUsedInBytes Couchbase couchbase.cluster.indexFragmentationThreshold cluster.indexFragmentationThreshold Couchbase couchbase.cluster.maximumBucketCount cluster.maximumBucketCount Couchbase couchbase.cluster.memoryQuotaTotalInBytes cluster.memoryQuotaTotalInBytes Couchbase couchbase.cluster.memoryQuotaTotalPerNodeInBytes cluster.memoryQuotaTotalPerNodeInBytes Couchbase couchbase.cluster.memoryQuotaUsedInBytes cluster.memoryQuotaUsedInBytes Couchbase couchbase.cluster.memoryQuotaUsedPerNodeInBytes cluster.memoryQuotaUsedPerNodeInBytes Couchbase couchbase.cluster.memoryTotalInBytes cluster.memoryTotalInBytes Couchbase couchbase.cluster.memoryUsedByDataInBytes cluster.memoryUsedByDataInBytes Couchbase couchbase.cluster.memoryUsedInBytes cluster.memoryUsedInBytes Couchbase couchbase.cluster.viewFragmentationThreshold cluster.viewFragmentationThreshold Couchbase couchbase.node.backgroundFetches node.backgroundFetches Couchbase couchbase.node.cmdGet node.cmdGet Couchbase couchbase.node.couchDocsActualDiskSizeInBytes node.couchDocsActualDiskSizeInBytes Couchbase couchbase.node.couchDocsDataSizeInBytes node.couchDocsDataSizeInBytes Couchbase couchbase.node.couchSpatialDataSizeInBytes node.couchSpatialDataSizeInBytes Couchbase couchbase.node.couchSpatialDiskSizeInBytes node.couchSpatialDiskSizeInBytes Couchbase couchbase.node.couchViewsActualDiskSizeInBytes node.couchViewsActualDiskSizeInBytes Couchbase couchbase.node.couchViewsDataSizeInBytes node.couchViewsDataSizeInBytes Couchbase couchbase.node.cpuUtilization node.cpuUtilization Couchbase couchbase.node.currentItems node.currentItems Couchbase couchbase.node.currentItemsTotal node.currentItemsTotal Couchbase couchbase.node.getHits node.getHits Couchbase couchbase.node.memoryFreeInBytes node.memoryFreeInBytes Couchbase couchbase.node.memoryTotalInBytes node.memoryTotalInBytes Couchbase couchbase.node.memoryUsedInBytes node.memoryUsedInBytes Couchbase couchbase.node.ops node.ops Couchbase couchbase.node.swapTotalInBytes node.swapTotalInBytes Couchbase couchbase.node.swapUsedInBytes node.swapUsedInBytes Couchbase couchbase.node.uptimeInMilliseconds node.uptimeInMilliseconds Couchbase couchbase.node.vbucketActiveNonResidentItems node.vbucketActiveNonResidentItems Couchbase couchbase.node.vbucketInMemoryItems node.vbucketInMemoryItems Couchbase couchbase.queryengine.activeRequests queryengine.activeRequests Couchbase couchbase.queryengine.averageRequestTimeInMilliseconds queryengine.averageRequestTimeInMilliseconds Couchbase couchbase.queryengine.completedLimit queryengine.completedLimit Couchbase couchbase.queryengine.completedRequests queryengine.completedRequests Couchbase couchbase.queryengine.completedThresholdInMilliseconds queryengine.completedThresholdInMilliseconds Couchbase couchbase.queryengine.cores queryengine.cores Couchbase couchbase.queryengine.garbageCollectionNumber queryengine.garbageCollectionNumber Couchbase couchbase.queryengine.garbageCollectionPaused queryengine.garbageCollectionPaused Couchbase couchbase.queryengine.garbageCollectionTimePausedInMilliseconds queryengine.garbageCollectionTimePausedInMilliseconds Couchbase couchbase.queryengine.medianRequestTimeInMilliseconds queryengine.medianRequestTimeInMilliseconds Couchbase couchbase.queryengine.preparedStatementUtilization queryengine.preparedStatementUtilization Couchbase couchbase.queryengine.requestsLast15MinutesPerSecond queryengine.requestsLast15MinutesPerSecond Couchbase couchbase.queryengine.requestsLast1MinutesPerSecond queryengine.requestsLast1MinutesPerSecond Couchbase couchbase.queryengine.requestsLast5MinutesPerSecond queryengine.requestsLast5MinutesPerSecond Couchbase couchbase.queryengine.requestTime80thPercentileInMilliseconds queryengine.requestTime80thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime95thPercentileInMilliseconds queryengine.requestTime95thPercentileInMilliseconds Couchbase couchbase.queryengine.requestTime99thPercentileInMilliseconds queryengine.requestTime99thPercentileInMilliseconds Couchbase couchbase.queryengine.systemCpuUtilization queryengine.systemCPUUtilization Couchbase couchbase.queryengine.systemMemoryInBytes queryengine.systemMemoryInBytes Couchbase couchbase.queryengine.totalMemoryInBytes queryengine.totalMemoryInBytes Couchbase couchbase.queryengine.totalThreads queryengine.totalThreads Couchbase couchbase.queryengine.uptimeInMilliseconds queryengine.uptimeInMilliseconds Couchbase couchbase.queryengine.usedMemoryInBytes queryengine.usedMemoryInBytes Couchbase couchbase.queryengine.userCpuUtilization queryengine.userCPUUtilization Docker docker.container.cpuKernelPercent cpuKernelPercent Docker docker.container.cpuLimitCores cpuLimitCores Docker docker.container.cpuPercent cpuPercent Docker docker.container.cpuThrottlePeriods cpuThrottlePeriods Docker docker.container.cpuThrottleTimeMs cpuThrottleTimeMs Docker docker.container.cpuUsedCores cpuUsedCores Docker docker.container.cpuUsedCoresPercent cpuUsedCoresPercent Docker docker.container.cpuUserPercent cpuUserPercent Docker docker.container.ioReadBytesPerSecond ioReadBytesPerSecond Docker docker.container.ioReadCountPerSecond ioReadCountPerSecond Docker docker.container.ioTotalBytes ioTotalBytes Docker docker.container.ioTotalReadBytes ioTotalReadBytes Docker docker.container.ioTotalReadCount ioTotalReadCount Docker docker.container.ioTotalWriteBytes ioTotalWriteBytes Docker docker.container.ioTotalWriteCount ioTotalWriteCount Docker docker.container.ioWriteBytesPerSecond ioWriteBytesPerSecond Docker docker.container.ioWriteCountPerSecond ioWriteCountPerSecond Docker docker.container.memoryCacheBytes memoryCacheBytes Docker docker.container.memoryResidentSizeBytes memoryResidentSizeBytes Docker docker.container.memorySizeLimitBytes memorySizeLimitBytes Docker docker.container.memoryUsageBytes memoryUsageBytes Docker docker.container.memoryUsageLimitPercent memoryUsageLimitPercent Docker docker.container.networkRxBytes networkRxBytes Docker docker.container.networkRxBytesPerSecond networkRxBytesPerSecond Docker docker.container.networkRxDropped networkRxDropped Docker docker.container.networkRxDroppedPerSecond networkRxDroppedPerSecond Docker docker.container.networkRxErrors networkRxErrors Docker docker.container.networkRxErrorsPerSecond networkRxErrorsPerSecond Docker docker.container.networkRxPackets networkRxPackets Docker docker.container.networkRxPacketsPerSecond networkRxPacketsPerSecond Docker docker.container.networkTxBytes networkTxBytes Docker docker.container.networkTxBytesPerSecond networkTxBytesPerSecond Docker docker.container.networkTxDropped networkTxDropped Docker docker.container.networkTxDroppedPerSecond networkTxDroppedPerSecond Docker docker.container.networkTxErrors networkTxErrors Docker docker.container.networkTxErrorsPerSecond networkTxErrorsPerSecond Docker docker.container.networkTxPackets networkTxPackets Docker docker.container.networkTxPacketsPerSecond networkTxPacketsPerSecond Docker docker.container.pids pids Docker docker.container.processCount processCount Docker docker.container.processCountLimit processCountLimit Docker docker.container.restartCount restartCount Docker docker.container.threadCount threadCount Docker docker.container.threadCountLimit threadCountLimit ElasticSearch elasticsearch.cluster.dataNodes cluster.dataNodes ElasticSearch elasticsearch.cluster.nodes cluster.nodes ElasticSearch elasticsearch.cluster.shards.active shards.active ElasticSearch elasticsearch.cluster.shards.initializing shards.initializing ElasticSearch elasticsearch.cluster.shards.primaryActive shards.primaryActive ElasticSearch elasticsearch.cluster.shards.relocating shards.relocating ElasticSearch elasticsearch.cluster.shards.unassigned shards.unassigned ElasticSearch elasticsearch.cluster.tempData temp-data ElasticSearch elasticsearch.index.docs index.docs ElasticSearch elasticsearch.index.docsDeleted index.docsDeleted ElasticSearch elasticsearch.index.primaryShards index.primaryShards ElasticSearch elasticsearch.index.primaryStoreSizeInBytes index.primaryStoreSizeInBytes ElasticSearch elasticsearch.index.replicaShards index.replicaShards ElasticSearch elasticsearch.index.rollup.docsCount primaries.docsnumber ElasticSearch elasticsearch.index.rollup.docsDeleted primaries.docsDeleted ElasticSearch elasticsearch.index.rollup.flushTotal primaries.flushesTotal ElasticSearch elasticsearch.index.rollup.flushTotalTimeInMilliseconds primaries.flushTotalTimeInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsExist primaries.get.documentsExist ElasticSearch elasticsearch.index.rollup.get.documentsExistInMilliseconds primaries.get.documentsExistInMilliseconds ElasticSearch elasticsearch.index.rollup.get.documentsMissing primaries.get.documentsMissing ElasticSearch elasticsearch.index.rollup.get.documentsMissingInMilliseconds primaries.get.documentsMissingInMilliseconds ElasticSearch elasticsearch.index.rollup.get.requests primaries.get.requests ElasticSearch elasticsearch.index.rollup.get.requestsCurrent primaries.get.requestsCurrent ElasticSearch elasticsearch.index.rollup.get.requestsInMilliseconds primaries.get.requestsInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeleted primaries.index.docsCurrentlyDeleted ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyDeletedInMilliseconds primaries.index.docsCurrentlyDeletedInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexing primaries.index.docsCurrentlyIndexing ElasticSearch elasticsearch.index.rollup.index.docsCurrentlyIndexingInMilliseconds primaries.index.docsCurrentlyIndexingInMilliseconds ElasticSearch elasticsearch.index.rollup.index.docsDeleted primaries.index.docsDeleted ElasticSearch elasticsearch.index.rollup.index.docsTotal primaries.index.docsTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotal primaries.indexRefreshesTotal ElasticSearch elasticsearch.index.rollup.indexRefreshesTotalInMilliseconds primaries.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.merges.current primaries.merges.current ElasticSearch elasticsearch.index.rollup.merges.docsSegmentsCurrentlyMerged primaries.merges.docsSegmentsCurrentlyMerged ElasticSearch elasticsearch.index.rollup.merges.docsTotal primaries.merges.docsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsCurrentlyMergedInBytes primaries.merges.segmentsCurrentlyMergedInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotal primaries.merges.segmentsTotal ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInBytes primaries.merges.segmentsTotalInBytes ElasticSearch elasticsearch.index.rollup.merges.segmentsTotalInMilliseconds primaries.merges.segmentsTotalInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesInMilliseconds primaries.queriesInMilliseconds ElasticSearch elasticsearch.index.rollup.queriesTotal primaries.queriesTotal ElasticSearch elasticsearch.index.rollup.queryActive primaries.queryActive ElasticSearch elasticsearch.index.rollup.queryFetches primaries.queryFetches ElasticSearch elasticsearch.index.rollup.queryFetchesInMilliseconds primaries.queryFetchesInMilliseconds ElasticSearch elasticsearch.index.rollup.queryFetchesTotal primaries.queryFetchesTotal ElasticSearch elasticsearch.index.rollup.sizeInBytes primaries.sizeInBytes ElasticSearch elasticsearch.index.storeSizeInBytes index.storeSizeInBytes ElasticSearch elasticsearch.node.activeSearches activeSearches ElasticSearch elasticsearch.node.activeSearchesInMilliseconds activeSearchesInMilliseconds ElasticSearch elasticsearch.node.breakers.estimatedSizeFieldDataCircuitBreakerInBytes breakers.estimatedSizeFieldDataCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeParentCircuitBreakerInBytes breakers.estimatedSizeParentCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.estimatedSizeRequestCircuitBreakerInBytes breakers.estimatedSizeRequestCircuitBreakerInBytes ElasticSearch elasticsearch.node.breakers.fieldDataCircuitBreakerTripped breakers.fieldDataCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.parentCircuitBreakerTripped breakers.parentCircuitBreakerTripped ElasticSearch elasticsearch.node.breakers.requestCircuitBreakerTripped breakers.requestCircuitBreakerTripped ElasticSearch elasticsearch.node.flush.indexRefreshesTotal flush.indexRefreshesTotal ElasticSearch elasticsearch.node.flush.indexRefreshesTotalInMilliseconds flush.indexRefreshesTotalInMilliseconds ElasticSearch elasticsearch.node.fs.bytesAvailableJvmInBytes fs.bytesAvailableJVMInBytes ElasticSearch elasticsearch.node.fs.dataRead fs.bytesReadsInBytes ElasticSearch elasticsearch.node.fs.dataWritten fs.writesInBytes ElasticSearch elasticsearch.node.fs.ioOperations fs.iOOperations ElasticSearch elasticsearch.node.fs.readOperations fs.reads ElasticSearch elasticsearch.node.fs.totalSizeInBytes fs.totalSizeInBytes ElasticSearch elasticsearch.node.fs.unallocatedBytes fs.unallocatedBytesInBYtes ElasticSearch elasticsearch.node.fs.writeOperations fs.writeOperations ElasticSearch elasticsearch.node.get.currentRequestsRunning get.currentRequestsRunning ElasticSearch elasticsearch.node.get.requestsDocumentExists get.requestsDocumentExists ElasticSearch elasticsearch.node.get.requestsDocumentExistsInMilliseconds get.requestsDocumentExistsInMilliseconds ElasticSearch elasticsearch.node.get.requestsDocumentMissing get.requestsDocumentMissing ElasticSearch elasticsearch.node.get.requestsDocumentMissingInMilliseconds get.requestsDocumentMissingInMilliseconds ElasticSearch elasticsearch.node.get.timeGetRequestsInMilliseconds get.timeGetRequestsInMilliseconds ElasticSearch elasticsearch.node.get.totalGetRequests get.totalGetRequests ElasticSearch elasticsearch.node.http.currentOpenConnections http.currentOpenConnections ElasticSearch elasticsearch.node.http.openedConnections http.openedConnections ElasticSearch elasticsearch.node.index.indexingOperationsFailed indices.indexingOperationsFailed ElasticSearch elasticsearch.node.index.indexingWaitedThrottlingInMilliseconds indices.indexingWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.memoryQueryCacheInBytes indices.memoryQueryCacheInBytes ElasticSearch elasticsearch.node.index.numberIndices indices.numberIndices ElasticSearch elasticsearch.node.index.queryCacheEvictions indices.queryCacheEvictions ElasticSearch elasticsearch.node.index.queryCacheHits indices.queryCacheHits ElasticSearch elasticsearch.node.index.queryCacheMisses indices.queryCacheMisses ElasticSearch elasticsearch.node.index.recoveryOngoingShardSource indices.recoveryOngoingShardSource ElasticSearch elasticsearch.node.index.recoveryOngoingShardTarget indices.recoveryOngoingShardTarget ElasticSearch elasticsearch.node.index.recoveryWaitedThrottlingInMilliseconds indices.recoveryWaitedThrottlingInMilliseconds ElasticSearch elasticsearch.node.index.requestCacheEvictions indices.requestCacheEvictions ElasticSearch elasticsearch.node.index.requestCacheHits indices.requestCacheHits ElasticSearch elasticsearch.node.index.requestCacheMemoryInBytes indices.requestCacheMemoryInBytes ElasticSearch elasticsearch.node.index.requestCacheMisses indices.requestCacheMisses ElasticSearch elasticsearch.node.index.segmentsIndexShard indices.segmentsIndexShard ElasticSearch elasticsearch.node.index.segmentsMemoryUsedDocValuesInBytes indices.segmentsMemoryUsedDocValuesInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedFixedBitSetInBytes indices.segmentsMemoryUsedFixedBitSetInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexSegmentsInBytes indices.segmentsMemoryUsedIndexSegmentsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedIndexWriterInBytes indices.segmentsMemoryUsedIndexWriterInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedNormsInBytes indices.segmentsMemoryUsedNormsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedSegmentVersionMapInBytes indices.segmentsMemoryUsedSegmentVersionMapInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedStoredFieldsInBytes indices.segmentsMemoryUsedStoredFieldsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermsInBytes indices.segmentsMemoryUsedTermsInBytes ElasticSearch elasticsearch.node.index.segmentsMemoryUsedTermVectorsInBytes indices.segmentsMemoryUsedTermVectorsInBytes ElasticSearch elasticsearch.node.index.translogOperations indices.translogOperations ElasticSearch elasticsearch.node.index.translogOperationsInBytes indices.translogOperationsInBytes ElasticSearch elasticsearch.node.indexing.docsCurrentlyDeleted indexing.docsCurrentlyDeleted ElasticSearch elasticsearch.node.indexing.documentsCurrentlyIndexing indexing.documentsCurrentlyIndexing ElasticSearch elasticsearch.node.indexing.documentsIndexed indexing.documentsIndexed ElasticSearch elasticsearch.node.indexing.timeDeletingDocumentsInMilliseconds indexing.timeDeletingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.timeIndexingDocumentsInMilliseconds indexing.timeIndexingDocumentsInMilliseconds ElasticSearch elasticsearch.node.indexing.totalDocumentsDeleted indexing.totalDocumentsDeleted ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjects jvm.gc.majorCollectionsOldGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds jvm.gc.majorCollectionsOldGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjects jvm.gc.majorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.majorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjects jvm.gc.minorCollectionsYoungGenerationObjects ElasticSearch elasticsearch.node.jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds jvm.gc.minorCollectionsYoungGenerationObjectsInMilliseconds ElasticSearch elasticsearch.node.jvm.mem.heapCommittedInBytes jvm.mem.heapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.heapMaxInBytes jvm.mem.heapMaxInBytes ElasticSearch elasticsearch.node.jvm.mem.heapUsed jvm.mem.heapUsed ElasticSearch elasticsearch.node.jvm.mem.heapUsedInBytes jvm.mem.heapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.maxOldGenerationHeapInBytes jvm.mem.maxOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.maxSurvivorSpaceInBytes jvm.mem.maxSurvivorSpaceInBYtes ElasticSearch elasticsearch.node.jvm.mem.maxYoungGenerationHeapInBytes jvm.mem.maxYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapCommittedInBytes jvm.mem.nonHeapCommittedInBytes ElasticSearch elasticsearch.node.jvm.mem.nonHeapUsedInBytes jvm.mem.nonHeapUsedInBytes ElasticSearch elasticsearch.node.jvm.mem.usedOldGenerationHeapInBytes jvm.mem.usedOldGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.mem.usedSurvivorSpaceInBytes jvm.mem.usedSurvivorSpaceInBytes ElasticSearch elasticsearch.node.jvm.mem.usedYoungGenerationHeapInBytes jvm.mem.usedYoungGenerationHeapInBytes ElasticSearch elasticsearch.node.jvm.threadsActive jvm.ThreadsActive ElasticSearch elasticsearch.node.jvm.threadsPeak jvm.ThreadsPeak ElasticSearch elasticsearch.node.merges.currentActive merges.currentActive ElasticSearch elasticsearch.node.merges.docsSegmentMerges merges.docsSegmentMerges ElasticSearch elasticsearch.node.merges.docsSegmentsMerging merges.docsSegmentsMerging ElasticSearch elasticsearch.node.merges.mergedSegmentsInBytes merges.mergedSegmentsInBytes ElasticSearch elasticsearch.node.merges.segmentMerges merges.segmentMerges ElasticSearch elasticsearch.node.merges.sizeSegmentsMergingInBytes merges.sizeSegmentsMergingInBytes ElasticSearch elasticsearch.node.merges.totalSegmentMergingInMilliseconds merges.totalSegmentMergingInMilliseconds ElasticSearch elasticsearch.node.openFd openFD ElasticSearch elasticsearch.node.queriesTotal queriesTotal ElasticSearch elasticsearch.node.refresh.total refresh.total ElasticSearch elasticsearch.node.refresh.totalInMilliseconds refresh.totalInMilliseconds ElasticSearch elasticsearch.node.searchFetchCurrentlyRunning searchFetchCurrentlyRunning ElasticSearch elasticsearch.node.searchFetches searchFetches ElasticSearch elasticsearch.node.sizeStoreInBytes sizeStoreInBytes ElasticSearch elasticsearch.node.threadpool.activeFetchShardStarted threadpool.activeFetchShardStarted ElasticSearch elasticsearch.node.threadpool.bulkActive threadpool.bulkActive ElasticSearch elasticsearch.node.threadpool.bulkQueue threadpool.bulkQueue ElasticSearch elasticsearch.node.threadpool.bulkRejected threadpool.bulkRejected ElasticSearch elasticsearch.node.threadpool.bulkThreads threadpool.bulkThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStartedQueue threadpool.fetchShardStartedQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStartedRejected threadpool.fetchShardStartedRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStartedThreads threadpool.fetchShardStartedThreads ElasticSearch elasticsearch.node.threadpool.fetchShardStoreActive threadpool.fetchShardStoreActive ElasticSearch elasticsearch.node.threadpool.fetchShardStoreQueue threadpool.fetchShardStoreQueue ElasticSearch elasticsearch.node.threadpool.fetchShardStoreRejected threadpool.fetchShardStoreRejected ElasticSearch elasticsearch.node.threadpool.fetchShardStoreThreads threadpool.fetchShardStoreThreads ElasticSearch elasticsearch.node.threadpool.flushActive threadpool.flushActive ElasticSearch elasticsearch.node.threadpool.flushQueue threadpool.flushQueue ElasticSearch elasticsearch.node.threadpool.flushRejected threadpool.flushRejected ElasticSearch elasticsearch.node.threadpool.flushThreads threadpool.flushThreads ElasticSearch elasticsearch.node.threadpool.forceMergeActive threadpool.forceMergeActive ElasticSearch elasticsearch.node.threadpool.forceMergeQueue threadpool.forceMergeQueue ElasticSearch elasticsearch.node.threadpool.forceMergeRejected threadpool.forceMergeRejected ElasticSearch elasticsearch.node.threadpool.forceMergeThreads threadpool.forceMergeThreads ElasticSearch elasticsearch.node.threadpool.genericActive threadpool.genericActive ElasticSearch elasticsearch.node.threadpool.genericQueue threadpool.genericQueue ElasticSearch elasticsearch.node.threadpool.genericRejected threadpool.genericRejected ElasticSearch elasticsearch.node.threadpool.genericThreads threadpool.genericThreads ElasticSearch elasticsearch.node.threadpool.getActive threadpool.getActive ElasticSearch elasticsearch.node.threadpool.getQueue threadpool.getQueue ElasticSearch elasticsearch.node.threadpool.getRejected threadpool.getRejected ElasticSearch elasticsearch.node.threadpool.getThreads threadpool.getThreads ElasticSearch elasticsearch.node.threadpool.indexActive threadpool.indexActive ElasticSearch elasticsearch.node.threadpool.indexQueue threadpool.indexQueue ElasticSearch elasticsearch.node.threadpool.indexRejected threadpool.indexRejected ElasticSearch elasticsearch.node.threadpool.indexThreads threadpool.indexThreads ElasticSearch elasticsearch.node.threadpool.listenerActive threadpool.listenerActive ElasticSearch elasticsearch.node.threadpool.listenerQueue threadpool.listenerQueue ElasticSearch elasticsearch.node.threadpool.listenerRejected threadpool.listenerRejected ElasticSearch elasticsearch.node.threadpool.listenerThreads threadpool.listenerThreads ElasticSearch elasticsearch.node.threadpool.managementActive threadpool.managementActive ElasticSearch elasticsearch.node.threadpool.managementQueue threadpool.managementQueue ElasticSearch elasticsearch.node.threadpool.managementRejected threadpool.managementRejected ElasticSearch elasticsearch.node.threadpool.managementThreads threadpool.managementThreads ElasticSearch elasticsearch.node.threadpool.refreshActive threadpool.refreshActive ElasticSearch elasticsearch.node.threadpool.refreshQueue threadpool.refreshQueue ElasticSearch elasticsearch.node.threadpool.refreshRejected threadpool.refreshRejected ElasticSearch elasticsearch.node.threadpool.refreshThreads threadpool.refreshThreads ElasticSearch elasticsearch.node.threadpool.searchActive threadpool.searchActive ElasticSearch elasticsearch.node.threadpool.searchQueue threadpool.searchQueue ElasticSearch elasticsearch.node.threadpool.searchRejected threadpool.searchRejected ElasticSearch elasticsearch.node.threadpool.searchThreads threadpool.searchThreads ElasticSearch elasticsearch.node.threadpool.snapshotActive threadpool.snapshotActive ElasticSearch elasticsearch.node.threadpool.snapshotQueue threadpool.snapshotQueue ElasticSearch elasticsearch.node.threadpool.snapshotRejected threadpool.snapshotRejected ElasticSearch elasticsearch.node.threadpool.snapshotThreads threadpool.snapshotThreads ElasticSearch elasticsearch.node.transport.connectionsOpened transport.connectionsOpened ElasticSearch elasticsearch.node.transport.packetsReceived transport.packetsReceived ElasticSearch elasticsearch.node.transport.packetsReceivedInBytes transport.packetsReceivedInBytes ElasticSearch elasticsearch.node.transport.packetsSent transport.packetsSent ElasticSearch elasticsearch.node.transport.packetsSentInBytes transport.packetsSentInBytes F5 f5.node.availabilityState node.availabilityState F5 f5.node.connections node.connections F5 f5.node.connectionsPerSecond node.connectionsPerSecond F5 f5.node.enabled node.enabled F5 f5.node.inDataInBytesPerSecond node.inDataInBytesPerSecond F5 f5.node.monitorStatus node.monitorStatus F5 f5.node.outDataInBytesPerSecond node.outDataInBytesPerSecond F5 f5.node.packetsReceivedPerSecond node.packetsReceivedPerSecond F5 f5.node.packetsSentPerSecond node.packetsSentPerSecond F5 f5.node.requestsPerSecond node.requestsPerSecond F5 f5.node.sessions node.sessions F5 f5.node.sessionStatus node.sessionStatus F5 f5.poolMember.availabilityState member.availabilityState F5 f5.poolMember.connections member.connections F5 f5.poolMember.enabled member.enabled F5 f5.poolMember.inDataInBytesPerSecond member.inDataInBytesPerSecond F5 f5.poolMember.monitorStatus member.monitorStatus F5 f5.poolMember.outDataInBytesPerSecond member.outDataInBytesPerSecond F5 f5.poolMember.packetsReceivedPerSecond member.packetsReceivedPerSecond F5 f5.poolMember.packetsSentPerSecond member.packetsSentPerSecond F5 f5.poolMember.requestsPerSecond member.requestsPerSecond F5 f5.poolMember.sessions member.sessions F5 f5.poolMember.sessionStatus member.sessionStatus F5 f5.pool.activeMembers pool.activeMembers F5 f5.pool.availabilityState pool.availabilityState F5 f5.pool.connections pool.connections F5 f5.pool.connqAgeEdm pool.connqAgeEdm F5 f5.pool.connqAgeEma pool.connqAgeEma F5 f5.pool.connqAgeHead pool.connqAgeHead F5 f5.pool.connqAgeMax pool.connqAgeMax F5 f5.pool.connqAllAgeEdm pool.connqAllAgeEdm F5 f5.pool.connqAllAgeEma pool.connqAllAgeEma F5 f5.pool.connqAllAgeHead pool.connqAllAgeHead F5 f5.pool.connqAllAgeMax pool.connqAllAgeMax F5 f5.pool.connqAllDepth pool.connqAllDepth F5 f5.pool.connqDepth pool.connqDepth F5 f5.pool.currentConnections pool.currentConnections F5 f5.pool.enabled pool.enabled F5 f5.pool.inDataInBytesPerSecond pool.inDataInBytesPerSecond F5 f5.pool.minActiveMembers pool.minActiveMembers F5 f5.pool.outDataInBytesPerSecond pool.outDataInBytesPerSecond F5 f5.pool.packetsReceivedPerSecond pool.packetsReceivedPerSecond F5 f5.pool.packetsSentPerSecond pool.packetsSentPerSecond F5 f5.pool.requestsPerSecond pool.requestsPerSecond F5 f5.pool.sessions pool.sessions F5 f5.system.cpuIdleTicksPerSecond system.cpuIdleTicksPerSecond F5 f5.system.cpuIdleUtilization system.cpuIdleUtilization F5 f5.system.cpuInterruptRequestUtilization system.cpuInterruptRequestUtilization F5 f5.system.cpuIoWaitUtilization system.cpuIOWaitUtilization F5 f5.system.cpuNiceLevelUtilization system.cpuNiceLevelUtilization F5 f5.system.cpuSoftInterruptRequestUtilization system.cpuSoftInterruptRequestUtilization F5 f5.system.cpuStolenUtilization system.cpuStolenUtilization F5 f5.system.cpuSystemTicksPerSecond system.cpuSystemTicksPerSecond F5 f5.system.cpuSystemUtilization system.cpuSystemUtilization F5 f5.system.cpuUserTicksPerSecond system.cpuUserTicksPerSecond F5 f5.system.cpuUserUtilization system.cpuUserUtilization F5 f5.system.memoryFreeInBytes system.memoryFreeInBytes F5 f5.system.memoryTotalInBytes system.memoryTotalInBytes F5 f5.system.memoryUsedInBytes system.memoryUsedInBytes F5 f5.system.otherMemoryFreeInBytes system.otherMemoryFreeInBytes F5 f5.system.otherMemoryTotalInBytes system.otherMemoryTotalInBytes F5 f5.system.otherMemoryUsedInBytes system.otherMemoryUsedInBytes F5 f5.system.swapFreeInBytes system.swapFreeInBytes F5 f5.system.swapTotalInBytes system.swapTotalInBytes F5 f5.system.swapUsedInBytes system.swapUsedInBytes F5 f5.system.tmmMemoryFreeInBytes system.tmmMemoryFreeInBytes F5 f5.system.tmmMemoryTotalInBytes system.tmmMemoryTotalInBytes F5 f5.system.tmmMemoryUsedInBytes system.tmmMemoryUsedInBytes F5 f5.virtualserver.availabilityState virtualserver.availabilityState F5 f5.virtualserver.clientsideConnectionsPerSecond virtualserver.clientsideConnectionsPerSecond F5 f5.virtualserver.connections virtualserver.connections F5 f5.virtualserver.csMaxConnDur virtualserver.csMaxConnDur F5 f5.virtualserver.csMeanConnDur virtualserver.csMeanConnDur F5 f5.virtualserver.csMinConnDur virtualserver.csMinConnDur F5 f5.virtualserver.enabled virtualserver.enabled F5 f5.virtualserver.ephemeralBytesInPerSecond virtualserver.ephemeralBytesInPerSecond F5 f5.virtualserver.ephemeralBytesOutPerSecond virtualserver.ephemeralBytesOutPerSecond F5 f5.virtualserver.ephemeralConnectionsPerSecond virtualserver.ephemeralConnectionsPerSecond F5 f5.virtualserver.ephemeralCurrentConnections virtualserver.ephemeralCurrentConnections F5 f5.virtualserver.ephemeralEvictedConnectionsPerSecond virtualserver.ephemeralEvictedConnectionsPerSecond F5 f5.virtualserver.ephemeralMaxConnections virtualserver.ephemeralMaxConnections F5 f5.virtualserver.ephemeralPacketsReceivedPerSecond virtualserver.ephemeralPacketsReceivedPerSecond F5 f5.virtualserver.ephemeralPacketsSentPerSecond virtualserver.ephemeralPacketsSentPerSecond F5 f5.virtualserver.ephemeralSlowKilledPerSecond virtualserver.ephemeralSlowKilledPerSecond F5 f5.virtualserver.evictedConnsPerSecond virtualserver.evictedConnsPerSecond F5 f5.virtualserver.inDataInBytesPerSecond virtualserver.inDataInBytesPerSecond F5 f5.virtualserver.outDataInBytesPerSecond virtualserver.outDataInBytesPerSecond F5 f5.virtualserver.packetsReceivedPerSecond virtualserver.packetsReceivedPerSecond F5 f5.virtualserver.packetsSentPerSecond virtualserver.packetsSentPerSecond F5 f5.virtualserver.requestsPerSecond virtualserver.requestsPerSecond F5 f5.virtualserver.slowKilledPerSecond virtualserver.slowKilledPerSecond F5 f5.virtualserver.usageRatio virtualserver.usageRatio HAProxy haproxy.backend.activeServers backend.activeServers HAProxy haproxy.backend.averageConnectTimeInSeconds backend.averageConnectTimeInSeconds HAProxy haproxy.backend.averageQueueTimeInSeconds backend.averageQueueTimeInSeconds HAProxy haproxy.backend.averageResponseTimeInSeconds backend.averageResponseTimeInSeconds HAProxy haproxy.backend.averageTotalSessionTimeInSeconds backend.averageTotalSessionTimeInSeconds HAProxy haproxy.backend.backupServers backend.backupServers HAProxy haproxy.backend.bytesInPerSecond backend.bytesInPerSecond HAProxy haproxy.backend.bytesOutPerSecond backend.bytesOutPerSecond HAProxy haproxy.backend.bytesThatBypassedCompressorPerSecond backend.bytesThatBypassedCompressorPerSecond HAProxy haproxy.backend.connectingRequestErrorsPerSecond backend.connectingRequestErrorsPerSecond HAProxy haproxy.backend.connectionRetriesPerSecond backend.connectionRetriesPerSecond HAProxy haproxy.backend.currentQueuedRequestsWithoutServer backend.currentQueuedRequestsWithoutServer HAProxy haproxy.backend.currentSessions backend.currentSessions HAProxy haproxy.backend.dataTransfersAbortedByClientPerSecond backend.dataTransfersAbortedByClientPerSecond HAProxy haproxy.backend.dataTransfersAbortedByServerPerSecond backend.dataTransfersAbortedByServerPerSecond HAProxy haproxy.backend.downtimeInSeconds backend.downtimeInSeconds HAProxy haproxy.backend.http100ResponsesPerSecond backend.http100ResponsesPerSecond HAProxy haproxy.backend.http200ResponsesPerSecond backend.http200ResponsesPerSecond HAProxy haproxy.backend.http300ResponsesPerSecond backend.http300ResponsesPerSecond HAProxy haproxy.backend.http400ResponsesPerSecond backend.http400ResponsesPerSecond HAProxy haproxy.backend.http500ResponsesPerSecond backend.http500ResponsesPerSecond HAProxy haproxy.backend.httpOtherResponsesPerSecond backend.httpOtherResponsesPerSecond HAProxy haproxy.backend.httpRequestsPerSecond backend.httpRequestsPerSecond HAProxy haproxy.backend.httpResponseBytesEmittedByCompressorPerSecond backend.httpResponseBytesEmittedByCompressorPerSecond HAProxy haproxy.backend.httpResponseBytesFedToCompressorPerSecond backend.httpResponseBytesFedToCompressorPerSecond HAProxy haproxy.backend.httpResponsesCompressedPerSecond backend.httpResponsesCompressedPerSecond HAProxy haproxy.backend.interceptedRequestsPerSecond backend.interceptedRequestsPerSecond HAProxy haproxy.backend.maxQueuedRequestsWithoutServer backend.maxQueuedRequestsWithoutServer HAProxy haproxy.backend.maxSessions backend.maxSessions HAProxy haproxy.backend.maxSessionsPerSecond backend.maxSessionsPerSecond HAProxy haproxy.backend.requestRedispatchPerSecond backend.requestRedispatchPerSecond HAProxy haproxy.backend.requestsDenied.securityConcernsPerSecond backend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.backend.responseErrorsPerSecond backend.responseErrorsPerSecond HAProxy haproxy.backend.responsesDenied.securityConcernsPerSecond backend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.backend.serverSelectedPerSecond backend.serverSelectedPerSecond HAProxy haproxy.backend.sessionsPerSecond backend.sessionsPerSecond HAProxy haproxy.backend.timeSinceLastSessionAssignedInSeconds backend.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.backend.timeSinceLastUpDownTransitionInSeconds backend.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.backend.totalWeight backend.totalWeight HAProxy haproxy.backend.type backend.type HAProxy haproxy.backend.upToDownTransitionsPerSecond backend.upToDownTransitionsPerSecond HAProxy haproxy.frontend.bytesInPerSecond frontend.bytesInPerSecond HAProxy haproxy.frontend.bytesOutPerSecond frontend.bytesOutPerSecond HAProxy haproxy.frontend.connectionsPerSecond frontend.connectionsPerSecond HAProxy haproxy.frontend.currentSessions frontend.currentSessions HAProxy haproxy.frontend.http100ResponsesPerSecond frontend.http100ResponsesPerSecond HAProxy haproxy.frontend.http200ResponsesPerSecond frontend.http200ResponsesPerSecond HAProxy haproxy.frontend.http300ResponsesPerSecond frontend.http300ResponsesPerSecond HAProxy haproxy.frontend.http400ResponsesPerSecond frontend.http400ResponsesPerSecond HAProxy haproxy.frontend.http500ResponsesPerSecond frontend.http500ResponsesPerSecond HAProxy haproxy.frontend.httpOtherResponsesPerSecond frontend.httpOtherResponsesPerSecond HAProxy haproxy.frontend.httpRequests.maxPerSecond frontend.httpRequests.maxPerSecond HAProxy haproxy.frontend.httpRequestsPerSecond frontend.httpRequestsPerSecond HAProxy haproxy.frontend.interceptedRequestsPerSecond frontend.interceptedRequestsPerSecond HAProxy haproxy.frontend.maxConnectionsPerSecond frontend.maxConnectionsPerSecond HAProxy haproxy.frontend.maxSessions frontend.maxSessions HAProxy haproxy.frontend.maxSessionsPerSecond frontend.maxSessionsPerSecond HAProxy haproxy.frontend.requestErrorsPerSecond frontend.requestErrorsPerSecond HAProxy haproxy.frontend.requestsDenied.securityConcernsPerSecond frontend.requestsDenied.securityConcernsPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestConnectionRulesPerSecond frontend.requestsDenied.tcpRequestConnectionRulesPerSecond HAProxy haproxy.frontend.requestsDenied.tcpRequestSessionRulesPerSecond frontend.requestsDenied.tcpRequestSessionRulesPerSecond HAProxy haproxy.frontend.responsesDenied.securityConcernsPerSecond frontend.responsesDenied.securityConcernsPerSecond HAProxy haproxy.frontend.sessionsPerSecond frontend.sessionsPerSecond HAProxy haproxy.server.averageConnectTimeInSeconds server.averageConnectTimeInSeconds HAProxy haproxy.server.averageQueueTimeInSeconds server.averageQueueTimeInSeconds HAProxy haproxy.server.averageResponseTimeInSeconds server.averageResponseTimeInSeconds HAProxy haproxy.server.averageTotalSessionTimeInSeconds server.averageTotalSessionTimeInSeconds HAProxy haproxy.server.bytesInPerSecond server.bytesInPerSecond HAProxy haproxy.server.bytesOutPerSecond server.bytesOutPerSecond HAProxy haproxy.server.connectingRequestErrorsPerSecond server.connectingRequestErrorsPerSecond HAProxy haproxy.server.connectionRetriesPerSecond server.connectionRetriesPerSecond HAProxy haproxy.server.currentQueuedRequestsWithoutServer server.currentQueuedRequestsWithoutServer HAProxy haproxy.server.currentSessions server.currentSessions HAProxy haproxy.server.dataTransfersAbortedByClientPerSecond server.dataTransfersAbortedByClientPerSecond HAProxy haproxy.server.dataTransfersAbortedByServerPerSecond server.dataTransfersAbortedByServerPerSecond HAProxy haproxy.server.downtimeInSeconds server.downtimeInSeconds HAProxy haproxy.server.failedChecksPerSecond server.failedChecksPerSecond HAProxy haproxy.server.healthCheckDurationInMilliseconds server.healthCheckDurationInMilliseconds HAProxy haproxy.server.http100ResponsesPerSecond server.http100ResponsesPerSecond HAProxy haproxy.server.http200ResponsesPerSecond server.http200ResponsesPerSecond HAProxy haproxy.server.http300ResponsesPerSecond server.http300ResponsesPerSecond HAProxy haproxy.server.http400ResponsesPerSecond server.http400ResponsesPerSecond HAProxy haproxy.server.http500ResponsesPerSecond server.http500ResponsesPerSecond HAProxy haproxy.server.httpOtherResponsesPerSecond server.httpOtherResponsesPerSecond HAProxy haproxy.server.isActive server.isActive HAProxy haproxy.server.isBackup server.isBackup HAProxy haproxy.server.maxQueuedRequestsWithoutServer server.maxQueuedRequestsWithoutServer HAProxy haproxy.server.maxSessions server.maxSessions HAProxy haproxy.server.maxSessionsPerSecond server.maxSessionsPerSecond HAProxy haproxy.server.requestRedispatchPerSecond server.requestRedispatchPerSecond HAProxy haproxy.server.requestsDenied.securityConcernsPerSecond server.requestsDenied.securityConcernsPerSecond HAProxy haproxy.server.responseErrorsPerSecond server.responseErrorsPerSecond HAProxy haproxy.server.responsesDenied.securityConcernsPerSecond server.responsesDenied.securityConcernsPerSecond HAProxy haproxy.server.serverSelectedPerSecond server.serverSelectedPerSecond HAProxy haproxy.server.serverWeight server.serverWeight HAProxy haproxy.server.sessionsPerSecond server.sessionsPerSecond HAProxy haproxy.server.throttlePercentage server.throttlePercentage HAProxy haproxy.server.timeSinceLastSessionAssignedInSeconds server.timeSinceLastSessionAssignedInSeconds HAProxy haproxy.server.timeSinceLastUpDownTransitionInSeconds server.timeSinceLastUpDownTransitionInSeconds HAProxy haproxy.server.type server.type HAProxy haproxy.server.upToDownTransitionsPerSecond server.upToDownTransitionsPerSecond Kafka kafka.broker.bytesWrittenToTopicPerSecond broker.bytesWrittenToTopicPerSecond Kafka kafka.broker.consumer.requestsExpiredPerSecond consumer.requestsExpiredPerSecond Kafka kafka.broker.follower.requestExpirationPerSecond follower.requestExpirationPerSecond Kafka kafka.broker.ioInPerSecond broker.IOInPerSecond Kafka kafka.broker.ioOutPerSecond broker.IOOutPerSecond Kafka kafka.broker.logFlushPerSecond broker.logFlushPerSecond Kafka kafka.broker.messagesInPerSecond broker.messagesInPerSecond Kafka kafka.broker.net.bytesRejectedPerSecond net.bytesRejectedPerSecond Kafka kafka.broker.replication.isrExpandsPerSecond replication.isrExpandsPerSecond Kafka kafka.broker.replication.isrShrinksPerSecond replication.isrShrinksPerSecond Kafka kafka.broker.replication.leaderElectionPerSecond replication.leaderElectionPerSecond Kafka kafka.broker.replication.uncleanLeaderElectionPerSecond replication.uncleanLeaderElectionPerSecond Kafka kafka.broker.replication.unreplicatedPartitions replication.unreplicatedPartitions Kafka kafka.broker.request.avgTimeFetch request.avgTimeFetch Kafka kafka.broker.request.avgTimeMetadata request.avgTimeMetadata Kafka kafka.broker.request.avgTimeMetadata99Percentile request.avgTimeMetadata99Percentile Kafka kafka.broker.request.avgTimeOffset request.avgTimeOffset Kafka kafka.broker.request.avgTimeOffset99Percentile request.avgTimeOffset99Percentile Kafka kafka.broker.request.avgTimeProduceRequest request.avgTimeProduceRequest Kafka kafka.broker.request.avgTimeUpdateMetadata request.avgTimeUpdateMetadata Kafka kafka.broker.request.avgTimeUpdateMetadata99Percentile request.avgTimeUpdateMetadata99Percentile Kafka kafka.broker.request.clientFetchesFailedPerSecond request.clientFetchesFailedPerSecond Kafka kafka.broker.request.fetchConsumerRequestsPerSecond request.fetchConsumerRequestsPerSecond Kafka kafka.broker.request.fetchFollowerRequestsPerSecond request.fetchFollowerRequestsPerSecond Kafka kafka.broker.request.fetchTime99Percentile request.fetchTime99Percentile Kafka kafka.broker.request.handlerIdle request.handlerIdle Kafka kafka.broker.request.listGroupsRequestsPerSecond request.listGroupsRequestsPerSecond Kafka kafka.broker.request.metadataRequestsPerSecond request.metadataRequestsPerSecond Kafka kafka.broker.request.offsetCommitRequestsPerSecond request.offsetCommitRequestsPerSecond Kafka kafka.broker.request.produceRequestsFailedPerSecond request.produceRequestsFailedPerSecond Kafka kafka.broker.request.produceRequestsPerSecond request.produceRequestsPerSecond Kafka kafka.broker.request.produceTime99Percentile request.produceTime99Percentile Kafka kafka.broker.topic.diskSize topic.diskSize Kafka kafka.topic.bytesInPerSec topic.BytesInPerSec Kafka kafka.topic.bytesOutPerSec topic.BytesOutPerSec Kafka kafka.topic.messagesInPerSec topic.MessagesInPerSec Kafka kafka.topic.partitionsWithNonPreferredLeader topic.partitionsWithNonPreferredLeader Kafka kafka.topic.respondsToMetadataRequests topic.respondsToMetadataRequests Kafka kafka.topic.retentionBytesOrTime topic.retentionBytesOrTime Kafka kafka.topic.underReplicatedPartitions topic.underReplicatedPartitions Kafka kafka.producer.ageMetadataUsedInMilliseconds producer.ageMetadataUsedInMilliseconds Kafka kafka.producer.availableBufferInBytes producer.availableBufferInBytes Kafka kafka.producer.avgBytesSentPerRequestInBytes producer.avgBytesSentPerRequestInBytes Kafka kafka.producer.avgCompressionRateRecordBatches producer.avgCompressionRateRecordBatches Kafka kafka.producer.avgRecordAccumulatorsInMilliseconds producer.avgRecordAccumulatorsInMilliseconds Kafka kafka.producer.avgRecordSizeInBytes producer.avgRecordSizeInBytes Kafka kafka.producer.avgRecordsSentPerSecond producer.avgRecordsSentPerSecond Kafka kafka.producer.avgRecordsSentPerTopicPerSecond producer.avgRecordsSentPerTopicPerSecond Kafka kafka.producer.avgRequestLatency producer.avgRequestLatencyPerSecond Kafka kafka.producer.avgThrottleTime producer.avgThrottleTime Kafka kafka.producer.bufferMemoryAvailableInBytes producer.bufferMemoryAvailableInBytes Kafka kafka.producer.bufferpoolWaitTime producer.bufferpoolWaitTime Kafka kafka.producer.bytesOutPerSecond producer.bytesOutPerSecond Kafka kafka.producer.compressionRateRecordBatches producer.compressionRateRecordBatches Kafka kafka.producer.ioWaitTime producer.ioWaitTime Kafka kafka.producer.maxBytesSentPerRequestInBytes producer.maxBytesSentPerRequestInBytes Kafka kafka.producer.maxRecordSizeInBytes producer.maxRecordSizeInBytes Kafka kafka.producer.maxRequestLatencyInMilliseconds producer.maxRequestLatencyInMilliseconds Kafka kafka.producer.maxThrottleTime producer.maxThrottleTime Kafka kafka.producer.requestPerSecond producer.requestPerSecond Kafka kafka.producer.requestsWaitingResponse producer.requestsWaitingResponse Kafka kafka.producer.responsePerSecond producer.responsePerSecond Kafka kafka.producer.threadsWaiting producer.threadsWaiting Kafka kafka.consumer.avgFetchSizeInBytes consumer.avgFetchSizeInBytes Kafka kafka.consumer.avgRecordConsumedPerTopic consumer.avgRecordConsumedPerTopic Kafka kafka.consumer.avgRecordConsumedPerTopicPerSecond consumer.avgRecordConsumedPerTopicPerSecond Kafka kafka.consumer.bytesInPerSecond consumer.bytesInPerSecond Kafka kafka.consumer.fetchPerSecond consumer.fetchPerSecond Kafka kafka.consumer.hwm consumer.hwm Kafka kafka.consumer.lag consumer.lag Kafka kafka.consumer.maxFetchSizeInBytes consumer.maxFetchSizeInBytes Kafka kafka.consumer.maxLag consumer.maxLag Kafka kafka.consumer.messageConsumptionPerSecond consumer.messageConsumptionPerSecond Kafka kafka.consumer.offset consumer.offset Kafka kafka.consumer.totalLag consumer.totalLag Kafka kafka.consumerGroup.maxLag consumerGroup.maxLag Kafka kafka.consumerGroup.totalLag consumerGroup.totalLag Kubernetes k8s.apiserver.goGoroutines goGoroutines Kubernetes k8s.apiserver.goThreads goThreads Kubernetes k8s.apiserver.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.apiserver.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.controllermanager.goGoroutines goGoroutines Kubernetes k8s.controllermanager.goThreads goThreads Kubernetes k8s.controllermanager.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.controllermanager.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.controllermanager.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.goGoroutines goGoroutines Kubernetes k8s.etcd.goThreads goThreads Kubernetes k8s.etcd.mvccDbTotalSizeInBytes etcdMvccDbTotalSizeInBytes Kubernetes k8s.etcd.networkClientGrpcReceivedBytesRate etcdNetworkClientGrpcReceivedBytesRate Kubernetes k8s.etcd.networkClientGrpcSentBytesRate etcdNetworkClientGrpcSentBytesRate Kubernetes k8s.etcd.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.etcd.process.maxFds processMaxFds Kubernetes k8s.etcd.process.openFds processOpenFds Kubernetes k8s.etcd.process.processFdsUtilization processFdsUtilization Kubernetes k8s.etcd.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.etcd.serverHasLeader etcdServerHasLeader Kubernetes k8s.etcd.serverLeaderChangesSeenDelta etcdServerLeaderChangesSeenDelta Kubernetes k8s.etcd.serverProposalsAppliedDelta etcdServerProposalsAppliedDelta Kubernetes k8s.etcd.serverProposalsAppliedRate etcdServerProposalsAppliedRate Kubernetes k8s.etcd.serverProposalsCommittedDelta etcdServerProposalsCommittedDelta Kubernetes k8s.etcd.serverProposalsCommittedRate etcdServerProposalsCommittedRate Kubernetes k8s.etcd.serverProposalsFailedDelta etcdServerProposalsFailedDelta Kubernetes k8s.etcd.serverProposalsFailedRate etcdServerProposalsFailedRate Kubernetes k8s.etcd.serverProposalsPending etcdServerProposalsPending Kubernetes k8s.scheduler.goGoroutines goGoroutines Kubernetes k8s.scheduler.goThreads goThreads Kubernetes k8s.scheduler.leaderElectionMasterStatus leaderElectionMasterStatus Kubernetes k8s.scheduler.podPreemptionVictims schedulerPodPreemptionVictims Kubernetes k8s.scheduler.preemptionAttemptsDelta schedulerPreemptionAttemptsDelta Kubernetes k8s.scheduler.process.cpuSecondsDelta processCpuSecondsDelta Kubernetes k8s.scheduler.process.residentMemoryBytes processResidentMemoryBytes Kubernetes k8s.container.cpuCfsPeriodsDelta containerCpuCfsPeriodsDelta Kubernetes k8s.container.cpuCfsPeriodsTotal containerCpuCfsPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledPeriodsDelta containerCpuCfsThrottledPeriodsDelta Kubernetes k8s.container.cpuCfsThrottledPeriodsTotal containerCpuCfsThrottledPeriodsTotal Kubernetes k8s.container.cpuCfsThrottledSecondsDelta containerCpuCfsThrottledSecondsDelta Kubernetes k8s.container.cpuCfsThrottledSecondsTotal containerCpuCfsThrottledSecondsTotal Kubernetes k8s.container.cpuCoresUtilization cpuCoresUtilization Kubernetes k8s.container.cpuLimitCores cpuLimitCores Kubernetes k8s.container.cpuRequestedCores cpuRequestedCores Kubernetes k8s.container.cpuUsedCores cpuUsedCores Kubernetes k8s.container.fsAvailableBytes fsAvailableBytes Kubernetes k8s.container.fsCapacityBytes fsCapacityBytes Kubernetes k8s.container.fsInodes fsInodes Kubernetes k8s.container.fsInodesFree fsInodesFree Kubernetes k8s.container.fsInodesUsed fsInodesUsed Kubernetes k8s.container.fsUsedBytes fsUsedBytes Kubernetes k8s.container.fsUsedPercent fsUsedPercent Kubernetes k8s.container.isReady isReady Kubernetes k8s.container.memoryLimitBytes memoryLimitBytes Kubernetes k8s.container.memoryMappedFileBytes containerMemoryMappedFileBytes Kubernetes k8s.container.memoryRequestedBytes memoryRequestedBytes Kubernetes k8s.container.memoryUsedBytes memoryUsedBytes Kubernetes k8s.container.memoryUtilization memoryUtilization Kubernetes k8s.container.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.container.requestedCpuCoresUtilization requestedCpuCoresUtilization Kubernetes k8s.container.requestedMemoryUtilization requestedMemoryUtilization Kubernetes k8s.container.restartCount restartCount Kubernetes k8s.daemonset.createdAt createdAt Kubernetes k8s.daemonset.metadataGeneration metadataGeneration Kubernetes k8s.daemonset.podsAvailable podsAvailable Kubernetes k8s.daemonset.podsDesired podsDesired Kubernetes k8s.daemonset.podsMisscheduled podsMisscheduled Kubernetes k8s.daemonset.podsReady podsReady Kubernetes k8s.daemonset.podsScheduled podsScheduled Kubernetes k8s.daemonset.podsUnavailable podsUnavailable Kubernetes k8s.daemonset.podsUpdatedScheduled podsUpdatedScheduled Kubernetes k8s.deployment.createdAt createdAt Kubernetes k8s.deployment.podsAvailable podsAvailable Kubernetes k8s.deployment.podsDesired podsDesired Kubernetes k8s.deployment.podsMaxUnavailable podsMaxUnavailable Kubernetes k8s.deployment.podsTotal podsTotal Kubernetes k8s.deployment.podsUnavailable podsUnavailable Kubernetes k8s.deployment.podsUpdated podsUpdated Kubernetes k8s.endpoint.addressAvailable addressAvailable Kubernetes k8s.endpoint.addressNotReady addressNotReady Kubernetes k8s.endpoint.createdAt createdAt Kubernetes k8s.namespace.createdAt createdAt Kubernetes k8s.node.allocatableAttachableVolumes* allocatableAttachableVolumes* Kubernetes k8s.node.allocatableCpuCores allocatableCpuCores Kubernetes k8s.node.allocatableCpuCoresUtilization allocatableCpuCoresUtilization Kubernetes k8s.node.allocatableEphemeralStorageBytes allocatableEphemeralStorageBytes Kubernetes k8s.node.allocatableHugepages* allocatableHugepages* Kubernetes k8s.node.allocatableMemoryBytes allocatableMemoryBytes Kubernetes k8s.node.allocatableMemoryUtilization allocatableMemoryUtilization Kubernetes k8s.node.allocatablePods allocatablePods Kubernetes k8s.node.capacityAttachableVolumes* capacityAttachableVolumes* Kubernetes k8s.node.capacityCpuCores capacityCpuCores Kubernetes k8s.node.capacityEphemeralStorageBytes capacityEphemeralStorageBytes Kubernetes k8s.node.capacityHugepages* capacityHugepages* Kubernetes k8s.node.capacityMemoryBytes capacityMemoryBytes Kubernetes k8s.node.capacityPods capacityPods Kubernetes k8s.node.cpuUsedCoreMilliseconds cpuUsedCoreMilliseconds Kubernetes k8s.node.cpuUsedCores cpuUsedCores Kubernetes k8s.node.fsAvailableBytes fsAvailableBytes Kubernetes k8s.node.fsCapacityBytes fsCapacityBytes Kubernetes k8s.node.fsCapacityUtilization fsCapacityUtilization Kubernetes k8s.node.fsInodes fsInodes Kubernetes k8s.node.fsInodesFree fsInodesFree Kubernetes k8s.node.fsInodesUsed fsInodesUsed Kubernetes k8s.node.fsUsedBytes fsUsedBytes Kubernetes k8s.node.memoryAvailableBytes memoryAvailableBytes Kubernetes k8s.node.memoryMajorPageFaultsPerSecond memoryMajorPageFaultsPerSecond Kubernetes k8s.node.memoryPageFaults memoryPageFaults Kubernetes k8s.node.memoryRssBytes memoryRssBytes Kubernetes k8s.node.memoryUsedBytes memoryUsedBytes Kubernetes k8s.node.memoryWorkingSetBytes memoryWorkingSetBytes Kubernetes k8s.node.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.node.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.node.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.node.runtimeAvailableBytes runtimeAvailableBytes Kubernetes k8s.node.runtimeCapacityBytes runtimeCapacityBytes Kubernetes k8s.node.runtimeInodes runtimeInodes Kubernetes k8s.node.runtimeInodesFree runtimeInodesFree Kubernetes k8s.node.runtimeInodesUsed runtimeInodesUsed Kubernetes k8s.node.runtimeUsedBytes runtimeUsedBytes Kubernetes k8s.pod.createdAt createdAt Kubernetes k8s.pod.isReady isReady Kubernetes k8s.pod.isScheduled isScheduled Kubernetes k8s.pod.netErrorsPerSecond net.errorsPerSecond Kubernetes k8s.pod.netRxBytesPerSecond net.rxBytesPerSecond Kubernetes k8s.pod.netTxBytesPerSecond net.txBytesPerSecond Kubernetes k8s.pod.startTime startTime Kubernetes k8s.replicaset.createdAt createdAt Kubernetes k8s.replicaset.observedGeneration observedGeneration Kubernetes k8s.replicaset.podsDesired podsDesired Kubernetes k8s.replicaset.podsFullyLabeled podsFullyLabeled Kubernetes k8s.replicaset.podsMissing podsMissing Kubernetes k8s.replicaset.podsReady podsReady Kubernetes k8s.replicaset.podsTotal podsTotal Kubernetes k8s.service.createdAt createdAt Kubernetes k8s.statefulset.createdAt createdAt Kubernetes k8s.statefulset.currentRevision currentRevision Kubernetes k8s.statefulset.metadataGeneration metadataGeneration Kubernetes k8s.statefulset.observedGeneration observedGeneration Kubernetes k8s.statefulset.podsCurrent podsCurrent Kubernetes k8s.statefulset.podsDesired podsDesired Kubernetes k8s.statefulset.podsReady podsReady Kubernetes k8s.statefulset.podsTotal podsTotal Kubernetes k8s.statefulset.podsUpdated podsUpdated Kubernetes k8s.statefulset.updateRevision updateRevision Kubernetes k8s.volume.fsAvailableBytes fsAvailableBytes Kubernetes k8s.volume.fsCapacityBytes fsCapacityBytes Kubernetes k8s.volume.fsInodes fsInodes Kubernetes k8s.volume.fsInodesFree fsInodesFree Kubernetes k8s.volume.fsInodesUsed fsInodesUsed Kubernetes k8s.volume.fsUsedBytes fsUsedBytes Kubernetes k8s.volume.fsUsedPercent fsUsedPercent Memcached memcached.server.activeSlabs activeSlabs Memcached memcached.server.avgItemSizeInBytes avgItemSizeInBytes Memcached memcached.server.bytesReadServerPerSecond bytesReadServerPerSecond Memcached memcached.server.bytesUsedServerInBytes bytesUsedServerInBytes Memcached memcached.server.bytesWrittenServerPerSecond bytesWrittenServerPerSecond Memcached memcached.server.casHitRatePerSecond casHitRatePerSecond Memcached memcached.server.casMissRatePerSecond casMissRatePerSecond Memcached memcached.server.casWrongRatePerSecond casWrongRatePerSecond Memcached memcached.server.cmdFlushRatePerSecond cmdFlushRatePerSecond Memcached memcached.server.cmdGetRatePerSecond cmdGetRatePerSecond Memcached memcached.server.cmdSetRatePerSecond cmdSetRatePerSecond Memcached memcached.server.connectionRateServerPerSecond connectionRateServerPerSecond Memcached memcached.server.connectionStructuresAllocated connectionStructuresAllocated Memcached memcached.server.currentItemsStoredServer currentItemsStoredServer Memcached memcached.server.deleteCmdNoneRemovedPerSecond deleteCmdNoneRemovedPerSecond Memcached memcached.server.deleteCmdRemovedPerSecond deleteCmdRemovedPerSecond Memcached memcached.server.evictionsPerSecond evictionsPerSecond Memcached memcached.server.getHitPercent getHitPercent Memcached memcached.server.getHitPerSecond getHitPerSecond Memcached memcached.server.getMissPerSecond getMissPerSecond Memcached memcached.server.itemsStoredPerSecond itemsStoredPerSecond Memcached memcached.server.limitBytesStorage limitBytesStorage Memcached memcached.server.limitMaxBytes limitMaxBytes Memcached memcached.server.maxConnectionLimitPerSecond serverMaxConnectionLimitPerSecond Memcached memcached.server.memAllocatedSlabsInBytes memAllocatedSlabsInBytes Memcached memcached.server.openConnectionsServer openConnectionsServer Memcached memcached.server.pointerSize pointerSize Memcached memcached.server.rusageSystem usageRate Memcached memcached.server.rusageUser executionTime Memcached memcached.server.storingItemsPercentMemory storingItemsPercentMemory Memcached memcached.server.threads threads Memcached memcached.server.uptimeInMilliseconds uptimeInMilliseconds Memcached memcached.slab.activeItemsBumpedPerSecond activeItemsBumpedPerSecond Memcached memcached.slab.casBadValPerSecond casBadValPerSecond Memcached memcached.slab.casModifiedSlabPerSecond casModifiedSlabPerSecond Memcached memcached.slab.chunkSizeInBytes chunkSizeInBytes Memcached memcached.slab.chunksPerPage chunksPerPage Memcached memcached.slab.cmdSetRateSlabPerSecond cmdSetRateSlabPerSecond Memcached memcached.slab.decrsModifySlabPerSecond decrsModifySlabPerSecond Memcached memcached.slab.deleteRateSlabPerSecond deleteRateSlabPerSecond Memcached memcached.slab.entriesReclaimedPerSecond entriesReclaimedPerSecond Memcached memcached.slab.evictionsBeforeExpirationPerSecond evictionsBeforeExpirationPerSecond Memcached memcached.slab.evictionsBeforeExplicitExpirationPerSecond evictionsBeforeExplicitExpirationPerSecond Memcached memcached.slab.expiredItemsReclaimedPerSecond expiredItemsReclaimedPerSecond Memcached memcached.slab.freedChunks freedChunks Memcached memcached.slab.freedChunksEnd freedChunksEnd Memcached memcached.slab.getHitRateSlabPerSecond getHitRateSlabPerSecond Memcached memcached.slab.incrsModifySlabPerSecond incrsModifySlabPerSecond Memcached memcached.slab.itemsCold itemsCold Memcached memcached.slab.itemsColdPerSecond itemsColdPerSecond Memcached memcached.slab.itemsDirectReclaimedPerSecond itemsDirectReclaimedPerSecond Memcached memcached.slab.itemsFreedCrawlerPerSecond itemsFreedCrawlerPerSecond Memcached memcached.slab.itemsHot itemsHot Memcached memcached.slab.itemsOldestInMilliseconds itemsOldestInMilliseconds Memcached memcached.slab.itemsRefcountLockedPerSecond itemsRefcountLockedPerSecond Memcached memcached.slab.itemsSlabClass itemsSlabClass Memcached memcached.slab.itemsTimeSinceEvictionInMilliseconds itemsTimeSinceEvictionInMilliseconds Memcached memcached.slab.itemsWarm itemsWarm Memcached memcached.slab.itemsWarmPerSecond itemsWarmPerSecond Memcached memcached.slab.memRequestedSlabInBytesPerSecond memRequestedSlabInBytesPerSecond Memcached memcached.slab.outOfMemoryPerSecond outOfMemoryPerSecond Memcached memcached.slab.selfHealedSlabPerSecond selfHealedSlabPerSecond Memcached memcached.slab.totalChunksSlab totalChunksSlab Memcached memcached.slab.totalPagesSlab totalPagesSlab Memcached memcached.slab.touchHitSlabPerSecond touchHitSlabPerSecond Memcached memcached.slab.usedChunksItems usedChunksItems Memcached memcached.slab.usedChunksPerSecond usedChunksPerSecond Memcached memcached.slab.validItemsEvictedPerSecond validItemsEvictedPerSecond MongoDB mongo.index.accesses collection.indexAccesses MongoDB mongo.index.sizeInBytes collection.indexSizeInBytes MongoDB mongo.collection.avgObjSizeInBytes collection.avgObjSizeInBytes MongoDB mongo.collection.capped collection.capped MongoDB mongo.collection.count collection.count MongoDB mongo.collection.max collection.max MongoDB mongo.collection.maxSizeInBytes collection.maxSizeInBytes MongoDB mongo.collection.nindexes collection.nindexes MongoDB mongo.collection.sizeInBytes collection.sizeInBytes MongoDB mongo.collection.storageSizeInBytes collection.storageSizeInBytes MongoDB mongo.configServer.asserts.messagesPerSecond asserts.messagesPerSecond MongoDB mongo.configServer.asserts.regularPerSecond asserts.regularPerSecond MongoDB mongo.configServer.asserts.rolloversPerSecond asserts.rolloversPerSecond MongoDB mongo.configServer.asserts.userPerSecond asserts.userPerSecond MongoDB mongo.configServer.asserts.warningPerSecond asserts.warningPerSecond MongoDB mongo.configServer.commands.countFailedPerSecond commands.countFailedPerSecond MongoDB mongo.configServer.commands.countPerSecond commands.countPerSecond MongoDB mongo.configServer.commands.createIndexesFailedPerSecond commands.createIndexesFailedPerSecond MongoDB mongo.configServer.commands.createIndexesPerSecond commands.createIndexesPerSecond MongoDB mongo.configServer.commands.deleteFailedPerSecond commands.deleteFailedPerSecond MongoDB mongo.configServer.commands.deletePerSecond commands.deletePerSecond MongoDB mongo.configServer.commands.evalFailedPerSecond commands.evalFailedPerSecond MongoDB mongo.configServer.commands.evalPerSecond commands.evalPerSecond MongoDB mongo.configServer.commands.findAndModifyFailedPerSecond commands.findAndModifyFailedPerSecond MongoDB mongo.configServer.commands.findAndModifyPerSecond commands.findAndModifyPerSecond MongoDB mongo.configServer.commands.insertFailedPerSecond commands.insertFailedPerSecond MongoDB mongo.configServer.commands.insertPerSecond commands.insertPerSecond MongoDB mongo.configServer.commands.updateFailedPerSecond commands.updateFailedPerSecond MongoDB mongo.configServer.commands.updatePerSecond commands.updatePerSecond MongoDB mongo.configServer.connections.available connections.available MongoDB mongo.configServer.connections.current connections.current MongoDB mongo.configServer.connections.totalCreated connections.totalCreated MongoDB mongo.configServer.cursor.openNoTimeout cursor.openNoTimeout MongoDB mongo.configServer.cursor.openPinned cursor.openPinned MongoDB mongo.configServer.cursor.openTotal cursor.openTotal MongoDB mongo.configServer.cursor.timedOutPerSecond cursor.timedOutPerSecond MongoDB mongo.configServer.document.deletedPerSecond document.deletedPerSecond MongoDB mongo.configServer.document.insertedPerSecond document.insertedPerSecond MongoDB mongo.configServer.document.returnedPerSecond document.returnedPerSecond MongoDB mongo.configServer.document.updatedPerSecond document.updatedPerSecond MongoDB mongo.configServer.dur.commits dur.commits MongoDB mongo.configServer.dur.commitsInWriteLock dur.commitsInWriteLock MongoDB mongo.configServer.dur.compression dur.compression MongoDB mongo.configServer.dur.earlyCommits dur.earlyCommits MongoDB mongo.configServer.dur.preparingInMilliseconds dur.preparingInMilliseconds MongoDB mongo.configServer.dur.remappingInMilliseconds dur.remappingInMilliseconds MongoDB mongo.configServer.dur.timeCollectedCommitsInMilliseconds dur.timeCollectedCommitsInMilliseconds MongoDB mongo.configServer.dur.writingDataFilesInMilliseconds dur.writingDataFilesInMilliseconds MongoDB mongo.configServer.dur.writingJournalInMilliseconds dur.writingJournalInMilliseconds MongoDB mongo.configServer.flush.averageInMilliseconds flush.averageInMilliseconds MongoDB mongo.configServer.flush.flushesDisk flush.flushesDisk MongoDB mongo.configServer.flush.lastInMilliseconds flush.lastInMilliseconds MongoDB mongo.configServer.flush.totalInMilliseconds flush.totalInMilliseconds MongoDB mongo.configServer.getlasterror.wtimeMillisPerSecond getlasterror.wtimeMillisPerSecond MongoDB mongo.configServer.getlasterror.wtimeoutsPerSecond getlasterror.wtimeoutsPerSecond MongoDB mongo.configServer.globallock.activeClientsReaders globallock.activeClientsReaders MongoDB mongo.configServer.globallock.activeClientsTotal globallock.activeClientsTotal MongoDB mongo.configServer.globallock.activeClientsWriters globallock.activeClientsWriters MongoDB mongo.configServer.globallock.currentQueueReaders globallock.currentQueueReaders MongoDB mongo.configServer.globallock.currentQueueTotal globallock.currentQueueTotal MongoDB mongo.configServer.globallock.currentQueueWriters globallock.currentQueueWriters MongoDB mongo.configServer.globallock.totalTime globallock.totaltime MongoDB mongo.configServer.locks.collectionAcquireExclusive locks.collectionAcquireExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentExclusive locks.collectionAcquireIntentExclusive MongoDB mongo.configServer.locks.collectionAcquireIntentShared locks.collectionAcquireIntentShared MongoDB mongo.configServer.locks.collectionAcquireWaitCountExclusive locks.collectionAcquireWaitCountExclusive MongoDB mongo.configServer.locks.collectionTimeAcquiringMicrosExclusive locks.collectionTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseAcquireExclusive locks.databaseAcquireExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentExclusive locks.databaseAcquireIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireIntentShared locks.databaseAcquireIntentShared MongoDB mongo.configServer.locks.databaseAcquireShared locks.databaseAcquireShared MongoDB mongo.configServer.locks.databaseAcquireWaitExclusive locks.databaseAcquireWaitExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentExclusive locks.databaseAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.databaseAcquireWaitIntentShared locks.databaseAcquireWaitIntentShared MongoDB mongo.configServer.locks.databaseAcquireWaitShared locks.databaseAcquireWaitShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosExclusive locks.databaseTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentExclusive locks.databaseTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosIntentShared locks.databaseTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.databaseTimeAcquiringMicrosShared locks.databaseTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.globalAcquireExclusive locks.globalAcquireExclusive MongoDB mongo.configServer.locks.globalAcquireIntentExclusive locks.globalAcquireIntentExclusive MongoDB mongo.configServer.locks.globalAcquireIntentShared locks.globalAcquireIntentShared MongoDB mongo.configServer.locks.globalAcquireShared locks.globalAcquireShared MongoDB mongo.configServer.locks.globalAcquireWaitExclusive locks.globalAcquireWaitExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentExclusive locks.globalAcquireWaitIntentExclusive MongoDB mongo.configServer.locks.globalAcquireWaitIntentShared locks.globalAcquireWaitIntentShared MongoDB mongo.configServer.locks.globalAcquireWaitShared locks.globalAcquireWaitShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosExclusive locks.globalTimeAcquiringMicrosExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentExclusive locks.globalTimeAcquiringMicrosIntentExclusive MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosIntentShared locks.globalTimeAcquiringMicrosIntentShared MongoDB mongo.configServer.locks.globalTimeAcquiringMicrosShared locks.globalTimeAcquiringMicrosShared MongoDB mongo.configServer.locks.metadataAcquireExclusive locks.metadataAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireExclusive locks.oplogAcquireExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentExclusive locks.oplogAcquireIntentExclusive MongoDB mongo.configServer.locks.oplogAcquireIntentShared locks.oplogAcquireIntentShared MongoDB mongo",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 148.06235,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": "New Relic Integrations Metrics The following table contains the metrics we collect for our <em>infrastructure</em> integrations. Integration Dimensional Metric Name (new) Sample Metric Name (previous) Agent host.cpuIdlePercent cpuIdlePercent Agent host.cpuIoWaitPercent cpuIOWaitPercent Agent host.cpuPercent"
      },
      "id": "603e8a8a64441f69a34e8841"
    },
    {
      "sections": [
        "Default infrastructure monitoring data",
        "Important",
        "Infrastructure events",
        "Supported Linux storage systems",
        "Supported Windows storage systems",
        "Query infrastructure data",
        "Manage data",
        "Add custom attributes",
        "Common Amazon EC2 attributes",
        "awsRegion",
        "awsAvailabilityZone",
        "ec2InstanceType",
        "ec2InstanceId",
        "ec2AmiId",
        "ec2SubnetId",
        "ec2VpcId",
        "Other Amazon EC2 attributes"
      ],
      "title": "Default infrastructure monitoring data ",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Manage your data",
        "Data and instrumentation"
      ],
      "external_id": "01647189a48892103f4dc6abe07ce29d5fc13f0d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data/",
      "published_at": "2021-06-20T22:10:28Z",
      "updated_at": "2021-03-30T08:36:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. New Relic's infrastructure monitoring agent collects and displays data using six primary events, each with associated attributes that represent assorted metrics and metadata. Understanding infrastructure data can help you: Better understand our infrastructure monitoring UI. Manage your infrastructure data. Create better host filter sets. Run better queries of your data. Set up better monitoring solutions using custom attributes. Infrastructure events The following are events reported by default by the infrastructure agent and some infrastructure integrations. The attributes attached to these events are the metadata and metrics used to create our infrastructure UI visualizations. You can also create custom queries and charts of this data. If you're using integrations, see that integration's doc for more on reported data. For common AWS attributes, see AWS data. Select an event name in the following table to see its attributes. Event Description SystemSample SystemSample contains data describing the current overall state of the entire server, including CPU, memory, disk, and network. We take a snapshot of this data every 5 seconds and package it into a SystemSample event, which is then sent to New Relic. This data appears in the Hosts UI page. ProcessSample ProcessSample gathers detailed resource usage information from programs running on a single system. We take a snapshot of this data every 20 seconds for every active process and package it into a ProcessSample event, which is then sent to New Relic. This data appears on the Processes UI page. Important Process metrics are not sent to New Relic by default for accounts created after July 20, 2020. Enable process metrics to get this data into the Infrastructure monitoring UI. StorageSample StorageSample represents a single storage device associated with a server. Each sample gathers descriptive information about the device, the type of file system it uses, and its current usage and capacity. We take a snapshot of this data every 20 seconds for each mounted file system and package it into a StorageSample event, which is then sent to New Relic. This data appears on the Storage UI page. Important If your server uses disks with file systems other than the supported file systems in the following table, StorageSample events will not be generated for those disks. Supported Linux storage systems Supported Linux storage file systems: xfs vxfs btrfs ext ext2 ext3 ext4 hfs Supported Windows storage systems Supported Windows storage file systems: NTFS ReFS (version 1.0.976 and higher) NetworkSample NetworkSample captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. We take a snapshot of this data every 10 seconds for each attached network interface and package it into a NetworkSample event, which is then sent to New Relic. This data appears on the Network UI page. ContainerSample ContainerSample collects the descriptive and state information for each Docker container. It includes the container's ID, name, image, image name, as well metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into a ContainerSample event, which is then sent to New Relic. This data appears on the Containers UI page. For more information, see Docker monitoring. InfrastructureEvent InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, New Relic will produce an InfrastructureEvent that logs that activity. This data appears on the Events UI page. To learn about infrastructure integration data, see the documentation for a specific integration. If an AWS integration is enabled, your infrastructure events may also have AWS attributes attached. Query infrastructure data You can query your infrastructure data to troubleshoot a problem or create a chart, or to understand what data is available. For example, to see what data is attached to ProcessSample, you would run this NRQL query: SELECT * FROM ProcessSample Copy You can also query infrastructure using dimensional metrics. Manage data For tips on managing data ingest and reporting, see Manage infrastructure data. Add custom attributes You can create custom attributes in the infrastructure agent's YAML file. Use this metadata to: Create infrastructure filter sets Populate the Group by menu Annotate your infrastructure data Common Amazon EC2 attributes If you connect your Amazon Elastic Compute Cloud (EC2) account to our infrastructure monitoring, we report data from your Amazon EC2 instances. Amazon EC2-related attributes are common attributes that can be used in any event. These attributes are drawn from the EC2 API. No CloudWatch information is collected. These attributes and their values are subject to change if Amazon changes the data they expose. awsRegion The region (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. awsAvailabilityZone The availability zone (determined by Amazon Web Services) where the AWS server exists. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceType The Amazon Web Services instance type, displayed in AWS-specific codes. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2InstanceId The Amazon Web Services instance's unique identifying number for the server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2AmiId The Amazon Machine Image (AMI) identification number of the image used by Amazon Web Services to bootstrap the Amazon EC2 instance. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2SubnetId The networking sub-net identifier on which the server is connected. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. ec2VpcId The Virtual Private Cloud identifier (if any) for this server. This attribute exists only for customers using New Relic to monitor Amazon EC2 servers. Other Amazon EC2 attributes If Amazon Web Services changes the metadata they make available to New Relic, other attributes and values collected also may be available.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 109.36444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>infrastructure</em> monitoring <em>data</em> ",
        "sections": "Default <em>infrastructure</em> monitoring <em>data</em>",
        "tags": "<em>Manage</em> <em>your</em> <em>data</em>",
        "body": ". <em>Manage</em> <em>your</em> <em>infrastructure</em> <em>data</em>. Create better host <em>filter</em> sets. Run better queries of <em>your</em> <em>data</em>. Set up better monitoring solutions using custom attributes. <em>Infrastructure</em> events The following are events reported by default by the <em>infrastructure</em> agent and some <em>infrastructure</em> integrations"
      },
      "id": "6043edcd28ccbcfa8a2c6086"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.76093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-20T20:45:36Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    },
    {
      "sections": [
        "Infrastructure alerting examples",
        "Examples: Infrastructure pages",
        "Examples: Threshold options",
        "Integrations providers",
        "CPU, disk, load average, memory, swap",
        "Byte size"
      ],
      "title": "Infrastructure alerting examples",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "1ec5f86b745413b2a8d6a5b676ecbe622c674ab1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples/",
      "published_at": "2021-06-20T04:26:54Z",
      "updated_at": "2021-03-16T07:35:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Alert type field in infrastructure monitoring's Settings > Alerts page shows what options you can select to create infrastructure alert conditions. You can also create alert conditions from any infrastructure chart by selecting the ellipses icon and then Create alert. Examples: Infrastructure pages Here are some examples of how to create alert conditions within the context of the Infrastructure monitoring UI page you are currently viewing. To create an alerts condition from any chart, select the ellipses icon and then Create alert. New Relic will automatically select the appropriate Alert type. Example Problem and solution High CPU usage Problem: Your Ops team monitors a filtered set of host clusters in your eastern region and notices that the CPU usage is constantly high. Solution: Use the CPU chart on Infrastructure monitoring's Hosts page to create an alert condition for system metrics. Virtual memory capacity Problem: Your night shift needs to be alerted when virtual memory for a set of background workers reaches an average of 10G for at least two minutes. Solution: Use the Top memory consumers chart on Infrastructure monitoring's Processes page to create an alert condition for process metrics. Limited bandwidth Problem: You want to monitor performance based on the average number of errors received or transmitted. Solution: Use the Top bandwidth chart on Infrastructure monitoring's Network page to create an alert condition for network metrics. I/O read and write operations Problem: You are testing a new set of hosts in your staging environment, and you want to be notified when their read or write capacity rises above your test threshold level. Solution: Use the Top I/O operations chart on Infrastructure monitoring's Storage page to create an alert condition for storage metrics. Host not reporting Problem: You want to be notified when we have stopped receiving data from an infrastructure agent. Solution: From the Hosts, Processes, Network, or Storage pages, create a host not reporting alert condition. Processes not running as expected Problem: You want to be notified if any of the processes on your hosts stop reporting. OR A process you expected to start on a host (such as a new program) is not actually running. Solution: From the Processes page (or from the Hosts, Network, or Storage pages), create a process running alert condition. Examples: Threshold options Use the thresholds dropdown for the selected Alert type to further define how you want to be alerted. Here are some examples of the options available. Integrations providers With infrastructure integrations, you can create an alert condition from your Integrations page. Depending on the type of provider selected (CloudFront, DynamoDB, EBS, etc.), options will vary from the Define thresholds dropdown; for example, bytes, errors, requests, CPU, connections, memory, records, latency, etc. CPU, disk, load average, memory, swap The System metrics thresholds dropdown allows you to select various criteria for CPU, disk, load average, memory, and swap metrics. Byte size The Network metrics thresholds provide flexibility with your business needs. Depending on the size of your network, you can easily set the threshold in bytes, KB, MB, GB, or TB.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.2703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Infrastructure</em> <em>alerting</em> examples",
        "sections": "<em>Infrastructure</em> <em>alerting</em> examples",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "The <em>Alert</em> type field in <em>infrastructure</em> monitoring&#x27;s Settings &gt; <em>Alerts</em> page shows what options you can select to create <em>infrastructure</em> <em>alert</em> <em>conditions</em>. You can also create <em>alert</em> <em>conditions</em> from any <em>infrastructure</em> chart by selecting the ellipses icon and then Create <em>alert</em>. Examples: <em>Infrastructure</em>"
      },
      "id": "603eb52a28ccbc9027eba7bb"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerting-examples": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.76093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-20T04:25:57Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-20T20:45:36Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    }
  ],
  "/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/infrastructure-alerts-add-edit-or-view-host-alert-information": [
    {
      "sections": [
        "REST API calls for infrastructure alerts",
        "Requirements",
        "Tip",
        "Using infrastructure API calls",
        "GET infrastructure conditions",
        "GET a list of infrastructure conditions",
        "Example GET a list of conditions",
        "GET a specific infrastructure condition",
        "Example GET a specific condition",
        "Create (POST) an infrastructure condition",
        "Important",
        "Update (PUT) an infrastructure condition",
        "Example update (PUT) a condition",
        "Remove (DELETE) an infrastructure condition",
        "Types of conditions",
        "Process running conditions API data",
        "Example condition types",
        "Metric conditions API data",
        "Example",
        "Host not reporting condition",
        "Definitions",
        "value",
        "duration_minutes",
        "time_function"
      ],
      "title": "REST API calls for infrastructure alerts",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "c35aa43cdb6645473d02886a49d6f9aeb37e577f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/rest-api-calls-new-relic-infrastructure-alerts/",
      "published_at": "2021-06-20T04:28:07Z",
      "updated_at": "2021-04-06T06:04:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the infrastructure REST API to add, update, delete, and list alerting conditions. You can also manage individual alerting conditions using the infrastructure monitoring UI. REST API calls for infrastructure alerts are not available in the API Explorer. Why use the API Examples Consistency Define the same set of conditions for every cluster without having to set up identical conditions in the Infrastructure monitoring UI each time. Manage multiple conditions quickly, without having to update them one by one using the UI. Flexibility Create conditions for an arbitrary group of hosts. Disable or delete conditions for hosts taken offline anytime. Create a condition with exclusionary filtering (for instance, environment NOT LIKE x). For more on this, see this post on exclusion filtering. For AWS Cloud integrations, select attributes that haven't been sent up by AWS yet. Create compound alert conditions by using the where_clause, which allows you to specify the limits on a secondary or tertiary metric. Exceed the 500-facet limitation on NRQL alert conditions. Reliability Audit when a condition was last updated. Requirements In order to use the Infrastructure REST API, you need: An API key The alerting condition's related policy_id from New Relic, available via GET list of conditions or via the Alerts REST API The condition id, available via GET list of conditions, or via the condition's URL in the Infrastructure monitoring UI Tip If your account hosts data in the EU data center, make sure you are using the proper API endpoints for EU region accounts. Using infrastructure API calls Here are some basic cURL commands and their responses for Infrastructure alert conditions. Depending on the type of condition, the DATA information you provide in the call will vary for POST (add) and PUT (update) calls. Definitions of each attribute used in the data blocks can be found in the Definitions section. GET infrastructure conditions You can either GET a list of infrastructure conditions or GET a specific infrastructure condition. Here are a few tips for listing infrastructure conditions. For pagination, use limit (records per page) and offset (how many records to skip) parameters. Default is 50 records per page, and offset starts at 0 (skip no records). To scope the results to a specific policy, use policy_id. Tip If you want to use the GET response as a template for your PUT or POST input, be sure to remove the created_at_epoch_millis, updated_at_epoch_millis and id information. GET a list of infrastructure conditions curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111\" Copy Example GET a list of conditions Response showing 2 of the 3 conditions for the example policy (formatted for readability and truncated): HTTP/1.1 200 OK Content-Length: 622 Content-Type: application/json { \"data\":[ { \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(`hostname` LIKE '%cassandra%')\", \"id\":13890, \"created_at_epoch_millis\":1490996713872, \"updated_at_epoch_millis\":1490996713872, \"policy_id\":111111, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(`commandName` = 'java')\" }, { \"created_at_epoch_millis\": 1501704525462, \"critical_threshold\": { \"duration_minutes\": 5 }, \"enabled\": true, \"filter\": { \"and\": [ { \"like\": { \"fullHostname\": \"Production_1\" } } ] }, \"id\": 448036, \"name\": \"PROD - Host Machine's Agent Not Responding ....\", \"policy_id\": 98485, \"type\": \"infra_host_not_reporting\", \"updated_at_epoch_millis\": 1504879191220 } . . . ], \"meta\":{ \"limit\":50, \"offset\":0, \"total\":3 }, \"links\":{} } Copy To get a list of the 10 Infrastructure conditions beyond the 50 limit: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions?policy_id=111111&offset=50&list=10\" Copy GET a specific infrastructure condition To get information about a single Infrastructure condition: curl -v -X GET --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition-id\" Copy Example GET a specific condition Response (formatted for readability): HTTP/1.1 200 OK Content-Length: 246 Content-Type: application/json { \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"demo condition\", \"enabled\":false, \"id\":13887, \"created_at_epoch_millis\":1490981583580, \"updated_at_epoch_millis\":1490981583580, \"policy_id\":23635, \"critical_threshold\":{ \"duration_minutes\":100 } } } Copy Create (POST) an infrastructure condition Important Do not include an \"id\": when adding a new condition (POST). It will be generated when the condition is created. To add an infrastructure condition, use this basic cURL command: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are adding: Process running conditions API data Metric conditions API data Host not reporting conditions API data Update (PUT) an infrastructure condition You only need to include the fields that need to be changed when updating an infrastructure condition. The API keeps the existing values for any missing fields. Important If you want to change the condition type, do not use PUT. Instead, delete the existing condition, then add (POST) a new condition with the new condition type and all fields. To update an infrastructure condition, use this basic cURL command. To indicate which condition is to be updated, be sure to include the \"id\": . Example update (PUT) a condition curl -X PUT 'https://infra-api.newrelic.com/v2/alerts/conditions/condition-id' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{\"data\":{DATA object details}}' Copy Include details in the DATA object (-d \\ section) for the type of infrastructure condition you are updating: Process running conditions API data Metric conditions API data Host not reporting conditions API data Remove (DELETE) an infrastructure condition To delete an infrastructure condition, use this basic cURL command: curl -v -X DELETE --header \"Api-Key: $API_KEY\" \"https://infra-api.newrelic.com/v2/alerts/conditions/condition_id\" Copy Types of conditions Process running conditions API data A process running condition alerts you when the number of processes is above, below, or equal to the threshold you define. To add (POST) or update (PUT) a process running condition, use your API key, and refer to the definitions to customize your values in the API call. Example condition types For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_process_running\", \"name\":\"Java is running\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"comparison\":\"equal\", \"critical_threshold\":{ \"value\":0, \"duration_minutes\":6 }, \"process_where_clause\":\"(commandName = '\\''java'\\'')\" } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause and process_where_clause Metric conditions API data A metric condition alerts you when the metric of your choice is above, below, or equal to the threshold you define. This includes: System metrics Process metrics Network metrics Storage metrics Cloud integration metrics To add (POST) or update (PUT) a metric condition, use your API key, and refer to the definitions to customize your values in the API call. If you are adding or updating a cloud integration alert condition: For the event_type field, enter the event type generated by your selected cloud integration service (for example, ComputeSample for the AWS EC2 integration). If you are setting up an alert condition on a cloud integration service that requires a provider value (for example, AWS RDS uses DatastoreSample with a provider value of RdsDbInstance or RdsDbCluster), you will need to add the \"integration_provider\" field and use the value that is appropriate for the service your alert condition is targeting (for example, \"integration_provider\":\"RdsDbInstance\"). For the select_value field, build the metric name by using the following syntax, where provider is a standard prefix string: provider.metric.aggregation_type Copy metric: Use the metric name as described in the New Relic documentation for your integration. aggregation_type: Use Sum, Average, Minimum, or Maximum. Refer to the original documentation by the integration's cloud provider to see which statistic aggregations are available for each metric. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_metric\", \"name\":\"Disk Space Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"event_type\":\"StorageSample\", \"select_value\":\"diskFreePercent\", \"comparison\":\"below\", \"critical_threshold\":{ \"value\":10, \"duration_minutes\":1, \"time_function\":\"any\" }, \"warning_threshold\":{ \"value\":30, \"duration_minutes\":2, \"time_function\":\"any\" } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Host not reporting condition A host not reporting condition alerts you when a host stops reporting. To add (POST) or update (PUT) a host not reporting condition, use your API key, and refer to the definitions to customize your values in the API call. Example For example: curl -X POST 'https://infra-api.newrelic.com/v2/alerts/conditions' -H 'Api-Key:$API_KEY' -i -H 'Content-Type: application/json' -d '{ \"data\":{ \"type\":\"infra_host_not_reporting\", \"name\":\"Cassandra Host Reporting Condition\", \"enabled\":true, \"where_clause\":\"(hostname LIKE '\\''%cassandra%'\\'')\", \"policy_id\":policy_id, \"critical_threshold\":{ \"duration_minutes\":12 } } }' Copy Important Note the extra single quotes escaping the single quote around the where_clause Definitions When formatting your cURL commands, use these values as needed. These are listed in alphabetical order, not the order they appear in your API calls. Field Definition comparison (enum) Condition type: infra_metric, infra_process_running The value used to define the threshold; for example, \"[\"above\", \"below\", \"equal\"]. critical_threshold and warning_threshold Condition type: all This object identifies the threshold value before opening a violation. The critical_threshold is required. The warning_threshold is optional and may only be used with infra_metric conditions. The keys of this object depend on the condition type. Condition type: infra_metric format: \"critical_threshold\":{ \"value\":<number>, \"duration_minutes\":<integer>, \"time_function\":\"any\" or \"all\" }, Copy Condition type: infra_process_running format: \"critical_threshold\":{ \"value\":<integer>, \"duration_minutes\":<integer>, }, Copy Condition type: infra_host_not_reporting format: \"critical_threshold\":{ \"duration_minutes\":<integer>, }, Copy value The numeric value that must be breached for the condition to open a violation duration_minutes The number of minutes the value must be passed or met for the condition to open a violation time_function Indicates if the condition needs to be sustained for a certain period of time to create a violation, or if it only needs to break the threshold once within a certain period of time. If you're setting up a for at least x minutes threshold, use all; for an at least once in x minutes threshold, use any. enabled (boolean) Condition type: all Whether the condition is turned on or off; true or false. event_type (string) Condition type: infra_metric The metric event; for example, system metrics, process metrics, storage metrics, or network metrics. This automatically populates for infrastructure integrations; for example, StorageSample or SystemSample. filter (string) Condition type: all If the condition was made in the UI, filter appears instead of where_clause; for example: {and: [{is: {ec2InstanceType: \"m3.medium\"}}]} Copy Recommendation: Use where_clause when creating a new condition. id (integer) Condition type: all The condition ID located in the URL. GET: This value appears in the GET response. PUT: Include this value in the DATA section. POST: Do not include this in the DATA section. DELETE: Include this value in the -X DELETE call. integration_provider (string) Condition type: infra_metric For alerts on integrations, use integration_provider instead of event_type. To see valid values: From the New Relic documentation for your cloud service, check the Find and use data section. Example: In the AWS RDS monitoring integration documentation, you can see that the DatastoreSample event type can be used with an integration_provider value of either RdsDbInstance for DB instances, or RdsDbCluster for Aurora DB clusters. name (string) Condition type: all The infrastructure alerting condition's name; for example: \"[test] process running\" Copy policy_id (integer) Condition type: all The unique ID for the alert policy's account ID associated with the condition; for example, 1234567890. This is not the policy's global ID. process_where_clause (string) Condition type: infra_process_running Any filters applied to processes, specifically in process running alert conditions. This parameter is mandatory for those types of alert conditions. For example: \"commandName = '\\''java'\\''\" Copy runbook_url (string) Condition type: all The runbook URL to display in notifications. select_value (string) Condition type: infra_metric The attribute name to identify the metric being targeted; for example, \"cpuPercent\", \"diskFreePercent\", \"memoryResidentSizeBytes\", or \"memoryFreeBytes/memoryTotalBytes*100\". This automatically populates for Infrastructure Integrations; for example, diskFreePercent. type (enum) Condition type: all The type of infrastructure alert condition: \"infra_process_running\", \"infra_metric\", or \"infra_host_not_reporting\". violation_close_timer (integer) Condition type: all The Violation time limit setting, expressed as hours. Possible values are 0, 1, 2, 4, 8,12, 24, 48, 72. This determines how much time will pass before a violation is automatically closed. Setting the time limit to 0 prevents a violation from being force-closed. For new conditions, if a value is not provided, the following default values are used: Host Not Responding (HNR) conditions: 0 (disabled) All other conditions: 24 When updating existing conditions, if a value is provided, it overrides the existing value, but does not affect already opened violations. where_clause (string) Condition type: all If applicable, this identifies any infrastructure host filters used; for example: \"(`hostname` LIKE '\\''%cassandra%'\\'')\", Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.76093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "sections": "REST API calls for <em>infrastructure</em> <em>alerts</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use the <em>infrastructure</em> REST API to add, update, delete, and list alerting <em>conditions</em>. You can also manage individual alerting <em>conditions</em> using the <em>infrastructure</em> monitoring UI. REST API calls for <em>infrastructure</em> <em>alerts</em> are not available in the API Explorer. Why use the API Examples Consistency"
      },
      "id": "6043fa6c196a678ae2960f31"
    },
    {
      "sections": [
        "Alert on infrastructure processes",
        "Important",
        "Examples",
        "Ensure enough processes are running to satisfy load",
        "Ensure that critical services run constantly",
        "Monitor startup for critical processes that require special attention",
        "Make sure a job doesn't take too long",
        "Validate that services started successfully",
        "Watch for runaway processes or configuration problems",
        "Create an infrastructure process running condition"
      ],
      "title": "Alert on infrastructure processes",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "5fcbe11b9beb16723ff2521fca981f19a4c716ce",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/infrastructure-alert-conditions/alert-infrastructure-processes/",
      "published_at": "2021-06-20T04:25:57Z",
      "updated_at": "2021-03-16T08:35:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic infrastructure's Process running alert condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start on a host (such as a new program) is not actually running This feature's flexibility allows you to easily filter what hosts and processes to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Important By default, the infrastructure agent doesn't send data about the operating system's processes. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Examples By applying filters to the hosts and processes that are important to your business, you can define alerting thresholds to decide when violations open and New Relic sends an email notification to you depending on the policy's incident preferences. These examples illustrate how to use infrastructure monitoring's Process running condition to monitor your processes. Ensure enough processes are running to satisfy load Problem: Some load balancers and application servers work by running many worker processes in parallel. Here, for example, you may want an alert violation when fewer than eight processes are running for a service like gunicorn. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Ensure that critical services run constantly Problem: A service, such as a database or application server, is expected to be running constantly on certain hosts, and you need to know when it has stopped. Solution: Use the No processes are running (default) threshold. Monitor startup for critical processes that require special attention Problem: You have processes requiring special attention due to security or potential performance impact. Solution: Use the At least one process is running threshold with condition filters set to a username and specific executable so that New Relic can open a violation when the process is running. Make sure a job doesn't take too long Problem: You have a job that runs periodically, and you want to open a violation when it has been running longer than an expected number of minutes. Solution: Use the At least one process is running threshold. Validate that services started successfully Problem: When provisioning new hosts, you want to open a violation if a required service fails to successfully start up. Solution: Use the No processes are running (default) threshold. Watch for runaway processes or configuration problems Problem: Sometimes problems with processes can be solved with changes to your configuration. For example, you have more than one Chef process running, and you may need to address an issue with how that service is configured. Solution: Depending on the situation, use any of these Process running thresholds options as needed: More than the defined number of processes are running Exactly the defined number of processes are running Fewer than the defined number of processes are running Create an infrastructure process running condition To define the Process running alert criteria: Follow standard procedures to create an infrastructure alert condition. Select Process running as the Alert type. Filter what hosts and processes you want the alert condition to apply to. Define the Critical threshold for triggering the alert notification: minimum 1 minute, default 5 minutes, maximum 60 minutes. If you create the alert condition directly with infrastructure monitoring, New Relic will send an email notification when the defined threshold for the alert condition passes depending on the policy's incident preferences. Your alert policy defines which personnel or teams and which notification channels we use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alert</em> on <em>infrastructure</em> processes",
        "sections": "<em>Alert</em> on <em>infrastructure</em> processes",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use New Relic <em>infrastructure</em>&#x27;s Process running <em>alert</em> condition to be notified when a set of processes on your filtered hosts stop running for a configurable number of minutes. This is useful, for example, when: Any of the processes on the hosts stop reporting A process you expected to start"
      },
      "id": "603eb49128ccbca939eba74a"
    },
    {
      "sections": [
        "Create infrastructure \"host not reporting\" condition",
        "Features",
        "Create \"host not reporting\" condition",
        "Investigate the problem",
        "Intentional outages"
      ],
      "title": "Create infrastructure \"host not reporting\" condition",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure alerts",
        "Infrastructure alert conditions"
      ],
      "external_id": "0a74e7e65e3eeb5268eac310c11802ca2e78a614",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-alerts/infrastructure-alert-conditions/create-infrastructure-host-not-reporting-condition/",
      "published_at": "2021-06-20T20:45:36Z",
      "updated_at": "2021-03-16T08:30:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use Infrastructure monitoring's Host not reporting condition to notify you when we've stopped receiving data from an infrastructure agent. This feature allows you to dynamically alert on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of alerts notifications. Features You can define conditions based on the sets of hosts most important to you, and configure thresholds appropriate for each filter set. The Host not reporting event triggers when data from the infrastructure agent doesn't reach our collector within the time frame you specify. This feature's flexibility allows you to easily customize what to monitor and when to notify selected individuals or teams. In addition, the email notification includes links to help you quickly troubleshoot the situation. Host not reporting condition Features What to monitor You can use filter sets to select which hosts you want to be monitored with the alert condition. The condition will also automatically apply to any hosts you add in the future that match these filters. How to notify Conditions are contained in policies. You can select an existing policy or create a new policy with email notifications from the Infrastructure monitoring UI. If you want to create a new policy with other types of notification channels, use the UI. When to notify Email addresses (identified in the policy) will be notified automatically about threshold violations for any host matching the filters you have applied, depending on the policy's incident preferences. Where to troubleshoot The link at the top of the email notification will take you to the infrastructure Events page centered on the time when the host disconnected. Additional links in the email will take you to additional detail. Create \"host not reporting\" condition To define the Host not reporting condition criteria: Follow standard procedures to create an infrastructure condition. Select Host not reporting as the Alert type. Define the Critical threshold for triggering the notification: minimum 5 minutes, maximum 60 minutes. Enable 'Don't trigger alerts for hosts that perform a clean shutdown' option, if you want to prevent false alerts when you have hosts set to shut down via command line. Currently this feature is supported on all Windows systems and Linux systems using systemd. Depending on the policy's incident preferences, it will define which notification channels to use when the defined Critical threshold for the condition passes. To avoid \"false positives,\" the host must stop reporting for the entire time period before a violation is opened. Example: You create a condition to open a violation when any of the filtered set of hosts stop reporting data for seven minutes. If any host stops reporting for five minutes, then resumes reporting, the condition does not open a violation. If any host stops reporting for seven minutes, even if the others are fine, the condition does open a violation. Investigate the problem To further investigate why a host is not reporting data: Review the details in the email notification. Use the link from the email notification to monitor ongoing changes in your environment from Infrastructure monitoring's Events page. For example, use the Events page to help determine if a host disconnected right after a root user made a configuration change to the host. Optional: Use the email notification's Acknowledge link to verify you are aware of and taking ownership of the alerting incident. Use the email links to examine additional details in the Incident details page. Intentional outages We can distinguish between unexpected situations and planned situations with the option Don't trigger alerts for hosts that perform a clean shutdown. Use this option for situations such as: Host has been taken offline intentionally. Host has planned downtime for maintenance. Host has been shut down or decommissioned. Autoscaling hosts or shutting down instances in a cloud console. We rely on Linux and Windows shutdown signals to flag a clean shutdown. We've confirmed that these scenarios are detected by the agent: AWS Auto-scaling event with EC2 instances that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) User-initiated shutdown of Windows systems User-initiated shutdown of Linux systems that use systemd (Amazon Linux, CentOs/RedHat 7 and newer, Ubuntu 16 and newer, Suse 12 and newer, Debian 9 and newer) We know that these scenarios are not detected by the agent: User-initiated shutdown of Linux systems that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other modern Linux systems that still use Upstart or SysV init systems. AWS Auto-scaling event with EC2 instances that don't use systemd (CentOs/RedHat 6 and earlier, Ubuntu 14, Debian 8). This includes other more modern Linux systems that still use Upstart or SysV init systems.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.27686,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "sections": "Create <em>infrastructure</em> &quot;host not reporting&quot; <em>condition</em>",
        "tags": "<em>Infrastructure</em> <em>alert</em> <em>conditions</em>",
        "body": "Use <em>Infrastructure</em> monitoring&#x27;s Host not reporting condition to notify you when we&#x27;ve stopped receiving data from an <em>infrastructure</em> agent. This feature allows you to dynamically <em>alert</em> on groups of hosts, configure the time window from five to 60 minutes, and take full advantage of <em>alerts</em>"
      },
      "id": "603ea06c196a67cd47a83dc1"
    }
  ]
}